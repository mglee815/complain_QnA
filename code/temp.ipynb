{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   제목      1000000 non-null  object\n",
      " 1   본문      999751 non-null   object\n",
      " 2   민원발생지   999972 non-null   object\n",
      " 3   접수기관    1000000 non-null  object\n",
      " 4   token   1000000 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 38.1+ MB\n",
      "None\n",
      "train len : 900000, test len : 100000\n",
      "get bertmodel and vocab\n",
      "using cached model. /home/mglee/VSCODE/git_folder/complain_department_classification/code/.cache/kobert_v1.zip\n",
      "using cached model. /home/mglee/VSCODE/git_folder/complain_department_classification/code/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "data setting\n",
      "using cached model. /home/mglee/VSCODE/git_folder/complain_department_classification/code/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "Train Start\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145c0c2065ba4273ac866eac6dd49f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 / 225000 loss 5.657588005065918 train acc 0.0\n",
      "epoch 1 batch id 101 / 225000 loss 5.795995712280273 train acc 0.0\n",
      "epoch 1 batch id 201 / 225000 loss 5.622037410736084 train acc 0.0012437810945273632\n",
      "epoch 1 batch id 301 / 225000 loss 5.938326358795166 train acc 0.0008305647840531562\n",
      "epoch 1 batch id 401 / 225000 loss 5.917154312133789 train acc 0.0006234413965087282\n",
      "epoch 1 batch id 501 / 225000 loss 5.962574005126953 train acc 0.0014970059880239522\n",
      "epoch 1 batch id 601 / 225000 loss 6.045806884765625 train acc 0.0016638935108153079\n",
      "epoch 1 batch id 701 / 225000 loss 5.707292079925537 train acc 0.001783166904422254\n",
      "epoch 1 batch id 801 / 225000 loss 5.83020544052124 train acc 0.0024968789013732834\n",
      "epoch 1 batch id 901 / 225000 loss 5.764742851257324 train acc 0.00388457269700333\n",
      "epoch 1 batch id 1001 / 225000 loss 5.72004508972168 train acc 0.004245754245754246\n",
      "epoch 1 batch id 1101 / 225000 loss 5.554431915283203 train acc 0.004087193460490463\n",
      "epoch 1 batch id 1201 / 225000 loss 5.4347357749938965 train acc 0.005412156536219817\n",
      "epoch 1 batch id 1301 / 225000 loss 5.846456050872803 train acc 0.00749423520368947\n",
      "epoch 1 batch id 1401 / 225000 loss 5.942523956298828 train acc 0.009100642398286937\n",
      "epoch 1 batch id 1501 / 225000 loss 5.639715194702148 train acc 0.011159227181878747\n",
      "epoch 1 batch id 1601 / 225000 loss 5.1678361892700195 train acc 0.013429106808244847\n",
      "epoch 1 batch id 1701 / 225000 loss 5.474166393280029 train acc 0.016901822457378014\n",
      "epoch 1 batch id 1801 / 225000 loss 5.862668991088867 train acc 0.020127706829539144\n",
      "epoch 1 batch id 1901 / 225000 loss 5.450639724731445 train acc 0.02327722251446607\n",
      "epoch 1 batch id 2001 / 225000 loss 5.1327104568481445 train acc 0.026486756621689155\n",
      "epoch 1 batch id 2101 / 225000 loss 5.287726402282715 train acc 0.031175630652070442\n",
      "epoch 1 batch id 2201 / 225000 loss 5.267292022705078 train acc 0.034756928668786914\n",
      "epoch 1 batch id 2301 / 225000 loss 5.46064567565918 train acc 0.039330725771403736\n",
      "epoch 1 batch id 2401 / 225000 loss 5.3882951736450195 train acc 0.044252394835485216\n",
      "epoch 1 batch id 2501 / 225000 loss 5.240353107452393 train acc 0.04818072770891643\n",
      "epoch 1 batch id 2601 / 225000 loss 5.516830921173096 train acc 0.05334486735870819\n",
      "epoch 1 batch id 2701 / 225000 loss 5.62850284576416 train acc 0.05766382821177342\n",
      "epoch 1 batch id 2801 / 225000 loss 4.933370590209961 train acc 0.06104962513388076\n",
      "epoch 1 batch id 2901 / 225000 loss 5.454165458679199 train acc 0.06428817649086521\n",
      "epoch 1 batch id 3001 / 225000 loss 5.271100044250488 train acc 0.06872709096967677\n",
      "epoch 1 batch id 3101 / 225000 loss 5.18634557723999 train acc 0.07215414382457272\n",
      "epoch 1 batch id 3201 / 225000 loss 5.235790729522705 train acc 0.07583567635114027\n",
      "epoch 1 batch id 3301 / 225000 loss 5.018314361572266 train acc 0.07883974553165707\n",
      "epoch 1 batch id 3401 / 225000 loss 5.449478626251221 train acc 0.08152014113496031\n",
      "epoch 1 batch id 3501 / 225000 loss 5.280072212219238 train acc 0.08540417023707512\n",
      "epoch 1 batch id 3601 / 225000 loss 5.526315689086914 train acc 0.08782282699250209\n",
      "epoch 1 batch id 3701 / 225000 loss 4.889265060424805 train acc 0.09058362604701432\n",
      "epoch 1 batch id 3801 / 225000 loss 4.849212169647217 train acc 0.0928702972901868\n",
      "epoch 1 batch id 3901 / 225000 loss 5.015707492828369 train acc 0.0959369392463471\n",
      "epoch 1 batch id 4001 / 225000 loss 4.508368968963623 train acc 0.0985378655336166\n",
      "epoch 1 batch id 4101 / 225000 loss 5.485183238983154 train acc 0.10046330163374786\n",
      "epoch 1 batch id 4201 / 225000 loss 4.692546844482422 train acc 0.10247560104736968\n",
      "epoch 1 batch id 4301 / 225000 loss 5.364796161651611 train acc 0.10433620088351546\n",
      "epoch 1 batch id 4401 / 225000 loss 3.9908297061920166 train acc 0.10673710520336287\n",
      "epoch 1 batch id 4501 / 225000 loss 4.809500694274902 train acc 0.10880915352143967\n",
      "epoch 1 batch id 4601 / 225000 loss 5.582087516784668 train acc 0.11111714844599001\n",
      "epoch 1 batch id 4701 / 225000 loss 4.851535797119141 train acc 0.11263560944479897\n",
      "epoch 1 batch id 4801 / 225000 loss 5.829901695251465 train acc 0.11461153926265362\n",
      "epoch 1 batch id 4901 / 225000 loss 5.265925407409668 train acc 0.11569067537237299\n",
      "epoch 1 batch id 5001 / 225000 loss 4.9192986488342285 train acc 0.11842631473705259\n",
      "epoch 1 batch id 5101 / 225000 loss 5.462367057800293 train acc 0.12051558517937659\n",
      "epoch 1 batch id 5201 / 225000 loss 5.106099605560303 train acc 0.12281292059219381\n",
      "epoch 1 batch id 5301 / 225000 loss 3.2701170444488525 train acc 0.12474061497830598\n",
      "epoch 1 batch id 5401 / 225000 loss 4.976648807525635 train acc 0.1264580633216071\n",
      "epoch 1 batch id 5501 / 225000 loss 4.74910306930542 train acc 0.12824940919832759\n",
      "epoch 1 batch id 5601 / 225000 loss 4.037938117980957 train acc 0.12975361542581682\n",
      "epoch 1 batch id 5701 / 225000 loss 4.127056121826172 train acc 0.13146816348009122\n",
      "epoch 1 batch id 5801 / 225000 loss 5.664512634277344 train acc 0.13325288743320118\n",
      "epoch 1 batch id 5901 / 225000 loss 3.2646830081939697 train acc 0.13468056261650568\n",
      "epoch 1 batch id 6001 / 225000 loss 3.6933741569519043 train acc 0.13660223296117313\n",
      "epoch 1 batch id 6101 / 225000 loss 4.5231804847717285 train acc 0.13878872316013768\n",
      "epoch 1 batch id 6201 / 225000 loss 4.94960880279541 train acc 0.1398161586840832\n",
      "epoch 1 batch id 6301 / 225000 loss 3.7727391719818115 train acc 0.14045389620695128\n",
      "epoch 1 batch id 6401 / 225000 loss 4.349826812744141 train acc 0.1416966099047024\n",
      "epoch 1 batch id 6501 / 225000 loss 3.186666965484619 train acc 0.14278572527303493\n",
      "epoch 1 batch id 6601 / 225000 loss 4.3353753089904785 train acc 0.14433419178912285\n",
      "epoch 1 batch id 6701 / 225000 loss 3.131502389907837 train acc 0.14509028503208476\n",
      "epoch 1 batch id 6801 / 225000 loss 4.563808917999268 train acc 0.14644905161005733\n",
      "epoch 1 batch id 6901 / 225000 loss 4.629976272583008 train acc 0.1476959860889726\n",
      "epoch 1 batch id 7001 / 225000 loss 3.0251479148864746 train acc 0.14937151835452078\n",
      "epoch 1 batch id 7101 / 225000 loss 4.1270270347595215 train acc 0.15107027179270524\n",
      "epoch 1 batch id 7201 / 225000 loss 3.757739543914795 train acc 0.15227051798361338\n",
      "epoch 1 batch id 7301 / 225000 loss 5.562964916229248 train acc 0.15391727160662924\n",
      "epoch 1 batch id 7401 / 225000 loss 4.4273481369018555 train acc 0.15511417376030265\n",
      "epoch 1 batch id 7501 / 225000 loss 3.805548906326294 train acc 0.15647913611518463\n",
      "epoch 1 batch id 7601 / 225000 loss 3.0382471084594727 train acc 0.15770951190632812\n",
      "epoch 1 batch id 7701 / 225000 loss 2.5925164222717285 train acc 0.15920010388261266\n",
      "epoch 1 batch id 7801 / 225000 loss 5.268202781677246 train acc 0.16029996154339188\n",
      "epoch 1 batch id 7901 / 225000 loss 4.0941972732543945 train acc 0.1617200354385521\n",
      "epoch 1 batch id 8001 / 225000 loss 2.1864371299743652 train acc 0.1630108736407949\n",
      "epoch 1 batch id 8101 / 225000 loss 4.346348762512207 train acc 0.1642389828416245\n",
      "epoch 1 batch id 8201 / 225000 loss 2.4562058448791504 train acc 0.16507133276429703\n",
      "epoch 1 batch id 8301 / 225000 loss 5.249184608459473 train acc 0.16630526442597277\n",
      "epoch 1 batch id 8401 / 225000 loss 5.584158897399902 train acc 0.1677478871562909\n",
      "epoch 1 batch id 8501 / 225000 loss 5.3469390869140625 train acc 0.16906834490059994\n",
      "epoch 1 batch id 8601 / 225000 loss 5.066574573516846 train acc 0.16977677014300663\n",
      "epoch 1 batch id 8701 / 225000 loss 3.7442545890808105 train acc 0.17092862889323066\n",
      "epoch 1 batch id 8801 / 225000 loss 3.5388216972351074 train acc 0.1727644585842518\n",
      "epoch 1 batch id 8901 / 225000 loss 1.6693553924560547 train acc 0.17413773733288396\n",
      "epoch 1 batch id 9001 / 225000 loss 3.469541072845459 train acc 0.1752860793245195\n",
      "epoch 1 batch id 9101 / 225000 loss 4.207034111022949 train acc 0.17640918580375783\n",
      "epoch 1 batch id 9201 / 225000 loss 2.820091724395752 train acc 0.17788827301380286\n",
      "epoch 1 batch id 9301 / 225000 loss 2.619274139404297 train acc 0.17914740350499947\n",
      "epoch 1 batch id 9401 / 225000 loss 3.554018974304199 train acc 0.18037974683544303\n",
      "epoch 1 batch id 9501 / 225000 loss 3.7311882972717285 train acc 0.1822439743184928\n",
      "epoch 1 batch id 9601 / 225000 loss 4.880614280700684 train acc 0.18352254973440266\n",
      "epoch 1 batch id 9701 / 225000 loss 4.699547290802002 train acc 0.1851355530357695\n",
      "epoch 1 batch id 9801 / 225000 loss 3.7953624725341797 train acc 0.18658810325476993\n",
      "epoch 1 batch id 9901 / 225000 loss 4.395512104034424 train acc 0.18836481163518837\n",
      "epoch 1 batch id 10001 / 225000 loss 5.4541215896606445 train acc 0.18938106189381063\n",
      "epoch 1 batch id 10101 / 225000 loss 3.6446022987365723 train acc 0.190995940995941\n",
      "epoch 1 batch id 10201 / 225000 loss 4.323583126068115 train acc 0.19226056268993236\n",
      "epoch 1 batch id 10301 / 225000 loss 1.7831392288208008 train acc 0.19381613435588776\n",
      "epoch 1 batch id 10401 / 225000 loss 4.643540382385254 train acc 0.19543793865974426\n",
      "epoch 1 batch id 10501 / 225000 loss 2.654081106185913 train acc 0.19681458908675364\n",
      "epoch 1 batch id 10601 / 225000 loss 2.713473081588745 train acc 0.19802377134232618\n",
      "epoch 1 batch id 10701 / 225000 loss 2.5080204010009766 train acc 0.19911690496215306\n",
      "epoch 1 batch id 10801 / 225000 loss 2.6382811069488525 train acc 0.19977316915100454\n",
      "epoch 1 batch id 10901 / 225000 loss 3.482783555984497 train acc 0.20099073479497293\n",
      "epoch 1 batch id 11001 / 225000 loss 1.9672306776046753 train acc 0.20232251613489682\n",
      "epoch 1 batch id 11101 / 225000 loss 5.617467880249023 train acc 0.20347266012070986\n",
      "epoch 1 batch id 11201 / 225000 loss 4.539124488830566 train acc 0.20500401749843764\n",
      "epoch 1 batch id 11301 / 225000 loss 2.601630449295044 train acc 0.2063534200513229\n",
      "epoch 1 batch id 11401 / 225000 loss 1.305545687675476 train acc 0.20783264625910008\n",
      "epoch 1 batch id 11501 / 225000 loss 4.0420241355896 train acc 0.20950352143291887\n",
      "epoch 1 batch id 11601 / 225000 loss 3.8088784217834473 train acc 0.2110378415653823\n",
      "epoch 1 batch id 11701 / 225000 loss 2.4887664318084717 train acc 0.21269549611144348\n",
      "epoch 1 batch id 11801 / 225000 loss 1.6468039751052856 train acc 0.2142191339716973\n",
      "epoch 1 batch id 11901 / 225000 loss 4.844195365905762 train acc 0.21544408032938409\n",
      "epoch 1 batch id 12001 / 225000 loss 4.124122619628906 train acc 0.21666944421298226\n",
      "epoch 1 batch id 12101 / 225000 loss 4.047745704650879 train acc 0.2179365341707297\n",
      "epoch 1 batch id 12201 / 225000 loss 2.3220160007476807 train acc 0.2195516760921236\n",
      "epoch 1 batch id 12301 / 225000 loss 2.4947760105133057 train acc 0.22071376310869034\n",
      "epoch 1 batch id 12401 / 225000 loss 2.94287109375 train acc 0.22181678896863155\n",
      "epoch 1 batch id 12501 / 225000 loss 4.824387550354004 train acc 0.22308215342772578\n",
      "epoch 1 batch id 12601 / 225000 loss 3.890153646469116 train acc 0.22438695341639553\n",
      "epoch 1 batch id 12701 / 225000 loss 2.287017822265625 train acc 0.22555310605464138\n",
      "epoch 1 batch id 12801 / 225000 loss 1.9477548599243164 train acc 0.22707210374189515\n",
      "epoch 1 batch id 12901 / 225000 loss 5.030682563781738 train acc 0.2279668242771878\n",
      "epoch 1 batch id 13001 / 225000 loss 5.22116231918335 train acc 0.22944388893162065\n",
      "epoch 1 batch id 13101 / 225000 loss 1.5475752353668213 train acc 0.23076482711243418\n",
      "epoch 1 batch id 13201 / 225000 loss 1.667592167854309 train acc 0.23208469055374592\n",
      "epoch 1 batch id 13301 / 225000 loss 1.6427311897277832 train acc 0.23332832117885874\n",
      "epoch 1 batch id 13401 / 225000 loss 2.908555507659912 train acc 0.23460935751063353\n",
      "epoch 1 batch id 13501 / 225000 loss 3.26688289642334 train acc 0.23596400266646916\n",
      "epoch 1 batch id 13601 / 225000 loss 3.945439100265503 train acc 0.23740901404308506\n",
      "epoch 1 batch id 13701 / 225000 loss 2.0615596771240234 train acc 0.2387964382161886\n",
      "epoch 1 batch id 13801 / 225000 loss 2.440366744995117 train acc 0.24039924643141802\n",
      "epoch 1 batch id 13901 / 225000 loss 1.9786800146102905 train acc 0.24188907272858068\n",
      "epoch 1 batch id 14001 / 225000 loss 4.052615165710449 train acc 0.24335761731304906\n",
      "epoch 1 batch id 14101 / 225000 loss 1.9500590562820435 train acc 0.24478760371604852\n",
      "epoch 1 batch id 14201 / 225000 loss 4.709273815155029 train acc 0.24635589043025138\n",
      "epoch 1 batch id 14301 / 225000 loss 4.536753177642822 train acc 0.24764002517306483\n",
      "epoch 1 batch id 14401 / 225000 loss 1.470741868019104 train acc 0.24907992500520798\n",
      "epoch 1 batch id 14501 / 225000 loss 2.940380573272705 train acc 0.2506034066616095\n",
      "epoch 1 batch id 14601 / 225000 loss 3.3069841861724854 train acc 0.25184918841175263\n",
      "epoch 1 batch id 14701 / 225000 loss 3.487060070037842 train acc 0.25328208965376503\n",
      "epoch 1 batch id 14801 / 225000 loss 3.7498764991760254 train acc 0.2548983176812378\n",
      "epoch 1 batch id 14901 / 225000 loss 0.5951927900314331 train acc 0.2562076370713375\n",
      "epoch 1 batch id 15001 / 225000 loss 1.9171576499938965 train acc 0.25751616558896073\n",
      "epoch 1 batch id 15101 / 225000 loss 3.684194326400757 train acc 0.2587576981656844\n",
      "epoch 1 batch id 15201 / 225000 loss 4.387950420379639 train acc 0.2602131438721137\n",
      "epoch 1 batch id 15301 / 225000 loss 1.7281825542449951 train acc 0.261584210182341\n",
      "epoch 1 batch id 15401 / 225000 loss 3.672973871231079 train acc 0.2633108239724693\n",
      "epoch 1 batch id 15501 / 225000 loss 2.7177155017852783 train acc 0.26459583252693375\n",
      "epoch 1 batch id 15601 / 225000 loss 4.594842910766602 train acc 0.26604063842061404\n",
      "epoch 1 batch id 15701 / 225000 loss 1.809104323387146 train acc 0.2674829628686071\n",
      "epoch 1 batch id 15801 / 225000 loss 3.2213213443756104 train acc 0.26881210049996834\n",
      "epoch 1 batch id 15901 / 225000 loss 1.99931001663208 train acc 0.2702502987233507\n",
      "epoch 1 batch id 16001 / 225000 loss 2.188302516937256 train acc 0.27181113680394975\n",
      "epoch 1 batch id 16101 / 225000 loss 2.9660301208496094 train acc 0.27308862803552575\n",
      "epoch 1 batch id 16201 / 225000 loss 0.900102972984314 train acc 0.27452009135238564\n",
      "epoch 1 batch id 16301 / 225000 loss 0.47211623191833496 train acc 0.2760106741917674\n",
      "epoch 1 batch id 16401 / 225000 loss 1.1801785230636597 train acc 0.2774525943540028\n",
      "epoch 1 batch id 16501 / 225000 loss 4.891077995300293 train acc 0.2787861341736864\n",
      "epoch 1 batch id 16601 / 225000 loss 2.1384780406951904 train acc 0.2804800915607494\n",
      "epoch 1 batch id 16701 / 225000 loss 4.272378444671631 train acc 0.2818543799772469\n",
      "epoch 1 batch id 16801 / 225000 loss 3.0507562160491943 train acc 0.2829593476578775\n",
      "epoch 1 batch id 16901 / 225000 loss 2.082378387451172 train acc 0.2844802082716999\n",
      "epoch 1 batch id 17001 / 225000 loss 4.258100509643555 train acc 0.2856155520263514\n",
      "epoch 1 batch id 17101 / 225000 loss 2.5976457595825195 train acc 0.28679609379568444\n",
      "epoch 1 batch id 17201 / 225000 loss 2.9272522926330566 train acc 0.28822452183012615\n",
      "epoch 1 batch id 17301 / 225000 loss 3.4906086921691895 train acc 0.28930408646899025\n",
      "epoch 1 batch id 17401 / 225000 loss 2.822235345840454 train acc 0.2909459226481237\n",
      "epoch 1 batch id 17501 / 225000 loss 2.114581346511841 train acc 0.29232615279126906\n",
      "epoch 1 batch id 17601 / 225000 loss 2.6204819679260254 train acc 0.29352025453099256\n",
      "epoch 1 batch id 17701 / 225000 loss 2.2094578742980957 train acc 0.2948138523247274\n",
      "epoch 1 batch id 17801 / 225000 loss 0.9749961495399475 train acc 0.2960929161283074\n",
      "epoch 1 batch id 17901 / 225000 loss 2.760237693786621 train acc 0.2971202726104687\n",
      "epoch 1 batch id 18001 / 225000 loss 1.2761735916137695 train acc 0.29845564135325814\n",
      "epoch 1 batch id 18101 / 225000 loss 5.503122806549072 train acc 0.2999696149384012\n",
      "epoch 1 batch id 18201 / 225000 loss 1.899643063545227 train acc 0.3010548870941157\n",
      "epoch 1 batch id 18301 / 225000 loss 0.9563882350921631 train acc 0.3024561499371619\n",
      "epoch 1 batch id 18401 / 225000 loss 1.3707780838012695 train acc 0.3036383892179773\n",
      "epoch 1 batch id 18501 / 225000 loss 1.806489109992981 train acc 0.30510512945246204\n",
      "epoch 1 batch id 18601 / 225000 loss 1.0919733047485352 train acc 0.30654265899682814\n",
      "epoch 1 batch id 18701 / 225000 loss 0.8882228136062622 train acc 0.307897973370408\n",
      "epoch 1 batch id 18801 / 225000 loss 1.3483257293701172 train acc 0.30905270996223605\n",
      "epoch 1 batch id 18901 / 225000 loss 1.4067773818969727 train acc 0.31026136183270725\n",
      "epoch 1 batch id 19001 / 225000 loss 1.6218825578689575 train acc 0.3116809641597811\n",
      "epoch 1 batch id 19101 / 225000 loss 4.4670090675354 train acc 0.31290246583948483\n",
      "epoch 1 batch id 19201 / 225000 loss 2.7920610904693604 train acc 0.3143716473100359\n",
      "epoch 1 batch id 19301 / 225000 loss 2.055108070373535 train acc 0.31576084140718097\n",
      "epoch 1 batch id 19401 / 225000 loss 2.005434989929199 train acc 0.3172001443224576\n",
      "epoch 1 batch id 19501 / 225000 loss 1.537498950958252 train acc 0.3184580277934465\n",
      "epoch 1 batch id 19601 / 225000 loss 1.610429286956787 train acc 0.3197668486301719\n",
      "epoch 1 batch id 19701 / 225000 loss 1.810971736907959 train acc 0.32091010608598547\n",
      "epoch 1 batch id 19801 / 225000 loss 1.7247447967529297 train acc 0.32231957981920106\n",
      "epoch 1 batch id 19901 / 225000 loss 3.719634532928467 train acc 0.32346364504296266\n",
      "epoch 1 batch id 20001 / 225000 loss 1.713545799255371 train acc 0.3245087745612719\n",
      "epoch 1 batch id 20101 / 225000 loss 2.3374452590942383 train acc 0.3256181284513208\n",
      "epoch 1 batch id 20201 / 225000 loss 1.4372282028198242 train acc 0.32685263105786844\n",
      "epoch 1 batch id 20301 / 225000 loss 1.9337618350982666 train acc 0.32821043298359687\n",
      "epoch 1 batch id 20401 / 225000 loss 2.770045518875122 train acc 0.3294813979706877\n",
      "epoch 1 batch id 20501 / 225000 loss 2.921992540359497 train acc 0.33082532559387345\n",
      "epoch 1 batch id 20601 / 225000 loss 1.3053480386734009 train acc 0.33208339400999953\n",
      "epoch 1 batch id 20701 / 225000 loss 2.278275966644287 train acc 0.3331843872276702\n",
      "epoch 1 batch id 20801 / 225000 loss 2.1945767402648926 train acc 0.33456324215181965\n",
      "epoch 1 batch id 20901 / 225000 loss 3.1341605186462402 train acc 0.33562987416870005\n",
      "epoch 1 batch id 21001 / 225000 loss 1.2855710983276367 train acc 0.3369125279748583\n",
      "epoch 1 batch id 21101 / 225000 loss 2.3355815410614014 train acc 0.3381356333823042\n",
      "epoch 1 batch id 21201 / 225000 loss 2.682356357574463 train acc 0.3395004952596576\n",
      "epoch 1 batch id 21301 / 225000 loss 1.820704460144043 train acc 0.3406060748321675\n",
      "epoch 1 batch id 21401 / 225000 loss 0.07760083675384521 train acc 0.3419583197046867\n",
      "epoch 1 batch id 21501 / 225000 loss 0.8416895866394043 train acc 0.3431003209153063\n",
      "epoch 1 batch id 21601 / 225000 loss 4.1913299560546875 train acc 0.3443359103745197\n",
      "epoch 1 batch id 21701 / 225000 loss 1.8527565002441406 train acc 0.3455946730565412\n",
      "epoch 1 batch id 21801 / 225000 loss 2.322269916534424 train acc 0.34664694280078895\n",
      "epoch 1 batch id 21901 / 225000 loss 2.294309616088867 train acc 0.3478836582804438\n",
      "epoch 1 batch id 22001 / 225000 loss 2.873422145843506 train acc 0.3492341257215581\n",
      "epoch 1 batch id 22101 / 225000 loss 1.2288719415664673 train acc 0.35038007329985066\n",
      "epoch 1 batch id 22201 / 225000 loss 2.406198024749756 train acc 0.35154947975316425\n",
      "epoch 1 batch id 22301 / 225000 loss 2.5211191177368164 train acc 0.3528205013228106\n",
      "epoch 1 batch id 22401 / 225000 loss 2.378908634185791 train acc 0.35382349002276686\n",
      "epoch 1 batch id 22501 / 225000 loss 0.9754353761672974 train acc 0.3550175547753433\n",
      "epoch 1 batch id 22601 / 225000 loss 2.485685348510742 train acc 0.35625636033803815\n",
      "epoch 1 batch id 22701 / 225000 loss 0.11845249682664871 train acc 0.3572309589885908\n",
      "epoch 1 batch id 22801 / 225000 loss 1.571846842765808 train acc 0.3583724398052717\n",
      "epoch 1 batch id 22901 / 225000 loss 1.4291229248046875 train acc 0.35925287105366577\n",
      "epoch 1 batch id 23001 / 225000 loss 2.4313549995422363 train acc 0.3603756358419199\n",
      "epoch 1 batch id 23101 / 225000 loss 2.652158737182617 train acc 0.36152114627072424\n",
      "epoch 1 batch id 23201 / 225000 loss 3.318723440170288 train acc 0.3626352312400328\n",
      "epoch 1 batch id 23301 / 225000 loss 1.2856518030166626 train acc 0.3636646495858547\n",
      "epoch 1 batch id 23401 / 225000 loss 1.9706947803497314 train acc 0.3648027862057177\n",
      "epoch 1 batch id 23501 / 225000 loss 2.515479803085327 train acc 0.36587804774264926\n",
      "epoch 1 batch id 23601 / 225000 loss 1.840934157371521 train acc 0.36699716113723996\n",
      "epoch 1 batch id 23701 / 225000 loss 2.124030590057373 train acc 0.3679591578414413\n",
      "epoch 1 batch id 23801 / 225000 loss 1.9512346982955933 train acc 0.3690916348052603\n",
      "epoch 1 batch id 23901 / 225000 loss 1.5553522109985352 train acc 0.3700054391029664\n",
      "epoch 1 batch id 24001 / 225000 loss 1.8228082656860352 train acc 0.37110953710262073\n",
      "epoch 1 batch id 24101 / 225000 loss 0.8646383881568909 train acc 0.37212148873490725\n",
      "epoch 1 batch id 24201 / 225000 loss 1.6712844371795654 train acc 0.3731870583860171\n",
      "epoch 1 batch id 24301 / 225000 loss 1.1713523864746094 train acc 0.37423357063495327\n",
      "epoch 1 batch id 24401 / 225000 loss 2.28125 train acc 0.37525101430269253\n",
      "epoch 1 batch id 24501 / 225000 loss 1.82152259349823 train acc 0.3761989306558916\n",
      "epoch 1 batch id 24601 / 225000 loss 4.695504665374756 train acc 0.377007032234462\n",
      "epoch 1 batch id 24701 / 225000 loss 2.0228192806243896 train acc 0.3780110116999312\n",
      "epoch 1 batch id 24801 / 225000 loss 1.145164132118225 train acc 0.37908753679287127\n",
      "epoch 1 batch id 24901 / 225000 loss 2.696563720703125 train acc 0.38012529617284446\n",
      "epoch 1 batch id 25001 / 225000 loss 3.9011616706848145 train acc 0.3811847526098956\n",
      "epoch 1 batch id 25101 / 225000 loss 1.8705259561538696 train acc 0.38224572726186207\n",
      "epoch 1 batch id 25201 / 225000 loss 2.5969080924987793 train acc 0.3830701162652276\n",
      "epoch 1 batch id 25301 / 225000 loss 1.3344615697860718 train acc 0.3841547764910478\n",
      "epoch 1 batch id 25401 / 225000 loss 2.865098237991333 train acc 0.3851816857604031\n",
      "epoch 1 batch id 25501 / 225000 loss 3.455141544342041 train acc 0.38623975530371357\n",
      "epoch 1 batch id 25601 / 225000 loss 2.3495500087738037 train acc 0.3873579157064177\n",
      "epoch 1 batch id 25701 / 225000 loss 2.8818259239196777 train acc 0.3882922843469126\n",
      "epoch 1 batch id 25801 / 225000 loss 2.1126415729522705 train acc 0.38918065191271656\n",
      "epoch 1 batch id 25901 / 225000 loss 1.0156668424606323 train acc 0.3901200725840701\n",
      "epoch 1 batch id 26001 / 225000 loss 0.8717595934867859 train acc 0.39106188223529864\n",
      "epoch 1 batch id 26101 / 225000 loss 1.6783968210220337 train acc 0.39201563158499675\n",
      "epoch 1 batch id 26201 / 225000 loss 2.977099657058716 train acc 0.3929716423037289\n",
      "epoch 1 batch id 26301 / 225000 loss 0.14480558037757874 train acc 0.39399642599140716\n",
      "epoch 1 batch id 26401 / 225000 loss 3.281989097595215 train acc 0.3950702624900572\n",
      "epoch 1 batch id 26501 / 225000 loss 2.1455302238464355 train acc 0.39603222519904907\n",
      "epoch 1 batch id 26601 / 225000 loss 1.3517999649047852 train acc 0.3969681590917635\n",
      "epoch 1 batch id 26701 / 225000 loss 0.6577440500259399 train acc 0.39793453428710535\n",
      "epoch 1 batch id 26801 / 225000 loss 0.19357675313949585 train acc 0.39888436998619453\n",
      "epoch 1 batch id 26901 / 225000 loss 0.8518359065055847 train acc 0.3998643173116241\n",
      "epoch 1 batch id 27001 / 225000 loss 2.7105743885040283 train acc 0.4006518277100848\n",
      "epoch 1 batch id 27101 / 225000 loss 3.002078056335449 train acc 0.40164569573078485\n",
      "epoch 1 batch id 27201 / 225000 loss 0.7228271961212158 train acc 0.4027057828756296\n",
      "epoch 1 batch id 27301 / 225000 loss 0.9595301151275635 train acc 0.40368484670891175\n",
      "epoch 1 batch id 27401 / 225000 loss 3.0478262901306152 train acc 0.404602021824021\n",
      "epoch 1 batch id 27501 / 225000 loss 3.885693311691284 train acc 0.40545798334606015\n",
      "epoch 1 batch id 27601 / 225000 loss 2.226841449737549 train acc 0.4063439730444549\n",
      "epoch 1 batch id 27701 / 225000 loss 3.3164191246032715 train acc 0.40731381538572614\n",
      "epoch 1 batch id 27801 / 225000 loss 3.139463424682617 train acc 0.40828567317722386\n",
      "epoch 1 batch id 27901 / 225000 loss 4.397054672241211 train acc 0.40901759793555786\n",
      "epoch 1 batch id 28001 / 225000 loss 3.792257070541382 train acc 0.409708581836363\n",
      "epoch 1 batch id 28101 / 225000 loss 1.6111514568328857 train acc 0.4105903704494502\n",
      "epoch 1 batch id 28201 / 225000 loss 0.10411278903484344 train acc 0.4115102301336832\n",
      "epoch 1 batch id 28301 / 225000 loss 2.862349271774292 train acc 0.412335253171266\n",
      "epoch 1 batch id 28401 / 225000 loss 1.9683351516723633 train acc 0.4131632688989824\n",
      "epoch 1 batch id 28501 / 225000 loss 1.5763944387435913 train acc 0.41393284446159784\n",
      "epoch 1 batch id 28601 / 225000 loss 1.2653660774230957 train acc 0.4147844480962204\n",
      "epoch 1 batch id 28701 / 225000 loss 1.658012866973877 train acc 0.41569980140064805\n",
      "epoch 1 batch id 28801 / 225000 loss 3.525607109069824 train acc 0.41658275754314084\n",
      "epoch 1 batch id 28901 / 225000 loss 3.34781813621521 train acc 0.41753745545136844\n",
      "epoch 1 batch id 29001 / 225000 loss 0.9779610633850098 train acc 0.418520051032723\n",
      "epoch 1 batch id 29101 / 225000 loss 4.570542335510254 train acc 0.41928971513006424\n",
      "epoch 1 batch id 29201 / 225000 loss 1.5767189264297485 train acc 0.4200969144892298\n",
      "epoch 1 batch id 29301 / 225000 loss 0.544314444065094 train acc 0.42083887921913926\n",
      "epoch 1 batch id 29401 / 225000 loss 1.204232096672058 train acc 0.42157579674160744\n",
      "epoch 1 batch id 29501 / 225000 loss 2.8748676776885986 train acc 0.42250262702959224\n",
      "epoch 1 batch id 29601 / 225000 loss 2.3579933643341064 train acc 0.42340630384108646\n",
      "epoch 1 batch id 29701 / 225000 loss 2.6406593322753906 train acc 0.4243207299417528\n",
      "epoch 1 batch id 29801 / 225000 loss 0.3761330544948578 train acc 0.42509479547666185\n",
      "epoch 1 batch id 29901 / 225000 loss 0.148588627576828 train acc 0.42593057088391695\n",
      "epoch 1 batch id 30001 / 225000 loss 0.43245965242385864 train acc 0.4267191093630212\n",
      "epoch 1 batch id 30101 / 225000 loss 2.119137763977051 train acc 0.4275605461612571\n",
      "epoch 1 batch id 30201 / 225000 loss 2.236135244369507 train acc 0.42842952220125163\n",
      "epoch 1 batch id 30301 / 225000 loss 0.09996365755796432 train acc 0.4291525032177156\n",
      "epoch 1 batch id 30401 / 225000 loss 1.1181278228759766 train acc 0.4301009835202789\n",
      "epoch 1 batch id 30501 / 225000 loss 2.0222971439361572 train acc 0.43086292252713027\n",
      "epoch 1 batch id 30601 / 225000 loss 2.9755783081054688 train acc 0.4316198817032123\n",
      "epoch 1 batch id 30701 / 225000 loss 0.8296869993209839 train acc 0.4324289111103873\n",
      "epoch 1 batch id 30801 / 225000 loss 2.133519411087036 train acc 0.4332732703483653\n",
      "epoch 1 batch id 30901 / 225000 loss 2.023838996887207 train acc 0.43409598394873955\n",
      "epoch 1 batch id 31001 / 225000 loss 1.201825499534607 train acc 0.4349698396825909\n",
      "epoch 1 batch id 31101 / 225000 loss 0.39377090334892273 train acc 0.43572553937172437\n",
      "epoch 1 batch id 31201 / 225000 loss 2.5914158821105957 train acc 0.4365485080606391\n",
      "epoch 1 batch id 31301 / 225000 loss 0.39144960045814514 train acc 0.437382192262228\n",
      "epoch 1 batch id 31401 / 225000 loss 4.0596818923950195 train acc 0.43804337441482755\n",
      "epoch 1 batch id 31501 / 225000 loss 1.1771169900894165 train acc 0.4387638487667058\n",
      "epoch 1 batch id 31601 / 225000 loss 2.4623942375183105 train acc 0.4395114078668397\n",
      "epoch 1 batch id 31701 / 225000 loss 1.5866369009017944 train acc 0.4401596164158859\n",
      "epoch 1 batch id 31801 / 225000 loss 1.1778424978256226 train acc 0.44092166912990155\n",
      "epoch 1 batch id 31901 / 225000 loss 2.67290997505188 train acc 0.4415300460800602\n",
      "epoch 1 batch id 32001 / 225000 loss 3.288491725921631 train acc 0.4421424330489672\n",
      "epoch 1 batch id 32101 / 225000 loss 2.102268695831299 train acc 0.44303915765863994\n",
      "epoch 1 batch id 32201 / 225000 loss 2.129302978515625 train acc 0.4436818732337505\n",
      "epoch 1 batch id 32301 / 225000 loss 1.9737006425857544 train acc 0.44435156806290826\n",
      "epoch 1 batch id 32401 / 225000 loss 2.4520065784454346 train acc 0.44507885559087684\n",
      "epoch 1 batch id 32501 / 225000 loss 1.1167709827423096 train acc 0.44584012799606165\n",
      "epoch 1 batch id 32601 / 225000 loss 0.38468503952026367 train acc 0.44655071930308887\n",
      "epoch 1 batch id 32701 / 225000 loss 0.14375366270542145 train acc 0.44727989969725696\n",
      "epoch 1 batch id 32801 / 225000 loss 1.3772218227386475 train acc 0.4479970122862108\n",
      "epoch 1 batch id 32901 / 225000 loss 1.0510941743850708 train acc 0.4487097656606182\n",
      "epoch 1 batch id 33001 / 225000 loss 2.472003221511841 train acc 0.44944850156055877\n",
      "epoch 1 batch id 33101 / 225000 loss 2.353358268737793 train acc 0.45008458958943837\n",
      "epoch 1 batch id 33201 / 225000 loss 0.6357277035713196 train acc 0.4507921448149152\n",
      "epoch 1 batch id 33301 / 225000 loss 0.0371343158185482 train acc 0.4516230743821507\n",
      "epoch 1 batch id 33401 / 225000 loss 3.11659836769104 train acc 0.4522993323553187\n",
      "epoch 1 batch id 33501 / 225000 loss 1.310356616973877 train acc 0.4530611026536521\n",
      "epoch 1 batch id 33601 / 225000 loss 1.0375913381576538 train acc 0.45375137644712954\n",
      "epoch 1 batch id 33701 / 225000 loss 1.0467957258224487 train acc 0.4544894810243019\n",
      "epoch 1 batch id 33801 / 225000 loss 2.3727803230285645 train acc 0.45519363332445784\n",
      "epoch 1 batch id 33901 / 225000 loss 0.9162135720252991 train acc 0.4558420105601605\n",
      "epoch 1 batch id 34001 / 225000 loss 2.4420742988586426 train acc 0.45658215934825447\n",
      "epoch 1 batch id 34101 / 225000 loss 2.356842041015625 train acc 0.45721533092871175\n",
      "epoch 1 batch id 34201 / 225000 loss 1.3105486631393433 train acc 0.45772784421508145\n",
      "epoch 1 batch id 34301 / 225000 loss 3.1678853034973145 train acc 0.45839042593510393\n",
      "epoch 1 batch id 34401 / 225000 loss 1.9020239114761353 train acc 0.459136362315049\n",
      "epoch 1 batch id 34501 / 225000 loss 1.493643045425415 train acc 0.45980551288368454\n",
      "epoch 1 batch id 34601 / 225000 loss 2.5273752212524414 train acc 0.4605647235629028\n",
      "epoch 1 batch id 34701 / 225000 loss 0.16879913210868835 train acc 0.46130514970750125\n",
      "epoch 1 batch id 34801 / 225000 loss 2.0340304374694824 train acc 0.4619263814258211\n",
      "epoch 1 batch id 34901 / 225000 loss 0.1415889710187912 train acc 0.4626085212458096\n",
      "epoch 1 batch id 35001 / 225000 loss 1.2174484729766846 train acc 0.4633081911945373\n",
      "epoch 1 batch id 35101 / 225000 loss 0.23049315810203552 train acc 0.46400387453348907\n",
      "epoch 1 batch id 35201 / 225000 loss 0.7765294313430786 train acc 0.464731115593307\n",
      "epoch 1 batch id 35301 / 225000 loss 1.2696388959884644 train acc 0.4654471544715447\n",
      "epoch 1 batch id 35401 / 225000 loss 1.2923167943954468 train acc 0.46615914804666536\n",
      "epoch 1 batch id 35501 / 225000 loss 0.4997537136077881 train acc 0.46685304639305936\n",
      "epoch 1 batch id 35601 / 225000 loss 2.1095008850097656 train acc 0.46746580152242917\n",
      "epoch 1 batch id 35701 / 225000 loss 3.6290769577026367 train acc 0.4680681213411389\n",
      "epoch 1 batch id 35801 / 225000 loss 1.6621125936508179 train acc 0.46872992374514677\n",
      "epoch 1 batch id 35901 / 225000 loss 1.6041462421417236 train acc 0.4693184033870923\n",
      "epoch 1 batch id 36001 / 225000 loss 1.7838069200515747 train acc 0.469966112052443\n",
      "epoch 1 batch id 36101 / 225000 loss 1.503309965133667 train acc 0.470513282180549\n",
      "epoch 1 batch id 36201 / 225000 loss 3.38978910446167 train acc 0.4711955470843347\n",
      "epoch 1 batch id 36301 / 225000 loss 0.020341968163847923 train acc 0.47181895815542274\n",
      "epoch 1 batch id 36401 / 225000 loss 1.7521082162857056 train acc 0.4724183401554902\n",
      "epoch 1 batch id 36501 / 225000 loss 1.3381335735321045 train acc 0.4730760801073943\n",
      "epoch 1 batch id 36601 / 225000 loss 1.5344809293746948 train acc 0.4737233955356411\n",
      "epoch 1 batch id 36701 / 225000 loss 0.685675859451294 train acc 0.47431950083104\n",
      "epoch 1 batch id 36801 / 225000 loss 0.9847363233566284 train acc 0.4749599195674031\n",
      "epoch 1 batch id 36901 / 225000 loss 1.0675140619277954 train acc 0.4755629928728219\n",
      "epoch 1 batch id 37001 / 225000 loss 0.024449411779642105 train acc 0.47627091159698387\n",
      "epoch 1 batch id 37101 / 225000 loss 1.4785845279693604 train acc 0.47692784561063045\n",
      "epoch 1 batch id 37201 / 225000 loss 1.524119257926941 train acc 0.4774871643235397\n",
      "epoch 1 batch id 37301 / 225000 loss 1.2871811389923096 train acc 0.4780903997211871\n",
      "epoch 1 batch id 37401 / 225000 loss 2.4882776737213135 train acc 0.4786503034678217\n",
      "epoch 1 batch id 37501 / 225000 loss 0.7729499340057373 train acc 0.47915388922962054\n",
      "epoch 1 batch id 37601 / 225000 loss 0.007531791925430298 train acc 0.47977447408313606\n",
      "epoch 1 batch id 37701 / 225000 loss 0.8101963996887207 train acc 0.480325455558208\n",
      "epoch 1 batch id 37801 / 225000 loss 2.505234956741333 train acc 0.48090658977275735\n",
      "epoch 1 batch id 37901 / 225000 loss 0.6875046491622925 train acc 0.481431888340677\n",
      "epoch 1 batch id 38001 / 225000 loss 0.15051566064357758 train acc 0.4820202099944738\n",
      "epoch 1 batch id 38101 / 225000 loss 2.6189892292022705 train acc 0.4826120049342537\n",
      "epoch 1 batch id 38201 / 225000 loss 2.1587653160095215 train acc 0.48321379021491584\n",
      "epoch 1 batch id 38301 / 225000 loss 2.4517908096313477 train acc 0.4838972872770946\n",
      "epoch 1 batch id 38401 / 225000 loss 0.21097694337368011 train acc 0.48448608109163827\n",
      "epoch 1 batch id 38501 / 225000 loss 2.0531234741210938 train acc 0.48516272304615465\n",
      "epoch 1 batch id 38601 / 225000 loss 0.7265848517417908 train acc 0.4857970000777182\n",
      "epoch 1 batch id 38701 / 225000 loss 1.6985182762145996 train acc 0.48627942430428156\n",
      "epoch 1 batch id 38801 / 225000 loss 1.1681482791900635 train acc 0.48677869127084356\n",
      "epoch 1 batch id 38901 / 225000 loss 1.102703332901001 train acc 0.48731395079818\n",
      "epoch 1 batch id 39001 / 225000 loss 0.08757204562425613 train acc 0.48787210584343993\n",
      "epoch 1 batch id 39101 / 225000 loss 2.750027656555176 train acc 0.4884082248535843\n",
      "epoch 1 batch id 39201 / 225000 loss 1.3212907314300537 train acc 0.48906915639907145\n",
      "epoch 1 batch id 39301 / 225000 loss 2.447377920150757 train acc 0.48966311289789066\n",
      "epoch 1 batch id 39401 / 225000 loss 2.9292969703674316 train acc 0.49030481459861425\n",
      "epoch 1 batch id 39501 / 225000 loss 0.8202260732650757 train acc 0.49076605655553024\n",
      "epoch 1 batch id 39601 / 225000 loss 1.1945003271102905 train acc 0.4913322895886468\n",
      "epoch 1 batch id 39701 / 225000 loss 5.299798488616943 train acc 0.4918767789224453\n",
      "epoch 1 batch id 39801 / 225000 loss 2.420175552368164 train acc 0.4925253134343358\n",
      "epoch 1 batch id 39901 / 225000 loss 2.1125648021698 train acc 0.4931142076639683\n",
      "epoch 1 batch id 40001 / 225000 loss 4.4552106857299805 train acc 0.4937064073398165\n",
      "epoch 1 batch id 40101 / 225000 loss 1.818221092224121 train acc 0.494301887733473\n",
      "epoch 1 batch id 40201 / 225000 loss 3.1111011505126953 train acc 0.49487574935946865\n",
      "epoch 1 batch id 40301 / 225000 loss 1.9921765327453613 train acc 0.49534130666732834\n",
      "epoch 1 batch id 40401 / 225000 loss 3.1503782272338867 train acc 0.49581693522437564\n",
      "epoch 1 batch id 40501 / 225000 loss 2.460139036178589 train acc 0.4963334238660774\n",
      "epoch 1 batch id 40601 / 225000 loss 1.5523064136505127 train acc 0.49695204551612027\n",
      "epoch 1 batch id 40701 / 225000 loss 1.4532808065414429 train acc 0.49745706493697944\n",
      "epoch 1 batch id 40801 / 225000 loss 0.4642120897769928 train acc 0.49790446312590375\n",
      "epoch 1 batch id 40901 / 225000 loss 2.9447436332702637 train acc 0.49842302144201855\n",
      "epoch 1 batch id 41001 / 225000 loss 3.591324806213379 train acc 0.4989146606180337\n",
      "epoch 1 batch id 41101 / 225000 loss 3.615295648574829 train acc 0.4993978248704411\n",
      "epoch 1 batch id 41201 / 225000 loss 0.7633095979690552 train acc 0.50003033906944\n",
      "epoch 1 batch id 41301 / 225000 loss 2.921344518661499 train acc 0.5007082152974505\n",
      "epoch 1 batch id 41401 / 225000 loss 0.7612878084182739 train acc 0.5012077002970943\n",
      "epoch 1 batch id 41501 / 225000 loss 0.023479672148823738 train acc 0.5017108021493458\n",
      "epoch 1 batch id 41601 / 225000 loss 0.03280521184206009 train acc 0.5021994663589817\n",
      "epoch 1 batch id 41701 / 225000 loss 0.018754616379737854 train acc 0.5026378264310208\n",
      "epoch 1 batch id 41801 / 225000 loss 0.3437325358390808 train acc 0.5032355685270687\n",
      "epoch 1 batch id 41901 / 225000 loss 0.7641528248786926 train acc 0.5037111286126823\n",
      "epoch 1 batch id 42001 / 225000 loss 1.2600551843643188 train acc 0.5041903764196091\n",
      "epoch 1 batch id 42101 / 225000 loss 3.1393651962280273 train acc 0.5046792237714068\n",
      "epoch 1 batch id 42201 / 225000 loss 3.4857540130615234 train acc 0.5051242861543566\n",
      "epoch 1 batch id 42301 / 225000 loss 3.217906951904297 train acc 0.5056322545566299\n",
      "epoch 1 batch id 42401 / 225000 loss 1.5052006244659424 train acc 0.5060434895403411\n",
      "epoch 1 batch id 42501 / 225000 loss 0.45559173822402954 train acc 0.5065939624950001\n",
      "epoch 1 batch id 42601 / 225000 loss 0.5650027394294739 train acc 0.5070772986549612\n",
      "epoch 1 batch id 42701 / 225000 loss 3.903480052947998 train acc 0.5075876443174633\n",
      "epoch 1 batch id 42801 / 225000 loss 0.08761954307556152 train acc 0.5081189691829631\n",
      "epoch 1 batch id 42901 / 225000 loss 1.672614574432373 train acc 0.5085429244073565\n",
      "epoch 1 batch id 43001 / 225000 loss 0.011740714311599731 train acc 0.5090986256133578\n",
      "epoch 1 batch id 43101 / 225000 loss 0.9320202469825745 train acc 0.509669149207675\n",
      "epoch 1 batch id 43201 / 225000 loss 1.0827049016952515 train acc 0.5101791625193861\n",
      "epoch 1 batch id 43301 / 225000 loss 3.194417953491211 train acc 0.5106464053947946\n",
      "epoch 1 batch id 43401 / 225000 loss 0.034427035599946976 train acc 0.511146056542476\n",
      "epoch 1 batch id 43501 / 225000 loss 0.15957409143447876 train acc 0.5115572055814809\n",
      "epoch 1 batch id 43601 / 225000 loss 0.03038276918232441 train acc 0.5121442168757597\n",
      "epoch 1 batch id 43701 / 225000 loss 0.07585126161575317 train acc 0.5126198485160522\n",
      "epoch 1 batch id 43801 / 225000 loss 4.387633323669434 train acc 0.5129620328303007\n",
      "epoch 1 batch id 43901 / 225000 loss 4.3130693435668945 train acc 0.5133482153026127\n",
      "epoch 1 batch id 44001 / 225000 loss 0.022357501089572906 train acc 0.5138974114224677\n",
      "epoch 1 batch id 44101 / 225000 loss 1.7271891832351685 train acc 0.5143364096052244\n",
      "epoch 1 batch id 44201 / 225000 loss 0.02523350715637207 train acc 0.514846949164046\n",
      "epoch 1 batch id 44301 / 225000 loss 2.3335189819335938 train acc 0.5153495406424234\n",
      "epoch 1 batch id 44401 / 225000 loss 5.140851974487305 train acc 0.5158386072385757\n",
      "epoch 1 batch id 44501 / 225000 loss 2.637315511703491 train acc 0.516331093683288\n",
      "epoch 1 batch id 44601 / 225000 loss 3.1663994789123535 train acc 0.5168662137620232\n",
      "epoch 1 batch id 44701 / 225000 loss 2.070556402206421 train acc 0.5173318270284781\n",
      "epoch 1 batch id 44801 / 225000 loss 1.1933144330978394 train acc 0.5177953617106761\n",
      "epoch 1 batch id 44901 / 225000 loss 1.0221319198608398 train acc 0.5182512638916728\n",
      "epoch 1 batch id 45001 / 225000 loss 0.09217904508113861 train acc 0.5187940267994045\n",
      "epoch 1 batch id 45101 / 225000 loss 0.11713145673274994 train acc 0.519334382829649\n",
      "epoch 1 batch id 45201 / 225000 loss 0.010161368176341057 train acc 0.5197949160416805\n",
      "epoch 1 batch id 45301 / 225000 loss 0.6735737919807434 train acc 0.5202589346813536\n",
      "epoch 1 batch id 45401 / 225000 loss 0.6002577543258667 train acc 0.5206933767978679\n",
      "epoch 1 batch id 45501 / 225000 loss 0.020042089745402336 train acc 0.5211259093206743\n",
      "epoch 1 batch id 45601 / 225000 loss 3.0504581928253174 train acc 0.5214852744457359\n",
      "epoch 1 batch id 45701 / 225000 loss 3.6969990730285645 train acc 0.5218485372311328\n",
      "epoch 1 batch id 45801 / 225000 loss 2.684911012649536 train acc 0.5222920896923648\n",
      "epoch 1 batch id 45901 / 225000 loss 2.2505972385406494 train acc 0.5227609420274069\n",
      "epoch 1 batch id 46001 / 225000 loss 2.3530194759368896 train acc 0.5232331905828134\n",
      "epoch 1 batch id 46101 / 225000 loss 3.316204786300659 train acc 0.5236003557406563\n",
      "epoch 1 batch id 46201 / 225000 loss 0.20990949869155884 train acc 0.5240849765156599\n",
      "epoch 1 batch id 46301 / 225000 loss 0.849112331867218 train acc 0.5245297077816894\n",
      "epoch 1 batch id 46401 / 225000 loss 1.644650936126709 train acc 0.5248701536604815\n",
      "epoch 1 batch id 46501 / 225000 loss 0.1586449295282364 train acc 0.5253327885421819\n",
      "epoch 1 batch id 46601 / 225000 loss 1.7398264408111572 train acc 0.5257827085255681\n",
      "epoch 1 batch id 46701 / 225000 loss 0.8678314089775085 train acc 0.5260968715873322\n",
      "epoch 1 batch id 46801 / 225000 loss 0.5627570748329163 train acc 0.526537894489434\n",
      "epoch 1 batch id 46901 / 225000 loss 1.758482813835144 train acc 0.5268864203321891\n",
      "epoch 1 batch id 47001 / 225000 loss 1.6040031909942627 train acc 0.5272972915469883\n",
      "epoch 1 batch id 47101 / 225000 loss 5.60939884185791 train acc 0.5277594955521114\n",
      "epoch 1 batch id 47201 / 225000 loss 0.5075617432594299 train acc 0.5281985551153577\n",
      "epoch 1 batch id 47301 / 225000 loss 0.646101176738739 train acc 0.5287203230375679\n",
      "epoch 1 batch id 47401 / 225000 loss 3.0783281326293945 train acc 0.529086939094112\n",
      "epoch 1 batch id 47501 / 225000 loss 0.3537226915359497 train acc 0.5295467463842867\n",
      "epoch 1 batch id 47601 / 225000 loss 0.8078820109367371 train acc 0.5300151257326526\n",
      "epoch 1 batch id 47701 / 225000 loss 0.3270370662212372 train acc 0.5304343724450221\n",
      "epoch 1 batch id 47801 / 225000 loss 0.01892203651368618 train acc 0.5308937051526119\n",
      "epoch 1 batch id 47901 / 225000 loss 1.8201003074645996 train acc 0.5312989290411474\n",
      "epoch 1 batch id 48001 / 225000 loss 1.068387746810913 train acc 0.5317545467802754\n",
      "epoch 1 batch id 48101 / 225000 loss 0.028533542528748512 train acc 0.5321043221554645\n",
      "epoch 1 batch id 48201 / 225000 loss 2.0853466987609863 train acc 0.532561565112757\n",
      "epoch 1 batch id 48301 / 225000 loss 2.536921501159668 train acc 0.5328823419804973\n",
      "epoch 1 batch id 48401 / 225000 loss 0.8499053120613098 train acc 0.5332379496291398\n",
      "epoch 1 batch id 48501 / 225000 loss 0.5583181977272034 train acc 0.5336436362136863\n",
      "epoch 1 batch id 48601 / 225000 loss 2.44449782371521 train acc 0.5341248122466616\n",
      "epoch 1 batch id 48701 / 225000 loss 1.4275422096252441 train acc 0.5344808114823104\n",
      "epoch 1 batch id 48801 / 225000 loss 1.55020272731781 train acc 0.5348455974262822\n",
      "epoch 1 batch id 48901 / 225000 loss 0.4670605957508087 train acc 0.5352651275025051\n",
      "epoch 1 batch id 49001 / 225000 loss 0.21108803153038025 train acc 0.5356013142588927\n",
      "epoch 1 batch id 49101 / 225000 loss 0.03505116328597069 train acc 0.5360125048369687\n",
      "epoch 1 batch id 49201 / 225000 loss 2.5218663215637207 train acc 0.5363712119672365\n",
      "epoch 1 batch id 49301 / 225000 loss 0.8139458298683167 train acc 0.5368045272915357\n",
      "epoch 1 batch id 49401 / 225000 loss 1.1391587257385254 train acc 0.537246209590899\n",
      "epoch 1 batch id 49501 / 225000 loss 2.9567689895629883 train acc 0.5376255025151007\n",
      "epoch 1 batch id 49601 / 225000 loss 1.517340064048767 train acc 0.5380536682728171\n",
      "epoch 1 batch id 49701 / 225000 loss 3.2065184116363525 train acc 0.5384801110641637\n",
      "epoch 1 batch id 49801 / 225000 loss 0.624997079372406 train acc 0.5388897813296922\n",
      "epoch 1 batch id 49901 / 225000 loss 3.4511919021606445 train acc 0.5391825815113925\n",
      "epoch 1 batch id 50001 / 225000 loss 0.4505215585231781 train acc 0.5395992080158397\n",
      "epoch 1 batch id 50101 / 225000 loss 0.17635804414749146 train acc 0.540009181453464\n",
      "epoch 1 batch id 50201 / 225000 loss 1.6505519151687622 train acc 0.5403976016414016\n",
      "epoch 1 batch id 50301 / 225000 loss 1.0557897090911865 train acc 0.540759627045188\n",
      "epoch 1 batch id 50401 / 225000 loss 1.1973146200180054 train acc 0.5410904545544731\n",
      "epoch 1 batch id 50501 / 225000 loss 2.6955766677856445 train acc 0.541419971881745\n",
      "epoch 1 batch id 50601 / 225000 loss 1.2330173254013062 train acc 0.5418568802988083\n",
      "epoch 1 batch id 50701 / 225000 loss 0.6143211126327515 train acc 0.5422575491607661\n",
      "epoch 1 batch id 50801 / 225000 loss 0.014556258916854858 train acc 0.5426664829432492\n",
      "epoch 1 batch id 50901 / 225000 loss 0.07128791511058807 train acc 0.5430738099447948\n",
      "epoch 1 batch id 51001 / 225000 loss 0.5111208558082581 train acc 0.5434501284288543\n",
      "epoch 1 batch id 51101 / 225000 loss 0.007012924179434776 train acc 0.5438151895266238\n",
      "epoch 1 batch id 51201 / 225000 loss 5.131034851074219 train acc 0.5442520653893479\n",
      "epoch 1 batch id 51301 / 225000 loss 2.0439682006835938 train acc 0.5446336328726535\n",
      "epoch 1 batch id 51401 / 225000 loss 0.05119552090764046 train acc 0.5449893970934417\n",
      "epoch 1 batch id 51501 / 225000 loss 1.613932490348816 train acc 0.5454117395778723\n",
      "epoch 1 batch id 51601 / 225000 loss 0.18054339289665222 train acc 0.5457258580260073\n",
      "epoch 1 batch id 51701 / 225000 loss 0.1680671125650406 train acc 0.5460822808069477\n",
      "epoch 1 batch id 51801 / 225000 loss 2.2642769813537598 train acc 0.5464180228180923\n",
      "epoch 1 batch id 51901 / 225000 loss 0.02261626534163952 train acc 0.546892160073987\n",
      "epoch 1 batch id 52001 / 225000 loss 1.3788070678710938 train acc 0.5472635141631892\n",
      "epoch 1 batch id 52101 / 225000 loss 0.03125910833477974 train acc 0.5476670313429685\n",
      "epoch 1 batch id 52201 / 225000 loss 0.11719126999378204 train acc 0.5480306890672593\n",
      "epoch 1 batch id 52301 / 225000 loss 0.6596230864524841 train acc 0.5484789965775033\n",
      "epoch 1 batch id 52401 / 225000 loss 1.0192492008209229 train acc 0.5488349458979791\n",
      "epoch 1 batch id 52501 / 225000 loss 0.009164521470665932 train acc 0.5491800156187501\n",
      "epoch 1 batch id 52601 / 225000 loss 0.08122844994068146 train acc 0.5495475371190662\n",
      "epoch 1 batch id 52701 / 225000 loss 2.154778242111206 train acc 0.5498994326483368\n",
      "epoch 1 batch id 52801 / 225000 loss 0.010385092347860336 train acc 0.5502547300240526\n",
      "epoch 1 batch id 52901 / 225000 loss 1.8224537372589111 train acc 0.5506275873802008\n",
      "epoch 1 batch id 53001 / 225000 loss 2.3427865505218506 train acc 0.5509660195090659\n",
      "epoch 1 batch id 53101 / 225000 loss 1.0298901796340942 train acc 0.551364381085102\n",
      "epoch 1 batch id 53201 / 225000 loss 0.7792468667030334 train acc 0.5517612450893781\n",
      "epoch 1 batch id 53301 / 225000 loss 5.190887928009033 train acc 0.5520487420498678\n",
      "epoch 1 batch id 53401 / 225000 loss 1.3110374212265015 train acc 0.5523492069436902\n",
      "epoch 1 batch id 53501 / 225000 loss 0.06405007839202881 train acc 0.552793405730734\n",
      "epoch 1 batch id 53601 / 225000 loss 1.1204910278320312 train acc 0.5531286729725192\n",
      "epoch 1 batch id 53701 / 225000 loss 0.7882557511329651 train acc 0.5535139010446732\n",
      "epoch 1 batch id 53801 / 225000 loss 0.06673166155815125 train acc 0.5539720451292727\n",
      "epoch 1 batch id 53901 / 225000 loss 0.009443880058825016 train acc 0.554317174078403\n",
      "epoch 1 batch id 54001 / 225000 loss 1.566394567489624 train acc 0.5547073202348105\n",
      "epoch 1 batch id 54101 / 225000 loss 2.144660711288452 train acc 0.5550313302896435\n",
      "epoch 1 batch id 54201 / 225000 loss 0.904961109161377 train acc 0.5553725946015756\n",
      "epoch 1 batch id 54301 / 225000 loss 0.8346085548400879 train acc 0.5556849781771974\n",
      "epoch 1 batch id 54401 / 225000 loss 1.0880001783370972 train acc 0.5559962133049025\n",
      "epoch 1 batch id 54501 / 225000 loss 6.012302398681641 train acc 0.5563017192345094\n",
      "epoch 1 batch id 54601 / 225000 loss 3.484844207763672 train acc 0.5566885221882383\n",
      "epoch 1 batch id 54701 / 225000 loss 1.0245229005813599 train acc 0.5569550830880605\n",
      "epoch 1 batch id 54801 / 225000 loss 0.8660708665847778 train acc 0.5572024233134432\n",
      "epoch 1 batch id 54901 / 225000 loss 3.2189226150512695 train acc 0.5575262745669478\n",
      "epoch 1 batch id 55001 / 225000 loss 0.09880215674638748 train acc 0.5578898565480628\n",
      "epoch 1 batch id 55101 / 225000 loss 3.59310245513916 train acc 0.5582294332226275\n",
      "epoch 1 batch id 55201 / 225000 loss 1.0241122245788574 train acc 0.5585904240865202\n",
      "epoch 1 batch id 55301 / 225000 loss 1.1625603437423706 train acc 0.5588370915534981\n",
      "epoch 1 batch id 55401 / 225000 loss 1.82058584690094 train acc 0.5591595819570044\n",
      "epoch 1 batch id 55501 / 225000 loss 1.586780071258545 train acc 0.559516945640619\n",
      "epoch 1 batch id 55601 / 225000 loss 1.4488186836242676 train acc 0.5598730238664772\n",
      "epoch 1 batch id 55701 / 225000 loss 1.1259299516677856 train acc 0.5602053823091148\n",
      "epoch 1 batch id 55801 / 225000 loss 1.685922384262085 train acc 0.5605096682855146\n",
      "epoch 1 batch id 55901 / 225000 loss 1.2266566753387451 train acc 0.5607949768340459\n",
      "epoch 1 batch id 56001 / 225000 loss 2.5929079055786133 train acc 0.561083730647667\n",
      "epoch 1 batch id 56101 / 225000 loss 0.7334794402122498 train acc 0.5613803675513805\n",
      "epoch 1 batch id 56201 / 225000 loss 0.006322493776679039 train acc 0.5616848454653832\n",
      "epoch 1 batch id 56301 / 225000 loss 0.014208185486495495 train acc 0.5619527184241843\n",
      "epoch 1 batch id 56401 / 225000 loss 1.6902397871017456 train acc 0.5622683994964628\n",
      "epoch 1 batch id 56501 / 225000 loss 0.2720661461353302 train acc 0.562600661935187\n",
      "epoch 1 batch id 56601 / 225000 loss 0.35641029477119446 train acc 0.562896415257681\n",
      "epoch 1 batch id 56701 / 225000 loss 1.3501752614974976 train acc 0.5632219890301758\n",
      "epoch 1 batch id 56801 / 225000 loss 2.1910805702209473 train acc 0.5635640217601803\n",
      "epoch 1 batch id 56901 / 225000 loss 1.390124797821045 train acc 0.5639004586914114\n",
      "epoch 1 batch id 57001 / 225000 loss 0.03013296239078045 train acc 0.5642883458184944\n",
      "epoch 1 batch id 57101 / 225000 loss 0.20095379650592804 train acc 0.5646442268962014\n",
      "epoch 1 batch id 57201 / 225000 loss 0.048630740493535995 train acc 0.5649420464677191\n",
      "epoch 1 batch id 57301 / 225000 loss 2.8058433532714844 train acc 0.5652213748451161\n",
      "epoch 1 batch id 57401 / 225000 loss 0.6812397241592407 train acc 0.5654735980209404\n",
      "epoch 1 batch id 57501 / 225000 loss 1.357699990272522 train acc 0.5657640736682841\n",
      "epoch 1 batch id 57601 / 225000 loss 0.29165032505989075 train acc 0.5660622211419941\n",
      "epoch 1 batch id 57701 / 225000 loss 1.341601848602295 train acc 0.5663246737491551\n",
      "epoch 1 batch id 57801 / 225000 loss 2.65335750579834 train acc 0.5666078441549454\n",
      "epoch 1 batch id 57901 / 225000 loss 1.7728185653686523 train acc 0.5669073073003921\n",
      "epoch 1 batch id 58001 / 225000 loss 1.3082066774368286 train acc 0.5672359097256944\n",
      "epoch 1 batch id 58101 / 225000 loss 0.10158728063106537 train acc 0.5675719867127932\n",
      "epoch 1 batch id 58201 / 225000 loss 0.058403655886650085 train acc 0.5678596587687497\n",
      "epoch 1 batch id 58301 / 225000 loss 4.15546989440918 train acc 0.5681420558824034\n",
      "epoch 1 batch id 58401 / 225000 loss 2.20719313621521 train acc 0.5684020821561274\n",
      "epoch 1 batch id 58501 / 225000 loss 0.005471512209624052 train acc 0.5687167740722381\n",
      "epoch 1 batch id 58601 / 225000 loss 0.00440563727170229 train acc 0.5690133274176209\n",
      "epoch 1 batch id 58701 / 225000 loss 0.8802878856658936 train acc 0.569240728437335\n",
      "epoch 1 batch id 58801 / 225000 loss 0.07012569159269333 train acc 0.569518375537831\n",
      "epoch 1 batch id 58901 / 225000 loss 1.8981397151947021 train acc 0.5698417683910291\n",
      "epoch 1 batch id 59001 / 225000 loss 1.3950635194778442 train acc 0.5700750834731615\n",
      "epoch 1 batch id 59101 / 225000 loss 0.058189671486616135 train acc 0.5704302803675064\n",
      "epoch 1 batch id 59201 / 225000 loss 2.3838067054748535 train acc 0.5707673856860526\n",
      "epoch 1 batch id 59301 / 225000 loss 1.2752447128295898 train acc 0.5709937437817237\n",
      "epoch 1 batch id 59401 / 225000 loss 0.10636164247989655 train acc 0.5712698439420212\n",
      "epoch 1 batch id 59501 / 225000 loss 1.9662675857543945 train acc 0.5715660241004353\n",
      "epoch 1 batch id 59601 / 225000 loss 2.1447954177856445 train acc 0.5718654049428701\n",
      "epoch 1 batch id 59701 / 225000 loss 0.10994281619787216 train acc 0.5721889080584914\n",
      "epoch 1 batch id 59801 / 225000 loss 3.3391120433807373 train acc 0.572415177003729\n",
      "epoch 1 batch id 59901 / 225000 loss 4.061298847198486 train acc 0.5726907731089631\n",
      "epoch 1 batch id 60001 / 225000 loss 0.9685589075088501 train acc 0.5729071182146964\n",
      "epoch 1 batch id 60101 / 225000 loss 0.010980619117617607 train acc 0.5731352223756676\n",
      "epoch 1 batch id 60201 / 225000 loss 0.23675158619880676 train acc 0.5733750269929071\n",
      "epoch 1 batch id 60301 / 225000 loss 0.01820194721221924 train acc 0.5736181821196995\n",
      "epoch 1 batch id 60401 / 225000 loss 2.3033645153045654 train acc 0.5738481150974322\n",
      "epoch 1 batch id 60501 / 225000 loss 0.9829605221748352 train acc 0.5740814201418158\n",
      "epoch 1 batch id 60601 / 225000 loss 0.016342805698513985 train acc 0.5743139552152605\n",
      "epoch 1 batch id 60701 / 225000 loss 0.03033624216914177 train acc 0.574586909606102\n",
      "epoch 1 batch id 60801 / 225000 loss 0.01254335418343544 train acc 0.5748918603312445\n",
      "epoch 1 batch id 60901 / 225000 loss 1.11292564868927 train acc 0.5751999146155236\n",
      "epoch 1 batch id 61001 / 225000 loss 3.578874111175537 train acc 0.5754987623153719\n",
      "epoch 1 batch id 61101 / 225000 loss 1.3277132511138916 train acc 0.5757393496014795\n",
      "epoch 1 batch id 61201 / 225000 loss 0.14767345786094666 train acc 0.5759954902697668\n",
      "epoch 1 batch id 61301 / 225000 loss 3.4295287132263184 train acc 0.576271186440678\n",
      "epoch 1 batch id 61401 / 225000 loss 0.14487795531749725 train acc 0.5765296982133842\n",
      "epoch 1 batch id 61501 / 225000 loss 1.804430365562439 train acc 0.5768117591583877\n",
      "epoch 1 batch id 61601 / 225000 loss 0.20155733823776245 train acc 0.5770563789548872\n",
      "epoch 1 batch id 61701 / 225000 loss 3.464163064956665 train acc 0.5772799468404077\n",
      "epoch 1 batch id 61801 / 225000 loss 0.6052566766738892 train acc 0.5775675150887526\n",
      "epoch 1 batch id 61901 / 225000 loss 1.5946661233901978 train acc 0.5778703090418572\n",
      "epoch 1 batch id 62001 / 225000 loss 3.523467779159546 train acc 0.5780713214302995\n",
      "epoch 1 batch id 62101 / 225000 loss 1.9673882722854614 train acc 0.5783360976473809\n",
      "epoch 1 batch id 62201 / 225000 loss 0.017217589542269707 train acc 0.578660310927477\n",
      "epoch 1 batch id 62301 / 225000 loss 1.8040707111358643 train acc 0.578919278984286\n",
      "epoch 1 batch id 62401 / 225000 loss 1.928686261177063 train acc 0.5792415185654076\n",
      "epoch 1 batch id 62501 / 225000 loss 1.1349655389785767 train acc 0.5794707284683445\n",
      "epoch 1 batch id 62601 / 225000 loss 2.185405731201172 train acc 0.5797311544544017\n",
      "epoch 1 batch id 62701 / 225000 loss 0.9833036065101624 train acc 0.5800266343439499\n",
      "epoch 1 batch id 62801 / 225000 loss 0.9903678894042969 train acc 0.5802734032897565\n",
      "epoch 1 batch id 62901 / 225000 loss 1.5166215896606445 train acc 0.5805392601071525\n",
      "epoch 1 batch id 63001 / 225000 loss 0.05217873677611351 train acc 0.5807685592292186\n",
      "epoch 1 batch id 63101 / 225000 loss 0.052444882690906525 train acc 0.5810803315319883\n",
      "epoch 1 batch id 63201 / 225000 loss 0.8274132609367371 train acc 0.5813001376560497\n",
      "epoch 1 batch id 63301 / 225000 loss 1.7643572092056274 train acc 0.5815350468397024\n",
      "epoch 1 batch id 63401 / 225000 loss 1.7519862651824951 train acc 0.581796817084904\n",
      "epoch 1 batch id 63501 / 225000 loss 1.8010673522949219 train acc 0.5820065825735028\n",
      "epoch 1 batch id 63601 / 225000 loss 0.2699522078037262 train acc 0.5823060958161035\n",
      "epoch 1 batch id 63701 / 225000 loss 1.4427821636199951 train acc 0.5825457999089496\n",
      "epoch 1 batch id 63801 / 225000 loss 0.01379178836941719 train acc 0.5827925894578455\n",
      "epoch 1 batch id 63901 / 225000 loss 0.08912236988544464 train acc 0.5831285895369399\n",
      "epoch 1 batch id 64001 / 225000 loss 1.7058639526367188 train acc 0.5833502601521852\n",
      "epoch 1 batch id 64101 / 225000 loss 0.00992558617144823 train acc 0.5835751392333973\n",
      "epoch 1 batch id 64201 / 225000 loss 3.5475401878356934 train acc 0.5838109998286631\n",
      "epoch 1 batch id 64301 / 225000 loss 0.7951233983039856 train acc 0.5840694545963515\n",
      "epoch 1 batch id 64401 / 225000 loss 3.253472328186035 train acc 0.5843814537041351\n",
      "epoch 1 batch id 64501 / 225000 loss 4.055123329162598 train acc 0.5845064417605929\n",
      "epoch 1 batch id 64601 / 225000 loss 2.4891669750213623 train acc 0.5847200507732079\n",
      "epoch 1 batch id 64701 / 225000 loss 1.9486442804336548 train acc 0.5849329994899615\n",
      "epoch 1 batch id 64801 / 225000 loss 1.9353625774383545 train acc 0.5851645807935063\n",
      "epoch 1 batch id 64901 / 225000 loss 0.020037557929754257 train acc 0.5853800403691777\n",
      "epoch 1 batch id 65001 / 225000 loss 0.9569686651229858 train acc 0.5855986830971831\n",
      "epoch 1 batch id 65101 / 225000 loss 2.332939624786377 train acc 0.5858550559899234\n",
      "epoch 1 batch id 65201 / 225000 loss 1.965737223625183 train acc 0.5861144767718287\n",
      "epoch 1 batch id 65301 / 225000 loss 3.1905922889709473 train acc 0.586311848210594\n",
      "epoch 1 batch id 65401 / 225000 loss 0.7835443019866943 train acc 0.5865735997920521\n",
      "epoch 1 batch id 65501 / 225000 loss 3.2590572834014893 train acc 0.5868269186729974\n",
      "epoch 1 batch id 65601 / 225000 loss 2.357841968536377 train acc 0.5870070578192406\n",
      "epoch 1 batch id 65701 / 225000 loss 2.557084798812866 train acc 0.5872208946591376\n",
      "epoch 1 batch id 65801 / 225000 loss 0.288627564907074 train acc 0.5874112855427729\n",
      "epoch 1 batch id 65901 / 225000 loss 0.35103774070739746 train acc 0.5876845571387385\n",
      "epoch 1 batch id 66001 / 225000 loss 0.12478311359882355 train acc 0.5879039711519523\n",
      "epoch 1 batch id 66101 / 225000 loss 2.063859462738037 train acc 0.5881756705647418\n",
      "epoch 1 batch id 66201 / 225000 loss 0.016688888892531395 train acc 0.5884692074137853\n",
      "epoch 1 batch id 66301 / 225000 loss 0.03509102761745453 train acc 0.588641196965355\n",
      "epoch 1 batch id 66401 / 225000 loss 0.3638926148414612 train acc 0.5889030285688469\n",
      "epoch 1 batch id 66501 / 225000 loss 1.2052357196807861 train acc 0.5891828694305349\n",
      "epoch 1 batch id 66601 / 225000 loss 2.06123948097229 train acc 0.5894243329679735\n",
      "epoch 1 batch id 66701 / 225000 loss 0.04734549671411514 train acc 0.5896913089758774\n",
      "epoch 1 batch id 66801 / 225000 loss 2.5326528549194336 train acc 0.5898901214053682\n",
      "epoch 1 batch id 66901 / 225000 loss 0.7939985394477844 train acc 0.5901070238113033\n",
      "epoch 1 batch id 67001 / 225000 loss 1.8443416357040405 train acc 0.590315816181848\n",
      "epoch 1 batch id 67101 / 225000 loss 2.381662130355835 train acc 0.5905016318683776\n",
      "epoch 1 batch id 67201 / 225000 loss 0.8300959467887878 train acc 0.5907612981949674\n",
      "epoch 1 batch id 67301 / 225000 loss 0.6285375356674194 train acc 0.5909793316592621\n",
      "epoch 1 batch id 67401 / 225000 loss 1.6682692766189575 train acc 0.5911410809928636\n",
      "epoch 1 batch id 67501 / 225000 loss 3.5217649936676025 train acc 0.5912764255344365\n",
      "epoch 1 batch id 67601 / 225000 loss 0.01202527154237032 train acc 0.5914668422064763\n",
      "epoch 1 batch id 67701 / 225000 loss 0.7259399890899658 train acc 0.5916825453095228\n",
      "epoch 1 batch id 67801 / 225000 loss 0.10103539377450943 train acc 0.5919086739133641\n",
      "epoch 1 batch id 67901 / 225000 loss 0.014678210951387882 train acc 0.592119409139777\n",
      "epoch 1 batch id 68001 / 225000 loss 2.93533992767334 train acc 0.5922523198188262\n",
      "epoch 1 batch id 68101 / 225000 loss 0.03303149715065956 train acc 0.5925096547774629\n",
      "epoch 1 batch id 68201 / 225000 loss 4.500061988830566 train acc 0.5926672629433586\n",
      "epoch 1 batch id 68301 / 225000 loss 2.015543222427368 train acc 0.5929049355060687\n",
      "epoch 1 batch id 68401 / 225000 loss 1.257251501083374 train acc 0.5930797795353869\n",
      "epoch 1 batch id 68501 / 225000 loss 0.02186083234846592 train acc 0.5932869593144625\n",
      "epoch 1 batch id 68601 / 225000 loss 0.01205396093428135 train acc 0.5934789580326817\n",
      "epoch 1 batch id 68701 / 225000 loss 2.0627479553222656 train acc 0.593684953639685\n",
      "epoch 1 batch id 68801 / 225000 loss 0.9924563765525818 train acc 0.593864914754146\n",
      "epoch 1 batch id 68901 / 225000 loss 1.8932088613510132 train acc 0.5940842658306846\n",
      "epoch 1 batch id 69001 / 225000 loss 0.6864587068557739 train acc 0.5943464587469747\n",
      "epoch 1 batch id 69101 / 225000 loss 0.7907634973526001 train acc 0.5944342339474104\n",
      "epoch 1 batch id 69201 / 225000 loss 1.2763195037841797 train acc 0.5946265227381107\n",
      "epoch 1 batch id 69301 / 225000 loss 0.004650260787457228 train acc 0.5948579385578852\n",
      "epoch 1 batch id 69401 / 225000 loss 0.007714452221989632 train acc 0.5951066987507385\n",
      "epoch 1 batch id 69501 / 225000 loss 1.3839619159698486 train acc 0.5952828016863067\n",
      "epoch 1 batch id 69601 / 225000 loss 0.007394690997898579 train acc 0.595548196146607\n",
      "epoch 1 batch id 69701 / 225000 loss 0.26637956500053406 train acc 0.5957626145966342\n",
      "epoch 1 batch id 69801 / 225000 loss 1.4307427406311035 train acc 0.5959728370653715\n",
      "epoch 1 batch id 69901 / 225000 loss 1.4263019561767578 train acc 0.5961753050743194\n",
      "epoch 1 batch id 70001 / 225000 loss 0.031002555042505264 train acc 0.5963664804788503\n",
      "epoch 1 batch id 70101 / 225000 loss 1.0815916061401367 train acc 0.5965963395671959\n",
      "epoch 1 batch id 70201 / 225000 loss 2.298569440841675 train acc 0.5968112989843449\n",
      "epoch 1 batch id 70301 / 225000 loss 1.1035490036010742 train acc 0.5970292029985349\n",
      "epoch 1 batch id 70401 / 225000 loss 1.7664262056350708 train acc 0.5972003238590361\n",
      "epoch 1 batch id 70501 / 225000 loss 2.13183856010437 train acc 0.5974028737181033\n",
      "epoch 1 batch id 70601 / 225000 loss 1.885120153427124 train acc 0.5975977677370009\n",
      "epoch 1 batch id 70701 / 225000 loss 3.2235727310180664 train acc 0.5978345426514476\n",
      "epoch 1 batch id 70801 / 225000 loss 1.6149643659591675 train acc 0.5980318074603466\n",
      "epoch 1 batch id 70901 / 225000 loss 1.239323616027832 train acc 0.5982426199912554\n",
      "epoch 1 batch id 71001 / 225000 loss 0.31677499413490295 train acc 0.598495091618428\n",
      "epoch 1 batch id 71101 / 225000 loss 1.344770073890686 train acc 0.5987257563184766\n",
      "epoch 1 batch id 71201 / 225000 loss 2.8043909072875977 train acc 0.5990014185194028\n",
      "epoch 1 batch id 71301 / 225000 loss 0.44212812185287476 train acc 0.5992272198145888\n",
      "epoch 1 batch id 71401 / 225000 loss 3.3299765586853027 train acc 0.5993998683491828\n",
      "epoch 1 batch id 71501 / 225000 loss 0.3110342025756836 train acc 0.5996524524132529\n",
      "epoch 1 batch id 71601 / 225000 loss 0.13069157302379608 train acc 0.5999008393737517\n",
      "epoch 1 batch id 71701 / 225000 loss 3.3453197479248047 train acc 0.6001345866863782\n",
      "epoch 1 batch id 71801 / 225000 loss 1.758732557296753 train acc 0.6003015278338741\n",
      "epoch 1 batch id 71901 / 225000 loss 1.6505156755447388 train acc 0.6005062516515765\n",
      "epoch 1 batch id 72001 / 225000 loss 1.3277709484100342 train acc 0.6007624894098693\n",
      "epoch 1 batch id 72101 / 225000 loss 1.454513430595398 train acc 0.6008931914952635\n",
      "epoch 1 batch id 72201 / 225000 loss 0.6204294562339783 train acc 0.601120483095802\n",
      "epoch 1 batch id 72301 / 225000 loss 2.6821651458740234 train acc 0.6013229415914026\n",
      "epoch 1 batch id 72401 / 225000 loss 0.7753891348838806 train acc 0.6015317467990774\n",
      "epoch 1 batch id 72501 / 225000 loss 2.1708078384399414 train acc 0.6017089419456283\n",
      "epoch 1 batch id 72601 / 225000 loss 0.01728985644876957 train acc 0.6018718750430435\n",
      "epoch 1 batch id 72701 / 225000 loss 2.5419769287109375 train acc 0.6020171662012902\n",
      "epoch 1 batch id 72801 / 225000 loss 2.3063981533050537 train acc 0.6022238705512287\n",
      "epoch 1 batch id 72901 / 225000 loss 1.1752372980117798 train acc 0.6024128612776231\n",
      "epoch 1 batch id 73001 / 225000 loss 0.9845070838928223 train acc 0.6025842111751893\n",
      "epoch 1 batch id 73101 / 225000 loss 1.453768014907837 train acc 0.6027516723437436\n",
      "epoch 1 batch id 73201 / 225000 loss 0.6964645385742188 train acc 0.602918675974372\n",
      "epoch 1 batch id 73301 / 225000 loss 0.7259653806686401 train acc 0.6031125086970164\n",
      "epoch 1 batch id 73401 / 225000 loss 1.1308822631835938 train acc 0.603278565687116\n",
      "epoch 1 batch id 73501 / 225000 loss 0.09493830054998398 train acc 0.6035053944844287\n",
      "epoch 1 batch id 73601 / 225000 loss 0.8307285904884338 train acc 0.6037010366706974\n",
      "epoch 1 batch id 73701 / 225000 loss 3.226212501525879 train acc 0.6038927558649136\n",
      "epoch 1 batch id 73801 / 225000 loss 0.6503722667694092 train acc 0.604060243086137\n",
      "epoch 1 batch id 73901 / 225000 loss 1.0618661642074585 train acc 0.6042577231701871\n",
      "epoch 1 batch id 74001 / 225000 loss 2.6895437240600586 train acc 0.6044512911987676\n",
      "epoch 1 batch id 74101 / 225000 loss 0.8046543002128601 train acc 0.6045971039527132\n",
      "epoch 1 batch id 74201 / 225000 loss 4.87937593460083 train acc 0.6047425236856646\n",
      "epoch 1 batch id 74301 / 225000 loss 0.46517297625541687 train acc 0.6049683045988614\n",
      "epoch 1 batch id 74401 / 225000 loss 1.6073800325393677 train acc 0.6050960336554616\n",
      "epoch 1 batch id 74501 / 225000 loss 0.3356998860836029 train acc 0.6052334867988349\n",
      "epoch 1 batch id 74601 / 225000 loss 1.628627061843872 train acc 0.6054241900242624\n",
      "epoch 1 batch id 74701 / 225000 loss 1.4635119438171387 train acc 0.605607689321428\n",
      "epoch 1 batch id 74801 / 225000 loss 1.5642988681793213 train acc 0.6057940401866285\n",
      "epoch 1 batch id 74901 / 225000 loss 1.3553506135940552 train acc 0.6059398405895783\n",
      "epoch 1 batch id 75001 / 225000 loss 0.9327043294906616 train acc 0.6060985853521953\n",
      "epoch 1 batch id 75101 / 225000 loss 1.628158688545227 train acc 0.6063201555238945\n",
      "epoch 1 batch id 75201 / 225000 loss 1.7188470363616943 train acc 0.6064846212151435\n",
      "epoch 1 batch id 75301 / 225000 loss 2.2933897972106934 train acc 0.6066054899669328\n",
      "epoch 1 batch id 75401 / 225000 loss 0.15560612082481384 train acc 0.6067989814458694\n",
      "epoch 1 batch id 75501 / 225000 loss 1.199031949043274 train acc 0.6069919603713858\n",
      "epoch 1 batch id 75601 / 225000 loss 4.061944484710693 train acc 0.6071678946045688\n",
      "epoch 1 batch id 75701 / 225000 loss 0.881912112236023 train acc 0.6073334566254078\n",
      "epoch 1 batch id 75801 / 225000 loss 1.8164145946502686 train acc 0.6074754950462395\n",
      "epoch 1 batch id 75901 / 225000 loss 1.3223580121994019 train acc 0.6077258534143161\n",
      "epoch 1 batch id 76001 / 225000 loss 0.39787328243255615 train acc 0.607896606623597\n",
      "epoch 1 batch id 76101 / 225000 loss 0.7652788758277893 train acc 0.6080767664025439\n",
      "epoch 1 batch id 76201 / 225000 loss 1.0365726947784424 train acc 0.6082269261558247\n",
      "epoch 1 batch id 76301 / 225000 loss 0.013136958703398705 train acc 0.6084356692572837\n",
      "epoch 1 batch id 76401 / 225000 loss 0.2104892134666443 train acc 0.6086275048755906\n",
      "epoch 1 batch id 76501 / 225000 loss 0.004321419168263674 train acc 0.6088286427628397\n",
      "epoch 1 batch id 76601 / 225000 loss 0.009965945035219193 train acc 0.6090325191577134\n",
      "epoch 1 batch id 76701 / 225000 loss 0.7108967900276184 train acc 0.6091706757408639\n",
      "epoch 1 batch id 76801 / 225000 loss 1.9619438648223877 train acc 0.6093345138735172\n",
      "epoch 1 batch id 76901 / 225000 loss 2.88565731048584 train acc 0.6094914240386992\n",
      "epoch 1 batch id 77001 / 225000 loss 1.3454135656356812 train acc 0.6096674069167933\n",
      "epoch 1 batch id 77101 / 225000 loss 0.3606223165988922 train acc 0.6098396907951907\n",
      "epoch 1 batch id 77201 / 225000 loss 1.9518693685531616 train acc 0.6100115283480784\n",
      "epoch 1 batch id 77301 / 225000 loss 0.0036780601367354393 train acc 0.6101893895292428\n",
      "epoch 1 batch id 77401 / 225000 loss 2.123135805130005 train acc 0.6103829407888787\n",
      "epoch 1 batch id 77501 / 225000 loss 0.14641866087913513 train acc 0.6105598637436936\n",
      "epoch 1 batch id 77601 / 225000 loss 2.7522313594818115 train acc 0.6107331091094187\n",
      "epoch 1 batch id 77701 / 225000 loss 0.03934226557612419 train acc 0.610912343470483\n",
      "epoch 1 batch id 77801 / 225000 loss 0.8847717642784119 train acc 0.6110911170807574\n",
      "epoch 1 batch id 77901 / 225000 loss 1.1864773035049438 train acc 0.6113271973402139\n",
      "epoch 1 batch id 78001 / 225000 loss 1.0431426763534546 train acc 0.61146331457289\n",
      "epoch 1 batch id 78101 / 225000 loss 0.4207259714603424 train acc 0.6117015147053175\n",
      "epoch 1 batch id 78201 / 225000 loss 0.0019803945906460285 train acc 0.6118751678367285\n",
      "epoch 1 batch id 78301 / 225000 loss 0.10472582280635834 train acc 0.612022834957408\n",
      "epoch 1 batch id 78401 / 225000 loss 0.017644284293055534 train acc 0.612176502850729\n",
      "epoch 1 batch id 78501 / 225000 loss 0.025037731975317 train acc 0.6122915631648005\n",
      "epoch 1 batch id 78601 / 225000 loss 2.176632881164551 train acc 0.6124285950560425\n",
      "epoch 1 batch id 78701 / 225000 loss 1.5420058965682983 train acc 0.6125684552928171\n",
      "epoch 1 batch id 78801 / 225000 loss 1.3934937715530396 train acc 0.6127301683988782\n",
      "epoch 1 batch id 78901 / 225000 loss 1.4614120721817017 train acc 0.6128502807315497\n",
      "epoch 1 batch id 79001 / 225000 loss 1.0870277881622314 train acc 0.6130302148074075\n",
      "epoch 1 batch id 79101 / 225000 loss 0.8220038414001465 train acc 0.6131907308377896\n",
      "epoch 1 batch id 79201 / 225000 loss 0.01096227578818798 train acc 0.6133413719523744\n",
      "epoch 1 batch id 79301 / 225000 loss 3.6572647094726562 train acc 0.6134821755085056\n",
      "epoch 1 batch id 79401 / 225000 loss 0.3564334809780121 train acc 0.6136572587247012\n",
      "epoch 1 batch id 79501 / 225000 loss 2.9473142623901367 train acc 0.613835046100049\n",
      "epoch 1 batch id 79601 / 225000 loss 2.242652416229248 train acc 0.6140375120915567\n",
      "epoch 1 batch id 79701 / 225000 loss 1.718396782875061 train acc 0.6142269231251803\n",
      "epoch 1 batch id 79801 / 225000 loss 2.9513638019561768 train acc 0.6144221250360271\n",
      "epoch 1 batch id 79901 / 225000 loss 0.13200664520263672 train acc 0.6145261010500495\n",
      "epoch 1 batch id 80001 / 225000 loss 1.248208999633789 train acc 0.6146891913851077\n",
      "epoch 1 batch id 80101 / 225000 loss 0.7212926149368286 train acc 0.6148674798067439\n",
      "epoch 1 batch id 80201 / 225000 loss 3.1318600177764893 train acc 0.6150453236243937\n",
      "epoch 1 batch id 80301 / 225000 loss 1.6552164554595947 train acc 0.6152538573616767\n",
      "epoch 1 batch id 80401 / 225000 loss 1.8966412544250488 train acc 0.6154121217397793\n",
      "epoch 1 batch id 80501 / 225000 loss 0.0023862775415182114 train acc 0.6155606762648911\n",
      "epoch 1 batch id 80601 / 225000 loss 3.7182974815368652 train acc 0.6157398791578268\n",
      "epoch 1 batch id 80701 / 225000 loss 4.56318473815918 train acc 0.6158721701094162\n",
      "epoch 1 batch id 80801 / 225000 loss 3.2783570289611816 train acc 0.6160165096966622\n",
      "epoch 1 batch id 80901 / 225000 loss 1.0142908096313477 train acc 0.6162315669769224\n",
      "epoch 1 batch id 81001 / 225000 loss 1.1648297309875488 train acc 0.6163781928618165\n",
      "epoch 1 batch id 81101 / 225000 loss 1.560807228088379 train acc 0.6164967139739337\n",
      "epoch 1 batch id 81201 / 225000 loss 2.9218499660491943 train acc 0.6166364946244505\n",
      "epoch 1 batch id 81301 / 225000 loss 0.2734900712966919 train acc 0.6168097563375604\n",
      "epoch 1 batch id 81401 / 225000 loss 2.9667723178863525 train acc 0.6169488089826907\n",
      "epoch 1 batch id 81501 / 225000 loss 1.3348487615585327 train acc 0.6170660482693464\n",
      "epoch 1 batch id 81601 / 225000 loss 0.23090490698814392 train acc 0.6172013823360007\n",
      "epoch 1 batch id 81701 / 225000 loss 0.7901701331138611 train acc 0.6173792242445013\n",
      "epoch 1 batch id 81801 / 225000 loss 2.2243828773498535 train acc 0.6175321817581693\n",
      "epoch 1 batch id 81901 / 225000 loss 1.509098768234253 train acc 0.6176786608222122\n",
      "epoch 1 batch id 82001 / 225000 loss 0.9469904899597168 train acc 0.6178430750844502\n",
      "epoch 1 batch id 82101 / 225000 loss 0.6389644145965576 train acc 0.6179766385305904\n",
      "epoch 1 batch id 82201 / 225000 loss 1.9574618339538574 train acc 0.618134207613046\n",
      "epoch 1 batch id 82301 / 225000 loss 0.10060060024261475 train acc 0.6182913937862238\n",
      "epoch 1 batch id 82401 / 225000 loss 0.533785343170166 train acc 0.6185149452069757\n",
      "epoch 1 batch id 82501 / 225000 loss 1.85862398147583 train acc 0.6186591677676634\n",
      "epoch 1 batch id 82601 / 225000 loss 1.0248538255691528 train acc 0.6187969879299282\n",
      "epoch 1 batch id 82701 / 225000 loss 1.2972089052200317 train acc 0.6189314518566885\n",
      "epoch 1 batch id 82801 / 225000 loss 2.203202724456787 train acc 0.619092764580138\n",
      "epoch 1 batch id 82901 / 225000 loss 1.5080019235610962 train acc 0.6192416255533709\n",
      "epoch 1 batch id 83001 / 225000 loss 2.605210542678833 train acc 0.6193600077107505\n",
      "epoch 1 batch id 83101 / 225000 loss 2.8597803115844727 train acc 0.619475096569235\n",
      "epoch 1 batch id 83201 / 225000 loss 2.103210687637329 train acc 0.6196199564909075\n",
      "epoch 1 batch id 83301 / 225000 loss 0.5605305433273315 train acc 0.6198184895739547\n",
      "epoch 1 batch id 83401 / 225000 loss 3.8849892616271973 train acc 0.6199835733384492\n",
      "epoch 1 batch id 83501 / 225000 loss 0.001882927492260933 train acc 0.620100358079544\n",
      "epoch 1 batch id 83601 / 225000 loss 1.2751796245574951 train acc 0.6202407865934618\n",
      "epoch 1 batch id 83701 / 225000 loss 0.48012495040893555 train acc 0.6203719190929619\n",
      "epoch 1 batch id 83801 / 225000 loss 1.5572872161865234 train acc 0.6205445042421928\n",
      "epoch 1 batch id 83901 / 225000 loss 0.0308969859033823 train acc 0.62069284037139\n",
      "epoch 1 batch id 84001 / 225000 loss 3.082521677017212 train acc 0.6208348710134404\n",
      "epoch 1 batch id 84101 / 225000 loss 1.5069668292999268 train acc 0.6209290020332695\n",
      "epoch 1 batch id 84201 / 225000 loss 2.4019484519958496 train acc 0.6210822911841902\n",
      "epoch 1 batch id 84301 / 225000 loss 1.0893620252609253 train acc 0.6212619067389473\n",
      "epoch 1 batch id 84401 / 225000 loss 0.5497641563415527 train acc 0.6214055520669186\n",
      "epoch 1 batch id 84501 / 225000 loss 2.712610960006714 train acc 0.6215518159548408\n",
      "epoch 1 batch id 84601 / 225000 loss 0.4698823094367981 train acc 0.6217095542605879\n",
      "epoch 1 batch id 84701 / 225000 loss 0.0056345416232943535 train acc 0.621887581020295\n",
      "epoch 1 batch id 84801 / 225000 loss 0.6852468848228455 train acc 0.6220062263416705\n",
      "epoch 1 batch id 84901 / 225000 loss 3.3469529151916504 train acc 0.6221216475659886\n",
      "epoch 1 batch id 85001 / 225000 loss 1.1297001838684082 train acc 0.6222544440653639\n",
      "epoch 1 batch id 85101 / 225000 loss 3.606022357940674 train acc 0.6223928038448432\n",
      "epoch 1 batch id 85201 / 225000 loss 0.016249677166342735 train acc 0.6225719181699745\n",
      "epoch 1 batch id 85301 / 225000 loss 0.9193653464317322 train acc 0.6227066505668163\n",
      "epoch 1 batch id 85401 / 225000 loss 0.02259179763495922 train acc 0.6228322853362372\n",
      "epoch 1 batch id 85501 / 225000 loss 3.6163039207458496 train acc 0.6229547022841838\n",
      "epoch 1 batch id 85601 / 225000 loss 0.3581874668598175 train acc 0.6230914358477121\n",
      "epoch 1 batch id 85701 / 225000 loss 2.1009135246276855 train acc 0.623257021505\n",
      "epoch 1 batch id 85801 / 225000 loss 2.211514472961426 train acc 0.62339308399669\n",
      "epoch 1 batch id 85901 / 225000 loss 1.1327377557754517 train acc 0.6235492019883354\n",
      "epoch 1 batch id 86001 / 225000 loss 0.06596231460571289 train acc 0.6236410041743701\n",
      "epoch 1 batch id 86101 / 225000 loss 0.06194554641842842 train acc 0.6237877608854717\n",
      "epoch 1 batch id 86201 / 225000 loss 4.846896171569824 train acc 0.6239428776928342\n",
      "epoch 1 batch id 86301 / 225000 loss 1.7762885093688965 train acc 0.6241179128862934\n",
      "epoch 1 batch id 86401 / 225000 loss 0.014248477295041084 train acc 0.6242578210900337\n",
      "epoch 1 batch id 86501 / 225000 loss 3.006049156188965 train acc 0.6244089663703309\n",
      "epoch 1 batch id 86601 / 225000 loss 1.8096106052398682 train acc 0.6245366681678041\n",
      "epoch 1 batch id 86701 / 225000 loss 0.012620017863810062 train acc 0.624666958858606\n",
      "epoch 1 batch id 86801 / 225000 loss 2.4090304374694824 train acc 0.6247710279835486\n",
      "epoch 1 batch id 86901 / 225000 loss 1.2501749992370605 train acc 0.6248978722914581\n",
      "epoch 1 batch id 87001 / 225000 loss 0.3434363603591919 train acc 0.6250445397179343\n",
      "epoch 1 batch id 87101 / 225000 loss 1.5779743194580078 train acc 0.6251736489822161\n",
      "epoch 1 batch id 87201 / 225000 loss 0.8413266539573669 train acc 0.6252823935505327\n",
      "epoch 1 batch id 87301 / 225000 loss 1.0623575448989868 train acc 0.6253765707151121\n",
      "epoch 1 batch id 87401 / 225000 loss 0.005822730250656605 train acc 0.625542041853068\n",
      "epoch 1 batch id 87501 / 225000 loss 0.01277436688542366 train acc 0.6256757065633536\n",
      "epoch 1 batch id 87601 / 225000 loss 1.861234426498413 train acc 0.6257662583760459\n",
      "epoch 1 batch id 87701 / 225000 loss 1.481136679649353 train acc 0.6258851096338697\n",
      "epoch 1 batch id 87801 / 225000 loss 2.933087110519409 train acc 0.6259809113791415\n",
      "epoch 1 batch id 87901 / 225000 loss 1.1581193208694458 train acc 0.6261163126699355\n",
      "epoch 1 batch id 88001 / 225000 loss 0.9872425198554993 train acc 0.6262542471108283\n",
      "epoch 1 batch id 88101 / 225000 loss 0.02515825815498829 train acc 0.6263748425103006\n",
      "epoch 1 batch id 88201 / 225000 loss 0.08194981515407562 train acc 0.6264781578440154\n",
      "epoch 1 batch id 88301 / 225000 loss 1.3891847133636475 train acc 0.626598226520651\n",
      "epoch 1 batch id 88401 / 225000 loss 0.052139297127723694 train acc 0.6267123675071549\n",
      "epoch 1 batch id 88501 / 225000 loss 0.5881041884422302 train acc 0.6268375498581937\n",
      "epoch 1 batch id 88601 / 225000 loss 0.2348518669605255 train acc 0.6269285899707678\n",
      "epoch 1 batch id 88701 / 225000 loss 2.311352491378784 train acc 0.627081430874511\n",
      "epoch 1 batch id 88801 / 225000 loss 1.6305944919586182 train acc 0.6271776218736276\n",
      "epoch 1 batch id 88901 / 225000 loss 1.2446058988571167 train acc 0.6272904691735751\n",
      "epoch 1 batch id 89001 / 225000 loss 1.518129587173462 train acc 0.6273974449725284\n",
      "epoch 1 batch id 89101 / 225000 loss 1.3547768592834473 train acc 0.6275378503047104\n",
      "epoch 1 batch id 89201 / 225000 loss 0.004599898122251034 train acc 0.6276807434894227\n",
      "epoch 1 batch id 89301 / 225000 loss 0.19887180626392365 train acc 0.6278037200031354\n",
      "epoch 1 batch id 89401 / 225000 loss 1.5833600759506226 train acc 0.6279459961297972\n",
      "epoch 1 batch id 89501 / 225000 loss 2.0262012481689453 train acc 0.6280711947352543\n",
      "epoch 1 batch id 89601 / 225000 loss 1.4566287994384766 train acc 0.6282156449146773\n",
      "epoch 1 batch id 89701 / 225000 loss 0.1528809815645218 train acc 0.6282594396940948\n",
      "epoch 1 batch id 89801 / 225000 loss 0.9391064643859863 train acc 0.6284172782040289\n",
      "epoch 1 batch id 89901 / 225000 loss 4.3721771240234375 train acc 0.628549738045183\n",
      "epoch 1 batch id 90001 / 225000 loss 0.10040472447872162 train acc 0.6287041255097165\n",
      "epoch 1 batch id 90101 / 225000 loss 0.8322795033454895 train acc 0.6288415222916505\n",
      "epoch 1 batch id 90201 / 225000 loss 0.021807916462421417 train acc 0.6289702996640836\n",
      "epoch 1 batch id 90301 / 225000 loss 2.6769137382507324 train acc 0.6291181714488212\n",
      "epoch 1 batch id 90401 / 225000 loss 1.364490032196045 train acc 0.6292408269820025\n",
      "epoch 1 batch id 90501 / 225000 loss 2.1974287033081055 train acc 0.6294018850620435\n",
      "epoch 1 batch id 90601 / 225000 loss 0.9421731233596802 train acc 0.6294991225262414\n",
      "epoch 1 batch id 90701 / 225000 loss 0.8677238821983337 train acc 0.6296154397415684\n",
      "epoch 1 batch id 90801 / 225000 loss 1.0873463153839111 train acc 0.6297672933117476\n",
      "epoch 1 batch id 90901 / 225000 loss 2.810736894607544 train acc 0.6298693083684448\n",
      "epoch 1 batch id 91001 / 225000 loss 0.9424518942832947 train acc 0.6299875825540379\n",
      "epoch 1 batch id 91101 / 225000 loss 0.6667174696922302 train acc 0.6301138297054917\n",
      "epoch 1 batch id 91201 / 225000 loss 0.03377570956945419 train acc 0.6302452823982193\n",
      "epoch 1 batch id 91301 / 225000 loss 1.0493085384368896 train acc 0.6303928763102267\n",
      "epoch 1 batch id 91401 / 225000 loss 2.5514113903045654 train acc 0.6304635616678155\n",
      "epoch 1 batch id 91501 / 225000 loss 2.373291254043579 train acc 0.630536824734156\n",
      "epoch 1 batch id 91601 / 225000 loss 1.4048875570297241 train acc 0.6306372201176843\n",
      "epoch 1 batch id 91701 / 225000 loss 2.1143834590911865 train acc 0.6307346702871288\n",
      "epoch 1 batch id 91801 / 225000 loss 0.4994977116584778 train acc 0.630916329887474\n",
      "epoch 1 batch id 91901 / 225000 loss 2.420783758163452 train acc 0.6310431877781526\n",
      "epoch 1 batch id 92001 / 225000 loss 2.304234743118286 train acc 0.6311181400202172\n",
      "epoch 1 batch id 92101 / 225000 loss 1.904662847518921 train acc 0.6312309312602469\n",
      "epoch 1 batch id 92201 / 225000 loss 0.017926150932908058 train acc 0.6313868613138686\n",
      "epoch 1 batch id 92301 / 225000 loss 1.191675066947937 train acc 0.6314882829005103\n",
      "epoch 1 batch id 92401 / 225000 loss 2.0462405681610107 train acc 0.6315597233796171\n",
      "epoch 1 batch id 92501 / 225000 loss 0.09580196440219879 train acc 0.6317066842520621\n",
      "epoch 1 batch id 92601 / 225000 loss 0.0729006826877594 train acc 0.6317804343365623\n",
      "epoch 1 batch id 92701 / 225000 loss 1.2457553148269653 train acc 0.6318944779452217\n",
      "epoch 1 batch id 92801 / 225000 loss 2.6179487705230713 train acc 0.6319840303445006\n",
      "epoch 1 batch id 92901 / 225000 loss 1.2994529008865356 train acc 0.6320733899527454\n",
      "epoch 1 batch id 93001 / 225000 loss 0.5278220176696777 train acc 0.6321383641036118\n",
      "epoch 1 batch id 93101 / 225000 loss 0.028279846534132957 train acc 0.6322219954672882\n",
      "epoch 1 batch id 93201 / 225000 loss 0.1567494124174118 train acc 0.6323188592397078\n",
      "epoch 1 batch id 93301 / 225000 loss 1.3007586002349854 train acc 0.6324396308721235\n",
      "epoch 1 batch id 93401 / 225000 loss 4.7891950607299805 train acc 0.6325494373721908\n",
      "epoch 1 batch id 93501 / 225000 loss 0.03280085697770119 train acc 0.6326322713126062\n",
      "epoch 1 batch id 93601 / 225000 loss 1.3914235830307007 train acc 0.632717599170949\n",
      "epoch 1 batch id 93701 / 225000 loss 0.8663419485092163 train acc 0.6328481019412813\n",
      "epoch 1 batch id 93801 / 225000 loss 1.7624609470367432 train acc 0.6329490090723979\n",
      "epoch 1 batch id 93901 / 225000 loss 0.19435995817184448 train acc 0.6331082736073098\n",
      "epoch 1 batch id 94001 / 225000 loss 0.5298396348953247 train acc 0.633198051084563\n",
      "epoch 1 batch id 94101 / 225000 loss 1.059931993484497 train acc 0.6332982646305565\n",
      "epoch 1 batch id 94201 / 225000 loss 0.840266764163971 train acc 0.6334407278054374\n",
      "epoch 1 batch id 94301 / 225000 loss 2.2829747200012207 train acc 0.6335351692983108\n",
      "epoch 1 batch id 94401 / 225000 loss 0.7417857050895691 train acc 0.6336479486446118\n",
      "epoch 1 batch id 94501 / 225000 loss 0.03561852499842644 train acc 0.6337604893069915\n",
      "epoch 1 batch id 94601 / 225000 loss 1.152539610862732 train acc 0.6338886481115421\n",
      "epoch 1 batch id 94701 / 225000 loss 0.003194918157532811 train acc 0.6340508547956198\n",
      "epoch 1 batch id 94801 / 225000 loss 0.007870109751820564 train acc 0.6342390903049546\n",
      "epoch 1 batch id 94901 / 225000 loss 0.3466683030128479 train acc 0.6343821456043667\n",
      "epoch 1 batch id 95001 / 225000 loss 0.7822445034980774 train acc 0.6344696371617141\n",
      "epoch 1 batch id 95101 / 225000 loss 0.010530702769756317 train acc 0.6345648310743315\n",
      "epoch 1 batch id 95201 / 225000 loss 2.147850513458252 train acc 0.6346834592073612\n",
      "epoch 1 batch id 95301 / 225000 loss 0.607832670211792 train acc 0.6347887220490865\n",
      "epoch 1 batch id 95401 / 225000 loss 0.01021596323698759 train acc 0.6348701795578663\n",
      "epoch 1 batch id 95501 / 225000 loss 0.010552069172263145 train acc 0.6349593197976985\n",
      "epoch 1 batch id 95601 / 225000 loss 0.520378053188324 train acc 0.6350613487306618\n",
      "epoch 1 batch id 95701 / 225000 loss 1.9941811561584473 train acc 0.6351501029247343\n",
      "epoch 1 batch id 95801 / 225000 loss 1.6654056310653687 train acc 0.6352647675911525\n",
      "epoch 1 batch id 95901 / 225000 loss 2.7590739727020264 train acc 0.6353870136912024\n",
      "epoch 1 batch id 96001 / 225000 loss 2.065579652786255 train acc 0.635459526463266\n",
      "epoch 1 batch id 96101 / 225000 loss 3.4116063117980957 train acc 0.6355605040530276\n",
      "epoch 1 batch id 96201 / 225000 loss 0.45423755049705505 train acc 0.6356716666146922\n",
      "epoch 1 batch id 96301 / 225000 loss 1.290963053703308 train acc 0.635782598311544\n",
      "epoch 1 batch id 96401 / 225000 loss 2.915764331817627 train acc 0.6358466198483418\n",
      "epoch 1 batch id 96501 / 225000 loss 0.12277485430240631 train acc 0.6359700935741599\n",
      "epoch 1 batch id 96601 / 225000 loss 0.0064942073076963425 train acc 0.6360596681193776\n",
      "epoch 1 batch id 96701 / 225000 loss 3.2168197631835938 train acc 0.636182666156503\n",
      "epoch 1 batch id 96801 / 225000 loss 0.008578226901590824 train acc 0.6362821665065443\n",
      "epoch 1 batch id 96901 / 225000 loss 4.761775970458984 train acc 0.636396941208037\n",
      "epoch 1 batch id 97001 / 225000 loss 1.6600407361984253 train acc 0.636475397160854\n",
      "epoch 1 batch id 97101 / 225000 loss 1.193092703819275 train acc 0.6365923110987528\n",
      "epoch 1 batch id 97201 / 225000 loss 0.046120647341012955 train acc 0.6366781205954671\n",
      "epoch 1 batch id 97301 / 225000 loss 0.44440528750419617 train acc 0.6367457682860402\n",
      "epoch 1 batch id 97401 / 225000 loss 1.932438850402832 train acc 0.6368697446638125\n",
      "epoch 1 batch id 97501 / 225000 loss 0.008423898369073868 train acc 0.637006287115004\n",
      "epoch 1 batch id 97601 / 225000 loss 1.609989881515503 train acc 0.6370836364381512\n",
      "epoch 1 batch id 97701 / 225000 loss 0.01690731756389141 train acc 0.6371915333517569\n",
      "epoch 1 batch id 97801 / 225000 loss 0.013514186255633831 train acc 0.637319659308187\n",
      "epoch 1 batch id 97901 / 225000 loss 0.02953949011862278 train acc 0.6374373091183951\n",
      "epoch 1 batch id 98001 / 225000 loss 0.0042483205907046795 train acc 0.6375521678350221\n",
      "epoch 1 batch id 98101 / 225000 loss 1.7271623611450195 train acc 0.6376718891754416\n",
      "epoch 1 batch id 98201 / 225000 loss 0.2240147888660431 train acc 0.6377633628985448\n",
      "epoch 1 batch id 98301 / 225000 loss 0.004459556192159653 train acc 0.6378470208848334\n",
      "epoch 1 batch id 98401 / 225000 loss 0.592451274394989 train acc 0.6379787807034482\n",
      "epoch 1 batch id 98501 / 225000 loss 0.05254806950688362 train acc 0.6380925066750591\n",
      "epoch 1 batch id 98601 / 225000 loss 1.0927969217300415 train acc 0.6381958600825549\n",
      "epoch 1 batch id 98701 / 225000 loss 1.461544394493103 train acc 0.6382888724531667\n",
      "epoch 1 batch id 98801 / 225000 loss 1.2961903810501099 train acc 0.638432303316768\n",
      "epoch 1 batch id 98901 / 225000 loss 2.371272563934326 train acc 0.6385248885248885\n",
      "epoch 1 batch id 99001 / 225000 loss 3.9276089668273926 train acc 0.6386299128291634\n",
      "epoch 1 batch id 99101 / 225000 loss 2.2648773193359375 train acc 0.6387019303538813\n",
      "epoch 1 batch id 99201 / 225000 loss 1.1479549407958984 train acc 0.6387511214604692\n",
      "epoch 1 batch id 99301 / 225000 loss 0.13684679567813873 train acc 0.6388505654525131\n",
      "epoch 1 batch id 99401 / 225000 loss 0.8753625750541687 train acc 0.6389422641623324\n",
      "epoch 1 batch id 99501 / 225000 loss 2.0855209827423096 train acc 0.6390262409423021\n",
      "epoch 1 batch id 99601 / 225000 loss 0.018180079758167267 train acc 0.6391577393801267\n",
      "epoch 1 batch id 99701 / 225000 loss 0.3796737790107727 train acc 0.6392287940943421\n",
      "epoch 1 batch id 99801 / 225000 loss 0.08746249973773956 train acc 0.6393147363252873\n",
      "epoch 1 batch id 99901 / 225000 loss 0.056837473064661026 train acc 0.6394455510955847\n",
      "epoch 1 batch id 100001 / 225000 loss 0.02784796617925167 train acc 0.6396086039139609\n",
      "epoch 1 batch id 100101 / 225000 loss 0.7797828912734985 train acc 0.6396964066293044\n",
      "epoch 1 batch id 100201 / 225000 loss 1.333994746208191 train acc 0.6397765491362362\n",
      "epoch 1 batch id 100301 / 225000 loss 1.4910045862197876 train acc 0.6398640093319109\n",
      "epoch 1 batch id 100401 / 225000 loss 3.010159492492676 train acc 0.639956275335903\n",
      "epoch 1 batch id 100501 / 225000 loss 0.004863697104156017 train acc 0.6400707455647208\n",
      "epoch 1 batch id 100601 / 225000 loss 0.3073878288269043 train acc 0.6401377719903381\n",
      "epoch 1 batch id 100701 / 225000 loss 3.5112507343292236 train acc 0.6402021826992781\n",
      "epoch 1 batch id 100801 / 225000 loss 0.10758326947689056 train acc 0.640296227219968\n",
      "epoch 1 batch id 100901 / 225000 loss 1.6491219997406006 train acc 0.6403851299788902\n",
      "epoch 1 batch id 101001 / 225000 loss 0.0034772565122693777 train acc 0.6404862328095762\n",
      "epoch 1 batch id 101101 / 225000 loss 0.7034343481063843 train acc 0.6406019722851406\n",
      "epoch 1 batch id 101201 / 225000 loss 0.015211428515613079 train acc 0.6406977203782571\n",
      "epoch 1 batch id 101301 / 225000 loss 1.4366198778152466 train acc 0.640776004185546\n",
      "epoch 1 batch id 101401 / 225000 loss 0.9574587941169739 train acc 0.6408763227187109\n",
      "epoch 1 batch id 101501 / 225000 loss 0.4718967080116272 train acc 0.6410232411503335\n",
      "epoch 1 batch id 101601 / 225000 loss 2.395400285720825 train acc 0.6411305006840484\n",
      "epoch 1 batch id 101701 / 225000 loss 3.3444442749023438 train acc 0.6412424656591381\n",
      "epoch 1 batch id 101801 / 225000 loss 0.006921772845089436 train acc 0.6413836799245587\n",
      "epoch 1 batch id 101901 / 225000 loss 4.84132719039917 train acc 0.6415049901374864\n",
      "epoch 1 batch id 102001 / 225000 loss 0.0037937872111797333 train acc 0.6415868471877727\n",
      "epoch 1 batch id 102101 / 225000 loss 0.9517391324043274 train acc 0.6416758895603373\n",
      "epoch 1 batch id 102201 / 225000 loss 1.9285932779312134 train acc 0.6417916654435867\n",
      "epoch 1 batch id 102301 / 225000 loss 1.2058546543121338 train acc 0.6419194338276263\n",
      "epoch 1 batch id 102401 / 225000 loss 1.5647672414779663 train acc 0.6420518354312946\n",
      "epoch 1 batch id 102501 / 225000 loss 1.369360327720642 train acc 0.6421547106857494\n",
      "epoch 1 batch id 102601 / 225000 loss 4.1353349685668945 train acc 0.6422208360542295\n",
      "epoch 1 batch id 102701 / 225000 loss 0.18196134269237518 train acc 0.6422843983992366\n",
      "epoch 1 batch id 102801 / 225000 loss 2.6115915775299072 train acc 0.6423599964980885\n",
      "epoch 1 batch id 102901 / 225000 loss 1.3185805082321167 train acc 0.6424305886240173\n",
      "epoch 1 batch id 103001 / 225000 loss 0.05630310997366905 train acc 0.642518033805497\n",
      "epoch 1 batch id 103101 / 225000 loss 1.6684929132461548 train acc 0.64261015897033\n",
      "epoch 1 batch id 103201 / 225000 loss 1.2352449893951416 train acc 0.6426512339996705\n",
      "epoch 1 batch id 103301 / 225000 loss 5.263990879058838 train acc 0.642743051858162\n",
      "epoch 1 batch id 103401 / 225000 loss 0.3728608191013336 train acc 0.6428153499482597\n",
      "epoch 1 batch id 103501 / 225000 loss 0.004285361617803574 train acc 0.642921324431648\n",
      "epoch 1 batch id 103601 / 225000 loss 1.4251558780670166 train acc 0.6430319205413075\n",
      "epoch 1 batch id 103701 / 225000 loss 1.1632989645004272 train acc 0.6431326602443563\n",
      "epoch 1 batch id 103801 / 225000 loss 4.944577693939209 train acc 0.6432428396643578\n",
      "epoch 1 batch id 103901 / 225000 loss 0.0061210570856928825 train acc 0.643328745632862\n",
      "epoch 1 batch id 104001 / 225000 loss 1.9714611768722534 train acc 0.6433640061153258\n",
      "epoch 1 batch id 104101 / 225000 loss 1.4460837841033936 train acc 0.6434904563837043\n",
      "epoch 1 batch id 104201 / 225000 loss 0.01939532160758972 train acc 0.6436118655291216\n",
      "epoch 1 batch id 104301 / 225000 loss 2.9127731323242188 train acc 0.6436731191455499\n",
      "epoch 1 batch id 104401 / 225000 loss 2.225844621658325 train acc 0.6437366500320878\n",
      "epoch 1 batch id 104501 / 225000 loss 2.264274835586548 train acc 0.6438359441536444\n",
      "epoch 1 batch id 104601 / 225000 loss 1.683402180671692 train acc 0.6439708989397807\n",
      "epoch 1 batch id 104701 / 225000 loss 3.5724213123321533 train acc 0.6440626164028996\n",
      "epoch 1 batch id 104801 / 225000 loss 0.020782681182026863 train acc 0.6441541588343622\n",
      "epoch 1 batch id 104901 / 225000 loss 4.572688102722168 train acc 0.6442693587287062\n",
      "epoch 1 batch id 105001 / 225000 loss 1.2176929712295532 train acc 0.6443700536185369\n",
      "epoch 1 batch id 105101 / 225000 loss 1.0561295747756958 train acc 0.6444348769279075\n",
      "epoch 1 batch id 105201 / 225000 loss 0.07090244442224503 train acc 0.6445589870818719\n",
      "epoch 1 batch id 105301 / 225000 loss 0.0838991180062294 train acc 0.6446377527278944\n",
      "epoch 1 batch id 105401 / 225000 loss 2.645667791366577 train acc 0.6447329721729396\n",
      "epoch 1 batch id 105501 / 225000 loss 0.018889324739575386 train acc 0.6448445986293969\n",
      "epoch 1 batch id 105601 / 225000 loss 1.8210222721099854 train acc 0.644939441861346\n",
      "epoch 1 batch id 105701 / 225000 loss 1.0508495569229126 train acc 0.645041201123925\n",
      "epoch 1 batch id 105801 / 225000 loss 0.043584857136011124 train acc 0.6451049612007448\n",
      "epoch 1 batch id 105901 / 225000 loss 2.1125664710998535 train acc 0.6452110933796659\n",
      "epoch 1 batch id 106001 / 225000 loss 0.6920274496078491 train acc 0.645288723691286\n",
      "epoch 1 batch id 106101 / 225000 loss 1.5191792249679565 train acc 0.6453944826156209\n",
      "epoch 1 batch id 106201 / 225000 loss 0.9709070920944214 train acc 0.6454788561312982\n",
      "epoch 1 batch id 106301 / 225000 loss 1.8083758354187012 train acc 0.6455677745270505\n",
      "epoch 1 batch id 106401 / 225000 loss 2.078934907913208 train acc 0.6456306801627805\n",
      "epoch 1 batch id 106501 / 225000 loss 1.670701503753662 train acc 0.6457075520417649\n",
      "epoch 1 batch id 106601 / 225000 loss 0.5733333826065063 train acc 0.6458077316347877\n",
      "epoch 1 batch id 106701 / 225000 loss 0.7180302739143372 train acc 0.6458749215096391\n",
      "epoch 1 batch id 106801 / 225000 loss 0.22915278375148773 train acc 0.6459888016029812\n",
      "epoch 1 batch id 106901 / 225000 loss 0.0017628241330385208 train acc 0.646121177538096\n",
      "epoch 1 batch id 107001 / 225000 loss 2.5682871341705322 train acc 0.6462065775086214\n",
      "epoch 1 batch id 107101 / 225000 loss 1.0775432586669922 train acc 0.6463034892297924\n",
      "epoch 1 batch id 107201 / 225000 loss 0.03789959102869034 train acc 0.6463722353336256\n",
      "epoch 1 batch id 107301 / 225000 loss 2.004032850265503 train acc 0.646447842983756\n",
      "epoch 1 batch id 107401 / 225000 loss 0.18741583824157715 train acc 0.6465279652889638\n",
      "epoch 1 batch id 107501 / 225000 loss 0.2622597813606262 train acc 0.6466172407698533\n",
      "epoch 1 batch id 107601 / 225000 loss 1.258246660232544 train acc 0.6466993801172851\n",
      "epoch 1 batch id 107701 / 225000 loss 1.891289472579956 train acc 0.6467604757615992\n",
      "epoch 1 batch id 107801 / 225000 loss 1.510026454925537 train acc 0.6468585634641608\n",
      "epoch 1 batch id 107901 / 225000 loss 1.1267914772033691 train acc 0.6469680540495454\n",
      "epoch 1 batch id 108001 / 225000 loss 0.01219773106276989 train acc 0.6470518791492671\n",
      "epoch 1 batch id 108101 / 225000 loss 0.5463334321975708 train acc 0.647107797337675\n",
      "epoch 1 batch id 108201 / 225000 loss 1.7580407857894897 train acc 0.6472098224600512\n",
      "epoch 1 batch id 108301 / 225000 loss 0.04209199920296669 train acc 0.6472931921219564\n",
      "epoch 1 batch id 108401 / 225000 loss 0.16236890852451324 train acc 0.6473787142185036\n",
      "epoch 1 batch id 108501 / 225000 loss 0.5390996932983398 train acc 0.6474802075556907\n",
      "epoch 1 batch id 108601 / 225000 loss 3.2817959785461426 train acc 0.6475561919319344\n",
      "epoch 1 batch id 108701 / 225000 loss 0.07318416237831116 train acc 0.6475929384274294\n",
      "epoch 1 batch id 108801 / 225000 loss 1.997955322265625 train acc 0.6476755728348085\n",
      "epoch 1 batch id 108901 / 225000 loss 0.007291809655725956 train acc 0.6477419858403504\n",
      "epoch 1 batch id 109001 / 225000 loss 3.323603630065918 train acc 0.6478266254438033\n",
      "epoch 1 batch id 109101 / 225000 loss 1.9421659708023071 train acc 0.6479042355248806\n",
      "epoch 1 batch id 109201 / 225000 loss 0.007446148432791233 train acc 0.6480000183148505\n",
      "epoch 1 batch id 109301 / 225000 loss 0.47042137384414673 train acc 0.6481253602437306\n",
      "epoch 1 batch id 109401 / 225000 loss 0.027896642684936523 train acc 0.6482230509775961\n",
      "epoch 1 batch id 109501 / 225000 loss 1.0336569547653198 train acc 0.6482954493566269\n",
      "epoch 1 batch id 109601 / 225000 loss 3.7201242446899414 train acc 0.6483608726197754\n",
      "epoch 1 batch id 109701 / 225000 loss 1.8195000886917114 train acc 0.6484261766073235\n",
      "epoch 1 batch id 109801 / 225000 loss 0.8560208678245544 train acc 0.6484868079525687\n",
      "epoch 1 batch id 109901 / 225000 loss 0.03648996725678444 train acc 0.6485950992256667\n",
      "epoch 1 batch id 110001 / 225000 loss 0.8281205296516418 train acc 0.6486418305288134\n",
      "epoch 1 batch id 110101 / 225000 loss 3.9972026348114014 train acc 0.648688476943897\n",
      "epoch 1 batch id 110201 / 225000 loss 0.29563409090042114 train acc 0.6487463816117821\n",
      "epoch 1 batch id 110301 / 225000 loss 1.7607150077819824 train acc 0.6487951151848125\n",
      "epoch 1 batch id 110401 / 225000 loss 1.3384889364242554 train acc 0.6488392315286999\n",
      "epoch 1 batch id 110501 / 225000 loss 1.0921552181243896 train acc 0.6489172043691912\n",
      "epoch 1 batch id 110601 / 225000 loss 5.027932643890381 train acc 0.6489814739468902\n",
      "epoch 1 batch id 110701 / 225000 loss 1.9376659393310547 train acc 0.6490636940949043\n",
      "epoch 1 batch id 110801 / 225000 loss 6.689984321594238 train acc 0.6491593036163934\n",
      "epoch 1 batch id 110901 / 225000 loss 0.992531418800354 train acc 0.6492164182469049\n",
      "epoch 1 batch id 111001 / 225000 loss 1.891702651977539 train acc 0.6492846911289087\n",
      "epoch 1 batch id 111101 / 225000 loss 2.9460983276367188 train acc 0.6493685925419214\n",
      "epoch 1 batch id 111201 / 225000 loss 0.014008810743689537 train acc 0.6494433503295833\n",
      "epoch 1 batch id 111301 / 225000 loss 0.08273854851722717 train acc 0.6495067429762535\n",
      "epoch 1 batch id 111401 / 225000 loss 1.5149195194244385 train acc 0.6495947074083716\n",
      "epoch 1 batch id 111501 / 225000 loss 1.0592972040176392 train acc 0.6496757876610972\n",
      "epoch 1 batch id 111601 / 225000 loss 1.8552000522613525 train acc 0.6497343213770486\n",
      "epoch 1 batch id 111701 / 225000 loss 0.9673415422439575 train acc 0.6498061789957118\n",
      "epoch 1 batch id 111801 / 225000 loss 3.2552976608276367 train acc 0.6498868525326249\n",
      "epoch 1 batch id 111901 / 225000 loss 1.273012638092041 train acc 0.6499651477645418\n",
      "epoch 1 batch id 112001 / 225000 loss 0.011762076057493687 train acc 0.6500187498325908\n",
      "epoch 1 batch id 112101 / 225000 loss 1.5458526611328125 train acc 0.6500655658736318\n",
      "epoch 1 batch id 112201 / 225000 loss 2.083425521850586 train acc 0.6501212110408998\n",
      "epoch 1 batch id 112301 / 225000 loss 1.4114413261413574 train acc 0.6501901140684411\n",
      "epoch 1 batch id 112401 / 225000 loss 2.0596840381622314 train acc 0.6502633428528216\n",
      "epoch 1 batch id 112501 / 225000 loss 0.004801663104444742 train acc 0.6503675522884241\n",
      "epoch 1 batch id 112601 / 225000 loss 0.006843533366918564 train acc 0.6504449338815819\n",
      "epoch 1 batch id 112701 / 225000 loss 0.8302243947982788 train acc 0.6504822494920187\n",
      "epoch 1 batch id 112801 / 225000 loss 1.104300618171692 train acc 0.650530580402656\n",
      "epoch 1 batch id 112901 / 225000 loss 1.108604907989502 train acc 0.6506253266135819\n",
      "epoch 1 batch id 113001 / 225000 loss 0.10751044750213623 train acc 0.6506867195865523\n",
      "epoch 1 batch id 113101 / 225000 loss 1.8822124004364014 train acc 0.6507590560649331\n",
      "epoch 1 batch id 113201 / 225000 loss 2.047391891479492 train acc 0.6508180139751416\n",
      "epoch 1 batch id 113301 / 225000 loss 2.063436269760132 train acc 0.6508923133952922\n",
      "epoch 1 batch id 113401 / 225000 loss 2.2798752784729004 train acc 0.6509730954753485\n",
      "epoch 1 batch id 113501 / 225000 loss 0.008654476143419743 train acc 0.6510691535757395\n",
      "epoch 1 batch id 113601 / 225000 loss 0.004599434323608875 train acc 0.6511496377672732\n",
      "epoch 1 batch id 113701 / 225000 loss 0.09489038586616516 train acc 0.6512167878910475\n",
      "epoch 1 batch id 113801 / 225000 loss 0.004208127968013287 train acc 0.6513453308846143\n",
      "epoch 1 batch id 113901 / 225000 loss 0.11495251953601837 train acc 0.6514121912889264\n",
      "epoch 1 batch id 114001 / 225000 loss 0.5723686218261719 train acc 0.6515140218068263\n",
      "epoch 1 batch id 114101 / 225000 loss 3.127188205718994 train acc 0.6515696619661528\n",
      "epoch 1 batch id 114201 / 225000 loss 2.427802801132202 train acc 0.6516164481922225\n",
      "epoch 1 batch id 114301 / 225000 loss 2.920046091079712 train acc 0.651685024627956\n",
      "epoch 1 batch id 114401 / 225000 loss 0.030632030218839645 train acc 0.6517600370626131\n",
      "epoch 1 batch id 114501 / 225000 loss 0.01235184632241726 train acc 0.6518196347630152\n",
      "epoch 1 batch id 114601 / 225000 loss 4.1732001304626465 train acc 0.6519074877182572\n",
      "epoch 1 batch id 114701 / 225000 loss 1.4929043054580688 train acc 0.6519777508478566\n",
      "epoch 1 batch id 114801 / 225000 loss 0.0068733347579836845 train acc 0.6520370031619933\n",
      "epoch 1 batch id 114901 / 225000 loss 0.8951838612556458 train acc 0.6520983281259519\n",
      "epoch 1 batch id 115001 / 225000 loss 1.5384825468063354 train acc 0.6521617203328667\n",
      "epoch 1 batch id 115101 / 225000 loss 0.25303584337234497 train acc 0.6522684424983276\n",
      "epoch 1 batch id 115201 / 225000 loss 0.0067595611326396465 train acc 0.6523380873429918\n",
      "epoch 1 batch id 115301 / 225000 loss 0.008385013788938522 train acc 0.6524357984752951\n",
      "epoch 1 batch id 115401 / 225000 loss 0.36119624972343445 train acc 0.652494345802896\n",
      "epoch 1 batch id 115501 / 225000 loss 0.36983373761177063 train acc 0.6525722721015402\n",
      "epoch 1 batch id 115601 / 225000 loss 3.3689537048339844 train acc 0.6526587140249652\n",
      "epoch 1 batch id 115701 / 225000 loss 0.0643702819943428 train acc 0.6527298813320542\n",
      "epoch 1 batch id 115801 / 225000 loss 1.0584625005722046 train acc 0.65280092572603\n",
      "epoch 1 batch id 115901 / 225000 loss 0.013281273655593395 train acc 0.6528783185649821\n",
      "epoch 1 batch id 116001 / 225000 loss 4.058234691619873 train acc 0.6529685088921647\n",
      "epoch 1 batch id 116101 / 225000 loss 0.013124130666255951 train acc 0.6530413174735791\n",
      "epoch 1 batch id 116201 / 225000 loss 0.015429622493684292 train acc 0.653114000740097\n",
      "epoch 1 batch id 116301 / 225000 loss 0.06442011892795563 train acc 0.6531908582041427\n",
      "epoch 1 batch id 116401 / 225000 loss 0.2921885550022125 train acc 0.6532332196458793\n",
      "epoch 1 batch id 116501 / 225000 loss 0.01655632257461548 train acc 0.6533055510253131\n",
      "epoch 1 batch id 116601 / 225000 loss 1.142117977142334 train acc 0.6533498855069854\n",
      "epoch 1 batch id 116701 / 225000 loss 1.1274718046188354 train acc 0.6534219929563586\n",
      "epoch 1 batch id 116801 / 225000 loss 4.67354154586792 train acc 0.6534811345793272\n",
      "epoch 1 batch id 116901 / 225000 loss 2.3276114463806152 train acc 0.6535423135815775\n",
      "epoch 1 batch id 117001 / 225000 loss 0.049466054886579514 train acc 0.653579883932616\n",
      "epoch 1 batch id 117101 / 225000 loss 3.8495707511901855 train acc 0.6536323344804912\n",
      "epoch 1 batch id 117201 / 225000 loss 2.9603567123413086 train acc 0.6537294903627102\n",
      "epoch 1 batch id 117301 / 225000 loss 0.06209259107708931 train acc 0.6538072991705101\n",
      "epoch 1 batch id 117401 / 225000 loss 0.461437463760376 train acc 0.6538934932411138\n",
      "epoch 1 batch id 117501 / 225000 loss 0.3567236065864563 train acc 0.6539731576752539\n",
      "epoch 1 batch id 117601 / 225000 loss 0.008137397468090057 train acc 0.6540463091300244\n",
      "epoch 1 batch id 117701 / 225000 loss 4.618802547454834 train acc 0.6541193362843136\n",
      "epoch 1 batch id 117801 / 225000 loss 3.504926919937134 train acc 0.6542028505700291\n",
      "epoch 1 batch id 117901 / 225000 loss 1.7733447551727295 train acc 0.6542692598027159\n",
      "epoch 1 batch id 118001 / 225000 loss 0.409309059381485 train acc 0.6543186074694283\n",
      "epoch 1 batch id 118101 / 225000 loss 0.9685593247413635 train acc 0.6543975072183978\n",
      "epoch 1 batch id 118201 / 225000 loss 0.29331669211387634 train acc 0.6544614681770882\n",
      "epoch 1 batch id 118301 / 225000 loss 0.8145995736122131 train acc 0.6544893956940347\n",
      "epoch 1 batch id 118401 / 225000 loss 0.005795279052108526 train acc 0.6545552824722765\n",
      "epoch 1 batch id 118501 / 225000 loss 0.40338265895843506 train acc 0.654621058050143\n",
      "epoch 1 batch id 118601 / 225000 loss 2.3973348140716553 train acc 0.6546951543410258\n",
      "epoch 1 batch id 118701 / 225000 loss 0.007827768102288246 train acc 0.6547585951255676\n",
      "epoch 1 batch id 118801 / 225000 loss 2.088775634765625 train acc 0.6548240334677318\n",
      "epoch 1 batch id 118901 / 225000 loss 0.013522929511964321 train acc 0.6548809513797192\n",
      "epoch 1 batch id 119001 / 225000 loss 0.7036823034286499 train acc 0.6549503785682473\n",
      "epoch 1 batch id 119101 / 225000 loss 1.4983034133911133 train acc 0.6549693117606066\n",
      "epoch 1 batch id 119201 / 225000 loss 1.133231282234192 train acc 0.6550070888667041\n",
      "epoch 1 batch id 119301 / 225000 loss 1.923980474472046 train acc 0.6550950955985281\n",
      "epoch 1 batch id 119401 / 225000 loss 1.117924451828003 train acc 0.6551913300558622\n",
      "epoch 1 batch id 119501 / 225000 loss 2.4787254333496094 train acc 0.6552602070275563\n",
      "epoch 1 batch id 119601 / 225000 loss 2.6144652366638184 train acc 0.6553394202389612\n",
      "epoch 1 batch id 119701 / 225000 loss 0.0035414635203778744 train acc 0.6554205896358426\n",
      "epoch 1 batch id 119801 / 225000 loss 0.005081753246486187 train acc 0.6554891027620805\n",
      "epoch 1 batch id 119901 / 225000 loss 0.0107144545763731 train acc 0.6555324809634615\n",
      "epoch 1 batch id 120001 / 225000 loss 0.48743629455566406 train acc 0.655611203239973\n",
      "epoch 1 batch id 120101 / 225000 loss 0.6591160893440247 train acc 0.6556481627963131\n",
      "epoch 1 batch id 120201 / 225000 loss 3.217438220977783 train acc 0.6556975399539106\n",
      "epoch 1 batch id 120301 / 225000 loss 1.1465156078338623 train acc 0.6557759287121471\n",
      "epoch 1 batch id 120401 / 225000 loss 3.3815150260925293 train acc 0.6558624928364383\n",
      "epoch 1 batch id 120501 / 225000 loss 2.227945327758789 train acc 0.6559364652575498\n",
      "epoch 1 batch id 120601 / 225000 loss 2.4240832328796387 train acc 0.6560082420543777\n",
      "epoch 1 batch id 120701 / 225000 loss 3.238467216491699 train acc 0.6560819711518546\n",
      "epoch 1 batch id 120801 / 225000 loss 3.625519275665283 train acc 0.6561659257787601\n",
      "epoch 1 batch id 120901 / 225000 loss 1.3808716535568237 train acc 0.6562104531807016\n",
      "epoch 1 batch id 121001 / 225000 loss 0.01996835693717003 train acc 0.6562445764911033\n",
      "epoch 1 batch id 121101 / 225000 loss 2.407630681991577 train acc 0.6562951585866343\n",
      "epoch 1 batch id 121201 / 225000 loss 2.3887696266174316 train acc 0.656355970660308\n",
      "epoch 1 batch id 121301 / 225000 loss 1.7934510707855225 train acc 0.6564249264227006\n",
      "epoch 1 batch id 121401 / 225000 loss 0.006635882426053286 train acc 0.6564917092939926\n",
      "epoch 1 batch id 121501 / 225000 loss 1.7860400676727295 train acc 0.6565254606957968\n",
      "epoch 1 batch id 121601 / 225000 loss 0.011509746313095093 train acc 0.6566105541895215\n",
      "epoch 1 batch id 121701 / 225000 loss 1.1076959371566772 train acc 0.6566913994133162\n",
      "epoch 1 batch id 121801 / 225000 loss 0.0028224375564604998 train acc 0.6567597967175968\n",
      "epoch 1 batch id 121901 / 225000 loss 2.263930320739746 train acc 0.6568055225141713\n",
      "epoch 1 batch id 122001 / 225000 loss 0.1314893513917923 train acc 0.6568819108040098\n",
      "epoch 1 batch id 122101 / 225000 loss 1.7986152172088623 train acc 0.6569458890590577\n",
      "epoch 1 batch id 122201 / 225000 loss 3.6406540870666504 train acc 0.6569974877455995\n",
      "epoch 1 batch id 122301 / 225000 loss 0.7884520292282104 train acc 0.6570571786003385\n",
      "epoch 1 batch id 122401 / 225000 loss 1.6586002111434937 train acc 0.6571331116575845\n",
      "epoch 1 batch id 122501 / 225000 loss 0.008026561699807644 train acc 0.6572048391441703\n",
      "epoch 1 batch id 122601 / 225000 loss 1.3356907367706299 train acc 0.6572519800001632\n",
      "epoch 1 batch id 122701 / 225000 loss 1.388426661491394 train acc 0.6573275686424723\n",
      "epoch 1 batch id 122801 / 225000 loss 0.035706017166376114 train acc 0.6573765685947183\n",
      "epoch 1 batch id 122901 / 225000 loss 2.3872110843658447 train acc 0.6574336254383609\n",
      "epoch 1 batch id 123001 / 225000 loss 0.707724392414093 train acc 0.6574519719351876\n",
      "epoch 1 batch id 123101 / 225000 loss 1.1896018981933594 train acc 0.6575210599426488\n",
      "epoch 1 batch id 123201 / 225000 loss 1.8640799522399902 train acc 0.6575758313650052\n",
      "epoch 1 batch id 123301 / 225000 loss 3.74604868888855 train acc 0.6576467344141572\n",
      "epoch 1 batch id 123401 / 225000 loss 1.0393779277801514 train acc 0.6577094188863948\n",
      "epoch 1 batch id 123501 / 225000 loss 0.11708156764507294 train acc 0.6577760503963531\n",
      "epoch 1 batch id 123601 / 225000 loss 0.7372069954872131 train acc 0.6578081892541322\n",
      "epoch 1 batch id 123701 / 225000 loss 3.5093116760253906 train acc 0.6578786751926016\n",
      "epoch 1 batch id 123801 / 225000 loss 1.0813380479812622 train acc 0.6579349116727652\n",
      "epoch 1 batch id 123901 / 225000 loss 0.8098580837249756 train acc 0.6579708799767556\n",
      "epoch 1 batch id 124001 / 225000 loss 0.012084201909601688 train acc 0.6580450964105128\n",
      "epoch 1 batch id 124101 / 225000 loss 0.008390833623707294 train acc 0.6581212077259652\n",
      "epoch 1 batch id 124201 / 225000 loss 3.649158000946045 train acc 0.6581810935499715\n",
      "epoch 1 batch id 124301 / 225000 loss 0.005125658120959997 train acc 0.6582428942647284\n",
      "epoch 1 batch id 124401 / 225000 loss 0.005015925504267216 train acc 0.6583327304442891\n",
      "epoch 1 batch id 124501 / 225000 loss 0.05945637822151184 train acc 0.6584224223098609\n",
      "epoch 1 batch id 124601 / 225000 loss 0.9336886405944824 train acc 0.6585019381866919\n",
      "epoch 1 batch id 124701 / 225000 loss 3.737230062484741 train acc 0.6585753121466548\n",
      "epoch 1 batch id 124801 / 225000 loss 0.3726416230201721 train acc 0.6586525748992396\n",
      "epoch 1 batch id 124901 / 225000 loss 0.8219089508056641 train acc 0.6587177044219021\n",
      "epoch 1 batch id 125001 / 225000 loss 2.9618585109710693 train acc 0.6587587299301606\n",
      "epoch 1 batch id 125101 / 225000 loss 0.020631391555070877 train acc 0.6588376591713895\n",
      "epoch 1 batch id 125201 / 225000 loss 0.6625306606292725 train acc 0.6589004880152715\n",
      "epoch 1 batch id 125301 / 225000 loss 1.863964557647705 train acc 0.6589692021611958\n",
      "epoch 1 batch id 125401 / 225000 loss 0.0031251246109604836 train acc 0.6590477747386384\n",
      "epoch 1 batch id 125501 / 225000 loss 0.14149482548236847 train acc 0.6591102859738169\n",
      "epoch 1 batch id 125601 / 225000 loss 1.5338623523712158 train acc 0.6591926019697295\n",
      "epoch 1 batch id 125701 / 225000 loss 0.005391787271946669 train acc 0.6592727981479861\n",
      "epoch 1 batch id 125801 / 225000 loss 1.0695524215698242 train acc 0.6593469050325514\n",
      "epoch 1 batch id 125901 / 225000 loss 1.2725200653076172 train acc 0.6594347940048133\n",
      "epoch 1 batch id 126001 / 225000 loss 2.9834299087524414 train acc 0.6594947659145562\n",
      "epoch 1 batch id 126101 / 225000 loss 2.688046932220459 train acc 0.6595268871777384\n",
      "epoch 1 batch id 126201 / 225000 loss 3.151515007019043 train acc 0.6595411288341614\n",
      "epoch 1 batch id 126301 / 225000 loss 1.9981703758239746 train acc 0.6596147298912914\n",
      "epoch 1 batch id 126401 / 225000 loss 4.540465831756592 train acc 0.6596367908481736\n",
      "epoch 1 batch id 126501 / 225000 loss 1.6756956577301025 train acc 0.6596726508090845\n",
      "epoch 1 batch id 126601 / 225000 loss 2.0266287326812744 train acc 0.6597084541196357\n",
      "epoch 1 batch id 126701 / 225000 loss 2.0433387756347656 train acc 0.6597757713040939\n",
      "epoch 1 batch id 126801 / 225000 loss 0.5254194140434265 train acc 0.6598370675310131\n",
      "epoch 1 batch id 126901 / 225000 loss 1.8474961519241333 train acc 0.659886446915312\n",
      "epoch 1 batch id 127001 / 225000 loss 0.04894670471549034 train acc 0.6599219691183534\n",
      "epoch 1 batch id 127101 / 225000 loss 2.6801328659057617 train acc 0.6599790717618272\n",
      "epoch 1 batch id 127201 / 225000 loss 1.5930228233337402 train acc 0.6600183960817918\n",
      "epoch 1 batch id 127301 / 225000 loss 2.0223636627197266 train acc 0.6600596224695799\n",
      "epoch 1 batch id 127401 / 225000 loss 0.640394389629364 train acc 0.6601262941421182\n",
      "epoch 1 batch id 127501 / 225000 loss 3.447037696838379 train acc 0.6601771750809797\n",
      "epoch 1 batch id 127601 / 225000 loss 0.9914087057113647 train acc 0.6602064247145398\n",
      "epoch 1 batch id 127701 / 225000 loss 0.005463516805320978 train acc 0.6602649940094439\n",
      "epoch 1 batch id 127801 / 225000 loss 0.11077137291431427 train acc 0.6603058661512821\n",
      "epoch 1 batch id 127901 / 225000 loss 1.1045914888381958 train acc 0.6603251733762833\n",
      "epoch 1 batch id 128001 / 225000 loss 1.1895900964736938 train acc 0.6604069499457036\n",
      "epoch 1 batch id 128101 / 225000 loss 0.28917747735977173 train acc 0.660455421893662\n",
      "epoch 1 batch id 128201 / 225000 loss 0.0944739505648613 train acc 0.6604979680345707\n",
      "epoch 1 batch id 128301 / 225000 loss 2.085609197616577 train acc 0.6605462934817343\n",
      "epoch 1 batch id 128401 / 225000 loss 1.9447680711746216 train acc 0.6606023317575408\n",
      "epoch 1 batch id 128501 / 225000 loss 2.563020944595337 train acc 0.6606466097540097\n",
      "epoch 1 batch id 128601 / 225000 loss 3.333937168121338 train acc 0.6606908188894333\n",
      "epoch 1 batch id 128701 / 225000 loss 4.068550109863281 train acc 0.6607582691665177\n",
      "epoch 1 batch id 128801 / 225000 loss 0.014323379844427109 train acc 0.6608100868782074\n",
      "epoch 1 batch id 128901 / 225000 loss 1.566961646080017 train acc 0.6608792794470175\n",
      "epoch 1 batch id 129001 / 225000 loss 2.7099289894104004 train acc 0.6609444888024124\n",
      "epoch 1 batch id 129101 / 225000 loss 1.7456462383270264 train acc 0.6610057242004322\n",
      "epoch 1 batch id 129201 / 225000 loss 0.15267832577228546 train acc 0.6610455801425685\n",
      "epoch 1 batch id 129301 / 225000 loss 0.9810997247695923 train acc 0.6611143765322774\n",
      "epoch 1 batch id 129401 / 225000 loss 1.537432312965393 train acc 0.6611386310770396\n",
      "epoch 1 batch id 129501 / 225000 loss 1.0062839984893799 train acc 0.6611802225465441\n",
      "epoch 1 batch id 129601 / 225000 loss 3.81447434425354 train acc 0.6612333238169459\n",
      "epoch 1 batch id 129701 / 225000 loss 2.8791732788085938 train acc 0.6613075458169174\n",
      "epoch 1 batch id 129801 / 225000 loss 0.003180037485435605 train acc 0.6613893575550266\n",
      "epoch 1 batch id 129901 / 225000 loss 1.3375177383422852 train acc 0.6614575715352461\n",
      "epoch 1 batch id 130001 / 225000 loss 2.7891108989715576 train acc 0.6615314497580788\n",
      "epoch 1 batch id 130101 / 225000 loss 0.1006932407617569 train acc 0.6616167439143434\n",
      "epoch 1 batch id 130201 / 225000 loss 1.3668354749679565 train acc 0.6617057472676862\n",
      "epoch 1 batch id 130301 / 225000 loss 0.42644447088241577 train acc 0.6617466481454478\n",
      "epoch 1 batch id 130401 / 225000 loss 0.005737263709306717 train acc 0.6618047407611904\n",
      "epoch 1 batch id 130501 / 225000 loss 1.7369788885116577 train acc 0.6618780698998475\n",
      "epoch 1 batch id 130601 / 225000 loss 0.049337293952703476 train acc 0.661934058697866\n",
      "epoch 1 batch id 130701 / 225000 loss 2.4259681701660156 train acc 0.6619765724822304\n",
      "epoch 1 batch id 130801 / 225000 loss 2.146089553833008 train acc 0.6620113760598161\n",
      "epoch 1 batch id 130901 / 225000 loss 1.5863900184631348 train acc 0.6620728642256362\n",
      "epoch 1 batch id 131001 / 225000 loss 0.023587964475154877 train acc 0.6621418920466255\n",
      "epoch 1 batch id 131101 / 225000 loss 1.4604060649871826 train acc 0.6621783968085675\n",
      "epoch 1 batch id 131201 / 225000 loss 1.5458953380584717 train acc 0.6622224678165562\n",
      "epoch 1 batch id 131301 / 225000 loss 0.5167769193649292 train acc 0.6622778958271452\n",
      "epoch 1 batch id 131401 / 225000 loss 2.847154378890991 train acc 0.6623389471921827\n",
      "epoch 1 batch id 131501 / 225000 loss 0.5592635273933411 train acc 0.6624056090828206\n",
      "epoch 1 batch id 131601 / 225000 loss 0.4752781391143799 train acc 0.662475969027591\n",
      "epoch 1 batch id 131701 / 225000 loss 0.03599182143807411 train acc 0.6625633062770974\n",
      "epoch 1 batch id 131801 / 225000 loss 0.07072271406650543 train acc 0.662587916631892\n",
      "epoch 1 batch id 131901 / 225000 loss 0.3093518316745758 train acc 0.6626541876104047\n",
      "epoch 1 batch id 132001 / 225000 loss 7.111629962921143 train acc 0.6627203581791047\n",
      "epoch 1 batch id 132101 / 225000 loss 0.01730266772210598 train acc 0.6627807510919675\n",
      "epoch 1 batch id 132201 / 225000 loss 0.031609244644641876 train acc 0.6628353794600645\n",
      "epoch 1 batch id 132301 / 225000 loss 0.3367776870727539 train acc 0.6628899252462188\n",
      "epoch 1 batch id 132401 / 225000 loss 0.006982540711760521 train acc 0.6629500532473319\n",
      "epoch 1 batch id 132501 / 225000 loss 0.017609836533665657 train acc 0.663021411159161\n",
      "epoch 1 batch id 132601 / 225000 loss 0.5271619558334351 train acc 0.6630813493110912\n",
      "epoch 1 batch id 132701 / 225000 loss 3.6282849311828613 train acc 0.6631185899126608\n",
      "epoch 1 batch id 132801 / 225000 loss 2.5196120738983154 train acc 0.66314447933374\n",
      "epoch 1 batch id 132901 / 225000 loss 1.9436900615692139 train acc 0.6631966651868684\n",
      "epoch 1 batch id 133001 / 225000 loss 0.9960482120513916 train acc 0.6632412538251592\n",
      "epoch 1 batch id 133101 / 225000 loss 2.2489163875579834 train acc 0.6632745058264025\n",
      "epoch 1 batch id 133201 / 225000 loss 1.7281932830810547 train acc 0.663290816135014\n",
      "epoch 1 batch id 133301 / 225000 loss 1.605223298072815 train acc 0.6632902228790482\n",
      "epoch 1 batch id 133401 / 225000 loss 0.013544611632823944 train acc 0.6633683405671622\n",
      "epoch 1 batch id 133501 / 225000 loss 1.8489220142364502 train acc 0.6633882892262979\n",
      "epoch 1 batch id 133601 / 225000 loss 0.03649899363517761 train acc 0.6634231779702248\n",
      "epoch 1 batch id 133701 / 225000 loss 2.644216537475586 train acc 0.6634654939005692\n",
      "epoch 1 batch id 133801 / 225000 loss 0.8896092772483826 train acc 0.663535773275237\n",
      "epoch 1 batch id 133901 / 225000 loss 4.6316819190979 train acc 0.6635872771674596\n",
      "epoch 1 batch id 134001 / 225000 loss 0.9864973425865173 train acc 0.663616316296147\n",
      "epoch 1 batch id 134101 / 225000 loss 0.5697735548019409 train acc 0.6636937830441234\n",
      "epoch 1 batch id 134201 / 225000 loss 6.033869743347168 train acc 0.6637525055700032\n",
      "epoch 1 batch id 134301 / 225000 loss 2.0074193477630615 train acc 0.6638018331955831\n",
      "epoch 1 batch id 134401 / 225000 loss 0.7339512705802917 train acc 0.6638603879435421\n",
      "epoch 1 batch id 134501 / 225000 loss 3.569136142730713 train acc 0.6639114207329313\n",
      "epoch 1 batch id 134601 / 225000 loss 1.4096990823745728 train acc 0.6639586630114189\n",
      "epoch 1 batch id 134701 / 225000 loss 0.029694216325879097 train acc 0.663996555333665\n",
      "epoch 1 batch id 134801 / 225000 loss 0.3927050232887268 train acc 0.6640251185080229\n",
      "epoch 1 batch id 134901 / 225000 loss 1.1436821222305298 train acc 0.6640629053898786\n",
      "epoch 1 batch id 135001 / 225000 loss 2.071099281311035 train acc 0.6641228583491974\n",
      "epoch 1 batch id 135101 / 225000 loss 1.192926049232483 train acc 0.6641827225557175\n",
      "epoch 1 batch id 135201 / 225000 loss 2.7409441471099854 train acc 0.6642498946013713\n",
      "epoch 1 batch id 135301 / 225000 loss 0.3839236795902252 train acc 0.664318815086363\n",
      "epoch 1 batch id 135401 / 225000 loss 0.9222133755683899 train acc 0.6643784019320389\n",
      "epoch 1 batch id 135501 / 225000 loss 0.018444260582327843 train acc 0.6644268307982967\n",
      "epoch 1 batch id 135601 / 225000 loss 1.368290901184082 train acc 0.6644917810340631\n",
      "epoch 1 batch id 135701 / 225000 loss 0.02352428063750267 train acc 0.6645400549738028\n",
      "epoch 1 batch id 135801 / 225000 loss 0.0022905049845576286 train acc 0.6645348708772395\n",
      "epoch 1 batch id 135901 / 225000 loss 0.4258303642272949 train acc 0.6645609671746345\n",
      "epoch 1 batch id 136001 / 225000 loss 2.8224058151245117 train acc 0.6646017308696259\n",
      "epoch 1 batch id 136101 / 225000 loss 2.667158603668213 train acc 0.6646516190182291\n",
      "epoch 1 batch id 136201 / 225000 loss 1.276250958442688 train acc 0.6646647234601801\n",
      "epoch 1 batch id 136301 / 225000 loss 0.694105327129364 train acc 0.6647328339483937\n",
      "epoch 1 batch id 136401 / 225000 loss 0.007498321123421192 train acc 0.6647623551146986\n",
      "epoch 1 batch id 136501 / 225000 loss 0.02604859508574009 train acc 0.6648284627951444\n",
      "epoch 1 batch id 136601 / 225000 loss 0.9650305509567261 train acc 0.664894473686137\n",
      "epoch 1 batch id 136701 / 225000 loss 0.14859600365161896 train acc 0.664971360853249\n",
      "epoch 1 batch id 136801 / 225000 loss 0.019686266779899597 train acc 0.6650316883648512\n",
      "epoch 1 batch id 136901 / 225000 loss 0.9453454613685608 train acc 0.6650499265892872\n",
      "epoch 1 batch id 137001 / 225000 loss 0.05876489356160164 train acc 0.6651228823147276\n",
      "epoch 1 batch id 137101 / 225000 loss 0.41956037282943726 train acc 0.6651537917301843\n",
      "epoch 1 batch id 137201 / 225000 loss 1.7781791687011719 train acc 0.6651955889534333\n",
      "epoch 1 batch id 137301 / 225000 loss 0.006002191454172134 train acc 0.6652409669266793\n",
      "epoch 1 batch id 137401 / 225000 loss 2.8576085567474365 train acc 0.6652935568154525\n",
      "epoch 1 batch id 137501 / 225000 loss 1.7003177404403687 train acc 0.6653442520418034\n",
      "epoch 1 batch id 137601 / 225000 loss 1.1709457635879517 train acc 0.6654075915145965\n",
      "epoch 1 batch id 137701 / 225000 loss 3.732994556427002 train acc 0.6654236352677178\n",
      "epoch 1 batch id 137801 / 225000 loss 0.06639657914638519 train acc 0.6654523552078723\n",
      "epoch 1 batch id 137901 / 225000 loss 1.690917730331421 train acc 0.6654919108635905\n",
      "epoch 1 batch id 138001 / 225000 loss 1.0903116464614868 train acc 0.6655513365845175\n",
      "epoch 1 batch id 138101 / 225000 loss 0.033845242112874985 train acc 0.6655980043591284\n",
      "epoch 1 batch id 138201 / 225000 loss 1.8973543643951416 train acc 0.6656409866788229\n",
      "epoch 1 batch id 138301 / 225000 loss 2.3092079162597656 train acc 0.6656802915380221\n",
      "epoch 1 batch id 138401 / 225000 loss 2.1492300033569336 train acc 0.6657195395987023\n",
      "epoch 1 batch id 138501 / 225000 loss 1.470550537109375 train acc 0.6657713662717236\n",
      "epoch 1 batch id 138601 / 225000 loss 0.0077902101911604404 train acc 0.6658177069429514\n",
      "epoch 1 batch id 138701 / 225000 loss 0.9324083924293518 train acc 0.6658477588481698\n",
      "epoch 1 batch id 138801 / 225000 loss 0.4058845341205597 train acc 0.6658849720102881\n",
      "epoch 1 batch id 138901 / 225000 loss 0.04361791908740997 train acc 0.6659401300206622\n",
      "epoch 1 batch id 139001 / 225000 loss 0.002711885143071413 train acc 0.6659736260890209\n",
      "epoch 1 batch id 139101 / 225000 loss 0.008346784859895706 train acc 0.6659747234024198\n",
      "epoch 1 batch id 139201 / 225000 loss 1.9535369873046875 train acc 0.6660279020984045\n",
      "epoch 1 batch id 139301 / 225000 loss 0.7129887342453003 train acc 0.6660684417197292\n",
      "epoch 1 batch id 139401 / 225000 loss 1.2779791355133057 train acc 0.6661250636652535\n",
      "epoch 1 batch id 139501 / 225000 loss 5.071624755859375 train acc 0.6661511387015147\n",
      "epoch 1 batch id 139601 / 225000 loss 0.08992317318916321 train acc 0.6661753855631407\n",
      "epoch 1 batch id 139701 / 225000 loss 3.080174446105957 train acc 0.666215703538271\n",
      "epoch 1 batch id 139801 / 225000 loss 0.08950037509202957 train acc 0.6662416577849943\n",
      "epoch 1 batch id 139901 / 225000 loss 0.3009090721607208 train acc 0.6662765098176567\n",
      "epoch 1 batch id 140001 / 225000 loss 2.3474979400634766 train acc 0.6663077406589953\n",
      "epoch 1 batch id 140101 / 225000 loss 2.8265488147735596 train acc 0.6663763998829416\n",
      "epoch 1 batch id 140201 / 225000 loss 0.545801043510437 train acc 0.6664324790836014\n",
      "epoch 1 batch id 140301 / 225000 loss 0.045622169971466064 train acc 0.6664849145765176\n",
      "epoch 1 batch id 140401 / 225000 loss 3.0682461261749268 train acc 0.6664874181807822\n",
      "epoch 1 batch id 140501 / 225000 loss 1.8511781692504883 train acc 0.6665237258097807\n",
      "epoch 1 batch id 140601 / 225000 loss 2.234100580215454 train acc 0.6665759845235809\n",
      "epoch 1 batch id 140701 / 225000 loss 1.6923785209655762 train acc 0.6666281689540231\n",
      "epoch 1 batch id 140801 / 225000 loss 0.006348736584186554 train acc 0.6666714014815236\n",
      "epoch 1 batch id 140901 / 225000 loss 0.37268200516700745 train acc 0.6667181212340579\n",
      "epoch 1 batch id 141001 / 225000 loss 0.056682709604501724 train acc 0.6667647747179098\n",
      "epoch 1 batch id 141101 / 225000 loss 0.003732489887624979 train acc 0.6668414823424356\n",
      "epoch 1 batch id 141201 / 225000 loss 1.1892528533935547 train acc 0.6668809002769103\n",
      "epoch 1 batch id 141301 / 225000 loss 2.54883074760437 train acc 0.666943262963461\n",
      "epoch 1 batch id 141401 / 225000 loss 1.7804635763168335 train acc 0.666977249100077\n",
      "epoch 1 batch id 141501 / 225000 loss 0.3573349118232727 train acc 0.6670588900431799\n",
      "epoch 1 batch id 141601 / 225000 loss 3.6068272590637207 train acc 0.6670998086171708\n",
      "epoch 1 batch id 141701 / 225000 loss 2.858048677444458 train acc 0.6671177338198037\n",
      "epoch 1 batch id 141801 / 225000 loss 1.6190890073776245 train acc 0.6671444489107975\n",
      "epoch 1 batch id 141901 / 225000 loss 0.8862946629524231 train acc 0.6672028385987414\n",
      "epoch 1 batch id 142001 / 225000 loss 2.623587131500244 train acc 0.6672400194364828\n",
      "epoch 1 batch id 142101 / 225000 loss 1.6963642835617065 train acc 0.6672877038162996\n",
      "epoch 1 batch id 142201 / 225000 loss 0.8227018713951111 train acc 0.6672966434835198\n",
      "epoch 1 batch id 142301 / 225000 loss 0.004316439386457205 train acc 0.667347734731309\n",
      "epoch 1 batch id 142401 / 225000 loss 1.9556820392608643 train acc 0.6673794425600944\n",
      "epoch 1 batch id 142501 / 225000 loss 0.6835243105888367 train acc 0.6674058427660157\n",
      "epoch 1 batch id 142601 / 225000 loss 0.08475890010595322 train acc 0.6674742813865261\n",
      "epoch 1 batch id 142701 / 225000 loss 0.8707159161567688 train acc 0.6675321125990707\n",
      "epoch 1 batch id 142801 / 225000 loss 0.623435378074646 train acc 0.6675986162561887\n",
      "epoch 1 batch id 142901 / 225000 loss 2.082643747329712 train acc 0.667651031133442\n",
      "epoch 1 batch id 143001 / 225000 loss 0.7393528819084167 train acc 0.6677016244641646\n",
      "epoch 1 batch id 143101 / 225000 loss 2.288593292236328 train acc 0.6677434119957233\n",
      "epoch 1 batch id 143201 / 225000 loss 3.6225080490112305 train acc 0.6678183113246415\n",
      "epoch 1 batch id 143301 / 225000 loss 0.03758342191576958 train acc 0.6678390241519598\n",
      "epoch 1 batch id 143401 / 225000 loss 1.9243032932281494 train acc 0.6678736549954324\n",
      "epoch 1 batch id 143501 / 225000 loss 3.25321102142334 train acc 0.6679099797213957\n",
      "epoch 1 batch id 143601 / 225000 loss 0.9636305570602417 train acc 0.667934067311509\n",
      "epoch 1 batch id 143701 / 225000 loss 2.792416572570801 train acc 0.6679737788881079\n",
      "epoch 1 batch id 143801 / 225000 loss 0.006864010822027922 train acc 0.6680238663152551\n",
      "epoch 1 batch id 143901 / 225000 loss 2.903459072113037 train acc 0.6680391380184988\n",
      "epoch 1 batch id 144001 / 225000 loss 3.4072043895721436 train acc 0.6680995270866175\n",
      "epoch 1 batch id 144101 / 225000 loss 1.3514070510864258 train acc 0.6681407485027863\n",
      "epoch 1 batch id 144201 / 225000 loss 0.029671872034668922 train acc 0.6681975159672956\n",
      "epoch 1 batch id 144301 / 225000 loss 0.6415767669677734 train acc 0.6682403448347551\n",
      "epoch 1 batch id 144401 / 225000 loss 1.1144516468048096 train acc 0.6682865769627634\n",
      "epoch 1 batch id 144501 / 225000 loss 3.04524564743042 train acc 0.6683431256531097\n",
      "epoch 1 batch id 144601 / 225000 loss 2.78079891204834 train acc 0.6683719338040539\n",
      "epoch 1 batch id 144701 / 225000 loss 3.545456886291504 train acc 0.6684266176460425\n",
      "epoch 1 batch id 144801 / 225000 loss 0.43225333094596863 train acc 0.6684967645251069\n",
      "epoch 1 batch id 144901 / 225000 loss 1.1767637729644775 train acc 0.6685185057384007\n",
      "epoch 1 batch id 145001 / 225000 loss 1.54446280002594 train acc 0.6685695271067096\n",
      "epoch 1 batch id 145101 / 225000 loss 0.009761707857251167 train acc 0.6686187552118869\n",
      "epoch 1 batch id 145201 / 225000 loss 2.632805824279785 train acc 0.6686696372614513\n",
      "epoch 1 batch id 145301 / 225000 loss 1.61136794090271 train acc 0.6687376549369929\n",
      "epoch 1 batch id 145401 / 225000 loss 0.022737549617886543 train acc 0.6687832270754671\n",
      "epoch 1 batch id 145501 / 225000 loss 1.3266749382019043 train acc 0.6688063999560141\n",
      "epoch 1 batch id 145601 / 225000 loss 1.7420004606246948 train acc 0.6688484282388171\n",
      "epoch 1 batch id 145701 / 225000 loss 2.8810617923736572 train acc 0.6688732404032917\n",
      "epoch 1 batch id 145801 / 225000 loss 0.6922192573547363 train acc 0.6689357411814734\n",
      "epoch 1 batch id 145901 / 225000 loss 3.5570852756500244 train acc 0.6689758809055455\n",
      "epoch 1 batch id 146001 / 225000 loss 0.5527302026748657 train acc 0.6690245272292655\n",
      "epoch 1 batch id 146101 / 225000 loss 1.8993006944656372 train acc 0.669050862074866\n",
      "epoch 1 batch id 146201 / 225000 loss 1.4055969715118408 train acc 0.6690822908188042\n",
      "epoch 1 batch id 146301 / 225000 loss 0.4264907240867615 train acc 0.6691170942098824\n",
      "epoch 1 batch id 146401 / 225000 loss 1.2826805114746094 train acc 0.6691740493575864\n",
      "epoch 1 batch id 146501 / 225000 loss 1.1977366209030151 train acc 0.6692121555484263\n",
      "epoch 1 batch id 146601 / 225000 loss 0.33484184741973877 train acc 0.6692246301184849\n",
      "epoch 1 batch id 146701 / 225000 loss 0.7375457882881165 train acc 0.6692592415866286\n",
      "epoch 1 batch id 146801 / 225000 loss 5.167869567871094 train acc 0.6693244596426455\n",
      "epoch 1 batch id 146901 / 225000 loss 4.411365032196045 train acc 0.6693708688164137\n",
      "epoch 1 batch id 147001 / 225000 loss 1.3019806146621704 train acc 0.6694036094992551\n",
      "epoch 1 batch id 147101 / 225000 loss 1.259934663772583 train acc 0.6694499017681729\n",
      "epoch 1 batch id 147201 / 225000 loss 2.0819242000579834 train acc 0.6694893377083037\n",
      "epoch 1 batch id 147301 / 225000 loss 1.7010279893875122 train acc 0.669542297744075\n",
      "epoch 1 batch id 147401 / 225000 loss 0.41862010955810547 train acc 0.6695951859213981\n",
      "epoch 1 batch id 147501 / 225000 loss 2.706906795501709 train acc 0.6696327482525543\n",
      "epoch 1 batch id 147601 / 225000 loss 2.739788770675659 train acc 0.6696888909966735\n",
      "epoch 1 batch id 147701 / 225000 loss 0.8990216851234436 train acc 0.6697415725012017\n",
      "epoch 1 batch id 147801 / 225000 loss 0.8692463040351868 train acc 0.6697840339375241\n",
      "epoch 1 batch id 147901 / 225000 loss 2.2798233032226562 train acc 0.6698213669954902\n",
      "epoch 1 batch id 148001 / 225000 loss 4.76279354095459 train acc 0.6698687846703738\n",
      "epoch 1 batch id 148101 / 225000 loss 3.1103973388671875 train acc 0.6698992579388391\n",
      "epoch 1 batch id 148201 / 225000 loss 0.9459824562072754 train acc 0.6699482459632526\n",
      "epoch 1 batch id 148301 / 225000 loss 1.518790602684021 train acc 0.6699921106398473\n",
      "epoch 1 batch id 148401 / 225000 loss 2.115318536758423 train acc 0.670044339323859\n",
      "epoch 1 batch id 148501 / 225000 loss 1.0786340236663818 train acc 0.6700796627632137\n",
      "epoch 1 batch id 148601 / 225000 loss 1.2097437381744385 train acc 0.6701115739463396\n",
      "epoch 1 batch id 148701 / 225000 loss 2.71838641166687 train acc 0.6701518483399573\n",
      "epoch 1 batch id 148801 / 225000 loss 6.724877834320068 train acc 0.6701567865807353\n",
      "epoch 1 batch id 148901 / 225000 loss 1.6545616388320923 train acc 0.6702154451615503\n",
      "epoch 1 batch id 149001 / 225000 loss 2.022315740585327 train acc 0.6702387903436889\n",
      "epoch 1 batch id 149101 / 225000 loss 1.4040873050689697 train acc 0.670253720632323\n",
      "epoch 1 batch id 149201 / 225000 loss 0.0030909765046089888 train acc 0.6702837112351794\n",
      "epoch 1 batch id 149301 / 225000 loss 1.6224130392074585 train acc 0.6703488255269556\n",
      "epoch 1 batch id 149401 / 225000 loss 1.430842399597168 train acc 0.6704038125581488\n",
      "epoch 1 batch id 149501 / 225000 loss 0.17803731560707092 train acc 0.6704403315027994\n",
      "epoch 1 batch id 149601 / 225000 loss 1.720757246017456 train acc 0.6704851571847782\n",
      "epoch 1 batch id 149701 / 225000 loss 0.6077811121940613 train acc 0.6705583129037214\n",
      "epoch 1 batch id 149801 / 225000 loss 1.014391541481018 train acc 0.6705963244571131\n",
      "epoch 1 batch id 149901 / 225000 loss 0.01771962083876133 train acc 0.6706259464579956\n",
      "epoch 1 batch id 150001 / 225000 loss 1.4117385149002075 train acc 0.6706621955853628\n",
      "epoch 1 batch id 150101 / 225000 loss 3.369755983352661 train acc 0.6707050585938801\n",
      "epoch 1 batch id 150201 / 225000 loss 1.3833895921707153 train acc 0.6707278912923349\n",
      "epoch 1 batch id 150301 / 225000 loss 0.0021383618004620075 train acc 0.6707689902262792\n",
      "epoch 1 batch id 150401 / 225000 loss 0.07132115960121155 train acc 0.6708067100617682\n",
      "epoch 1 batch id 150501 / 225000 loss 0.03134424239397049 train acc 0.6708377352974398\n",
      "epoch 1 batch id 150601 / 225000 loss 0.060291193425655365 train acc 0.6708637392845997\n",
      "epoch 1 batch id 150701 / 225000 loss 1.9000377655029297 train acc 0.6708980033310993\n",
      "epoch 1 batch id 150801 / 225000 loss 0.10458319634199142 train acc 0.6709305641209276\n",
      "epoch 1 batch id 150901 / 225000 loss 0.07843565940856934 train acc 0.670986275770207\n",
      "epoch 1 batch id 151001 / 225000 loss 0.016308728605508804 train acc 0.6710352911570122\n",
      "epoch 1 batch id 151101 / 225000 loss 0.01051941979676485 train acc 0.671085896188642\n",
      "epoch 1 batch id 151201 / 225000 loss 0.12659047544002533 train acc 0.6711628891343311\n",
      "epoch 1 batch id 151301 / 225000 loss 1.644702434539795 train acc 0.6711968195848012\n",
      "epoch 1 batch id 151401 / 225000 loss 2.975951671600342 train acc 0.6712207977490241\n",
      "epoch 1 batch id 151501 / 225000 loss 3.7419514656066895 train acc 0.6712744470333529\n",
      "epoch 1 batch id 151601 / 225000 loss 0.794330358505249 train acc 0.6712900970310223\n",
      "epoch 1 batch id 151701 / 225000 loss 1.1749669313430786 train acc 0.6713287980962551\n",
      "epoch 1 batch id 151801 / 225000 loss 0.9837873578071594 train acc 0.6713427447777024\n",
      "epoch 1 batch id 151901 / 225000 loss 2.207880973815918 train acc 0.6713649021402097\n",
      "epoch 1 batch id 152001 / 225000 loss 0.7104300260543823 train acc 0.6714084117867646\n",
      "epoch 1 batch id 152101 / 225000 loss 2.3617873191833496 train acc 0.6714403587090157\n",
      "epoch 1 batch id 152201 / 225000 loss 1.3112404346466064 train acc 0.6714903318637854\n",
      "epoch 1 batch id 152301 / 225000 loss 2.0873005390167236 train acc 0.6714975607514068\n",
      "epoch 1 batch id 152401 / 225000 loss 0.023596763610839844 train acc 0.6715523520186876\n",
      "epoch 1 batch id 152501 / 225000 loss 1.7868670225143433 train acc 0.671598874761477\n",
      "epoch 1 batch id 152601 / 225000 loss 0.02696162648499012 train acc 0.6716453365312154\n",
      "epoch 1 batch id 152701 / 225000 loss 0.8192249536514282 train acc 0.671691737447692\n",
      "epoch 1 batch id 152801 / 225000 loss 4.445732116699219 train acc 0.6717429859752226\n",
      "epoch 1 batch id 152901 / 225000 loss 1.4361799955368042 train acc 0.671800707647432\n",
      "epoch 1 batch id 153001 / 225000 loss 2.155320167541504 train acc 0.6718583538669682\n",
      "epoch 1 batch id 153101 / 225000 loss 0.5473606586456299 train acc 0.6718767349658069\n",
      "epoch 1 batch id 153201 / 225000 loss 1.8228400945663452 train acc 0.6719081468136631\n",
      "epoch 1 batch id 153301 / 225000 loss 1.4574280977249146 train acc 0.6719476715742233\n",
      "epoch 1 batch id 153401 / 225000 loss 0.04811473935842514 train acc 0.6719838853723248\n",
      "epoch 1 batch id 153501 / 225000 loss 0.15405651926994324 train acc 0.6720298239099419\n",
      "epoch 1 batch id 153601 / 225000 loss 1.038979172706604 train acc 0.6720594266964408\n",
      "epoch 1 batch id 153701 / 225000 loss 0.06839697808027267 train acc 0.6721068828439632\n",
      "epoch 1 batch id 153801 / 225000 loss 0.19884416460990906 train acc 0.6721591537116144\n",
      "epoch 1 batch id 153901 / 225000 loss 1.3961539268493652 train acc 0.6721869903379445\n",
      "epoch 1 batch id 154001 / 225000 loss 1.397982120513916 train acc 0.6722164141791287\n",
      "epoch 1 batch id 154101 / 225000 loss 0.8390827775001526 train acc 0.6722425552072991\n",
      "epoch 1 batch id 154201 / 225000 loss 2.6346733570098877 train acc 0.6722962237598978\n",
      "epoch 1 batch id 154301 / 225000 loss 0.023810233920812607 train acc 0.6723401014899449\n",
      "epoch 1 batch id 154401 / 225000 loss 1.4049302339553833 train acc 0.6723547774949644\n",
      "epoch 1 batch id 154501 / 225000 loss 0.4220027029514313 train acc 0.6723839975145792\n",
      "epoch 1 batch id 154601 / 225000 loss 3.9598898887634277 train acc 0.6724228821288348\n",
      "epoch 1 batch id 154701 / 225000 loss 2.260063409805298 train acc 0.6724196999372984\n",
      "epoch 1 batch id 154801 / 225000 loss 0.004649137146770954 train acc 0.6724375165535106\n",
      "epoch 1 batch id 154901 / 225000 loss 1.04410982131958 train acc 0.6724746773745812\n",
      "epoch 1 batch id 155001 / 225000 loss 2.079486131668091 train acc 0.6725198547106148\n",
      "epoch 1 batch id 155101 / 225000 loss 1.2134063243865967 train acc 0.6725617500854282\n",
      "epoch 1 batch id 155201 / 225000 loss 0.005345178302377462 train acc 0.6726180888009742\n",
      "epoch 1 batch id 155301 / 225000 loss 0.680456817150116 train acc 0.6726485985280197\n",
      "epoch 1 batch id 155401 / 225000 loss 0.005205891560763121 train acc 0.6727015913668509\n",
      "epoch 1 batch id 155501 / 225000 loss 1.3487589359283447 train acc 0.6727432621012084\n",
      "epoch 1 batch id 155601 / 225000 loss 1.1593964099884033 train acc 0.6727848792745548\n",
      "epoch 1 batch id 155701 / 225000 loss 2.090073585510254 train acc 0.6728248373485077\n",
      "epoch 1 batch id 155801 / 225000 loss 0.7027062773704529 train acc 0.6728679533507487\n",
      "epoch 1 batch id 155901 / 225000 loss 0.42090606689453125 train acc 0.6728981853868802\n",
      "epoch 1 batch id 156001 / 225000 loss 1.6379427909851074 train acc 0.6729267761104095\n",
      "epoch 1 batch id 156101 / 225000 loss 0.0071192411705851555 train acc 0.6729473225667997\n",
      "epoch 1 batch id 156201 / 225000 loss 1.611657738685608 train acc 0.6729998527538236\n",
      "epoch 1 batch id 156301 / 225000 loss 0.31069451570510864 train acc 0.6730203261655395\n",
      "epoch 1 batch id 156401 / 225000 loss 0.005847502499818802 train acc 0.6730695455911407\n",
      "epoch 1 batch id 156501 / 225000 loss 1.6004159450531006 train acc 0.6730947406086862\n",
      "epoch 1 batch id 156601 / 225000 loss 0.6553195118904114 train acc 0.6731406568285004\n",
      "epoch 1 batch id 156701 / 225000 loss 0.00984271802008152 train acc 0.6731705604941896\n",
      "epoch 1 batch id 156801 / 225000 loss 1.2159862518310547 train acc 0.6732243416814944\n",
      "epoch 1 batch id 156901 / 225000 loss 2.5320639610290527 train acc 0.6732525605318003\n",
      "epoch 1 batch id 157001 / 225000 loss 1.7245346307754517 train acc 0.6732934822071197\n",
      "epoch 1 batch id 157101 / 225000 loss 0.2969074547290802 train acc 0.6733343517864304\n",
      "epoch 1 batch id 157201 / 225000 loss 0.012764954008162022 train acc 0.6734053854619245\n",
      "epoch 1 batch id 157301 / 225000 loss 0.0054324110969901085 train acc 0.6734493105574663\n",
      "epoch 1 batch id 157401 / 225000 loss 0.03203302621841431 train acc 0.6734931798400264\n",
      "epoch 1 batch id 157501 / 225000 loss 3.997793197631836 train acc 0.6735449298734612\n",
      "epoch 1 batch id 157601 / 225000 loss 2.6039958000183105 train acc 0.6735617159789595\n",
      "epoch 1 batch id 157701 / 225000 loss 3.1967885494232178 train acc 0.6735800660744067\n",
      "epoch 1 batch id 157801 / 225000 loss 0.09766653180122375 train acc 0.6736522582239656\n",
      "epoch 1 batch id 157901 / 225000 loss 2.9804089069366455 train acc 0.6737037764168688\n",
      "epoch 1 batch id 158001 / 225000 loss 1.9720720052719116 train acc 0.6737615584711489\n",
      "epoch 1 batch id 158101 / 225000 loss 0.7731653451919556 train acc 0.6738129423596309\n",
      "epoch 1 batch id 158201 / 225000 loss 2.174999952316284 train acc 0.673838976997617\n",
      "epoch 1 batch id 158301 / 225000 loss 0.5289090871810913 train acc 0.673882350711619\n",
      "epoch 1 batch id 158401 / 225000 loss 0.8269120454788208 train acc 0.673924091388312\n",
      "epoch 1 batch id 158501 / 225000 loss 1.0375491380691528 train acc 0.6739831294439783\n",
      "epoch 1 batch id 158601 / 225000 loss 0.5680999755859375 train acc 0.6740200250944194\n",
      "epoch 1 batch id 158701 / 225000 loss 1.8279168605804443 train acc 0.6740474225115154\n",
      "epoch 1 batch id 158801 / 225000 loss 0.017881210893392563 train acc 0.674082656910221\n",
      "epoch 1 batch id 158901 / 225000 loss 0.008031060919165611 train acc 0.6741272868012158\n",
      "epoch 1 batch id 159001 / 225000 loss 0.004501250572502613 train acc 0.6741482757970075\n",
      "epoch 1 batch id 159101 / 225000 loss 0.01155640184879303 train acc 0.6741770950528281\n",
      "epoch 1 batch id 159201 / 225000 loss 1.9042315483093262 train acc 0.6742278628903084\n",
      "epoch 1 batch id 159301 / 225000 loss 1.6165260076522827 train acc 0.6742518879354179\n",
      "epoch 1 batch id 159401 / 225000 loss 1.4273284673690796 train acc 0.6743041135250093\n",
      "epoch 1 batch id 159501 / 225000 loss 0.024439217522740364 train acc 0.6743374649688717\n",
      "epoch 1 batch id 159601 / 225000 loss 1.7628560066223145 train acc 0.6743519777445004\n",
      "epoch 1 batch id 159701 / 225000 loss 1.1017705202102661 train acc 0.6744071734053012\n",
      "epoch 1 batch id 159801 / 225000 loss 1.8128726482391357 train acc 0.6744247532869005\n",
      "epoch 1 batch id 159901 / 225000 loss 0.0036063180305063725 train acc 0.6744735805279517\n",
      "epoch 1 batch id 160001 / 225000 loss 0.8513016700744629 train acc 0.6745207842450984\n",
      "epoch 1 batch id 160101 / 225000 loss 1.852321982383728 train acc 0.6745445062804105\n",
      "epoch 1 batch id 160201 / 225000 loss 1.9182072877883911 train acc 0.6745962884126816\n",
      "epoch 1 batch id 160301 / 225000 loss 0.1483873724937439 train acc 0.6746230528817662\n",
      "epoch 1 batch id 160401 / 225000 loss 3.5387473106384277 train acc 0.6746513425726772\n",
      "epoch 1 batch id 160501 / 225000 loss 1.6811199188232422 train acc 0.674695173238796\n",
      "epoch 1 batch id 160601 / 225000 loss 0.6777978539466858 train acc 0.6747654124195989\n",
      "epoch 1 batch id 160701 / 225000 loss 0.0034199459478259087 train acc 0.6748200073428292\n",
      "epoch 1 batch id 160801 / 225000 loss 1.1049869060516357 train acc 0.67486987021225\n",
      "epoch 1 batch id 160901 / 225000 loss 0.008725151419639587 train acc 0.6749274398543204\n",
      "epoch 1 batch id 161001 / 225000 loss 1.2213876247406006 train acc 0.6749709629132739\n",
      "epoch 1 batch id 161101 / 225000 loss 0.9480152726173401 train acc 0.6749989137249304\n",
      "epoch 1 batch id 161201 / 225000 loss 0.0588986799120903 train acc 0.6750624996122853\n",
      "epoch 1 batch id 161301 / 225000 loss 1.386444330215454 train acc 0.6751105076843913\n",
      "epoch 1 batch id 161401 / 225000 loss 0.5562905669212341 train acc 0.6751383200847578\n",
      "epoch 1 batch id 161501 / 225000 loss 2.043691635131836 train acc 0.6752017015374517\n",
      "epoch 1 batch id 161601 / 225000 loss 0.5636366009712219 train acc 0.6752340641456427\n",
      "epoch 1 batch id 161701 / 225000 loss 3.007685661315918 train acc 0.6752679327895313\n",
      "epoch 1 batch id 161801 / 225000 loss 0.9251381158828735 train acc 0.6752832182742999\n",
      "epoch 1 batch id 161901 / 225000 loss 1.7199548482894897 train acc 0.6753185588723973\n",
      "epoch 1 batch id 162001 / 225000 loss 2.9268741607666016 train acc 0.6753600286417986\n",
      "epoch 1 batch id 162101 / 225000 loss 6.025337219238281 train acc 0.6753968205007989\n",
      "epoch 1 batch id 162201 / 225000 loss 0.21783700585365295 train acc 0.6754181540187791\n",
      "epoch 1 batch id 162301 / 225000 loss 0.9355395436286926 train acc 0.6754425419436726\n",
      "epoch 1 batch id 162401 / 225000 loss 0.09280439466238022 train acc 0.6754668998343606\n",
      "epoch 1 batch id 162501 / 225000 loss 0.6411745548248291 train acc 0.675495843102504\n",
      "epoch 1 batch id 162601 / 225000 loss 0.01660931669175625 train acc 0.6755293632880487\n",
      "epoch 1 batch id 162701 / 225000 loss 1.0086393356323242 train acc 0.6755474766596394\n",
      "epoch 1 batch id 162801 / 225000 loss 1.7342993021011353 train acc 0.6755671033961708\n",
      "epoch 1 batch id 162901 / 225000 loss 1.1582324504852295 train acc 0.6756173995248648\n",
      "epoch 1 batch id 163001 / 225000 loss 1.9517004489898682 train acc 0.675655364077521\n",
      "epoch 1 batch id 163101 / 225000 loss 2.763726234436035 train acc 0.6756856181139294\n",
      "epoch 1 batch id 163201 / 225000 loss 0.276527464389801 train acc 0.6757005165409525\n",
      "epoch 1 batch id 163301 / 225000 loss 0.006368956062942743 train acc 0.6757521386886792\n",
      "epoch 1 batch id 163401 / 225000 loss 0.008307774551212788 train acc 0.6757883978678221\n",
      "epoch 1 batch id 163501 / 225000 loss 0.339097797870636 train acc 0.6758460192904019\n",
      "epoch 1 batch id 163601 / 225000 loss 1.4960923194885254 train acc 0.6758837048673296\n",
      "epoch 1 batch id 163701 / 225000 loss 0.9828862547874451 train acc 0.6758938552605054\n",
      "epoch 1 batch id 163801 / 225000 loss 1.9209390878677368 train acc 0.6759268868932424\n",
      "epoch 1 batch id 163901 / 225000 loss 2.0546011924743652 train acc 0.6759812325733217\n",
      "epoch 1 batch id 164001 / 225000 loss 0.057073161005973816 train acc 0.6760217925500455\n",
      "epoch 1 batch id 164101 / 225000 loss 0.015659714117646217 train acc 0.676068396901908\n",
      "epoch 1 batch id 164201 / 225000 loss 0.9042730331420898 train acc 0.6760966741980865\n",
      "epoch 1 batch id 164301 / 225000 loss 0.07808565348386765 train acc 0.6761370898533788\n",
      "epoch 1 batch id 164401 / 225000 loss 0.005917740520089865 train acc 0.6761652909653835\n",
      "epoch 1 batch id 164501 / 225000 loss 0.14794687926769257 train acc 0.6762208132473359\n",
      "epoch 1 batch id 164601 / 225000 loss 2.5023040771484375 train acc 0.6762550045260964\n",
      "epoch 1 batch id 164701 / 225000 loss 0.009804148226976395 train acc 0.6762709394599912\n",
      "epoch 1 batch id 164801 / 225000 loss 1.9521163702011108 train acc 0.676318711658303\n",
      "epoch 1 batch id 164901 / 225000 loss 0.21910007297992706 train acc 0.6763603616715483\n",
      "epoch 1 batch id 165001 / 225000 loss 0.9749444723129272 train acc 0.6763943854885728\n",
      "epoch 1 batch id 165101 / 225000 loss 0.046540793031454086 train acc 0.6764313965390882\n",
      "epoch 1 batch id 165201 / 225000 loss 1.646991491317749 train acc 0.6764577696260918\n",
      "epoch 1 batch id 165301 / 225000 loss 0.8247581124305725 train acc 0.6764841108039273\n",
      "epoch 1 batch id 165401 / 225000 loss 0.9569284915924072 train acc 0.6765089086523056\n",
      "epoch 1 batch id 165501 / 225000 loss 2.361802816390991 train acc 0.6765442504879124\n",
      "epoch 1 batch id 165601 / 225000 loss 1.2704391479492188 train acc 0.6765855882512787\n",
      "epoch 1 batch id 165701 / 225000 loss 0.513203501701355 train acc 0.676643472278381\n",
      "epoch 1 batch id 165801 / 225000 loss 3.9008677005767822 train acc 0.6766892238285656\n",
      "epoch 1 batch id 165901 / 225000 loss 3.0525341033935547 train acc 0.6767198509954732\n",
      "epoch 1 batch id 166001 / 225000 loss 0.20182961225509644 train acc 0.6768001397581942\n",
      "epoch 1 batch id 166101 / 225000 loss 1.0856281518936157 train acc 0.6768442092461815\n",
      "epoch 1 batch id 166201 / 225000 loss 2.1256227493286133 train acc 0.6768701752697035\n",
      "epoch 1 batch id 166301 / 225000 loss 1.931541085243225 train acc 0.676902123258429\n",
      "epoch 1 batch id 166401 / 225000 loss 0.271525502204895 train acc 0.6769400424276296\n",
      "epoch 1 batch id 166501 / 225000 loss 1.5358445644378662 train acc 0.6769824205260029\n",
      "epoch 1 batch id 166601 / 225000 loss 1.672970175743103 train acc 0.6770157442032161\n",
      "epoch 1 batch id 166701 / 225000 loss 0.16332224011421204 train acc 0.6770550266645071\n",
      "epoch 1 batch id 166801 / 225000 loss 4.305753707885742 train acc 0.6770837704809923\n",
      "epoch 1 batch id 166901 / 225000 loss 3.4114489555358887 train acc 0.6771034924895597\n",
      "epoch 1 batch id 167001 / 225000 loss 3.303907632827759 train acc 0.6771396578463602\n",
      "epoch 1 batch id 167101 / 225000 loss 1.354762077331543 train acc 0.6771847565244972\n",
      "epoch 1 batch id 167201 / 225000 loss 1.5363826751708984 train acc 0.6772223252253275\n",
      "epoch 1 batch id 167301 / 225000 loss 1.9225579500198364 train acc 0.6772523774514199\n",
      "epoch 1 batch id 167401 / 225000 loss 0.670443058013916 train acc 0.67727642009307\n",
      "epoch 1 batch id 167501 / 225000 loss 2.516777276992798 train acc 0.6773093891976765\n",
      "epoch 1 batch id 167601 / 225000 loss 0.006118112243711948 train acc 0.6773557437008132\n",
      "epoch 1 batch id 167701 / 225000 loss 2.1939876079559326 train acc 0.6773990614247977\n",
      "epoch 1 batch id 167801 / 225000 loss 1.0246742963790894 train acc 0.6774333883588298\n",
      "epoch 1 batch id 167901 / 225000 loss 1.7968895435333252 train acc 0.6774527846766845\n",
      "epoch 1 batch id 168001 / 225000 loss 0.005934959277510643 train acc 0.6774974553722894\n",
      "epoch 1 batch id 168101 / 225000 loss 1.1750978231430054 train acc 0.6775628937365037\n",
      "epoch 1 batch id 168201 / 225000 loss 0.16438880562782288 train acc 0.6776015005856089\n",
      "epoch 1 batch id 168301 / 225000 loss 2.3742012977600098 train acc 0.6776222363503485\n",
      "epoch 1 batch id 168401 / 225000 loss 2.9566214084625244 train acc 0.6776355247296632\n",
      "epoch 1 batch id 168501 / 225000 loss 1.225585699081421 train acc 0.6776651177144349\n",
      "epoch 1 batch id 168601 / 225000 loss 1.4702237844467163 train acc 0.6776783648970054\n",
      "epoch 1 batch id 168701 / 225000 loss 1.0953574180603027 train acc 0.6776871506392967\n",
      "epoch 1 batch id 168801 / 225000 loss 1.475048542022705 train acc 0.6777270276834853\n",
      "epoch 1 batch id 168901 / 225000 loss 0.8017745018005371 train acc 0.6777772186073499\n",
      "epoch 1 batch id 169001 / 225000 loss 0.9422117471694946 train acc 0.6778051609162076\n",
      "epoch 1 batch id 169101 / 225000 loss 2.7902541160583496 train acc 0.6778271565514101\n",
      "epoch 1 batch id 169201 / 225000 loss 0.5501547455787659 train acc 0.6778476486545588\n",
      "epoch 1 batch id 169301 / 225000 loss 0.013130603358149529 train acc 0.677894696428255\n",
      "epoch 1 batch id 169401 / 225000 loss 3.4073073863983154 train acc 0.6778944634329195\n",
      "epoch 1 batch id 169501 / 225000 loss 2.467395544052124 train acc 0.6779163544757848\n",
      "epoch 1 batch id 169601 / 225000 loss 0.8116514086723328 train acc 0.6779603304225801\n",
      "epoch 1 batch id 169701 / 225000 loss 0.024927517399191856 train acc 0.678002781362514\n",
      "epoch 1 batch id 169801 / 225000 loss 1.4399502277374268 train acc 0.6780319314962809\n",
      "epoch 1 batch id 169901 / 225000 loss 0.927045464515686 train acc 0.6780610473157898\n",
      "epoch 1 batch id 170001 / 225000 loss 4.432238578796387 train acc 0.6780695407674072\n",
      "epoch 1 batch id 170101 / 225000 loss 3.184372663497925 train acc 0.6780971305283332\n",
      "epoch 1 batch id 170201 / 225000 loss 3.9489989280700684 train acc 0.6781335009782551\n",
      "epoch 1 batch id 170301 / 225000 loss 2.0094029903411865 train acc 0.6781801046382582\n",
      "epoch 1 batch id 170401 / 225000 loss 0.09937721490859985 train acc 0.6782105151965071\n",
      "epoch 1 batch id 170501 / 225000 loss 1.122828722000122 train acc 0.6782423563498161\n",
      "epoch 1 batch id 170601 / 225000 loss 0.0826101005077362 train acc 0.6782712293597342\n",
      "epoch 1 batch id 170701 / 225000 loss 1.6793336868286133 train acc 0.6783132494830142\n",
      "epoch 1 batch id 170801 / 225000 loss 0.029432768002152443 train acc 0.6783391197943806\n",
      "epoch 1 batch id 170901 / 225000 loss 0.006260434165596962 train acc 0.6783869023586755\n",
      "epoch 1 batch id 171001 / 225000 loss 0.0074995532631874084 train acc 0.678434629037257\n",
      "epoch 1 batch id 171101 / 225000 loss 0.3211090564727783 train acc 0.6784662275498098\n",
      "epoch 1 batch id 171201 / 225000 loss 2.311683416366577 train acc 0.6785284548571562\n",
      "epoch 1 batch id 171301 / 225000 loss 1.0562126636505127 train acc 0.6785803935762197\n",
      "epoch 1 batch id 171401 / 225000 loss 1.3310332298278809 train acc 0.67860310033197\n",
      "epoch 1 batch id 171501 / 225000 loss 0.14946310222148895 train acc 0.6786330691949318\n",
      "epoch 1 batch id 171601 / 225000 loss 2.3733768463134766 train acc 0.6786644599973194\n",
      "epoch 1 batch id 171701 / 225000 loss 1.2094883918762207 train acc 0.6787001822936384\n",
      "epoch 1 batch id 171801 / 225000 loss 3.396507740020752 train acc 0.6787271319724565\n",
      "epoch 1 batch id 171901 / 225000 loss 2.027014970779419 train acc 0.6787874997818512\n",
      "epoch 1 batch id 172001 / 225000 loss 0.026981329545378685 train acc 0.6788332625973105\n",
      "epoch 1 batch id 172101 / 225000 loss 4.653462886810303 train acc 0.6788528247947426\n",
      "epoch 1 batch id 172201 / 225000 loss 0.07126137614250183 train acc 0.6789086590670205\n",
      "epoch 1 batch id 172301 / 225000 loss 2.2394967079162598 train acc 0.678945566189401\n",
      "epoch 1 batch id 172401 / 225000 loss 0.04409780725836754 train acc 0.6789853307115388\n",
      "epoch 1 batch id 172501 / 225000 loss 0.07201100140810013 train acc 0.6790467881345615\n",
      "epoch 1 batch id 172601 / 225000 loss 3.7158446311950684 train acc 0.6790936900713206\n",
      "epoch 1 batch id 172701 / 225000 loss 1.167555570602417 train acc 0.6791506708125604\n",
      "epoch 1 batch id 172801 / 225000 loss 0.008078626357018948 train acc 0.6791656298285311\n",
      "epoch 1 batch id 172901 / 225000 loss 1.5392721891403198 train acc 0.6791979225105697\n",
      "epoch 1 batch id 173001 / 225000 loss 1.5511733293533325 train acc 0.6792359581736521\n",
      "epoch 1 batch id 173101 / 225000 loss 0.053264275193214417 train acc 0.6792595074551852\n",
      "epoch 1 batch id 173201 / 225000 loss 0.014591961167752743 train acc 0.6793003504598704\n",
      "epoch 1 batch id 173301 / 225000 loss 0.017282212153077126 train acc 0.6793512443667377\n",
      "epoch 1 batch id 173401 / 225000 loss 1.3745636940002441 train acc 0.6793833368896374\n",
      "epoch 1 batch id 173501 / 225000 loss 1.4893977642059326 train acc 0.6794168333323727\n",
      "epoch 1 batch id 173601 / 225000 loss 1.45845365524292 train acc 0.6794560515204405\n",
      "epoch 1 batch id 173701 / 225000 loss 0.5444237589836121 train acc 0.6794750749851757\n",
      "epoch 1 batch id 173801 / 225000 loss 1.9292821884155273 train acc 0.6794911997054102\n",
      "epoch 1 batch id 173901 / 225000 loss 0.023066047579050064 train acc 0.6795188066773624\n",
      "epoch 1 batch id 174001 / 225000 loss 2.968273639678955 train acc 0.6795277038637709\n",
      "epoch 1 batch id 174101 / 225000 loss 1.0199168920516968 train acc 0.679536590829461\n",
      "epoch 1 batch id 174201 / 225000 loss 2.3691675662994385 train acc 0.679581345686879\n",
      "epoch 1 batch id 174301 / 225000 loss 1.3417978286743164 train acc 0.6796375235942421\n",
      "epoch 1 batch id 174401 / 225000 loss 2.8698534965515137 train acc 0.6796635340393691\n",
      "epoch 1 batch id 174501 / 225000 loss 3.7102880477905273 train acc 0.6796837840470829\n",
      "epoch 1 batch id 174601 / 225000 loss 0.9928386211395264 train acc 0.6796982835149856\n",
      "epoch 1 batch id 174701 / 225000 loss 2.4541919231414795 train acc 0.679745679761421\n",
      "epoch 1 batch id 174801 / 225000 loss 0.799254298210144 train acc 0.6797801499991419\n",
      "epoch 1 batch id 174901 / 225000 loss 2.025726795196533 train acc 0.6798145808200068\n",
      "epoch 1 batch id 175001 / 225000 loss 0.7342031598091125 train acc 0.6798418294752602\n",
      "epoch 1 batch id 175101 / 225000 loss 1.3601994514465332 train acc 0.6798576250278411\n",
      "epoch 1 batch id 175201 / 225000 loss 0.8637608289718628 train acc 0.6798762564140616\n",
      "epoch 1 batch id 175301 / 225000 loss 1.7426602840423584 train acc 0.6798934404253256\n",
      "epoch 1 batch id 175401 / 225000 loss 0.04490160197019577 train acc 0.6799220072861615\n",
      "epoch 1 batch id 175501 / 225000 loss 0.19752278923988342 train acc 0.6799491170990478\n",
      "epoch 1 batch id 175601 / 225000 loss 1.1581754684448242 train acc 0.6799747723532326\n",
      "epoch 1 batch id 175701 / 225000 loss 2.0211803913116455 train acc 0.6799975526604857\n",
      "epoch 1 batch id 175801 / 225000 loss 0.1304524838924408 train acc 0.6800587027377546\n",
      "epoch 1 batch id 175901 / 225000 loss 0.003904261626303196 train acc 0.6800927794611742\n",
      "epoch 1 batch id 176001 / 225000 loss 1.078487753868103 train acc 0.6801310788006887\n",
      "epoch 1 batch id 176101 / 225000 loss 0.02168865129351616 train acc 0.6801721739229193\n",
      "epoch 1 batch id 176201 / 225000 loss 2.4744224548339844 train acc 0.6801933587210062\n",
      "epoch 1 batch id 176301 / 225000 loss 1.566962480545044 train acc 0.6802088473689882\n",
      "epoch 1 batch id 176401 / 225000 loss 1.606006145477295 train acc 0.6802299873583483\n",
      "epoch 1 batch id 176501 / 225000 loss 1.5018370151519775 train acc 0.6802638511963105\n",
      "epoch 1 batch id 176601 / 225000 loss 1.7254791259765625 train acc 0.6803061704067361\n",
      "epoch 1 batch id 176701 / 225000 loss 0.03131556138396263 train acc 0.680318730510863\n",
      "epoch 1 batch id 176801 / 225000 loss 0.7987428307533264 train acc 0.6803609708089886\n",
      "epoch 1 batch id 176901 / 225000 loss 3.208711624145508 train acc 0.6803763121746061\n",
      "epoch 1 batch id 177001 / 225000 loss 4.084627151489258 train acc 0.6804071728408314\n",
      "epoch 1 batch id 177101 / 225000 loss 2.322333335876465 train acc 0.6804309405367559\n",
      "epoch 1 batch id 177201 / 225000 loss 0.0032896632328629494 train acc 0.6804448056162211\n",
      "epoch 1 batch id 177301 / 225000 loss 1.1233367919921875 train acc 0.6804755754338667\n",
      "epoch 1 batch id 177401 / 225000 loss 0.7219603657722473 train acc 0.6805204029289575\n",
      "epoch 1 batch id 177501 / 225000 loss 1.224852442741394 train acc 0.6805412363874006\n",
      "epoch 1 batch id 177601 / 225000 loss 0.6483344435691833 train acc 0.6805733075827276\n",
      "epoch 1 batch id 177701 / 225000 loss 0.002476709196344018 train acc 0.6806095632551308\n",
      "epoch 1 batch id 177801 / 225000 loss 2.3370108604431152 train acc 0.6806485902778949\n",
      "epoch 1 batch id 177901 / 225000 loss 0.001399977132678032 train acc 0.6806594679063075\n",
      "epoch 1 batch id 178001 / 225000 loss 0.8779640197753906 train acc 0.680687187150634\n",
      "epoch 1 batch id 178101 / 225000 loss 0.5542116165161133 train acc 0.6807162789653062\n",
      "epoch 1 batch id 178201 / 225000 loss 1.3189210891723633 train acc 0.6807593672313847\n",
      "epoch 1 batch id 178301 / 225000 loss 3.816699743270874 train acc 0.6808122220290408\n",
      "epoch 1 batch id 178401 / 225000 loss 1.7247724533081055 train acc 0.6808524055358434\n",
      "epoch 1 batch id 178501 / 225000 loss 1.5016369819641113 train acc 0.6808855412574719\n",
      "epoch 1 batch id 178601 / 225000 loss 0.031142402440309525 train acc 0.6809270384824273\n",
      "epoch 1 batch id 178701 / 225000 loss 0.038798220455646515 train acc 0.6809475044907415\n",
      "epoch 1 batch id 178801 / 225000 loss 1.437182903289795 train acc 0.680981929631266\n",
      "epoch 1 batch id 178901 / 225000 loss 1.5278493165969849 train acc 0.6810079317611416\n",
      "epoch 1 batch id 179001 / 225000 loss 0.00752392178401351 train acc 0.6810185417958559\n",
      "epoch 1 batch id 179101 / 225000 loss 0.8934391736984253 train acc 0.6810347234242131\n",
      "epoch 1 batch id 179201 / 225000 loss 3.4142062664031982 train acc 0.6810620476448234\n",
      "epoch 1 batch id 179301 / 225000 loss 0.0021898967679589987 train acc 0.6810656382284538\n",
      "epoch 1 batch id 179401 / 225000 loss 1.128427267074585 train acc 0.681081766545337\n",
      "epoch 1 batch id 179501 / 225000 loss 0.13322675228118896 train acc 0.6811076261413586\n",
      "epoch 1 batch id 179601 / 225000 loss 1.2494828701019287 train acc 0.6811390248383917\n",
      "epoch 1 batch id 179701 / 225000 loss 4.712696075439453 train acc 0.6811773445890674\n",
      "epoch 1 batch id 179801 / 225000 loss 2.543349027633667 train acc 0.6812267451237757\n",
      "epoch 1 batch id 179901 / 225000 loss 0.006317543797194958 train acc 0.68126497351321\n",
      "epoch 1 batch id 180001 / 225000 loss 3.4039134979248047 train acc 0.6812962150210277\n",
      "epoch 1 batch id 180101 / 225000 loss 1.539466381072998 train acc 0.6813343623855503\n",
      "epoch 1 batch id 180201 / 225000 loss 2.493602752685547 train acc 0.6813821787892409\n",
      "epoch 1 batch id 180301 / 225000 loss 1.9349026679992676 train acc 0.6814243958713485\n",
      "epoch 1 batch id 180401 / 225000 loss 1.9826593399047852 train acc 0.6814346927123464\n",
      "epoch 1 batch id 180501 / 225000 loss 0.13648083806037903 train acc 0.6814463631780433\n",
      "epoch 1 batch id 180601 / 225000 loss 3.21138596534729 train acc 0.681494011661065\n",
      "epoch 1 batch id 180701 / 225000 loss 0.0020718639716506004 train acc 0.6815208548928894\n",
      "epoch 1 batch id 180801 / 225000 loss 2.5856094360351562 train acc 0.6815587303167571\n",
      "epoch 1 batch id 180901 / 225000 loss 0.027708785608410835 train acc 0.6816186754080962\n",
      "epoch 1 batch id 181001 / 225000 loss 1.9360487461090088 train acc 0.6816233059485859\n",
      "epoch 1 batch id 181101 / 225000 loss 0.669081449508667 train acc 0.6816458771624674\n",
      "epoch 1 batch id 181201 / 225000 loss 1.275376796722412 train acc 0.6816711828301169\n",
      "epoch 1 batch id 181301 / 225000 loss 1.4594299793243408 train acc 0.6817005973491597\n",
      "epoch 1 batch id 181401 / 225000 loss 0.9739919900894165 train acc 0.6817520300329105\n",
      "epoch 1 batch id 181501 / 225000 loss 1.4893486499786377 train acc 0.6817772353871329\n",
      "epoch 1 batch id 181601 / 225000 loss 1.9278643131256104 train acc 0.6817872698938883\n",
      "epoch 1 batch id 181701 / 225000 loss 1.689903736114502 train acc 0.6818193075437119\n",
      "epoch 1 batch id 181801 / 225000 loss 0.5692247748374939 train acc 0.68185268507874\n",
      "epoch 1 batch id 181901 / 225000 loss 0.011447395198047161 train acc 0.681880528419305\n",
      "epoch 1 batch id 182001 / 225000 loss 0.7802176475524902 train acc 0.6819234509700496\n",
      "epoch 1 batch id 182101 / 225000 loss 1.3811314105987549 train acc 0.6819525977342245\n",
      "epoch 1 batch id 182201 / 225000 loss 0.9573678374290466 train acc 0.6819762240602412\n",
      "epoch 1 batch id 182301 / 225000 loss 0.006131947971880436 train acc 0.682001195824488\n",
      "epoch 1 batch id 182401 / 225000 loss 1.0905053615570068 train acc 0.6820302520271271\n",
      "epoch 1 batch id 182501 / 225000 loss 2.1837363243103027 train acc 0.682057906532019\n",
      "epoch 1 batch id 182601 / 225000 loss 1.0039212703704834 train acc 0.6820855307473672\n",
      "epoch 1 batch id 182701 / 225000 loss 3.1516380310058594 train acc 0.6821008095193787\n",
      "epoch 1 batch id 182801 / 225000 loss 3.26015043258667 train acc 0.6821338504712775\n",
      "epoch 1 batch id 182901 / 225000 loss 0.1985951066017151 train acc 0.6821641215739662\n",
      "epoch 1 batch id 183001 / 225000 loss 1.276227355003357 train acc 0.6821834306916356\n",
      "epoch 1 batch id 183101 / 225000 loss 1.42920982837677 train acc 0.682223199217918\n",
      "epoch 1 batch id 183201 / 225000 loss 0.9857034683227539 train acc 0.6822601950862713\n",
      "epoch 1 batch id 183301 / 225000 loss 3.387132167816162 train acc 0.682288967326965\n",
      "epoch 1 batch id 183401 / 225000 loss 2.8068082332611084 train acc 0.6823040768589048\n",
      "epoch 1 batch id 183501 / 225000 loss 0.9992425441741943 train acc 0.6823355186075281\n",
      "epoch 1 batch id 183601 / 225000 loss 3.5602080821990967 train acc 0.6823655644577099\n",
      "epoch 1 batch id 183701 / 225000 loss 1.4342769384384155 train acc 0.6824173521102226\n",
      "epoch 1 batch id 183801 / 225000 loss 0.0410778783261776 train acc 0.6824554817438425\n",
      "epoch 1 batch id 183901 / 225000 loss 0.5645866394042969 train acc 0.6824704596494853\n",
      "epoch 1 batch id 184001 / 225000 loss 0.873605489730835 train acc 0.6824854212748844\n",
      "epoch 1 batch id 184101 / 225000 loss 0.04172296077013016 train acc 0.6825125881988691\n",
      "epoch 1 batch id 184201 / 225000 loss 0.5365545153617859 train acc 0.6825166530040554\n",
      "epoch 1 batch id 184301 / 225000 loss 3.9768002033233643 train acc 0.6825071486318577\n",
      "epoch 1 batch id 184401 / 225000 loss 1.592786192893982 train acc 0.6824949430859919\n",
      "epoch 1 batch id 184501 / 225000 loss 0.4783039391040802 train acc 0.6825112059013231\n",
      "epoch 1 batch id 184601 / 225000 loss 0.5719732046127319 train acc 0.6825423480912888\n",
      "epoch 1 batch id 184701 / 225000 loss 0.03144276887178421 train acc 0.6825517999361129\n",
      "epoch 1 batch id 184801 / 225000 loss 0.08890644460916519 train acc 0.6825801808431773\n",
      "epoch 1 batch id 184901 / 225000 loss 1.1398292779922485 train acc 0.6826071789768579\n",
      "epoch 1 batch id 185001 / 225000 loss 0.0074050165712833405 train acc 0.6826233371711504\n",
      "epoch 1 batch id 185101 / 225000 loss 4.122652530670166 train acc 0.6826624383444714\n",
      "epoch 1 batch id 185201 / 225000 loss 0.18834730982780457 train acc 0.6826960977532519\n",
      "epoch 1 batch id 185301 / 225000 loss 2.2343101501464844 train acc 0.6827378157700175\n",
      "epoch 1 batch id 185401 / 225000 loss 1.3694519996643066 train acc 0.6827646560698163\n",
      "epoch 1 batch id 185501 / 225000 loss 1.4704209566116333 train acc 0.6827752950118867\n",
      "epoch 1 batch id 185601 / 225000 loss 0.7836861610412598 train acc 0.6828142089751672\n",
      "epoch 1 batch id 185701 / 225000 loss 0.06627782434225082 train acc 0.6828382722764013\n",
      "epoch 1 batch id 185801 / 225000 loss 4.736329555511475 train acc 0.6828434723171565\n",
      "epoch 1 batch id 185901 / 225000 loss 1.1192034482955933 train acc 0.6828607699797203\n",
      "epoch 1 batch id 186001 / 225000 loss 1.1892518997192383 train acc 0.6829062746974479\n",
      "epoch 1 batch id 186101 / 225000 loss 2.1386518478393555 train acc 0.682947700442233\n",
      "epoch 1 batch id 186201 / 225000 loss 0.003635235596448183 train acc 0.6829917669615093\n",
      "epoch 1 batch id 186301 / 225000 loss 2.110581398010254 train acc 0.683023708944128\n",
      "epoch 1 batch id 186401 / 225000 loss 3.231386661529541 train acc 0.6830623226270245\n",
      "epoch 1 batch id 186501 / 225000 loss 2.298793077468872 train acc 0.6831035758521402\n",
      "epoch 1 batch id 186601 / 225000 loss 1.3254200220108032 train acc 0.6831220089924491\n",
      "epoch 1 batch id 186701 / 225000 loss 1.0325676202774048 train acc 0.6831605079779969\n",
      "epoch 1 batch id 186801 / 225000 loss 0.005535634700208902 train acc 0.6831802292278949\n",
      "epoch 1 batch id 186901 / 225000 loss 0.06930222362279892 train acc 0.6831945789482132\n",
      "epoch 1 batch id 187001 / 225000 loss 2.5885558128356934 train acc 0.6832129239950588\n",
      "epoch 1 batch id 187101 / 225000 loss 0.6503528952598572 train acc 0.6832165514882337\n",
      "epoch 1 batch id 187201 / 225000 loss 0.01676134392619133 train acc 0.6832415425131276\n",
      "epoch 1 batch id 187301 / 225000 loss 1.3672997951507568 train acc 0.6832691763525022\n",
      "epoch 1 batch id 187401 / 225000 loss 2.3079023361206055 train acc 0.6832901105116835\n",
      "epoch 1 batch id 187501 / 225000 loss 1.643394112586975 train acc 0.6833296889083258\n",
      "epoch 1 batch id 187601 / 225000 loss 0.5502710938453674 train acc 0.6833558989557625\n",
      "epoch 1 batch id 187701 / 225000 loss 0.018234150484204292 train acc 0.6833967320365901\n",
      "epoch 1 batch id 187801 / 225000 loss 4.51827335357666 train acc 0.6834295344540231\n",
      "epoch 1 batch id 187901 / 225000 loss 0.057284269481897354 train acc 0.6834529885418386\n",
      "epoch 1 batch id 188001 / 225000 loss 1.1676687002182007 train acc 0.6834777474587901\n",
      "epoch 1 batch id 188101 / 225000 loss 2.6178970336914062 train acc 0.6835250742951925\n",
      "epoch 1 batch id 188201 / 225000 loss 0.019999375566840172 train acc 0.6835471118644428\n",
      "epoch 1 batch id 188301 / 225000 loss 2.9764645099639893 train acc 0.6835850579657039\n",
      "epoch 1 batch id 188401 / 225000 loss 0.4968340992927551 train acc 0.6836150020435136\n",
      "epoch 1 batch id 188501 / 225000 loss 2.721992254257202 train acc 0.6836422618447647\n",
      "epoch 1 batch id 188601 / 225000 loss 0.5478798151016235 train acc 0.6836920270836316\n",
      "epoch 1 batch id 188701 / 225000 loss 1.5104180574417114 train acc 0.6837457141191621\n",
      "epoch 1 batch id 188801 / 225000 loss 1.1343693733215332 train acc 0.6837702130814985\n",
      "epoch 1 batch id 188901 / 225000 loss 0.032320838421583176 train acc 0.6837721875479749\n",
      "epoch 1 batch id 189001 / 225000 loss 0.96253502368927 train acc 0.6837913556012931\n",
      "epoch 1 batch id 189101 / 225000 loss 2.3779971599578857 train acc 0.6838369442784543\n",
      "epoch 1 batch id 189201 / 225000 loss 0.1448381394147873 train acc 0.6838600218814911\n",
      "epoch 1 batch id 189301 / 225000 loss 0.006146073341369629 train acc 0.6838949609352302\n",
      "epoch 1 batch id 189401 / 225000 loss 4.389425754547119 train acc 0.6839153436359893\n",
      "epoch 1 batch id 189501 / 225000 loss 2.2822694778442383 train acc 0.6839541743843041\n",
      "epoch 1 batch id 189601 / 225000 loss 2.4537508487701416 train acc 0.6839784600292192\n",
      "epoch 1 batch id 189701 / 225000 loss 2.6136233806610107 train acc 0.683997448616507\n",
      "epoch 1 batch id 189801 / 225000 loss 2.152749538421631 train acc 0.6840137828567816\n",
      "epoch 1 batch id 189901 / 225000 loss 3.095505714416504 train acc 0.6840340493204354\n",
      "epoch 1 batch id 190001 / 225000 loss 1.5757105350494385 train acc 0.684062189146373\n",
      "epoch 1 batch id 190101 / 225000 loss 0.002315462101250887 train acc 0.6840863540959805\n",
      "epoch 1 batch id 190201 / 225000 loss 0.050807345658540726 train acc 0.6841236376254594\n",
      "epoch 1 batch id 190301 / 225000 loss 2.509202003479004 train acc 0.6841595682629098\n",
      "epoch 1 batch id 190401 / 225000 loss 0.3418106436729431 train acc 0.6841915221033503\n",
      "epoch 1 batch id 190501 / 225000 loss 0.5794134140014648 train acc 0.684224754725697\n",
      "epoch 1 batch id 190601 / 225000 loss 0.9554398655891418 train acc 0.6842448360711644\n",
      "epoch 1 batch id 190701 / 225000 loss 4.583442687988281 train acc 0.6842858716000441\n",
      "epoch 1 batch id 190801 / 225000 loss 0.8910487294197083 train acc 0.6843006588015786\n",
      "epoch 1 batch id 190901 / 225000 loss 1.0173159837722778 train acc 0.6843311454628315\n",
      "epoch 1 batch id 191001 / 225000 loss 0.10014808923006058 train acc 0.6843602913073753\n",
      "epoch 1 batch id 191101 / 225000 loss 2.291813373565674 train acc 0.6843959476925814\n",
      "epoch 1 batch id 191201 / 225000 loss 2.408531665802002 train acc 0.6844302592559662\n",
      "epoch 1 batch id 191301 / 225000 loss 1.7960634231567383 train acc 0.6844606144243888\n",
      "epoch 1 batch id 191401 / 225000 loss 1.3849962949752808 train acc 0.6844909378738878\n",
      "epoch 1 batch id 191501 / 225000 loss 2.917356491088867 train acc 0.6845264515589997\n",
      "epoch 1 batch id 191601 / 225000 loss 1.506930947303772 train acc 0.6845540994044916\n",
      "epoch 1 batch id 191701 / 225000 loss 1.1254340410232544 train acc 0.6845856307478835\n",
      "epoch 1 batch id 191801 / 225000 loss 1.9471123218536377 train acc 0.6846171292120479\n",
      "epoch 1 batch id 191901 / 225000 loss 0.0032708458602428436 train acc 0.6846485948483854\n",
      "epoch 1 batch id 192001 / 225000 loss 1.6209392547607422 train acc 0.6846774235550857\n",
      "epoch 1 batch id 192101 / 225000 loss 1.038385272026062 train acc 0.6846945096589815\n",
      "epoch 1 batch id 192201 / 225000 loss 0.00368793704546988 train acc 0.68472848736479\n",
      "epoch 1 batch id 192301 / 225000 loss 1.3957390785217285 train acc 0.6847728300944873\n",
      "epoch 1 batch id 192401 / 225000 loss 0.08226049691438675 train acc 0.6848132286214729\n",
      "epoch 1 batch id 192501 / 225000 loss 3.0005950927734375 train acc 0.6848392995361063\n",
      "epoch 1 batch id 192601 / 225000 loss 2.6470730304718018 train acc 0.6848692374390579\n",
      "epoch 1 batch id 192701 / 225000 loss 0.01840588077902794 train acc 0.6848887654968059\n",
      "epoch 1 batch id 192801 / 225000 loss 5.835297584533691 train acc 0.6849082732973377\n",
      "epoch 1 batch id 192901 / 225000 loss 2.5821011066436768 train acc 0.6849459048942204\n",
      "epoch 1 batch id 193001 / 225000 loss 0.12459725141525269 train acc 0.6849770208444516\n",
      "epoch 1 batch id 193101 / 225000 loss 2.2112083435058594 train acc 0.6850119885448548\n",
      "epoch 1 batch id 193201 / 225000 loss 0.6766338348388672 train acc 0.6850417440903515\n",
      "epoch 1 batch id 193301 / 225000 loss 0.0023821841459721327 train acc 0.6850805220873146\n",
      "epoch 1 batch id 193401 / 225000 loss 1.2006458044052124 train acc 0.6851127967280417\n",
      "epoch 1 batch id 193501 / 225000 loss 0.028017893433570862 train acc 0.6851347021462422\n",
      "epoch 1 batch id 193601 / 225000 loss 0.5171735286712646 train acc 0.6851604588819272\n",
      "epoch 1 batch id 193701 / 225000 loss 0.11300897598266602 train acc 0.6851771544803589\n",
      "epoch 1 batch id 193801 / 225000 loss 0.08320821821689606 train acc 0.6852118926114932\n",
      "epoch 1 batch id 193901 / 225000 loss 2.350860357284546 train acc 0.6852337017343902\n",
      "epoch 1 batch id 194001 / 225000 loss 0.11266996711492538 train acc 0.6852490451080149\n",
      "epoch 1 batch id 194101 / 225000 loss 0.163267120718956 train acc 0.6852811165321148\n",
      "epoch 1 batch id 194201 / 225000 loss 0.9947366714477539 train acc 0.6853286028393263\n",
      "epoch 1 batch id 194301 / 225000 loss 4.003724575042725 train acc 0.6853515936613811\n",
      "epoch 1 batch id 194401 / 225000 loss 2.6397011280059814 train acc 0.6853655588191419\n",
      "epoch 1 batch id 194501 / 225000 loss 4.479778289794922 train acc 0.6853782242764819\n",
      "epoch 1 batch id 194601 / 225000 loss 1.3955135345458984 train acc 0.6854191396755412\n",
      "epoch 1 batch id 194701 / 225000 loss 1.6872514486312866 train acc 0.6854330486232736\n",
      "epoch 1 batch id 194801 / 225000 loss 0.0008898759842850268 train acc 0.6854584935395609\n",
      "epoch 1 batch id 194901 / 225000 loss 0.8418686985969543 train acc 0.6854877604527426\n",
      "epoch 1 batch id 195001 / 225000 loss 0.005678233690559864 train acc 0.6854913564545823\n",
      "epoch 1 batch id 195101 / 225000 loss 0.08478926867246628 train acc 0.6855039184832471\n",
      "epoch 1 batch id 195201 / 225000 loss 1.686610221862793 train acc 0.685503660329609\n",
      "epoch 1 batch id 195301 / 225000 loss 0.01500219851732254 train acc 0.6855123629679315\n",
      "epoch 1 batch id 195401 / 225000 loss 1.2325109243392944 train acc 0.6855428068433631\n",
      "epoch 1 batch id 195501 / 225000 loss 0.09351654350757599 train acc 0.6855911222960497\n",
      "epoch 1 batch id 195601 / 225000 loss 2.38972544670105 train acc 0.685621494777634\n",
      "epoch 1 batch id 195701 / 225000 loss 1.8005799055099487 train acc 0.6856480038425966\n",
      "epoch 1 batch id 195801 / 225000 loss 2.0615334510803223 train acc 0.6856566105382506\n",
      "epoch 1 batch id 195901 / 225000 loss 0.9156387448310852 train acc 0.6857022169361054\n",
      "epoch 1 batch id 196001 / 225000 loss 0.30588191747665405 train acc 0.6857324707527003\n",
      "epoch 1 batch id 196101 / 225000 loss 3.286163806915283 train acc 0.6857626937139535\n",
      "epoch 1 batch id 196201 / 225000 loss 0.14945361018180847 train acc 0.6857890632565583\n",
      "epoch 1 batch id 196301 / 225000 loss 0.08881060779094696 train acc 0.685819226595891\n",
      "epoch 1 batch id 196401 / 225000 loss 0.14965994656085968 train acc 0.6858480863132062\n",
      "epoch 1 batch id 196501 / 225000 loss 1.7287930250167847 train acc 0.6858667385916611\n",
      "epoch 1 batch id 196601 / 225000 loss 0.7072122693061829 train acc 0.6858828286733027\n",
      "epoch 1 batch id 196701 / 225000 loss 0.008606425486505032 train acc 0.6858861927494013\n",
      "epoch 1 batch id 196801 / 225000 loss 0.2932601869106293 train acc 0.6859213113754503\n",
      "epoch 1 batch id 196901 / 225000 loss 0.476231187582016 train acc 0.6859424279206302\n",
      "epoch 1 batch id 197001 / 225000 loss 0.45719778537750244 train acc 0.6859495637077985\n",
      "epoch 1 batch id 197101 / 225000 loss 0.018223527818918228 train acc 0.6859731812623985\n",
      "epoch 1 batch id 197201 / 225000 loss 1.079742193222046 train acc 0.6860018458324247\n",
      "epoch 1 batch id 197301 / 225000 loss 2.1024012565612793 train acc 0.686012741952651\n",
      "epoch 1 batch id 197401 / 225000 loss 0.8493729829788208 train acc 0.6860616207617996\n",
      "epoch 1 batch id 197501 / 225000 loss 1.755373239517212 train acc 0.6860965260935388\n",
      "epoch 1 batch id 197601 / 225000 loss 0.008991068229079247 train acc 0.6861212746899055\n",
      "epoch 1 batch id 197701 / 225000 loss 0.05861984193325043 train acc 0.6861219720689323\n",
      "epoch 1 batch id 197801 / 225000 loss 2.2338531017303467 train acc 0.686153002259847\n",
      "epoch 1 batch id 197901 / 225000 loss 0.28962260484695435 train acc 0.6861713685125391\n",
      "epoch 1 batch id 198001 / 225000 loss 0.002601735293865204 train acc 0.6861632011959535\n",
      "epoch 1 batch id 198101 / 225000 loss 1.5789709091186523 train acc 0.686182805740506\n",
      "epoch 1 batch id 198201 / 225000 loss 2.511995553970337 train acc 0.6861948224277375\n",
      "epoch 1 batch id 198301 / 225000 loss 1.3998446464538574 train acc 0.6862106091245127\n",
      "epoch 1 batch id 198401 / 225000 loss 0.029520150274038315 train acc 0.6862389806502991\n",
      "epoch 1 batch id 198501 / 225000 loss 1.6627681255340576 train acc 0.6862811774247989\n",
      "epoch 1 batch id 198601 / 225000 loss 1.1773744821548462 train acc 0.6862956379877241\n",
      "epoch 1 batch id 198701 / 225000 loss 0.005438771564513445 train acc 0.6863113421673771\n",
      "epoch 1 batch id 198801 / 225000 loss 2.4146041870117188 train acc 0.6863446360933798\n",
      "epoch 1 batch id 198901 / 225000 loss 0.8819730877876282 train acc 0.6863515015007466\n",
      "epoch 1 batch id 199001 / 225000 loss 1.668914794921875 train acc 0.6863545911829588\n",
      "epoch 1 batch id 199101 / 225000 loss 0.7114458680152893 train acc 0.6863589334056585\n",
      "epoch 1 batch id 199201 / 225000 loss 0.8834252953529358 train acc 0.6863883715443195\n",
      "epoch 1 batch id 199301 / 225000 loss 0.1898289918899536 train acc 0.6864140169893779\n",
      "epoch 1 batch id 199401 / 225000 loss 1.9794660806655884 train acc 0.6864446517319371\n",
      "epoch 1 batch id 199501 / 225000 loss 2.9246652126312256 train acc 0.6864451807259111\n",
      "epoch 1 batch id 199601 / 225000 loss 1.5569913387298584 train acc 0.6864632441721233\n",
      "epoch 1 batch id 199701 / 225000 loss 1.4069361686706543 train acc 0.6864712745554604\n",
      "epoch 1 batch id 199801 / 225000 loss 0.04722839593887329 train acc 0.6864955630852698\n",
      "epoch 1 batch id 199901 / 225000 loss 3.528265953063965 train acc 0.6865185766954642\n",
      "epoch 1 batch id 200001 / 225000 loss 1.5526880025863647 train acc 0.6865653171734142\n",
      "epoch 1 batch id 200101 / 225000 loss 2.2354393005371094 train acc 0.6865945197675174\n",
      "epoch 1 batch id 200201 / 225000 loss 0.06755220144987106 train acc 0.6866274394233794\n",
      "epoch 1 batch id 200301 / 225000 loss 1.0733237266540527 train acc 0.6866740555464027\n",
      "epoch 1 batch id 200401 / 225000 loss 3.65675687789917 train acc 0.6867118926552263\n",
      "epoch 1 batch id 200501 / 225000 loss 0.01827777363359928 train acc 0.6867272482431509\n",
      "epoch 1 batch id 200601 / 225000 loss 2.618168354034424 train acc 0.6867525585615226\n",
      "epoch 1 batch id 200701 / 225000 loss 0.39475518465042114 train acc 0.686784071828242\n",
      "epoch 1 batch id 200801 / 225000 loss 1.0623793601989746 train acc 0.686820533762282\n",
      "epoch 1 batch id 200901 / 225000 loss 1.2444764375686646 train acc 0.6868494930338823\n",
      "epoch 1 batch id 201001 / 225000 loss 1.35336434841156 train acc 0.6868933487893095\n",
      "epoch 1 batch id 201101 / 225000 loss 3.2292613983154297 train acc 0.686919756739151\n",
      "epoch 1 batch id 201201 / 225000 loss 0.040620360523462296 train acc 0.6869411682844518\n",
      "epoch 1 batch id 201301 / 225000 loss 1.8065577745437622 train acc 0.6869799454548164\n",
      "epoch 1 batch id 201401 / 225000 loss 0.12098772078752518 train acc 0.6869913754152164\n",
      "epoch 1 batch id 201501 / 225000 loss 0.004550876095890999 train acc 0.6870238857375398\n",
      "epoch 1 batch id 201601 / 225000 loss 2.5559303760528564 train acc 0.68704396307558\n",
      "epoch 1 batch id 201701 / 225000 loss 2.6779990196228027 train acc 0.6870764150896624\n",
      "epoch 1 batch id 201801 / 225000 loss 2.713500499725342 train acc 0.6871113126297689\n",
      "epoch 1 batch id 201901 / 225000 loss 0.007634171284735203 train acc 0.6871399844478234\n",
      "epoch 1 batch id 202001 / 225000 loss 2.002537727355957 train acc 0.6871649150251732\n",
      "epoch 1 batch id 202101 / 225000 loss 0.019630378112196922 train acc 0.6872046649942356\n",
      "epoch 1 batch id 202201 / 225000 loss 0.42226749658584595 train acc 0.6872283025306501\n",
      "epoch 1 batch id 202301 / 225000 loss 1.5944647789001465 train acc 0.6872457377867632\n",
      "epoch 1 batch id 202401 / 225000 loss 0.08576227724552155 train acc 0.6872804482191294\n",
      "epoch 1 batch id 202501 / 225000 loss 0.0047342488542199135 train acc 0.687299075066296\n",
      "epoch 1 batch id 202601 / 225000 loss 3.1124720573425293 train acc 0.6873139816684024\n",
      "epoch 1 batch id 202701 / 225000 loss 3.0646750926971436 train acc 0.6873412069994721\n",
      "epoch 1 batch id 202801 / 225000 loss 0.47103577852249146 train acc 0.6873819655721619\n",
      "epoch 1 batch id 202901 / 225000 loss 0.3844742774963379 train acc 0.6874115948171768\n",
      "epoch 1 batch id 203001 / 225000 loss 4.051011085510254 train acc 0.6874264166186373\n",
      "epoch 1 batch id 203101 / 225000 loss 0.037616025656461716 train acc 0.6874510711419441\n",
      "epoch 1 batch id 203201 / 225000 loss 4.196147918701172 train acc 0.6874781620169192\n",
      "epoch 1 batch id 203301 / 225000 loss 0.028741497546434402 train acc 0.6875039965371542\n",
      "epoch 1 batch id 203401 / 225000 loss 2.0623831748962402 train acc 0.6875298056548395\n",
      "epoch 1 batch id 203501 / 225000 loss 0.05580943450331688 train acc 0.6875703313497231\n",
      "epoch 1 batch id 203601 / 225000 loss 0.06344500929117203 train acc 0.6875997662093998\n",
      "epoch 1 batch id 203701 / 225000 loss 2.053453207015991 train acc 0.6876058536776942\n",
      "epoch 1 batch id 203801 / 225000 loss 0.5260371565818787 train acc 0.6876438290292982\n",
      "epoch 1 batch id 203901 / 225000 loss 1.118540644645691 train acc 0.6876780888764645\n",
      "epoch 1 batch id 204001 / 225000 loss 0.05841362103819847 train acc 0.6876963838412556\n",
      "epoch 1 batch id 204101 / 225000 loss 1.9255019426345825 train acc 0.6877171106461997\n",
      "epoch 1 batch id 204201 / 225000 loss 1.1926440000534058 train acc 0.6877316957311669\n",
      "epoch 1 batch id 204301 / 225000 loss 0.7745932936668396 train acc 0.6877572797000504\n",
      "epoch 1 batch id 204401 / 225000 loss 0.04463079944252968 train acc 0.6877632692599351\n",
      "epoch 1 batch id 204501 / 225000 loss 2.034498929977417 train acc 0.6877924802323705\n",
      "epoch 1 batch id 204601 / 225000 loss 1.75105619430542 train acc 0.6878143313082536\n",
      "epoch 1 batch id 204701 / 225000 loss 3.8500146865844727 train acc 0.6878569230243136\n",
      "epoch 1 batch id 204801 / 225000 loss 0.017897499725222588 train acc 0.6878628522321668\n",
      "epoch 1 batch id 204901 / 225000 loss 0.8111090064048767 train acc 0.6878821967681954\n",
      "epoch 1 batch id 205001 / 225000 loss 2.078728675842285 train acc 0.6879161565065536\n",
      "epoch 1 batch id 205101 / 225000 loss 0.37700340151786804 train acc 0.687948864218117\n",
      "epoch 1 batch id 205201 / 225000 loss 1.4221954345703125 train acc 0.6879730118274278\n",
      "epoch 1 batch id 205301 / 225000 loss 1.3602986335754395 train acc 0.68798495867044\n",
      "epoch 1 batch id 205401 / 225000 loss 0.13120754063129425 train acc 0.6880127165885268\n",
      "epoch 1 batch id 205501 / 225000 loss 0.07192079722881317 train acc 0.6880319317180938\n",
      "epoch 1 batch id 205601 / 225000 loss 0.03441324830055237 train acc 0.6880547759981712\n",
      "epoch 1 batch id 205701 / 225000 loss 0.3331688344478607 train acc 0.6880751673545583\n",
      "epoch 1 batch id 205801 / 225000 loss 1.578217625617981 train acc 0.6880846060028862\n",
      "epoch 1 batch id 205901 / 225000 loss 1.0494667291641235 train acc 0.6880891787800933\n",
      "epoch 1 batch id 206001 / 225000 loss 0.004660499282181263 train acc 0.6881192324309106\n",
      "epoch 1 batch id 206101 / 225000 loss 0.008978067897260189 train acc 0.6881419789326593\n",
      "epoch 1 batch id 206201 / 225000 loss 1.723513126373291 train acc 0.6881574289164456\n",
      "epoch 1 batch id 206301 / 225000 loss 1.5290968418121338 train acc 0.6881692284574481\n",
      "epoch 1 batch id 206401 / 225000 loss 0.7637171745300293 train acc 0.6881810165648422\n",
      "epoch 1 batch id 206501 / 225000 loss 2.2296626567840576 train acc 0.688202478438361\n",
      "epoch 1 batch id 206601 / 225000 loss 0.07914989441633224 train acc 0.6882444905881385\n",
      "epoch 1 batch id 206701 / 225000 loss 1.8847997188568115 train acc 0.6882550156990048\n",
      "epoch 1 batch id 206801 / 225000 loss 0.033609405159950256 train acc 0.6882631128476168\n",
      "epoch 1 batch id 206901 / 225000 loss 0.007794576231390238 train acc 0.6882857018574101\n",
      "epoch 1 batch id 207001 / 225000 loss 0.008657398633658886 train acc 0.6882998149767392\n",
      "epoch 1 batch id 207101 / 225000 loss 0.5266704559326172 train acc 0.6883308144335373\n",
      "epoch 1 batch id 207201 / 225000 loss 0.03627694770693779 train acc 0.6883545446209236\n",
      "epoch 1 batch id 207301 / 225000 loss 0.0658385381102562 train acc 0.688387899720696\n",
      "epoch 1 batch id 207401 / 225000 loss 1.5522273778915405 train acc 0.6884079633174383\n",
      "epoch 1 batch id 207501 / 225000 loss 1.0890617370605469 train acc 0.6884255979489255\n",
      "epoch 1 batch id 207601 / 225000 loss 0.5478456616401672 train acc 0.6884371944258457\n",
      "epoch 1 batch id 207701 / 225000 loss 0.6165896058082581 train acc 0.6884656308828556\n",
      "epoch 1 batch id 207801 / 225000 loss 1.3142038583755493 train acc 0.6884868215263642\n",
      "epoch 1 batch id 207901 / 225000 loss 0.28200727701187134 train acc 0.6885043842982959\n",
      "epoch 1 batch id 208001 / 225000 loss 2.6930716037750244 train acc 0.6885255359349234\n",
      "epoch 1 batch id 208101 / 225000 loss 1.9318242073059082 train acc 0.6885418618843735\n",
      "epoch 1 batch id 208201 / 225000 loss 1.6503465175628662 train acc 0.6885665774900217\n",
      "epoch 1 batch id 208301 / 225000 loss 0.3047838509082794 train acc 0.6885804676885853\n",
      "epoch 1 batch id 208401 / 225000 loss 0.30318278074264526 train acc 0.6886051410501869\n",
      "epoch 1 batch id 208501 / 225000 loss 2.0996944904327393 train acc 0.6886333878494587\n",
      "epoch 1 batch id 208601 / 225000 loss 2.2681803703308105 train acc 0.6886592106461618\n",
      "epoch 1 batch id 208701 / 225000 loss 0.8666467666625977 train acc 0.6886802171527688\n",
      "epoch 1 batch id 208801 / 225000 loss 0.7873982191085815 train acc 0.6887119793487579\n",
      "epoch 1 batch id 208901 / 225000 loss 0.8566796183586121 train acc 0.6887281535272689\n",
      "epoch 1 batch id 209001 / 225000 loss 1.0921653509140015 train acc 0.6887526853938498\n",
      "epoch 1 batch id 209101 / 225000 loss 2.538355827331543 train acc 0.6887819761741933\n",
      "epoch 1 batch id 209201 / 225000 loss 3.0138614177703857 train acc 0.6887992887223292\n",
      "epoch 1 batch id 209301 / 225000 loss 0.7893731594085693 train acc 0.6888106124672123\n",
      "epoch 1 batch id 209401 / 225000 loss 3.93613338470459 train acc 0.6888255070415137\n",
      "epoch 1 batch id 209501 / 225000 loss 0.2640513777732849 train acc 0.6888678335664269\n",
      "epoch 1 batch id 209601 / 225000 loss 1.2431340217590332 train acc 0.6888850721132056\n",
      "epoch 1 batch id 209701 / 225000 loss 2.7079551219940186 train acc 0.6888975255244372\n",
      "epoch 1 batch id 209801 / 225000 loss 1.6285579204559326 train acc 0.6889409488038665\n",
      "epoch 1 batch id 209901 / 225000 loss 1.1956193447113037 train acc 0.6889748024068489\n",
      "epoch 1 batch id 210001 / 225000 loss 0.6021876335144043 train acc 0.6889931476516779\n",
      "epoch 1 batch id 210101 / 225000 loss 1.0643717050552368 train acc 0.6890209946644709\n",
      "epoch 1 batch id 210201 / 225000 loss 2.9954912662506104 train acc 0.6890476258438352\n",
      "epoch 1 batch id 210301 / 225000 loss 1.9715136289596558 train acc 0.689069476607339\n",
      "epoch 1 batch id 210401 / 225000 loss 2.010479688644409 train acc 0.6890924948075342\n",
      "epoch 1 batch id 210501 / 225000 loss 1.966996669769287 train acc 0.6891095529237391\n",
      "epoch 1 batch id 210601 / 225000 loss 1.217430830001831 train acc 0.6891325302348992\n",
      "epoch 1 batch id 210701 / 225000 loss 0.5077110528945923 train acc 0.6891590452821771\n",
      "epoch 1 batch id 210801 / 225000 loss 0.7463065385818481 train acc 0.6891748615993283\n",
      "epoch 1 batch id 210901 / 225000 loss 0.8321546912193298 train acc 0.6892001460400852\n",
      "epoch 1 batch id 211001 / 225000 loss 0.4668039381504059 train acc 0.6892289610001848\n",
      "epoch 1 batch id 211101 / 225000 loss 0.010223694145679474 train acc 0.6892482745226218\n",
      "epoch 1 batch id 211201 / 225000 loss 0.016342638060450554 train acc 0.6892569163971761\n",
      "epoch 1 batch id 211301 / 225000 loss 0.4427827000617981 train acc 0.6892773815552222\n",
      "epoch 1 batch id 211401 / 225000 loss 2.19486403465271 train acc 0.6893108358049395\n",
      "epoch 1 batch id 211501 / 225000 loss 0.006414785049855709 train acc 0.6893312561169923\n",
      "epoch 1 batch id 211601 / 225000 loss 2.2503678798675537 train acc 0.6893540200660677\n",
      "epoch 1 batch id 211701 / 225000 loss 0.862703800201416 train acc 0.6893614106688206\n",
      "epoch 1 batch id 211801 / 225000 loss 0.004017222672700882 train acc 0.6893687942927559\n",
      "epoch 1 batch id 211901 / 225000 loss 0.004499814007431269 train acc 0.6893773507439795\n",
      "epoch 1 batch id 212001 / 225000 loss 0.004761221818625927 train acc 0.6894142008764109\n",
      "epoch 1 batch id 212101 / 225000 loss 0.007346899714320898 train acc 0.6894262639025747\n",
      "epoch 1 batch id 212201 / 225000 loss 2.0291945934295654 train acc 0.6894359593027366\n",
      "epoch 1 batch id 212301 / 225000 loss 2.1903223991394043 train acc 0.6894762624763896\n",
      "epoch 1 batch id 212401 / 225000 loss 3.801420211791992 train acc 0.689498872415855\n",
      "epoch 1 batch id 212501 / 225000 loss 2.7334189414978027 train acc 0.6895344021910486\n",
      "epoch 1 batch id 212601 / 225000 loss 0.09633136540651321 train acc 0.6895510839553907\n",
      "epoch 1 batch id 212701 / 225000 loss 1.3340044021606445 train acc 0.6895736268282707\n",
      "epoch 1 batch id 212801 / 225000 loss 0.0123426029458642 train acc 0.6896219942575458\n",
      "epoch 1 batch id 212901 / 225000 loss 0.22315864264965057 train acc 0.6896386113733614\n",
      "epoch 1 batch id 213001 / 225000 loss 1.1912730932235718 train acc 0.6896458232590458\n",
      "epoch 1 batch id 213101 / 225000 loss 1.5408035516738892 train acc 0.6896471626130333\n",
      "epoch 1 batch id 213201 / 225000 loss 2.957990884780884 train acc 0.6896742979629551\n",
      "epoch 1 batch id 213301 / 225000 loss 1.683013916015625 train acc 0.6897084401854656\n",
      "epoch 1 batch id 213401 / 225000 loss 1.1001389026641846 train acc 0.6897472364234469\n",
      "epoch 1 batch id 213501 / 225000 loss 3.7650179862976074 train acc 0.6897625772244627\n",
      "epoch 1 batch id 213601 / 225000 loss 0.004345220513641834 train acc 0.6897755628484885\n",
      "epoch 1 batch id 213701 / 225000 loss 4.1693220138549805 train acc 0.6897826870253297\n",
      "epoch 1 batch id 213801 / 225000 loss 3.3388686180114746 train acc 0.6897898045378646\n",
      "epoch 1 batch id 213901 / 225000 loss 2.015831470489502 train acc 0.6898121093403022\n",
      "epoch 1 batch id 214001 / 225000 loss 1.225692868232727 train acc 0.6898320568595474\n",
      "epoch 1 batch id 214101 / 225000 loss 1.0909061431884766 train acc 0.6898753392090649\n",
      "epoch 1 batch id 214201 / 225000 loss 1.0210826396942139 train acc 0.6898952385843203\n",
      "epoch 1 batch id 214301 / 225000 loss 3.447904109954834 train acc 0.689908119887448\n",
      "epoch 1 batch id 214401 / 225000 loss 0.9279652237892151 train acc 0.6899256533318407\n",
      "epoch 1 batch id 214501 / 225000 loss 0.9478015303611755 train acc 0.6899489979067697\n",
      "epoch 1 batch id 214601 / 225000 loss 0.8269739747047424 train acc 0.6899536814833109\n",
      "epoch 1 batch id 214701 / 225000 loss 0.03564915060997009 train acc 0.6899618539270893\n",
      "epoch 1 batch id 214801 / 225000 loss 0.08603895455598831 train acc 0.6899944599885476\n",
      "epoch 1 batch id 214901 / 225000 loss 0.21981188654899597 train acc 0.6900305256839195\n",
      "epoch 1 batch id 215001 / 225000 loss 0.27792173624038696 train acc 0.6900560927623592\n",
      "epoch 1 batch id 215101 / 225000 loss 0.028860418125987053 train acc 0.6900839605580634\n",
      "epoch 1 batch id 215201 / 225000 loss 1.1021922826766968 train acc 0.6901059939312549\n",
      "epoch 1 batch id 215301 / 225000 loss 1.8555247783660889 train acc 0.6901349738273393\n",
      "epoch 1 batch id 215401 / 225000 loss 0.007226351648569107 train acc 0.690162766189572\n",
      "epoch 1 batch id 215501 / 225000 loss 0.694341242313385 train acc 0.6901719713597617\n",
      "epoch 1 batch id 215601 / 225000 loss 1.2619954347610474 train acc 0.6901892848363412\n",
      "epoch 1 batch id 215701 / 225000 loss 0.03780458867549896 train acc 0.6902251264481852\n",
      "epoch 1 batch id 215801 / 225000 loss 3.7906861305236816 train acc 0.69024935009569\n",
      "epoch 1 batch id 215901 / 225000 loss 0.7158167362213135 train acc 0.6902631298604452\n",
      "epoch 1 batch id 216001 / 225000 loss 1.6342424154281616 train acc 0.6902792116703164\n",
      "epoch 1 batch id 216101 / 225000 loss 0.009414337575435638 train acc 0.6902883373977908\n",
      "epoch 1 batch id 216201 / 225000 loss 1.6317194700241089 train acc 0.6903032363402575\n",
      "epoch 1 batch id 216301 / 225000 loss 1.0184868574142456 train acc 0.6903296794744361\n",
      "epoch 1 batch id 216401 / 225000 loss 2.502161741256714 train acc 0.6903422350173982\n",
      "epoch 1 batch id 216501 / 225000 loss 0.8274677991867065 train acc 0.6903593978780699\n",
      "epoch 1 batch id 216601 / 225000 loss 2.6024391651153564 train acc 0.6903996288105779\n",
      "epoch 1 batch id 216701 / 225000 loss 0.028169967234134674 train acc 0.6904225176625858\n",
      "epoch 1 batch id 216801 / 225000 loss 1.3364473581314087 train acc 0.6904303946937514\n",
      "epoch 1 batch id 216901 / 225000 loss 1.2093747854232788 train acc 0.6904763002475783\n",
      "epoch 1 batch id 217001 / 225000 loss 2.3563284873962402 train acc 0.6904979700554376\n",
      "epoch 1 batch id 217101 / 225000 loss 2.071431875228882 train acc 0.6905069529850162\n",
      "epoch 1 batch id 217201 / 225000 loss 2.574573278427124 train acc 0.6905009645443622\n",
      "epoch 1 batch id 217301 / 225000 loss 0.025411702692508698 train acc 0.6905076368723567\n",
      "epoch 1 batch id 217401 / 225000 loss 1.5034364461898804 train acc 0.6905430517798906\n",
      "epoch 1 batch id 217501 / 225000 loss 0.9944181442260742 train acc 0.6905611928221019\n",
      "epoch 1 batch id 217601 / 225000 loss 0.2925097942352295 train acc 0.6905873594330908\n",
      "epoch 1 batch id 217701 / 225000 loss 0.002010420197620988 train acc 0.690598573272516\n",
      "epoch 1 batch id 217801 / 225000 loss 0.09684142470359802 train acc 0.6906074811410416\n",
      "epoch 1 batch id 217901 / 225000 loss 2.439793109893799 train acc 0.6906140862134639\n",
      "epoch 1 batch id 218001 / 225000 loss 3.5463309288024902 train acc 0.6906241255774056\n",
      "epoch 1 batch id 218101 / 225000 loss 0.10459865629673004 train acc 0.6906536421199353\n",
      "epoch 1 batch id 218201 / 225000 loss 0.6069322228431702 train acc 0.6906659456189477\n",
      "epoch 1 batch id 218301 / 225000 loss 0.8835738897323608 train acc 0.6906816734692007\n",
      "epoch 1 batch id 218401 / 225000 loss 0.15344856679439545 train acc 0.6907053997005508\n",
      "epoch 1 batch id 218501 / 225000 loss 3.006243944168091 train acc 0.6907325366931959\n",
      "epoch 1 batch id 218601 / 225000 loss 0.7126160860061646 train acc 0.6907539306773528\n",
      "epoch 1 batch id 218701 / 225000 loss 0.8989812731742859 train acc 0.6907993104741176\n",
      "epoch 1 batch id 218801 / 225000 loss 0.5885899662971497 train acc 0.6908103710677739\n",
      "epoch 1 batch id 218901 / 225000 loss 3.83981990814209 train acc 0.6908511153443794\n",
      "epoch 1 batch id 219001 / 225000 loss 0.006771732587367296 train acc 0.6908781238441833\n",
      "epoch 1 batch id 219101 / 225000 loss 0.0033469293266534805 train acc 0.6909142359003382\n",
      "epoch 1 batch id 219201 / 225000 loss 1.6534725427627563 train acc 0.6909309264100073\n",
      "epoch 1 batch id 219301 / 225000 loss 0.0024016923271119595 train acc 0.6909156820990329\n",
      "epoch 1 batch id 219401 / 225000 loss 1.8375900983810425 train acc 0.6909243804722859\n",
      "epoch 1 batch id 219501 / 225000 loss 2.519636869430542 train acc 0.6909387656548261\n",
      "epoch 1 batch id 219601 / 225000 loss 0.03420637175440788 train acc 0.6909394765961904\n",
      "epoch 1 batch id 219701 / 225000 loss 3.3142318725585938 train acc 0.6909447385310035\n",
      "epoch 1 batch id 219801 / 225000 loss 0.7190814018249512 train acc 0.6909807052743163\n",
      "epoch 1 batch id 219901 / 225000 loss 2.728677988052368 train acc 0.6910018599278767\n",
      "epoch 1 batch id 220001 / 225000 loss 3.3150129318237305 train acc 0.6910264044254344\n",
      "epoch 1 batch id 220101 / 225000 loss 0.6312993764877319 train acc 0.6910361606716916\n",
      "epoch 1 batch id 220201 / 225000 loss 2.5304882526397705 train acc 0.6910493140358127\n",
      "epoch 1 batch id 220301 / 225000 loss 3.3349368572235107 train acc 0.6910647250806851\n",
      "epoch 1 batch id 220401 / 225000 loss 0.004351047798991203 train acc 0.691106210951856\n",
      "epoch 1 batch id 220501 / 225000 loss 1.5675618648529053 train acc 0.6911465254125831\n",
      "epoch 1 batch id 220601 / 225000 loss 4.544295787811279 train acc 0.6911664045040594\n",
      "epoch 1 batch id 220701 / 225000 loss 1.3394739627838135 train acc 0.6911772035468802\n",
      "epoch 1 batch id 220801 / 225000 loss 1.8135929107666016 train acc 0.691194786255497\n",
      "epoch 1 batch id 220901 / 225000 loss 1.7594338655471802 train acc 0.6912112213163363\n",
      "epoch 1 batch id 221001 / 225000 loss 1.4509382247924805 train acc 0.6912344288034896\n",
      "epoch 1 batch id 221101 / 225000 loss 2.4247422218322754 train acc 0.6912768372825089\n",
      "epoch 1 batch id 221201 / 225000 loss 1.6473451852798462 train acc 0.6912683486964345\n",
      "epoch 1 batch id 221301 / 225000 loss 0.6962026357650757 train acc 0.6912892395425235\n",
      "epoch 1 batch id 221401 / 225000 loss 0.01561904326081276 train acc 0.6912988197885285\n",
      "epoch 1 batch id 221501 / 225000 loss 3.575542449951172 train acc 0.6913320933088338\n",
      "epoch 1 batch id 221601 / 225000 loss 0.05980329215526581 train acc 0.6913517989539758\n",
      "epoch 1 batch id 221701 / 225000 loss 1.9702026844024658 train acc 0.6913771250467973\n",
      "epoch 1 batch id 221801 / 225000 loss 1.7649818658828735 train acc 0.6914001740298736\n",
      "epoch 1 batch id 221901 / 225000 loss 3.9081380367279053 train acc 0.6914254554959194\n",
      "epoch 1 batch id 222001 / 225000 loss 0.03268814459443092 train acc 0.6914462097017581\n",
      "epoch 1 batch id 222101 / 225000 loss 3.4466400146484375 train acc 0.6914568146924147\n",
      "epoch 1 batch id 222201 / 225000 loss 2.336927652359009 train acc 0.6914955378238622\n",
      "epoch 1 batch id 222301 / 225000 loss 0.5206186771392822 train acc 0.6915196062995668\n",
      "epoch 1 batch id 222401 / 225000 loss 0.029728863388299942 train acc 0.6915267916960806\n",
      "epoch 1 batch id 222501 / 225000 loss 2.417067050933838 train acc 0.6915541952620438\n",
      "epoch 1 batch id 222601 / 225000 loss 2.3912570476531982 train acc 0.6915737126068616\n",
      "epoch 1 batch id 222701 / 225000 loss 0.16333319246768951 train acc 0.6916044382378166\n",
      "epoch 1 batch id 222801 / 225000 loss 0.7312371134757996 train acc 0.6916194272018528\n",
      "epoch 1 batch id 222901 / 225000 loss 1.3958837985992432 train acc 0.6916456184584188\n",
      "epoch 1 batch id 223001 / 225000 loss 3.396644353866577 train acc 0.6916572122994964\n",
      "epoch 1 batch id 223101 / 225000 loss 4.039318084716797 train acc 0.6916687957472176\n",
      "epoch 1 batch id 223201 / 225000 loss 0.005360474810004234 train acc 0.6916814888822183\n",
      "epoch 1 batch id 223301 / 225000 loss 1.8768866062164307 train acc 0.6917031271691573\n",
      "epoch 1 batch id 223401 / 225000 loss 0.36733078956604004 train acc 0.6917247460843953\n",
      "epoch 1 batch id 223501 / 225000 loss 1.374329686164856 train acc 0.6917530570333018\n",
      "epoch 1 batch id 223601 / 225000 loss 1.6190564632415771 train acc 0.6917735162186216\n",
      "epoch 1 batch id 223701 / 225000 loss 0.012027155607938766 train acc 0.6917928395492197\n",
      "epoch 1 batch id 223801 / 225000 loss 0.005928765516728163 train acc 0.6918043261647624\n",
      "epoch 1 batch id 223901 / 225000 loss 0.5132124423980713 train acc 0.6918303178636986\n",
      "epoch 1 batch id 224001 / 225000 loss 1.2612403631210327 train acc 0.6918495899571877\n",
      "epoch 1 batch id 224101 / 225000 loss 1.9622997045516968 train acc 0.691871075988059\n",
      "epoch 1 batch id 224201 / 225000 loss 0.9909922480583191 train acc 0.6918981182064309\n",
      "epoch 1 batch id 224301 / 225000 loss 2.5117475986480713 train acc 0.6919229071649257\n",
      "epoch 1 batch id 224401 / 225000 loss 0.37841904163360596 train acc 0.6919354191826239\n",
      "epoch 1 batch id 224501 / 225000 loss 0.3568837344646454 train acc 0.6919590558616665\n",
      "epoch 1 batch id 224601 / 225000 loss 1.9427003860473633 train acc 0.6919938023428213\n",
      "epoch 1 batch id 224701 / 225000 loss 1.4302424192428589 train acc 0.6920296304867357\n",
      "epoch 1 batch id 224801 / 225000 loss 1.1487025022506714 train acc 0.692039848577186\n",
      "epoch 1 batch id 224901 / 225000 loss 2.5191822052001953 train acc 0.6920522807813215\n",
      "epoch 1 train acc 0.6920655555555556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9724eef9cc41e2a6def0c27def5af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.74562\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c1294413be43d580db4c5550114a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 / 225000 loss 1.432610273361206 train acc 0.5\n",
      "epoch 2 batch id 101 / 225000 loss 1.8412120342254639 train acc 0.75\n",
      "epoch 2 batch id 201 / 225000 loss 2.5359153747558594 train acc 0.7400497512437811\n",
      "epoch 2 batch id 301 / 225000 loss 0.09419600665569305 train acc 0.7508305647840532\n",
      "epoch 2 batch id 401 / 225000 loss 1.2347075939178467 train acc 0.7406483790523691\n",
      "epoch 2 batch id 501 / 225000 loss 0.7325811386108398 train acc 0.7370259481037924\n",
      "epoch 2 batch id 601 / 225000 loss 3.6766269207000732 train acc 0.7329450915141431\n",
      "epoch 2 batch id 701 / 225000 loss 1.9752117395401 train acc 0.7325249643366619\n",
      "epoch 2 batch id 801 / 225000 loss 2.1268680095672607 train acc 0.7362671660424469\n",
      "epoch 2 batch id 901 / 225000 loss 0.12025005370378494 train acc 0.733906770255272\n",
      "epoch 2 batch id 1001 / 225000 loss 1.1002925634384155 train acc 0.7355144855144855\n",
      "epoch 2 batch id 1101 / 225000 loss 0.005999056622385979 train acc 0.7359218891916439\n",
      "epoch 2 batch id 1201 / 225000 loss 0.004128836095333099 train acc 0.7375104079933389\n",
      "epoch 2 batch id 1301 / 225000 loss 1.1200975179672241 train acc 0.73923904688701\n",
      "epoch 2 batch id 1401 / 225000 loss 0.014918423257768154 train acc 0.7398286937901499\n",
      "epoch 2 batch id 1501 / 225000 loss 3.6068949699401855 train acc 0.7396735509660226\n",
      "epoch 2 batch id 1601 / 225000 loss 0.005037397611886263 train acc 0.7390693316677077\n",
      "epoch 2 batch id 1701 / 225000 loss 0.004509253427386284 train acc 0.7392710170487948\n",
      "epoch 2 batch id 1801 / 225000 loss 1.4275224208831787 train acc 0.7394503053858967\n",
      "epoch 2 batch id 1901 / 225000 loss 2.5815086364746094 train acc 0.7392162019989479\n",
      "epoch 2 batch id 2001 / 225000 loss 0.0012645134702324867 train acc 0.7408795602198901\n",
      "epoch 2 batch id 2101 / 225000 loss 1.4706230163574219 train acc 0.7423845787720134\n",
      "epoch 2 batch id 2201 / 225000 loss 0.0043240562081336975 train acc 0.7426169922762381\n",
      "epoch 2 batch id 2301 / 225000 loss 1.6451237201690674 train acc 0.7430465015210778\n",
      "epoch 2 batch id 2401 / 225000 loss 1.5719643831253052 train acc 0.7439608496459809\n",
      "epoch 2 batch id 2501 / 225000 loss 0.004946510773152113 train acc 0.7444022391043582\n",
      "epoch 2 batch id 2601 / 225000 loss 1.6382477283477783 train acc 0.7446174548250672\n",
      "epoch 2 batch id 2701 / 225000 loss 1.2612433433532715 train acc 0.7445390596075527\n",
      "epoch 2 batch id 2801 / 225000 loss 1.5918138027191162 train acc 0.7431274544805426\n",
      "epoch 2 batch id 2901 / 225000 loss 0.03284619748592377 train acc 0.7420716994139952\n",
      "epoch 2 batch id 3001 / 225000 loss 1.318310260772705 train acc 0.7432522492502499\n",
      "epoch 2 batch id 3101 / 225000 loss 0.4986720681190491 train acc 0.7420187036439858\n",
      "epoch 2 batch id 3201 / 225000 loss 0.10309639573097229 train acc 0.7415651358950328\n",
      "epoch 2 batch id 3301 / 225000 loss 1.1841455698013306 train acc 0.7423508027870342\n",
      "epoch 2 batch id 3401 / 225000 loss 0.9525014162063599 train acc 0.741105557189062\n",
      "epoch 2 batch id 3501 / 225000 loss 1.5324288606643677 train acc 0.7402884890031419\n",
      "epoch 2 batch id 3601 / 225000 loss 0.0324530228972435 train acc 0.7406970286031658\n",
      "epoch 2 batch id 3701 / 225000 loss 2.848418712615967 train acc 0.740272899216428\n",
      "epoch 2 batch id 3801 / 225000 loss 1.9400440454483032 train acc 0.7411207576953434\n",
      "epoch 2 batch id 3901 / 225000 loss 5.060249328613281 train acc 0.7398743911817482\n",
      "epoch 2 batch id 4001 / 225000 loss 3.871143102645874 train acc 0.7390027493126718\n",
      "epoch 2 batch id 4101 / 225000 loss 4.1940741539001465 train acc 0.7383564984150207\n",
      "epoch 2 batch id 4201 / 225000 loss 0.13767166435718536 train acc 0.7383956200904547\n",
      "epoch 2 batch id 4301 / 225000 loss 0.08047423511743546 train acc 0.7388979307137875\n",
      "epoch 2 batch id 4401 / 225000 loss 0.9866613745689392 train acc 0.7340377187002954\n",
      "epoch 2 batch id 4501 / 225000 loss 2.093531608581543 train acc 0.728726949566763\n",
      "epoch 2 batch id 4601 / 225000 loss 3.5988593101501465 train acc 0.7238643773092805\n",
      "epoch 2 batch id 4701 / 225000 loss 1.8295270204544067 train acc 0.7187832376090194\n",
      "epoch 2 batch id 4801 / 225000 loss 4.918212890625 train acc 0.7157883774213706\n",
      "epoch 2 batch id 4901 / 225000 loss 2.6495158672332764 train acc 0.7112834115486636\n",
      "epoch 2 batch id 5001 / 225000 loss 2.227649688720703 train acc 0.7075084983003399\n",
      "epoch 2 batch id 5101 / 225000 loss 2.6426804065704346 train acc 0.7062830817486767\n",
      "epoch 2 batch id 5201 / 225000 loss 1.4534978866577148 train acc 0.7048644491443953\n",
      "epoch 2 batch id 5301 / 225000 loss 0.00924362987279892 train acc 0.7033578570081117\n",
      "epoch 2 batch id 5401 / 225000 loss 2.026893138885498 train acc 0.7021384928716904\n",
      "epoch 2 batch id 5501 / 225000 loss 0.04994426667690277 train acc 0.7018269405562625\n",
      "epoch 2 batch id 5601 / 225000 loss 1.642612338066101 train acc 0.7008123549366184\n",
      "epoch 2 batch id 5701 / 225000 loss 1.2637529373168945 train acc 0.6999649184353622\n",
      "epoch 2 batch id 5801 / 225000 loss 1.2986098527908325 train acc 0.6997931391139459\n",
      "epoch 2 batch id 5901 / 225000 loss 0.6417954564094543 train acc 0.6994577190306728\n",
      "epoch 2 batch id 6001 / 225000 loss 0.5562735199928284 train acc 0.7003416097317113\n",
      "epoch 2 batch id 6101 / 225000 loss 0.4271135628223419 train acc 0.7011965251598099\n",
      "epoch 2 batch id 6201 / 225000 loss 1.9811100959777832 train acc 0.701862602805999\n",
      "epoch 2 batch id 6301 / 225000 loss 1.937923789024353 train acc 0.7021901285510237\n",
      "epoch 2 batch id 6401 / 225000 loss 1.0287134647369385 train acc 0.7027027027027027\n",
      "epoch 2 batch id 6501 / 225000 loss 0.020536713302135468 train acc 0.7018151053684049\n",
      "epoch 2 batch id 6601 / 225000 loss 0.8087334632873535 train acc 0.7020527192849568\n",
      "epoch 2 batch id 6701 / 225000 loss 0.00715363584458828 train acc 0.7024324727652589\n",
      "epoch 2 batch id 6801 / 225000 loss 1.6719640493392944 train acc 0.7025437435671225\n",
      "epoch 2 batch id 6901 / 225000 loss 1.4785032272338867 train acc 0.7029778293001014\n",
      "epoch 2 batch id 7001 / 225000 loss 1.4245244264602661 train acc 0.7032923868018854\n",
      "epoch 2 batch id 7101 / 225000 loss 2.2817256450653076 train acc 0.7038797352485565\n",
      "epoch 2 batch id 7201 / 225000 loss 1.3749433755874634 train acc 0.7045896403277323\n",
      "epoch 2 batch id 7301 / 225000 loss 0.16545595228672028 train acc 0.7049376797698945\n",
      "epoch 2 batch id 7401 / 225000 loss 0.014441436156630516 train acc 0.7052087555735711\n",
      "epoch 2 batch id 7501 / 225000 loss 1.5618441104888916 train acc 0.7054392747633649\n",
      "epoch 2 batch id 7601 / 225000 loss 0.13749271631240845 train acc 0.7055979476384686\n",
      "epoch 2 batch id 7701 / 225000 loss 1.2311973571777344 train acc 0.7058174263082716\n",
      "epoch 2 batch id 7801 / 225000 loss 0.6032544374465942 train acc 0.7056467119600052\n",
      "epoch 2 batch id 7901 / 225000 loss 2.683356285095215 train acc 0.7057334514618403\n",
      "epoch 2 batch id 8001 / 225000 loss 0.8873090744018555 train acc 0.7055680539932508\n",
      "epoch 2 batch id 8101 / 225000 loss 2.200514554977417 train acc 0.706054808048389\n",
      "epoch 2 batch id 8201 / 225000 loss 0.008888941258192062 train acc 0.7063772710645043\n",
      "epoch 2 batch id 8301 / 225000 loss 0.2600197196006775 train acc 0.706270328876039\n",
      "epoch 2 batch id 8401 / 225000 loss 2.042229175567627 train acc 0.7069396500416617\n",
      "epoch 2 batch id 8501 / 225000 loss 1.6095176935195923 train acc 0.7074755911069286\n",
      "epoch 2 batch id 8601 / 225000 loss 1.9907835721969604 train acc 0.7075340076735264\n",
      "epoch 2 batch id 8701 / 225000 loss 2.137350559234619 train acc 0.7077060108033559\n",
      "epoch 2 batch id 8801 / 225000 loss 0.5840613842010498 train acc 0.7083570048858084\n",
      "epoch 2 batch id 8901 / 225000 loss 0.001582732773385942 train acc 0.7092180653859117\n",
      "epoch 2 batch id 9001 / 225000 loss 1.5023434162139893 train acc 0.7095322741917565\n",
      "epoch 2 batch id 9101 / 225000 loss 0.21078179776668549 train acc 0.7096472915064279\n",
      "epoch 2 batch id 9201 / 225000 loss 1.0958163738250732 train acc 0.709950005434192\n",
      "epoch 2 batch id 9301 / 225000 loss 0.03044993430376053 train acc 0.7101386947640038\n",
      "epoch 2 batch id 9401 / 225000 loss 0.007922308519482613 train acc 0.710536113179449\n",
      "epoch 2 batch id 9501 / 225000 loss 3.099057674407959 train acc 0.7110567308704346\n",
      "epoch 2 batch id 9601 / 225000 loss 0.021487625315785408 train acc 0.7117227372148734\n",
      "epoch 2 batch id 9701 / 225000 loss 3.599207878112793 train acc 0.7121946191114318\n",
      "epoch 2 batch id 9801 / 225000 loss 0.04258923977613449 train acc 0.7124783185389246\n",
      "epoch 2 batch id 9901 / 225000 loss 0.9017777442932129 train acc 0.7127562872437128\n",
      "epoch 2 batch id 10001 / 225000 loss 1.1881513595581055 train acc 0.7133786621337866\n",
      "epoch 2 batch id 10101 / 225000 loss 3.9655864238739014 train acc 0.7133947133947134\n",
      "epoch 2 batch id 10201 / 225000 loss 0.029995227232575417 train acc 0.713753553573179\n",
      "epoch 2 batch id 10301 / 225000 loss 0.13756850361824036 train acc 0.7138870012620134\n",
      "epoch 2 batch id 10401 / 225000 loss 0.023280829191207886 train acc 0.714426497452168\n",
      "epoch 2 batch id 10501 / 225000 loss 2.8338356018066406 train acc 0.7150033330159032\n",
      "epoch 2 batch id 10601 / 225000 loss 2.9272971153259277 train acc 0.7149325535326856\n",
      "epoch 2 batch id 10701 / 225000 loss 2.905914783477783 train acc 0.7152135314456592\n",
      "epoch 2 batch id 10801 / 225000 loss 0.6337207555770874 train acc 0.7155124525506897\n",
      "epoch 2 batch id 10901 / 225000 loss 1.9072136878967285 train acc 0.7153701495275663\n",
      "epoch 2 batch id 11001 / 225000 loss 1.4254510402679443 train acc 0.7155940369057359\n",
      "epoch 2 batch id 11101 / 225000 loss 5.939216136932373 train acc 0.7154760832357445\n",
      "epoch 2 batch id 11201 / 225000 loss 2.08931827545166 train acc 0.7157843049727702\n",
      "epoch 2 batch id 11301 / 225000 loss 2.5091233253479004 train acc 0.7158437306433059\n",
      "epoch 2 batch id 11401 / 225000 loss 0.0029695695266127586 train acc 0.7162091044645207\n",
      "epoch 2 batch id 11501 / 225000 loss 0.0035114497877657413 train acc 0.7162855403877924\n",
      "epoch 2 batch id 11601 / 225000 loss 2.38084077835083 train acc 0.716360658563917\n",
      "epoch 2 batch id 11701 / 225000 loss 0.0668601468205452 train acc 0.7167336125117512\n",
      "epoch 2 batch id 11801 / 225000 loss 0.03603151813149452 train acc 0.7168036607067197\n",
      "epoch 2 batch id 11901 / 225000 loss 1.073392629623413 train acc 0.7171456180152929\n",
      "epoch 2 batch id 12001 / 225000 loss 0.9956239461898804 train acc 0.7172943921339888\n",
      "epoch 2 batch id 12101 / 225000 loss 2.3516483306884766 train acc 0.71748202627882\n",
      "epoch 2 batch id 12201 / 225000 loss 1.4662835597991943 train acc 0.7177690353249734\n",
      "epoch 2 batch id 12301 / 225000 loss 1.036248803138733 train acc 0.7180513779367531\n",
      "epoch 2 batch id 12401 / 225000 loss 1.5137577056884766 train acc 0.7183090073381179\n",
      "epoch 2 batch id 12501 / 225000 loss 4.981932640075684 train acc 0.718642508599312\n",
      "epoch 2 batch id 12601 / 225000 loss 2.3241591453552246 train acc 0.7187921593524323\n",
      "epoch 2 batch id 12701 / 225000 loss 1.8444015979766846 train acc 0.7188607196283757\n",
      "epoch 2 batch id 12801 / 225000 loss 0.8689896464347839 train acc 0.7192602140457777\n",
      "epoch 2 batch id 12901 / 225000 loss 0.6756857633590698 train acc 0.7195372451747927\n",
      "epoch 2 batch id 13001 / 225000 loss 1.712946891784668 train acc 0.7198484731943696\n",
      "epoch 2 batch id 13101 / 225000 loss 1.1220476627349854 train acc 0.7200213724143195\n",
      "epoch 2 batch id 13201 / 225000 loss 0.041749898344278336 train acc 0.7199833345958639\n",
      "epoch 2 batch id 13301 / 225000 loss 2.2401490211486816 train acc 0.7200962333659123\n",
      "epoch 2 batch id 13401 / 225000 loss 1.87592351436615 train acc 0.7203753451234982\n",
      "epoch 2 batch id 13501 / 225000 loss 2.504927158355713 train acc 0.7205577364639656\n",
      "epoch 2 batch id 13601 / 225000 loss 1.9039127826690674 train acc 0.7205903977648702\n",
      "epoch 2 batch id 13701 / 225000 loss 0.004633451346307993 train acc 0.7208232975695205\n",
      "epoch 2 batch id 13801 / 225000 loss 0.09572235494852066 train acc 0.7210528222592566\n",
      "epoch 2 batch id 13901 / 225000 loss 1.3191921710968018 train acc 0.7211531544493202\n",
      "epoch 2 batch id 14001 / 225000 loss 0.008023443631827831 train acc 0.7210556388829369\n",
      "epoch 2 batch id 14101 / 225000 loss 1.751449465751648 train acc 0.7210126941351677\n",
      "epoch 2 batch id 14201 / 225000 loss 2.3819751739501953 train acc 0.7213400464756003\n",
      "epoch 2 batch id 14301 / 225000 loss 3.1323418617248535 train acc 0.7214530452415915\n",
      "epoch 2 batch id 14401 / 225000 loss 0.04045771062374115 train acc 0.7214776751614471\n",
      "epoch 2 batch id 14501 / 225000 loss 0.010399119928479195 train acc 0.7218295289980001\n",
      "epoch 2 batch id 14601 / 225000 loss 2.101581573486328 train acc 0.7216457776864599\n",
      "epoch 2 batch id 14701 / 225000 loss 3.345905065536499 train acc 0.7217196109108224\n",
      "epoch 2 batch id 14801 / 225000 loss 0.012119810096919537 train acc 0.7219106817106952\n",
      "epoch 2 batch id 14901 / 225000 loss 0.004156854934990406 train acc 0.7219146366015704\n",
      "epoch 2 batch id 15001 / 225000 loss 1.2723608016967773 train acc 0.7219685354309713\n",
      "epoch 2 batch id 15101 / 225000 loss 4.024044036865234 train acc 0.7225183762664724\n",
      "epoch 2 batch id 15201 / 225000 loss 2.419163465499878 train acc 0.7224360239457931\n",
      "epoch 2 batch id 15301 / 225000 loss 0.8648484945297241 train acc 0.722518136069538\n",
      "epoch 2 batch id 15401 / 225000 loss 1.4197250604629517 train acc 0.7227777417050841\n",
      "epoch 2 batch id 15501 / 225000 loss 1.15971040725708 train acc 0.7229533578478807\n",
      "epoch 2 batch id 15601 / 225000 loss 2.5974655151367188 train acc 0.7230946734183706\n",
      "epoch 2 batch id 15701 / 225000 loss 0.01050726231187582 train acc 0.7232182663524617\n",
      "epoch 2 batch id 15801 / 225000 loss 0.0046096486039459705 train acc 0.7233402949180432\n",
      "epoch 2 batch id 15901 / 225000 loss 1.755081295967102 train acc 0.7236651782906736\n",
      "epoch 2 batch id 16001 / 225000 loss 3.489525318145752 train acc 0.7239235047809512\n",
      "epoch 2 batch id 16101 / 225000 loss 3.406466007232666 train acc 0.7239767716290914\n",
      "epoch 2 batch id 16201 / 225000 loss 1.608602523803711 train acc 0.7241836923646688\n",
      "epoch 2 batch id 16301 / 225000 loss 0.35683926939964294 train acc 0.72443408379854\n",
      "epoch 2 batch id 16401 / 225000 loss 0.0042235227301716805 train acc 0.7243155905127736\n",
      "epoch 2 batch id 16501 / 225000 loss 2.352212905883789 train acc 0.7241379310344828\n",
      "epoch 2 batch id 16601 / 225000 loss 0.0024883823934942484 train acc 0.7244744292512499\n",
      "epoch 2 batch id 16701 / 225000 loss 0.005785329733043909 train acc 0.7245374528471349\n",
      "epoch 2 batch id 16801 / 225000 loss 1.2073322534561157 train acc 0.7244806856734718\n",
      "epoch 2 batch id 16901 / 225000 loss 0.05075717344880104 train acc 0.7246612626471807\n",
      "epoch 2 batch id 17001 / 225000 loss 2.663163900375366 train acc 0.7247220751720487\n",
      "epoch 2 batch id 17101 / 225000 loss 1.066693663597107 train acc 0.7247237003683995\n",
      "epoch 2 batch id 17201 / 225000 loss 3.014836072921753 train acc 0.7248997151328411\n",
      "epoch 2 batch id 17301 / 225000 loss 0.6247754693031311 train acc 0.7248424946534883\n",
      "epoch 2 batch id 17401 / 225000 loss 1.6128771305084229 train acc 0.7251594735934717\n",
      "epoch 2 batch id 17501 / 225000 loss 0.5200048089027405 train acc 0.7251157076738473\n",
      "epoch 2 batch id 17601 / 225000 loss 1.3750181198120117 train acc 0.725115050281234\n",
      "epoch 2 batch id 17701 / 225000 loss 0.061416078358888626 train acc 0.7252415117789955\n",
      "epoch 2 batch id 17801 / 225000 loss 2.396406650543213 train acc 0.7252120667378237\n",
      "epoch 2 batch id 17901 / 225000 loss 0.12691371142864227 train acc 0.7252946762750684\n",
      "epoch 2 batch id 18001 / 225000 loss 0.022082015872001648 train acc 0.7253485917449031\n",
      "epoch 2 batch id 18101 / 225000 loss 4.607786655426025 train acc 0.7255952709795039\n",
      "epoch 2 batch id 18201 / 225000 loss 0.03512772172689438 train acc 0.7256332069666502\n",
      "epoch 2 batch id 18301 / 225000 loss 0.8908818364143372 train acc 0.7256160865526474\n",
      "epoch 2 batch id 18401 / 225000 loss 0.725134015083313 train acc 0.7256127384381283\n",
      "epoch 2 batch id 18501 / 225000 loss 0.9970498085021973 train acc 0.7258661693962488\n",
      "epoch 2 batch id 18601 / 225000 loss 0.011535091325640678 train acc 0.7260899951615505\n",
      "epoch 2 batch id 18701 / 225000 loss 0.005725066177546978 train acc 0.7261911127747179\n",
      "epoch 2 batch id 18801 / 225000 loss 0.0025200543459504843 train acc 0.7260651029200574\n",
      "epoch 2 batch id 18901 / 225000 loss 0.008160223253071308 train acc 0.7258875191788794\n",
      "epoch 2 batch id 19001 / 225000 loss 1.6684117317199707 train acc 0.7262380927319615\n",
      "epoch 2 batch id 19101 / 225000 loss 3.5807442665100098 train acc 0.72625778755039\n",
      "epoch 2 batch id 19201 / 225000 loss 0.6635933518409729 train acc 0.7263814384667465\n",
      "epoch 2 batch id 19301 / 225000 loss 1.9544658660888672 train acc 0.7265167607895964\n",
      "epoch 2 batch id 19401 / 225000 loss 0.011331446468830109 train acc 0.7267022318437194\n",
      "epoch 2 batch id 19501 / 225000 loss 1.0916308164596558 train acc 0.7267576021742475\n",
      "epoch 2 batch id 19601 / 225000 loss 0.0069388882257044315 train acc 0.7268889342380491\n",
      "epoch 2 batch id 19701 / 225000 loss 1.8895277976989746 train acc 0.7269301050708086\n",
      "epoch 2 batch id 19801 / 225000 loss 1.054842233657837 train acc 0.7270844906822888\n",
      "epoch 2 batch id 19901 / 225000 loss 1.5602037906646729 train acc 0.727111702929501\n",
      "epoch 2 batch id 20001 / 225000 loss 1.1639078855514526 train acc 0.7269386530673466\n",
      "epoch 2 batch id 20101 / 225000 loss 0.12756213545799255 train acc 0.7270409432366549\n",
      "epoch 2 batch id 20201 / 225000 loss 0.02629273571074009 train acc 0.7271422206821444\n",
      "epoch 2 batch id 20301 / 225000 loss 0.007145296782255173 train acc 0.7274272203339737\n",
      "epoch 2 batch id 20401 / 225000 loss 2.826639413833618 train acc 0.7275011028871133\n",
      "epoch 2 batch id 20501 / 225000 loss 3.4871363639831543 train acc 0.7276108482513048\n",
      "epoch 2 batch id 20601 / 225000 loss 3.0962917804718018 train acc 0.727683122178535\n",
      "epoch 2 batch id 20701 / 225000 loss 0.9995741248130798 train acc 0.7275735471716342\n",
      "epoch 2 batch id 20801 / 225000 loss 1.3971691131591797 train acc 0.7276813614730061\n",
      "epoch 2 batch id 20901 / 225000 loss 3.3010904788970947 train acc 0.7278718721592269\n",
      "epoch 2 batch id 21001 / 225000 loss 0.0010190601460635662 train acc 0.7278701014237418\n",
      "epoch 2 batch id 21101 / 225000 loss 1.1505703926086426 train acc 0.7280223686081229\n",
      "epoch 2 batch id 21201 / 225000 loss 2.092146873474121 train acc 0.7281260317909533\n",
      "epoch 2 batch id 21301 / 225000 loss 1.7673050165176392 train acc 0.7282874043472137\n",
      "epoch 2 batch id 21401 / 225000 loss 0.25407999753952026 train acc 0.7284472688192141\n",
      "epoch 2 batch id 21501 / 225000 loss 0.003931068349629641 train acc 0.7283149620947863\n",
      "epoch 2 batch id 21601 / 225000 loss 3.7241547107696533 train acc 0.7285310865237721\n",
      "epoch 2 batch id 21701 / 225000 loss 0.8746073246002197 train acc 0.7285839362241371\n",
      "epoch 2 batch id 21801 / 225000 loss 0.8753208518028259 train acc 0.728487225356635\n",
      "epoch 2 batch id 21901 / 225000 loss 3.6652207374572754 train acc 0.7286082827268161\n",
      "epoch 2 batch id 22001 / 225000 loss 2.0575923919677734 train acc 0.7289327757829189\n",
      "epoch 2 batch id 22101 / 225000 loss 0.011161405593156815 train acc 0.7289828514546853\n",
      "epoch 2 batch id 22201 / 225000 loss 0.8251968026161194 train acc 0.7291225620467546\n",
      "epoch 2 batch id 22301 / 225000 loss 0.9419448971748352 train acc 0.7290480247522533\n",
      "epoch 2 batch id 22401 / 225000 loss 1.7643938064575195 train acc 0.7291080755323424\n",
      "epoch 2 batch id 22501 / 225000 loss 0.3029617667198181 train acc 0.7292120350206658\n",
      "epoch 2 batch id 22601 / 225000 loss 1.9972937107086182 train acc 0.7294256891287996\n",
      "epoch 2 batch id 22701 / 225000 loss 0.48860523104667664 train acc 0.7294172062904718\n",
      "epoch 2 batch id 22801 / 225000 loss 0.9282885193824768 train acc 0.7295074777422043\n",
      "epoch 2 batch id 22901 / 225000 loss 0.8768178224563599 train acc 0.7293677132002969\n",
      "epoch 2 batch id 23001 / 225000 loss 1.8690677881240845 train acc 0.7295443676361897\n",
      "epoch 2 batch id 23101 / 225000 loss 0.7738497257232666 train acc 0.7295571620276179\n",
      "epoch 2 batch id 23201 / 225000 loss 3.1718099117279053 train acc 0.729440541355976\n",
      "epoch 2 batch id 23301 / 225000 loss 2.1964027881622314 train acc 0.7294858589760096\n",
      "epoch 2 batch id 23401 / 225000 loss 0.4564063549041748 train acc 0.7293705397205248\n",
      "epoch 2 batch id 23501 / 225000 loss 0.37052756547927856 train acc 0.7292562018637505\n",
      "epoch 2 batch id 23601 / 225000 loss 2.568915367126465 train acc 0.729301724503199\n",
      "epoch 2 batch id 23701 / 225000 loss 1.8938839435577393 train acc 0.7291780937513185\n",
      "epoch 2 batch id 23801 / 225000 loss 1.7020372152328491 train acc 0.7292340657955548\n",
      "epoch 2 batch id 23901 / 225000 loss 0.7363064885139465 train acc 0.7291640517133174\n",
      "epoch 2 batch id 24001 / 225000 loss 1.9712868928909302 train acc 0.7291779509187117\n",
      "epoch 2 batch id 24101 / 225000 loss 1.6616053581237793 train acc 0.7291087506742459\n",
      "epoch 2 batch id 24201 / 225000 loss 1.0280596017837524 train acc 0.7292054047353416\n",
      "epoch 2 batch id 24301 / 225000 loss 1.5138012170791626 train acc 0.7291778116126908\n",
      "epoch 2 batch id 24401 / 225000 loss 1.762976050376892 train acc 0.7292733904348182\n",
      "epoch 2 batch id 24501 / 225000 loss 1.7966334819793701 train acc 0.729133504754908\n",
      "epoch 2 batch id 24601 / 225000 loss 2.0847952365875244 train acc 0.7290455672533637\n",
      "epoch 2 batch id 24701 / 225000 loss 0.00680387020111084 train acc 0.7291202785312335\n",
      "epoch 2 batch id 24801 / 225000 loss 0.006196309812366962 train acc 0.7291742268456917\n",
      "epoch 2 batch id 24901 / 225000 loss 2.7924835681915283 train acc 0.7292578611300751\n",
      "epoch 2 batch id 25001 / 225000 loss 2.435006618499756 train acc 0.7294408223671053\n",
      "epoch 2 batch id 25101 / 225000 loss 0.005143885500729084 train acc 0.7295028086530417\n",
      "epoch 2 batch id 25201 / 225000 loss 0.4520660638809204 train acc 0.7294353398674656\n",
      "epoch 2 batch id 25301 / 225000 loss 0.22131860256195068 train acc 0.729407928540374\n",
      "epoch 2 batch id 25401 / 225000 loss 3.2288241386413574 train acc 0.7295382071571985\n",
      "epoch 2 batch id 25501 / 225000 loss 1.5149667263031006 train acc 0.729726285243716\n",
      "epoch 2 batch id 25601 / 225000 loss 2.5536723136901855 train acc 0.7299128940275771\n",
      "epoch 2 batch id 25701 / 225000 loss 0.009424585849046707 train acc 0.7298937784522003\n",
      "epoch 2 batch id 25801 / 225000 loss 0.019649848341941833 train acc 0.7299523274291694\n",
      "epoch 2 batch id 25901 / 225000 loss 0.007174658123403788 train acc 0.7300104243079418\n",
      "epoch 2 batch id 26001 / 225000 loss 0.0069237444549798965 train acc 0.7300488442752202\n",
      "epoch 2 batch id 26101 / 225000 loss 2.028330087661743 train acc 0.7300103444312478\n",
      "epoch 2 batch id 26201 / 225000 loss 1.4550912380218506 train acc 0.7301057211556811\n",
      "epoch 2 batch id 26301 / 225000 loss 0.055579036474227905 train acc 0.7301433405573933\n",
      "epoch 2 batch id 26401 / 225000 loss 0.10490640997886658 train acc 0.7302090829892807\n",
      "epoch 2 batch id 26501 / 225000 loss 4.263907432556152 train acc 0.7301611259952454\n",
      "epoch 2 batch id 26601 / 225000 loss 0.7005804777145386 train acc 0.730245103567535\n",
      "epoch 2 batch id 26701 / 225000 loss 0.008585738949477673 train acc 0.7304595333508108\n",
      "epoch 2 batch id 26801 / 225000 loss 0.0023865611292421818 train acc 0.7304764747584045\n",
      "epoch 2 batch id 26901 / 225000 loss 0.00741784181445837 train acc 0.7305397568863611\n",
      "epoch 2 batch id 27001 / 225000 loss 1.2575627565383911 train acc 0.730324802785082\n",
      "epoch 2 batch id 27101 / 225000 loss 2.6914730072021484 train acc 0.7303697280543153\n",
      "epoch 2 batch id 27201 / 225000 loss 0.002158831339329481 train acc 0.7305705672585566\n",
      "epoch 2 batch id 27301 / 225000 loss 0.02734890952706337 train acc 0.7306966777773708\n",
      "epoch 2 batch id 27401 / 225000 loss 1.2454103231430054 train acc 0.7307671252873983\n",
      "epoch 2 batch id 27501 / 225000 loss 2.737725019454956 train acc 0.730873422784626\n",
      "epoch 2 batch id 27601 / 225000 loss 1.6308060884475708 train acc 0.7309246041810079\n",
      "epoch 2 batch id 27701 / 225000 loss 0.47512203454971313 train acc 0.731038590664597\n",
      "epoch 2 batch id 27801 / 225000 loss 4.058565139770508 train acc 0.731124779684184\n",
      "epoch 2 batch id 27901 / 225000 loss 3.382645845413208 train acc 0.7311207483602739\n",
      "epoch 2 batch id 28001 / 225000 loss 3.605602979660034 train acc 0.7310631763151316\n",
      "epoch 2 batch id 28101 / 225000 loss 1.9765350818634033 train acc 0.7309526351375396\n",
      "epoch 2 batch id 28201 / 225000 loss 0.25060105323791504 train acc 0.7310822311265558\n",
      "epoch 2 batch id 28301 / 225000 loss 2.873218297958374 train acc 0.7310607399031837\n",
      "epoch 2 batch id 28401 / 225000 loss 0.09357485920190811 train acc 0.7310922150628499\n",
      "epoch 2 batch id 28501 / 225000 loss 1.0930066108703613 train acc 0.7309041788007439\n",
      "epoch 2 batch id 28601 / 225000 loss 2.884132146835327 train acc 0.7308485717282612\n",
      "epoch 2 batch id 28701 / 225000 loss 0.6186608076095581 train acc 0.7309849831016341\n",
      "epoch 2 batch id 28801 / 225000 loss 4.582350730895996 train acc 0.7309034408527482\n",
      "epoch 2 batch id 28901 / 225000 loss 1.0175559520721436 train acc 0.7310387183834469\n",
      "epoch 2 batch id 29001 / 225000 loss 0.0034519073087722063 train acc 0.7312334057446295\n",
      "epoch 2 batch id 29101 / 225000 loss 0.31606847047805786 train acc 0.7313322566234838\n",
      "epoch 2 batch id 29201 / 225000 loss 2.1510307788848877 train acc 0.7313961850621554\n",
      "epoch 2 batch id 29301 / 225000 loss 0.012059380300343037 train acc 0.731357291560015\n",
      "epoch 2 batch id 29401 / 225000 loss 0.3187485635280609 train acc 0.7313016564062447\n",
      "epoch 2 batch id 29501 / 225000 loss 3.404052495956421 train acc 0.7313141927392292\n",
      "epoch 2 batch id 29601 / 225000 loss 2.1032376289367676 train acc 0.7313435356913618\n",
      "epoch 2 batch id 29701 / 225000 loss 2.3363327980041504 train acc 0.7314484360795933\n",
      "epoch 2 batch id 29801 / 225000 loss 0.07146825641393661 train acc 0.7313932418375222\n",
      "epoch 2 batch id 29901 / 225000 loss 0.00926068052649498 train acc 0.7313969432460453\n",
      "epoch 2 batch id 30001 / 225000 loss 1.0790220499038696 train acc 0.731400619979334\n",
      "epoch 2 batch id 30101 / 225000 loss 0.9003762006759644 train acc 0.7314457991428857\n",
      "epoch 2 batch id 30201 / 225000 loss 2.7937777042388916 train acc 0.7315817357041158\n",
      "epoch 2 batch id 30301 / 225000 loss 0.18394456803798676 train acc 0.7314445067819544\n",
      "epoch 2 batch id 30401 / 225000 loss 1.5190790891647339 train acc 0.7315466596493536\n",
      "epoch 2 batch id 30501 / 225000 loss 2.3022942543029785 train acc 0.7315333923477919\n",
      "epoch 2 batch id 30601 / 225000 loss 2.0659968852996826 train acc 0.731585569099049\n",
      "epoch 2 batch id 30701 / 225000 loss 0.9168528318405151 train acc 0.7316455490049184\n",
      "epoch 2 batch id 30801 / 225000 loss 0.6965072154998779 train acc 0.7316645563455731\n",
      "epoch 2 batch id 30901 / 225000 loss 0.735923171043396 train acc 0.7317724345490437\n",
      "epoch 2 batch id 31001 / 225000 loss 1.0517257452011108 train acc 0.7318796167865552\n",
      "epoch 2 batch id 31101 / 225000 loss 0.2409815937280655 train acc 0.7319459181376805\n",
      "epoch 2 batch id 31201 / 225000 loss 3.0641982555389404 train acc 0.7319877568026666\n",
      "epoch 2 batch id 31301 / 225000 loss 0.00951908715069294 train acc 0.7320213411712085\n",
      "epoch 2 batch id 31401 / 225000 loss 3.731459140777588 train acc 0.7320228655138371\n",
      "epoch 2 batch id 31501 / 225000 loss 1.280434489250183 train acc 0.7320402526903907\n",
      "epoch 2 batch id 31601 / 225000 loss 0.23813942074775696 train acc 0.7320575298250055\n",
      "epoch 2 batch id 31701 / 225000 loss 1.7422047853469849 train acc 0.7319090880413867\n",
      "epoch 2 batch id 31801 / 225000 loss 0.007257292978465557 train acc 0.7319738373007139\n",
      "epoch 2 batch id 31901 / 225000 loss 2.7142841815948486 train acc 0.7320146703865082\n",
      "epoch 2 batch id 32001 / 225000 loss 1.8779598474502563 train acc 0.7318677541326833\n",
      "epoch 2 batch id 32101 / 225000 loss 1.793905258178711 train acc 0.7319553907977945\n",
      "epoch 2 batch id 32201 / 225000 loss 1.4554250240325928 train acc 0.7318095711313313\n",
      "epoch 2 batch id 32301 / 225000 loss 1.4804799556732178 train acc 0.7318117086158323\n",
      "epoch 2 batch id 32401 / 225000 loss 3.4714503288269043 train acc 0.7318138329063918\n",
      "epoch 2 batch id 32501 / 225000 loss 0.38213038444519043 train acc 0.7319159410479678\n",
      "epoch 2 batch id 32601 / 225000 loss 0.03793352469801903 train acc 0.7319790803963069\n",
      "epoch 2 batch id 32701 / 225000 loss 0.0051986174657940865 train acc 0.7320265435307789\n",
      "epoch 2 batch id 32801 / 225000 loss 0.06102048233151436 train acc 0.7319975000762172\n",
      "epoch 2 batch id 32901 / 225000 loss 0.7307317852973938 train acc 0.7319762317254794\n",
      "epoch 2 batch id 33001 / 225000 loss 2.5637829303741455 train acc 0.7320384230780885\n",
      "epoch 2 batch id 33101 / 225000 loss 2.3703885078430176 train acc 0.7320322648862572\n",
      "epoch 2 batch id 33201 / 225000 loss 0.09556510299444199 train acc 0.7321014427276287\n",
      "epoch 2 batch id 33301 / 225000 loss 1.09645676612854 train acc 0.7322377706375184\n",
      "epoch 2 batch id 33401 / 225000 loss 1.0015504360198975 train acc 0.732275979761085\n",
      "epoch 2 batch id 33501 / 225000 loss 1.6924357414245605 train acc 0.7323587355601325\n",
      "epoch 2 batch id 33601 / 225000 loss 0.7619255781173706 train acc 0.7324633195440612\n",
      "epoch 2 batch id 33701 / 225000 loss 3.2618916034698486 train acc 0.7325598646924424\n",
      "epoch 2 batch id 33801 / 225000 loss 2.8207523822784424 train acc 0.7325596875832076\n",
      "epoch 2 batch id 33901 / 225000 loss 0.2951779365539551 train acc 0.7326037580012389\n",
      "epoch 2 batch id 34001 / 225000 loss 1.1219909191131592 train acc 0.7326255110143819\n",
      "epoch 2 batch id 34101 / 225000 loss 3.9893240928649902 train acc 0.7326104806310665\n",
      "epoch 2 batch id 34201 / 225000 loss 1.9367643594741821 train acc 0.7325224408643022\n",
      "epoch 2 batch id 34301 / 225000 loss 3.2960095405578613 train acc 0.7325733943616805\n",
      "epoch 2 batch id 34401 / 225000 loss 0.047521043568849564 train acc 0.7326531205488213\n",
      "epoch 2 batch id 34501 / 225000 loss 1.8481720685958862 train acc 0.73264543056723\n",
      "epoch 2 batch id 34601 / 225000 loss 1.7524385452270508 train acc 0.732702812057455\n",
      "epoch 2 batch id 34701 / 225000 loss 1.0514782667160034 train acc 0.7327886804414858\n",
      "epoch 2 batch id 34801 / 225000 loss 1.8516370058059692 train acc 0.7328094020286773\n",
      "epoch 2 batch id 34901 / 225000 loss 0.03880329057574272 train acc 0.732915962293344\n",
      "epoch 2 batch id 35001 / 225000 loss 0.015210317447781563 train acc 0.7329504871289392\n",
      "epoch 2 batch id 35101 / 225000 loss 0.021905923262238503 train acc 0.7329919375516367\n",
      "epoch 2 batch id 35201 / 225000 loss 1.1379252672195435 train acc 0.733132581460754\n",
      "epoch 2 batch id 35301 / 225000 loss 0.7601286172866821 train acc 0.7332582646383955\n",
      "epoch 2 batch id 35401 / 225000 loss 2.0133516788482666 train acc 0.7332914324454112\n",
      "epoch 2 batch id 35501 / 225000 loss 0.12871631979942322 train acc 0.7333596236725726\n",
      "epoch 2 batch id 35601 / 225000 loss 1.8257896900177002 train acc 0.7333852981657819\n",
      "epoch 2 batch id 35701 / 225000 loss 4.092081069946289 train acc 0.7333267975686956\n",
      "epoch 2 batch id 35801 / 225000 loss 1.5726163387298584 train acc 0.7333105220524566\n",
      "epoch 2 batch id 35901 / 225000 loss 0.06579627096652985 train acc 0.7333221915824072\n",
      "epoch 2 batch id 36001 / 225000 loss 1.923134684562683 train acc 0.7332851865225966\n",
      "epoch 2 batch id 36101 / 225000 loss 3.425074577331543 train acc 0.7332345364394338\n",
      "epoch 2 batch id 36201 / 225000 loss 2.6690444946289062 train acc 0.7333015662550758\n",
      "epoch 2 batch id 36301 / 225000 loss 0.0028824906330555677 train acc 0.7332924712817829\n",
      "epoch 2 batch id 36401 / 225000 loss 0.36978861689567566 train acc 0.7333108980522514\n",
      "epoch 2 batch id 36501 / 225000 loss 1.1636502742767334 train acc 0.7333292238568806\n",
      "epoch 2 batch id 36601 / 225000 loss 1.5143611431121826 train acc 0.7333064670364198\n",
      "epoch 2 batch id 36701 / 225000 loss 1.6371943950653076 train acc 0.7333315168524018\n",
      "epoch 2 batch id 36801 / 225000 loss 0.3982578217983246 train acc 0.7333224640634766\n",
      "epoch 2 batch id 36901 / 225000 loss 0.5221714973449707 train acc 0.7333270101081272\n",
      "epoch 2 batch id 37001 / 225000 loss 0.0035162861458957195 train acc 0.7335207156563336\n",
      "epoch 2 batch id 37101 / 225000 loss 0.3515594005584717 train acc 0.7335314412010457\n",
      "epoch 2 batch id 37201 / 225000 loss 0.8726089000701904 train acc 0.7335689900809118\n",
      "epoch 2 batch id 37301 / 225000 loss 1.0031627416610718 train acc 0.7335996353985148\n",
      "epoch 2 batch id 37401 / 225000 loss 1.3597431182861328 train acc 0.733663538408064\n",
      "epoch 2 batch id 37501 / 225000 loss 0.12268432974815369 train acc 0.7337004346550758\n",
      "epoch 2 batch id 37601 / 225000 loss 0.001789103145711124 train acc 0.7337570809286987\n",
      "epoch 2 batch id 37701 / 225000 loss 0.028352700173854828 train acc 0.733767008832657\n",
      "epoch 2 batch id 37801 / 225000 loss 2.3405637741088867 train acc 0.7337570434644586\n",
      "epoch 2 batch id 37901 / 225000 loss 1.645782232284546 train acc 0.7337735152106805\n",
      "epoch 2 batch id 38001 / 225000 loss 0.21917623281478882 train acc 0.7337899002657825\n",
      "epoch 2 batch id 38101 / 225000 loss 1.6072461605072021 train acc 0.73382588383507\n",
      "epoch 2 batch id 38201 / 225000 loss 2.442598342895508 train acc 0.733881312007539\n",
      "epoch 2 batch id 38301 / 225000 loss 3.5965933799743652 train acc 0.7339429779901308\n",
      "epoch 2 batch id 38401 / 225000 loss 0.011430663987994194 train acc 0.7340043228040937\n",
      "epoch 2 batch id 38501 / 225000 loss 1.0684444904327393 train acc 0.7340978156411522\n",
      "epoch 2 batch id 38601 / 225000 loss 0.8866249918937683 train acc 0.7341519649750007\n",
      "epoch 2 batch id 38701 / 225000 loss 0.01587521657347679 train acc 0.7341089377535465\n",
      "epoch 2 batch id 38801 / 225000 loss 1.165795087814331 train acc 0.7340468029174506\n",
      "epoch 2 batch id 38901 / 225000 loss 1.3767309188842773 train acc 0.7340685329425979\n",
      "epoch 2 batch id 39001 / 225000 loss 0.017675884068012238 train acc 0.7340196405220379\n",
      "epoch 2 batch id 39101 / 225000 loss 2.7419118881225586 train acc 0.7340860847548656\n",
      "epoch 2 batch id 39201 / 225000 loss 1.0483161211013794 train acc 0.7341203030534935\n",
      "epoch 2 batch id 39301 / 225000 loss 2.6173789501190186 train acc 0.7341289025724537\n",
      "epoch 2 batch id 39401 / 225000 loss 1.9271773099899292 train acc 0.7342199436562524\n",
      "epoch 2 batch id 39501 / 225000 loss 0.055883120745420456 train acc 0.7342219184324448\n",
      "epoch 2 batch id 39601 / 225000 loss 1.7601052522659302 train acc 0.7342680740385343\n",
      "epoch 2 batch id 39701 / 225000 loss 2.523710250854492 train acc 0.7343202941991386\n",
      "epoch 2 batch id 39801 / 225000 loss 2.0190279483795166 train acc 0.7343848144518982\n",
      "epoch 2 batch id 39901 / 225000 loss 2.3439323902130127 train acc 0.7343926217388035\n",
      "epoch 2 batch id 40001 / 225000 loss 7.539406776428223 train acc 0.7344128896777581\n",
      "epoch 2 batch id 40101 / 225000 loss 1.4377397298812866 train acc 0.734389416722775\n",
      "epoch 2 batch id 40201 / 225000 loss 1.5605632066726685 train acc 0.7343536230442029\n",
      "epoch 2 batch id 40301 / 225000 loss 2.403611421585083 train acc 0.7343428202774125\n",
      "epoch 2 batch id 40401 / 225000 loss 2.7376506328582764 train acc 0.7343073191257642\n",
      "epoch 2 batch id 40501 / 225000 loss 2.7636635303497314 train acc 0.7342658205970223\n",
      "epoch 2 batch id 40601 / 225000 loss 1.0573394298553467 train acc 0.734335361198\n",
      "epoch 2 batch id 40701 / 225000 loss 1.009099006652832 train acc 0.7342817129800251\n",
      "epoch 2 batch id 40801 / 225000 loss 1.6525629758834839 train acc 0.7341180363226392\n",
      "epoch 2 batch id 40901 / 225000 loss 3.5987327098846436 train acc 0.7340835187403731\n",
      "epoch 2 batch id 41001 / 225000 loss 3.633592128753662 train acc 0.7340308772956757\n",
      "epoch 2 batch id 41101 / 225000 loss 3.7503838539123535 train acc 0.7340149874698912\n",
      "epoch 2 batch id 41201 / 225000 loss 0.881653368473053 train acc 0.7341205310550715\n",
      "epoch 2 batch id 41301 / 225000 loss 3.970224618911743 train acc 0.734255829156679\n",
      "epoch 2 batch id 41401 / 225000 loss 0.031693607568740845 train acc 0.7342878191348035\n",
      "epoch 2 batch id 41501 / 225000 loss 1.4650564193725586 train acc 0.7343256788993037\n",
      "epoch 2 batch id 41601 / 225000 loss 0.014492237940430641 train acc 0.7343032619408187\n",
      "epoch 2 batch id 41701 / 225000 loss 0.018104076385498047 train acc 0.7342389870746505\n",
      "epoch 2 batch id 41801 / 225000 loss 0.06157291680574417 train acc 0.7343364991268152\n",
      "epoch 2 batch id 41901 / 225000 loss 0.006212803069502115 train acc 0.7343500155127562\n",
      "epoch 2 batch id 42001 / 225000 loss 0.975864827632904 train acc 0.7343515630580224\n",
      "epoch 2 batch id 42101 / 225000 loss 1.823979139328003 train acc 0.7343174746443077\n",
      "epoch 2 batch id 42201 / 225000 loss 3.0446321964263916 train acc 0.7342716997227554\n",
      "epoch 2 batch id 42301 / 225000 loss 3.559169054031372 train acc 0.7342556913548143\n",
      "epoch 2 batch id 42401 / 225000 loss 0.6829057931900024 train acc 0.7342161741468362\n",
      "epoch 2 batch id 42501 / 225000 loss 0.026574663817882538 train acc 0.7343003694030729\n",
      "epoch 2 batch id 42601 / 225000 loss 1.597966194152832 train acc 0.7342961432830215\n",
      "epoch 2 batch id 42701 / 225000 loss 5.104197025299072 train acc 0.7343621929228824\n",
      "epoch 2 batch id 42801 / 225000 loss 0.004691801033914089 train acc 0.7343870470316114\n",
      "epoch 2 batch id 42901 / 225000 loss 1.6749972105026245 train acc 0.7343418568331741\n",
      "epoch 2 batch id 43001 / 225000 loss 0.012458314187824726 train acc 0.7343782702727844\n",
      "epoch 2 batch id 43101 / 225000 loss 1.0798897743225098 train acc 0.7345189206746944\n",
      "epoch 2 batch id 43201 / 225000 loss 0.38259369134902954 train acc 0.7345605425800329\n",
      "epoch 2 batch id 43301 / 225000 loss 3.0235633850097656 train acc 0.7345904251633911\n",
      "epoch 2 batch id 43401 / 225000 loss 0.00772513821721077 train acc 0.7346316905140434\n",
      "epoch 2 batch id 43501 / 225000 loss 0.9971797466278076 train acc 0.7345463322682237\n",
      "epoch 2 batch id 43601 / 225000 loss 0.08364324271678925 train acc 0.73462191234146\n",
      "epoch 2 batch id 43701 / 225000 loss 0.17729374766349792 train acc 0.7346284982037025\n",
      "epoch 2 batch id 43801 / 225000 loss 3.3470258712768555 train acc 0.7345551471427593\n",
      "epoch 2 batch id 43901 / 225000 loss 4.333432197570801 train acc 0.7345390765586205\n",
      "epoch 2 batch id 44001 / 225000 loss 0.042356234043836594 train acc 0.7346367128019817\n",
      "epoch 2 batch id 44101 / 225000 loss 0.3231985867023468 train acc 0.7346375365637967\n",
      "epoch 2 batch id 44201 / 225000 loss 0.0025893410202115774 train acc 0.7346722924820706\n",
      "epoch 2 batch id 44301 / 225000 loss 1.7106343507766724 train acc 0.7347181779192343\n",
      "epoch 2 batch id 44401 / 225000 loss 5.156870365142822 train acc 0.7346906601202675\n",
      "epoch 2 batch id 44501 / 225000 loss 3.188948392868042 train acc 0.7347531516145704\n",
      "epoch 2 batch id 44601 / 225000 loss 2.3963303565979004 train acc 0.7347985471177776\n",
      "epoch 2 batch id 44701 / 225000 loss 1.4814330339431763 train acc 0.7348045905013311\n",
      "epoch 2 batch id 44801 / 225000 loss 1.2491928339004517 train acc 0.7347994464409277\n",
      "epoch 2 batch id 44901 / 225000 loss 1.3323960304260254 train acc 0.7348444355359569\n",
      "epoch 2 batch id 45001 / 225000 loss 0.012346608564257622 train acc 0.734955889869114\n",
      "epoch 2 batch id 45101 / 225000 loss 0.003614946035668254 train acc 0.7350613068446376\n",
      "epoch 2 batch id 45201 / 225000 loss 0.0019260169938206673 train acc 0.7350777637662883\n",
      "epoch 2 batch id 45301 / 225000 loss 0.200811505317688 train acc 0.7351051853159974\n",
      "epoch 2 batch id 45401 / 225000 loss 0.38277167081832886 train acc 0.7351049536353825\n",
      "epoch 2 batch id 45501 / 225000 loss 0.007361038122326136 train acc 0.7351047229731215\n",
      "epoch 2 batch id 45601 / 225000 loss 2.975107192993164 train acc 0.7350003289401548\n",
      "epoch 2 batch id 45701 / 225000 loss 3.4133143424987793 train acc 0.7350112689000241\n",
      "epoch 2 batch id 45801 / 225000 loss 2.514282464981079 train acc 0.7350439946726054\n",
      "epoch 2 batch id 45901 / 225000 loss 1.811622142791748 train acc 0.7351255963922355\n",
      "epoch 2 batch id 46001 / 225000 loss 3.8544445037841797 train acc 0.7351851046716376\n",
      "epoch 2 batch id 46101 / 225000 loss 2.3410820960998535 train acc 0.7351467430207588\n",
      "epoch 2 batch id 46201 / 225000 loss 0.07319217175245285 train acc 0.7352059479232051\n",
      "epoch 2 batch id 46301 / 225000 loss 1.056177020072937 train acc 0.735243299280793\n",
      "epoch 2 batch id 46401 / 225000 loss 0.7470189332962036 train acc 0.7351942846059352\n",
      "epoch 2 batch id 46501 / 225000 loss 0.0505647137761116 train acc 0.7352261241693727\n",
      "epoch 2 batch id 46601 / 225000 loss 1.8721578121185303 train acc 0.7352310036265316\n",
      "epoch 2 batch id 46701 / 225000 loss 2.8220481872558594 train acc 0.7350966788719727\n",
      "epoch 2 batch id 46801 / 225000 loss 0.5169160962104797 train acc 0.7351071558300036\n",
      "epoch 2 batch id 46901 / 225000 loss 1.9426904916763306 train acc 0.7350589539668664\n",
      "epoch 2 batch id 47001 / 225000 loss 1.8310654163360596 train acc 0.735085423714389\n",
      "epoch 2 batch id 47101 / 225000 loss 5.819012641906738 train acc 0.7351277042950256\n",
      "epoch 2 batch id 47201 / 225000 loss 0.050289515405893326 train acc 0.7351327302387661\n",
      "epoch 2 batch id 47301 / 225000 loss 1.6590415239334106 train acc 0.7352064438383966\n",
      "epoch 2 batch id 47401 / 225000 loss 1.8050932884216309 train acc 0.7351796375603891\n",
      "epoch 2 batch id 47501 / 225000 loss 0.20910689234733582 train acc 0.7352108376665755\n",
      "epoch 2 batch id 47601 / 225000 loss 1.1952463388442993 train acc 0.7352261507111195\n",
      "epoch 2 batch id 47701 / 225000 loss 0.7211825847625732 train acc 0.7350998930840025\n",
      "epoch 2 batch id 47801 / 225000 loss 0.0016278930706903338 train acc 0.7350787640425932\n",
      "epoch 2 batch id 47901 / 225000 loss 1.3777893781661987 train acc 0.7349794367549738\n",
      "epoch 2 batch id 48001 / 225000 loss 1.1627451181411743 train acc 0.7349742713693465\n",
      "epoch 2 batch id 48101 / 225000 loss 0.0050757997669279575 train acc 0.7348963639009584\n",
      "epoch 2 batch id 48201 / 225000 loss 2.1288814544677734 train acc 0.7348654592228377\n",
      "epoch 2 batch id 48301 / 225000 loss 2.38771390914917 train acc 0.7347777478727149\n",
      "epoch 2 batch id 48401 / 225000 loss 0.05012766644358635 train acc 0.7346955641412367\n",
      "epoch 2 batch id 48501 / 225000 loss 2.5138444900512695 train acc 0.734711655429785\n",
      "epoch 2 batch id 48601 / 225000 loss 2.5831313133239746 train acc 0.7347842636982778\n",
      "epoch 2 batch id 48701 / 225000 loss 1.8552672863006592 train acc 0.7348052401388062\n",
      "epoch 2 batch id 48801 / 225000 loss 0.7194390892982483 train acc 0.7348414991496076\n",
      "epoch 2 batch id 48901 / 225000 loss 0.008187638595700264 train acc 0.7348724974949388\n",
      "epoch 2 batch id 49001 / 225000 loss 0.012488331645727158 train acc 0.7348829615722128\n",
      "epoch 2 batch id 49101 / 225000 loss 0.00791300181299448 train acc 0.7349188407568074\n",
      "epoch 2 batch id 49201 / 225000 loss 2.465256690979004 train acc 0.734878356130973\n",
      "epoch 2 batch id 49301 / 225000 loss 0.04401468485593796 train acc 0.7349850915802925\n",
      "epoch 2 batch id 49401 / 225000 loss 1.544385313987732 train acc 0.7350357280216999\n",
      "epoch 2 batch id 49501 / 225000 loss 2.136993408203125 train acc 0.735050807054403\n",
      "epoch 2 batch id 49601 / 225000 loss 1.734890341758728 train acc 0.7350708655067438\n",
      "epoch 2 batch id 49701 / 225000 loss 4.0651021003723145 train acc 0.7351260538017343\n",
      "epoch 2 batch id 49801 / 225000 loss 0.004625112283974886 train acc 0.735155920563844\n",
      "epoch 2 batch id 49901 / 225000 loss 2.684257984161377 train acc 0.7351055089076372\n",
      "epoch 2 batch id 50001 / 225000 loss 0.9116802215576172 train acc 0.7351152976940462\n",
      "epoch 2 batch id 50101 / 225000 loss 0.03555016964673996 train acc 0.7351200574838825\n",
      "epoch 2 batch id 50201 / 225000 loss 1.5970922708511353 train acc 0.7351198183303121\n",
      "epoch 2 batch id 50301 / 225000 loss 1.0611608028411865 train acc 0.7350847895668078\n",
      "epoch 2 batch id 50401 / 225000 loss 0.03286144509911537 train acc 0.7350498998035754\n",
      "epoch 2 batch id 50501 / 225000 loss 2.4892172813415527 train acc 0.7350002970238213\n",
      "epoch 2 batch id 50601 / 225000 loss 2.2663066387176514 train acc 0.7350398213474042\n",
      "epoch 2 batch id 50701 / 225000 loss 0.2534516155719757 train acc 0.7351137058440662\n",
      "epoch 2 batch id 50801 / 225000 loss 0.0033678661566227674 train acc 0.7351528513218244\n",
      "epoch 2 batch id 50901 / 225000 loss 0.18883076310157776 train acc 0.7352016659790573\n",
      "epoch 2 batch id 51001 / 225000 loss 0.3004346489906311 train acc 0.7352649948040234\n",
      "epoch 2 batch id 51101 / 225000 loss 0.01997200772166252 train acc 0.735254691689008\n",
      "epoch 2 batch id 51201 / 225000 loss 3.6410324573516846 train acc 0.7353274350110349\n",
      "epoch 2 batch id 51301 / 225000 loss 1.090130090713501 train acc 0.7353462895460128\n",
      "epoch 2 batch id 51401 / 225000 loss 0.003169164527207613 train acc 0.735389389311492\n",
      "epoch 2 batch id 51501 / 225000 loss 1.1376640796661377 train acc 0.735427467427817\n",
      "epoch 2 batch id 51601 / 225000 loss 1.8521456718444824 train acc 0.7353491211410632\n",
      "epoch 2 batch id 51701 / 225000 loss 0.06807446479797363 train acc 0.7353387748786291\n",
      "epoch 2 batch id 51801 / 225000 loss 1.6871633529663086 train acc 0.7353960348255825\n",
      "epoch 2 batch id 51901 / 225000 loss 0.005685374606400728 train acc 0.7355349607907362\n",
      "epoch 2 batch id 52001 / 225000 loss 0.8227890729904175 train acc 0.7355627776388916\n",
      "epoch 2 batch id 52101 / 225000 loss 0.009644825011491776 train acc 0.7355856893341779\n",
      "epoch 2 batch id 52201 / 225000 loss 0.027502020820975304 train acc 0.7356085132468727\n",
      "epoch 2 batch id 52301 / 225000 loss 2.180887460708618 train acc 0.735664710043785\n",
      "epoch 2 batch id 52401 / 225000 loss 0.8439337015151978 train acc 0.7356395870307818\n",
      "epoch 2 batch id 52501 / 225000 loss 0.004837206099182367 train acc 0.7355955124664292\n",
      "epoch 2 batch id 52601 / 225000 loss 0.014546649530529976 train acc 0.735599133096329\n",
      "epoch 2 batch id 52701 / 225000 loss 1.2516568899154663 train acc 0.7356312024439764\n",
      "epoch 2 batch id 52801 / 225000 loss 0.00491507351398468 train acc 0.7356820893543683\n",
      "epoch 2 batch id 52901 / 225000 loss 0.2725200951099396 train acc 0.7356760741762916\n",
      "epoch 2 batch id 53001 / 225000 loss 3.0301733016967773 train acc 0.7356512141280354\n",
      "epoch 2 batch id 53101 / 225000 loss 1.6176366806030273 train acc 0.735715899888891\n",
      "epoch 2 batch id 53201 / 225000 loss 0.9053438901901245 train acc 0.7357756433149752\n",
      "epoch 2 batch id 53301 / 225000 loss 4.496762752532959 train acc 0.7357366653533705\n",
      "epoch 2 batch id 53401 / 225000 loss 1.0290309190750122 train acc 0.7356744255725548\n",
      "epoch 2 batch id 53501 / 225000 loss 0.02899577096104622 train acc 0.7357946580437749\n",
      "epoch 2 batch id 53601 / 225000 loss 1.3850445747375488 train acc 0.7357698550400179\n",
      "epoch 2 batch id 53701 / 225000 loss 0.8816713690757751 train acc 0.7358615295804547\n",
      "epoch 2 batch id 53801 / 225000 loss 0.44817841053009033 train acc 0.7359621568372335\n",
      "epoch 2 batch id 53901 / 225000 loss 0.005826616659760475 train acc 0.7360253056529563\n",
      "epoch 2 batch id 54001 / 225000 loss 1.0313109159469604 train acc 0.7360604433251237\n",
      "epoch 2 batch id 54101 / 225000 loss 2.0636982917785645 train acc 0.7360954511007191\n",
      "epoch 2 batch id 54201 / 225000 loss 0.5031384825706482 train acc 0.7361395546207634\n",
      "epoch 2 batch id 54301 / 225000 loss 0.6350905299186707 train acc 0.7361558718992284\n",
      "epoch 2 batch id 54401 / 225000 loss 0.5456534624099731 train acc 0.7360986011286558\n",
      "epoch 2 batch id 54501 / 225000 loss 2.2232019901275635 train acc 0.7360965853837544\n",
      "epoch 2 batch id 54601 / 225000 loss 3.904618263244629 train acc 0.7361540997417629\n",
      "epoch 2 batch id 54701 / 225000 loss 2.3178696632385254 train acc 0.7361199978062558\n",
      "epoch 2 batch id 54801 / 225000 loss 0.5439222455024719 train acc 0.7360404007226146\n",
      "epoch 2 batch id 54901 / 225000 loss 2.9689266681671143 train acc 0.7360385056738493\n",
      "epoch 2 batch id 55001 / 225000 loss 0.012060062028467655 train acc 0.7360638897474592\n",
      "epoch 2 batch id 55101 / 225000 loss 3.1791582107543945 train acc 0.7361027930527576\n",
      "epoch 2 batch id 55201 / 225000 loss 2.737515449523926 train acc 0.7361460843100669\n",
      "epoch 2 batch id 55301 / 225000 loss 0.9552919268608093 train acc 0.7360852425815084\n",
      "epoch 2 batch id 55401 / 225000 loss 1.2489107847213745 train acc 0.7361013339109402\n",
      "epoch 2 batch id 55501 / 225000 loss 1.4470349550247192 train acc 0.736117367254644\n",
      "epoch 2 batch id 55601 / 225000 loss 0.9994888305664062 train acc 0.7361063649934354\n",
      "epoch 2 batch id 55701 / 225000 loss 1.2556124925613403 train acc 0.7361537494838513\n",
      "epoch 2 batch id 55801 / 225000 loss 0.1643141508102417 train acc 0.7361382412501568\n",
      "epoch 2 batch id 55901 / 225000 loss 1.0481078624725342 train acc 0.7361272606930108\n",
      "epoch 2 batch id 56001 / 225000 loss 1.8439147472381592 train acc 0.7360939983214585\n",
      "epoch 2 batch id 56101 / 225000 loss 0.10517401248216629 train acc 0.7360563982816706\n",
      "epoch 2 batch id 56201 / 225000 loss 0.0035344664938747883 train acc 0.7360990017971211\n",
      "epoch 2 batch id 56301 / 225000 loss 0.001444658963009715 train acc 0.7360926093675068\n",
      "epoch 2 batch id 56401 / 225000 loss 1.4959335327148438 train acc 0.7361881881526924\n",
      "epoch 2 batch id 56501 / 225000 loss 0.15389384329319 train acc 0.7361816605015841\n",
      "epoch 2 batch id 56601 / 225000 loss 0.10453010350465775 train acc 0.7361795727990672\n",
      "epoch 2 batch id 56701 / 225000 loss 1.1427298784255981 train acc 0.7361819015537645\n",
      "epoch 2 batch id 56801 / 225000 loss 2.2970118522644043 train acc 0.7361754194468407\n",
      "epoch 2 batch id 56901 / 225000 loss 1.1995131969451904 train acc 0.7362260768703538\n",
      "epoch 2 batch id 57001 / 225000 loss 0.004772707354277372 train acc 0.7362590129997719\n",
      "epoch 2 batch id 57101 / 225000 loss 1.88913094997406 train acc 0.7362699427330519\n",
      "epoch 2 batch id 57201 / 225000 loss 0.011721217073500156 train acc 0.7362895753570742\n",
      "epoch 2 batch id 57301 / 225000 loss 1.1973598003387451 train acc 0.736287324828537\n",
      "epoch 2 batch id 57401 / 225000 loss 1.482890009880066 train acc 0.7362720161669657\n",
      "epoch 2 batch id 57501 / 225000 loss 3.5826151371002197 train acc 0.7362784995043564\n",
      "epoch 2 batch id 57601 / 225000 loss 0.6972524523735046 train acc 0.7362675995208416\n",
      "epoch 2 batch id 57701 / 225000 loss 2.2054154872894287 train acc 0.7362480719571585\n",
      "epoch 2 batch id 57801 / 225000 loss 1.5795042514801025 train acc 0.7362372623311015\n",
      "epoch 2 batch id 57901 / 225000 loss 3.4597225189208984 train acc 0.7362653494758294\n",
      "epoch 2 batch id 58001 / 225000 loss 1.024872899055481 train acc 0.7363019603110291\n",
      "epoch 2 batch id 58101 / 225000 loss 0.4203993082046509 train acc 0.7363298394175659\n",
      "epoch 2 batch id 58201 / 225000 loss 0.04263436421751976 train acc 0.73631466813285\n",
      "epoch 2 batch id 58301 / 225000 loss 4.096886157989502 train acc 0.7362995488928149\n",
      "epoch 2 batch id 58401 / 225000 loss 3.5787692070007324 train acc 0.7362416739439394\n",
      "epoch 2 batch id 58501 / 225000 loss 0.0017242509638890624 train acc 0.7362438248918822\n",
      "epoch 2 batch id 58601 / 225000 loss 0.004728653933852911 train acc 0.736241702360028\n",
      "epoch 2 batch id 58701 / 225000 loss 0.7710452079772949 train acc 0.7361969983475579\n",
      "epoch 2 batch id 58801 / 225000 loss 1.1767756938934326 train acc 0.7361907110423292\n",
      "epoch 2 batch id 58901 / 225000 loss 1.0608818531036377 train acc 0.7362481112375002\n",
      "epoch 2 batch id 59001 / 225000 loss 1.4604870080947876 train acc 0.7361993864510771\n",
      "epoch 2 batch id 59101 / 225000 loss 2.1542837619781494 train acc 0.7362523476760122\n",
      "epoch 2 batch id 59201 / 225000 loss 2.557999849319458 train acc 0.7362840154727116\n",
      "epoch 2 batch id 59301 / 225000 loss 1.6834454536437988 train acc 0.7362354766361444\n",
      "epoch 2 batch id 59401 / 225000 loss 0.011506193317472935 train acc 0.7362291880608071\n",
      "epoch 2 batch id 59501 / 225000 loss 1.8742426633834839 train acc 0.7362607351136956\n",
      "epoch 2 batch id 59601 / 225000 loss 1.5964128971099854 train acc 0.7363005654267546\n",
      "epoch 2 batch id 59701 / 225000 loss 0.015104338526725769 train acc 0.7363444498417112\n",
      "epoch 2 batch id 59801 / 225000 loss 3.8159875869750977 train acc 0.7362711325897561\n",
      "epoch 2 batch id 59901 / 225000 loss 3.902060031890869 train acc 0.736298225405252\n",
      "epoch 2 batch id 60001 / 225000 loss 1.1334199905395508 train acc 0.7363335611073148\n",
      "epoch 2 batch id 60101 / 225000 loss 0.006689415778964758 train acc 0.7362731069366566\n",
      "epoch 2 batch id 60201 / 225000 loss 1.5577130317687988 train acc 0.7361920898323948\n",
      "epoch 2 batch id 60301 / 225000 loss 0.003833131166175008 train acc 0.7361901129334505\n",
      "epoch 2 batch id 60401 / 225000 loss 2.629566192626953 train acc 0.7361922815847419\n",
      "epoch 2 batch id 60501 / 225000 loss 0.6605081558227539 train acc 0.7361489892729046\n",
      "epoch 2 batch id 60601 / 225000 loss 0.012019021436572075 train acc 0.7361347172488902\n",
      "epoch 2 batch id 60701 / 225000 loss 0.6050986051559448 train acc 0.736157559183539\n",
      "epoch 2 batch id 60801 / 225000 loss 0.0015356221701949835 train acc 0.7361926613049128\n",
      "epoch 2 batch id 60901 / 225000 loss 1.5237705707550049 train acc 0.7362522782877129\n",
      "epoch 2 batch id 61001 / 225000 loss 3.4493749141693115 train acc 0.7363076015147293\n",
      "epoch 2 batch id 61101 / 225000 loss 1.6345690488815308 train acc 0.7363300109654507\n",
      "epoch 2 batch id 61201 / 225000 loss 0.5937690734863281 train acc 0.736348262283296\n",
      "epoch 2 batch id 61301 / 225000 loss 3.2007503509521484 train acc 0.7363460628701\n",
      "epoch 2 batch id 61401 / 225000 loss 0.032011713832616806 train acc 0.7363357274311493\n",
      "epoch 2 batch id 61501 / 225000 loss 0.04969463869929314 train acc 0.7363660753483683\n",
      "epoch 2 batch id 61601 / 225000 loss 0.43818387389183044 train acc 0.7363638577295823\n",
      "epoch 2 batch id 61701 / 225000 loss 2.980041027069092 train acc 0.7363170775190029\n",
      "epoch 2 batch id 61801 / 225000 loss 0.5442824363708496 train acc 0.7363675345059142\n",
      "epoch 2 batch id 61901 / 225000 loss 2.8348498344421387 train acc 0.7364460994168107\n",
      "epoch 2 batch id 62001 / 225000 loss 3.2232251167297363 train acc 0.7364034451057241\n",
      "epoch 2 batch id 62101 / 225000 loss 1.379418134689331 train acc 0.7364575449670697\n",
      "epoch 2 batch id 62201 / 225000 loss 0.0016299255657941103 train acc 0.7365637208405009\n",
      "epoch 2 batch id 62301 / 225000 loss 1.1170969009399414 train acc 0.7366053514389818\n",
      "epoch 2 batch id 62401 / 225000 loss 2.981637716293335 train acc 0.7366628739924039\n",
      "epoch 2 batch id 62501 / 225000 loss 1.217054843902588 train acc 0.7366242140125758\n",
      "epoch 2 batch id 62601 / 225000 loss 2.2454404830932617 train acc 0.7366136323700899\n",
      "epoch 2 batch id 62701 / 225000 loss 0.7744988203048706 train acc 0.7366828280250713\n",
      "epoch 2 batch id 62801 / 225000 loss 0.9477240443229675 train acc 0.7366283976369803\n",
      "epoch 2 batch id 62901 / 225000 loss 3.8058536052703857 train acc 0.7366337578098917\n",
      "epoch 2 batch id 63001 / 225000 loss 0.28018447756767273 train acc 0.7366311645846891\n",
      "epoch 2 batch id 63101 / 225000 loss 0.38666272163391113 train acc 0.7367236652350992\n",
      "epoch 2 batch id 63201 / 225000 loss 0.8021517395973206 train acc 0.7367169823262291\n",
      "epoch 2 batch id 63301 / 225000 loss 0.7597939372062683 train acc 0.7367300674554904\n",
      "epoch 2 batch id 63401 / 225000 loss 1.4809871912002563 train acc 0.7367273386855097\n",
      "epoch 2 batch id 63501 / 225000 loss 1.3391145467758179 train acc 0.7367088707264452\n",
      "epoch 2 batch id 63601 / 225000 loss 0.4441511332988739 train acc 0.7367808682253424\n",
      "epoch 2 batch id 63701 / 225000 loss 1.8743853569030762 train acc 0.736793770898416\n",
      "epoch 2 batch id 63801 / 225000 loss 0.0036919955164194107 train acc 0.7367909593893512\n",
      "epoch 2 batch id 63901 / 225000 loss 0.012543248012661934 train acc 0.7368624904148605\n",
      "epoch 2 batch id 64001 / 225000 loss 1.3725438117980957 train acc 0.7368205184293996\n",
      "epoch 2 batch id 64101 / 225000 loss 0.013674371875822544 train acc 0.7367981778755401\n",
      "epoch 2 batch id 64201 / 225000 loss 3.0824968814849854 train acc 0.7367992710393919\n",
      "epoch 2 batch id 64301 / 225000 loss 0.9085350632667542 train acc 0.7367925848742632\n",
      "epoch 2 batch id 64401 / 225000 loss 1.3252218961715698 train acc 0.736828620673592\n",
      "epoch 2 batch id 64501 / 225000 loss 3.4040791988372803 train acc 0.7367676470132246\n",
      "epoch 2 batch id 64601 / 225000 loss 1.3362237215042114 train acc 0.7367416913050882\n",
      "epoch 2 batch id 64701 / 225000 loss 1.3657681941986084 train acc 0.7367003601180816\n",
      "epoch 2 batch id 64801 / 225000 loss 1.692623257637024 train acc 0.7366938781808923\n",
      "epoch 2 batch id 64901 / 225000 loss 0.008079318329691887 train acc 0.7366296359069968\n",
      "epoch 2 batch id 65001 / 225000 loss 0.8397853374481201 train acc 0.7365502069198936\n",
      "epoch 2 batch id 65101 / 225000 loss 2.3380329608917236 train acc 0.7365555060598148\n",
      "epoch 2 batch id 65201 / 225000 loss 2.0874218940734863 train acc 0.7365952976181347\n",
      "epoch 2 batch id 65301 / 225000 loss 1.9604772329330444 train acc 0.736531599822361\n",
      "epoch 2 batch id 65401 / 225000 loss 0.7367083430290222 train acc 0.7365445482484977\n",
      "epoch 2 batch id 65501 / 225000 loss 3.282205104827881 train acc 0.7365727240805484\n",
      "epoch 2 batch id 65601 / 225000 loss 3.183288097381592 train acc 0.7365093519915855\n",
      "epoch 2 batch id 65701 / 225000 loss 1.5398503541946411 train acc 0.7364690035159283\n",
      "epoch 2 batch id 65801 / 225000 loss 0.6096208691596985 train acc 0.7364173796750809\n",
      "epoch 2 batch id 65901 / 225000 loss 0.07712855190038681 train acc 0.7364228160422451\n",
      "epoch 2 batch id 66001 / 225000 loss 0.04572334513068199 train acc 0.736397933364646\n",
      "epoch 2 batch id 66101 / 225000 loss 3.183520793914795 train acc 0.7364298573395259\n",
      "epoch 2 batch id 66201 / 225000 loss 0.001971861580386758 train acc 0.7364918958928113\n",
      "epoch 2 batch id 66301 / 225000 loss 0.006276961416006088 train acc 0.7364971870710849\n",
      "epoch 2 batch id 66401 / 225000 loss 0.07347136735916138 train acc 0.7365212873300101\n",
      "epoch 2 batch id 66501 / 225000 loss 1.0296714305877686 train acc 0.7365490744500083\n",
      "epoch 2 batch id 66601 / 225000 loss 2.0976293087005615 train acc 0.7365617633368868\n",
      "epoch 2 batch id 66701 / 225000 loss 0.01028447411954403 train acc 0.7366043987346517\n",
      "epoch 2 batch id 66801 / 225000 loss 2.7886452674865723 train acc 0.7366057394350384\n",
      "epoch 2 batch id 66901 / 225000 loss 1.9639453887939453 train acc 0.7366332341818508\n",
      "epoch 2 batch id 67001 / 225000 loss 1.9470198154449463 train acc 0.7366233339800898\n",
      "epoch 2 batch id 67101 / 225000 loss 0.12214288860559464 train acc 0.7365911089253513\n",
      "epoch 2 batch id 67201 / 225000 loss 0.7910094857215881 train acc 0.7366445439800003\n",
      "epoch 2 batch id 67301 / 225000 loss 0.3407103419303894 train acc 0.7366458150696127\n",
      "epoch 2 batch id 67401 / 225000 loss 1.0560063123703003 train acc 0.7365914452307829\n",
      "epoch 2 batch id 67501 / 225000 loss 3.2157278060913086 train acc 0.7365261255388809\n",
      "epoch 2 batch id 67601 / 225000 loss 0.009274264797568321 train acc 0.7365164716498277\n",
      "epoch 2 batch id 67701 / 225000 loss 1.3677493333816528 train acc 0.7365474660640168\n",
      "epoch 2 batch id 67801 / 225000 loss 0.094597727060318 train acc 0.7365673072668545\n",
      "epoch 2 batch id 67901 / 225000 loss 0.003199064638465643 train acc 0.736564999042724\n",
      "epoch 2 batch id 68001 / 225000 loss 3.0644471645355225 train acc 0.7365259334421552\n",
      "epoch 2 batch id 68101 / 225000 loss 0.004584332928061485 train acc 0.7365824290392211\n",
      "epoch 2 batch id 68201 / 225000 loss 4.275522232055664 train acc 0.736569111889855\n",
      "epoch 2 batch id 68301 / 225000 loss 1.9374549388885498 train acc 0.7365887761526185\n",
      "epoch 2 batch id 68401 / 225000 loss 0.03546043857932091 train acc 0.7365791435797723\n",
      "epoch 2 batch id 68501 / 225000 loss 0.004622548818588257 train acc 0.736547641640268\n",
      "epoch 2 batch id 68601 / 225000 loss 0.005934447515755892 train acc 0.7365818282532325\n",
      "epoch 2 batch id 68701 / 225000 loss 0.7921200394630432 train acc 0.7365722478566542\n",
      "epoch 2 batch id 68801 / 225000 loss 0.08143967390060425 train acc 0.7366026656589294\n",
      "epoch 2 batch id 68901 / 225000 loss 1.364874243736267 train acc 0.7366257383782528\n",
      "epoch 2 batch id 69001 / 225000 loss 0.8160489797592163 train acc 0.736659613628788\n",
      "epoch 2 batch id 69101 / 225000 loss 0.1494223177433014 train acc 0.7366210329807094\n",
      "epoch 2 batch id 69201 / 225000 loss 2.2576682567596436 train acc 0.7366223031459083\n",
      "epoch 2 batch id 69301 / 225000 loss 0.002053586533293128 train acc 0.7366704665156347\n",
      "epoch 2 batch id 69401 / 225000 loss 0.001137502258643508 train acc 0.7367004798201755\n",
      "epoch 2 batch id 69501 / 225000 loss 1.6580296754837036 train acc 0.7367052272629171\n",
      "epoch 2 batch id 69601 / 225000 loss 0.2849234342575073 train acc 0.7367027772589474\n",
      "epoch 2 batch id 69701 / 225000 loss 0.12049203366041183 train acc 0.7367541355217285\n",
      "epoch 2 batch id 69801 / 225000 loss 1.3364261388778687 train acc 0.7367480408590135\n",
      "epoch 2 batch id 69901 / 225000 loss 1.0231595039367676 train acc 0.7367383871475373\n",
      "epoch 2 batch id 70001 / 225000 loss 0.015798261389136314 train acc 0.7367216182625963\n",
      "epoch 2 batch id 70101 / 225000 loss 1.4416275024414062 train acc 0.7367655240296144\n",
      "epoch 2 batch id 70201 / 225000 loss 3.5137171745300293 train acc 0.7368021823050954\n",
      "epoch 2 batch id 70301 / 225000 loss 0.7398189902305603 train acc 0.7368031749192757\n",
      "epoch 2 batch id 70401 / 225000 loss 2.667586326599121 train acc 0.7367970625417253\n",
      "epoch 2 batch id 70501 / 225000 loss 1.7944390773773193 train acc 0.736822881944937\n",
      "epoch 2 batch id 70601 / 225000 loss 1.9322017431259155 train acc 0.7368486282063993\n",
      "epoch 2 batch id 70701 / 225000 loss 3.345280408859253 train acc 0.736902589779494\n",
      "epoch 2 batch id 70801 / 225000 loss 2.1570372581481934 train acc 0.7369034335673225\n",
      "epoch 2 batch id 70901 / 225000 loss 1.6030992269515991 train acc 0.7369430614518836\n",
      "epoch 2 batch id 71001 / 225000 loss 0.004069031681865454 train acc 0.7369931409416769\n",
      "epoch 2 batch id 71101 / 225000 loss 0.06641717255115509 train acc 0.7370360473129773\n",
      "epoch 2 batch id 71201 / 225000 loss 5.040183067321777 train acc 0.7370999002822994\n",
      "epoch 2 batch id 71301 / 225000 loss 0.46726012229919434 train acc 0.7371390303081303\n",
      "epoch 2 batch id 71401 / 225000 loss 2.5464413166046143 train acc 0.7371325331577989\n",
      "epoch 2 batch id 71501 / 225000 loss 0.019389841705560684 train acc 0.7372134655459365\n",
      "epoch 2 batch id 71601 / 225000 loss 0.0025047052185982466 train acc 0.7372767140123742\n",
      "epoch 2 batch id 71701 / 225000 loss 3.58944034576416 train acc 0.737304919038786\n",
      "epoch 2 batch id 71801 / 225000 loss 1.5575180053710938 train acc 0.7373400091920725\n",
      "epoch 2 batch id 71901 / 225000 loss 1.6940104961395264 train acc 0.737385432747806\n",
      "epoch 2 batch id 72001 / 225000 loss 1.2748409509658813 train acc 0.7374515631727337\n",
      "epoch 2 batch id 72101 / 225000 loss 1.221064805984497 train acc 0.7373926852609534\n",
      "epoch 2 batch id 72201 / 225000 loss 0.6483542919158936 train acc 0.7374655475685933\n",
      "epoch 2 batch id 72301 / 225000 loss 1.6164560317993164 train acc 0.7375001728883418\n",
      "epoch 2 batch id 72401 / 225000 loss 0.6654840707778931 train acc 0.7375312495683761\n",
      "epoch 2 batch id 72501 / 225000 loss 2.2866103649139404 train acc 0.7375484476076192\n",
      "epoch 2 batch id 72601 / 225000 loss 0.026875363662838936 train acc 0.737496728695197\n",
      "epoch 2 batch id 72701 / 225000 loss 2.535288095474243 train acc 0.7374623457724103\n",
      "epoch 2 batch id 72801 / 225000 loss 1.3892261981964111 train acc 0.7375036057197016\n",
      "epoch 2 batch id 72901 / 225000 loss 1.0071804523468018 train acc 0.7375447524725313\n",
      "epoch 2 batch id 73001 / 225000 loss 0.8891212940216064 train acc 0.7375104450623964\n",
      "epoch 2 batch id 73101 / 225000 loss 1.7413727045059204 train acc 0.7375412101065649\n",
      "epoch 2 batch id 73201 / 225000 loss 0.42242681980133057 train acc 0.7375274927938142\n",
      "epoch 2 batch id 73301 / 225000 loss 0.5680698156356812 train acc 0.737564971828488\n",
      "epoch 2 batch id 73401 / 225000 loss 1.3185371160507202 train acc 0.7375614773640686\n",
      "epoch 2 batch id 73501 / 225000 loss 0.005120135378092527 train acc 0.7376192160650875\n",
      "epoch 2 batch id 73601 / 225000 loss 1.6110588312149048 train acc 0.7376122607029796\n",
      "epoch 2 batch id 73701 / 225000 loss 2.724125862121582 train acc 0.7375951479627142\n",
      "epoch 2 batch id 73801 / 225000 loss 1.0078538656234741 train acc 0.7375408192300917\n",
      "epoch 2 batch id 73901 / 225000 loss 0.3279251754283905 train acc 0.7375306152826078\n",
      "epoch 2 batch id 74001 / 225000 loss 3.4592678546905518 train acc 0.7375440872420643\n",
      "epoch 2 batch id 74101 / 225000 loss 2.085245370864868 train acc 0.7374900473677818\n",
      "epoch 2 batch id 74201 / 225000 loss 3.281198024749756 train acc 0.7374361531515747\n",
      "epoch 2 batch id 74301 / 225000 loss 1.2225288152694702 train acc 0.7374396037738389\n",
      "epoch 2 batch id 74401 / 225000 loss 2.115417242050171 train acc 0.7374060832515692\n",
      "epoch 2 batch id 74501 / 225000 loss 0.21344870328903198 train acc 0.7373894310143488\n",
      "epoch 2 batch id 74601 / 225000 loss 1.4299554824829102 train acc 0.7373795257436228\n",
      "epoch 2 batch id 74701 / 225000 loss 0.817146897315979 train acc 0.7373964203959786\n",
      "epoch 2 batch id 74801 / 225000 loss 0.9428128600120544 train acc 0.7374166120773786\n",
      "epoch 2 batch id 74901 / 225000 loss 1.448637843132019 train acc 0.7373966969733381\n",
      "epoch 2 batch id 75001 / 225000 loss 0.010697086341679096 train acc 0.7374035012866496\n",
      "epoch 2 batch id 75101 / 225000 loss 1.9950145483016968 train acc 0.7374835221901173\n",
      "epoch 2 batch id 75201 / 225000 loss 1.4542962312698364 train acc 0.7374635975585431\n",
      "epoch 2 batch id 75301 / 225000 loss 2.1564066410064697 train acc 0.7374404058379039\n",
      "epoch 2 batch id 75401 / 225000 loss 0.008929120376706123 train acc 0.7374471160859936\n",
      "epoch 2 batch id 75501 / 225000 loss 0.7104665040969849 train acc 0.737450497344406\n",
      "epoch 2 batch id 75601 / 225000 loss 4.460588455200195 train acc 0.7374704038306371\n",
      "epoch 2 batch id 75701 / 225000 loss 1.4507876634597778 train acc 0.7374242083988323\n",
      "epoch 2 batch id 75801 / 225000 loss 2.292117118835449 train acc 0.7374012216197675\n",
      "epoch 2 batch id 75901 / 225000 loss 2.6031112670898438 train acc 0.7374606395172659\n",
      "epoch 2 batch id 76001 / 225000 loss 1.1413110494613647 train acc 0.7374606913066933\n",
      "epoch 2 batch id 76101 / 225000 loss 2.1853902339935303 train acc 0.7374804536077055\n",
      "epoch 2 batch id 76201 / 225000 loss 0.2261657416820526 train acc 0.737447671290403\n",
      "epoch 2 batch id 76301 / 225000 loss 0.10971083492040634 train acc 0.7374542928664106\n",
      "epoch 2 batch id 76401 / 225000 loss 0.16688814759254456 train acc 0.7374674415256345\n",
      "epoch 2 batch id 76501 / 225000 loss 0.02424381859600544 train acc 0.7374968954654187\n",
      "epoch 2 batch id 76601 / 225000 loss 0.0060804737731814384 train acc 0.7375458544927612\n",
      "epoch 2 batch id 76701 / 225000 loss 0.984960675239563 train acc 0.7375360164795766\n",
      "epoch 2 batch id 76801 / 225000 loss 2.045616626739502 train acc 0.7375652660772646\n",
      "epoch 2 batch id 76901 / 225000 loss 3.4465627670288086 train acc 0.7375781849390776\n",
      "epoch 2 batch id 77001 / 225000 loss 2.943946361541748 train acc 0.7375910702458409\n",
      "epoch 2 batch id 77101 / 225000 loss 0.0075304387137293816 train acc 0.7376136496284095\n",
      "epoch 2 batch id 77201 / 225000 loss 2.4915764331817627 train acc 0.7376458854159921\n",
      "epoch 2 batch id 77301 / 225000 loss 0.001115833641961217 train acc 0.7376877401327279\n",
      "epoch 2 batch id 77401 / 225000 loss 1.7145334482192993 train acc 0.7377424064288575\n",
      "epoch 2 batch id 77501 / 225000 loss 1.0040605068206787 train acc 0.7377517709448911\n",
      "epoch 2 batch id 77601 / 225000 loss 2.9342877864837646 train acc 0.7377707761497919\n",
      "epoch 2 batch id 77701 / 225000 loss 2.68160080909729 train acc 0.737789732435876\n",
      "epoch 2 batch id 77801 / 225000 loss 1.0886114835739136 train acc 0.7378214932970013\n",
      "epoch 2 batch id 77901 / 225000 loss 0.16715306043624878 train acc 0.7378788462279047\n",
      "epoch 2 batch id 78001 / 225000 loss 3.7496705055236816 train acc 0.737875155446725\n",
      "epoch 2 batch id 78101 / 225000 loss 1.0568925142288208 train acc 0.7379386947670324\n",
      "epoch 2 batch id 78201 / 225000 loss 0.004364568740129471 train acc 0.7379477244536515\n",
      "epoch 2 batch id 78301 / 225000 loss 0.0024320012889802456 train acc 0.7379375742327684\n",
      "epoch 2 batch id 78401 / 225000 loss 0.06975971907377243 train acc 0.7379274499049757\n",
      "epoch 2 batch id 78501 / 225000 loss 0.004295456223189831 train acc 0.737930090062547\n",
      "epoch 2 batch id 78601 / 225000 loss 2.278740882873535 train acc 0.7378977366700169\n",
      "epoch 2 batch id 78701 / 225000 loss 2.7501606941223145 train acc 0.7378654654959912\n",
      "epoch 2 batch id 78801 / 225000 loss 2.089771270751953 train acc 0.7378618291646045\n",
      "epoch 2 batch id 78901 / 225000 loss 2.5605525970458984 train acc 0.7378391908847797\n",
      "epoch 2 batch id 79001 / 225000 loss 1.2309143543243408 train acc 0.7378799002544272\n",
      "epoch 2 batch id 79101 / 225000 loss 1.2784032821655273 train acc 0.7378762594657463\n",
      "epoch 2 batch id 79201 / 225000 loss 0.002097899094223976 train acc 0.737856845241853\n",
      "epoch 2 batch id 79301 / 225000 loss 2.3578648567199707 train acc 0.7378311748906067\n",
      "epoch 2 batch id 79401 / 225000 loss 0.24858307838439941 train acc 0.7378370549489301\n",
      "epoch 2 batch id 79501 / 225000 loss 2.7997848987579346 train acc 0.7378020402259091\n",
      "epoch 2 batch id 79601 / 225000 loss 1.705179214477539 train acc 0.7378676147284582\n",
      "epoch 2 batch id 79701 / 225000 loss 0.21653077006340027 train acc 0.7379110676152119\n",
      "epoch 2 batch id 79801 / 225000 loss 2.748720645904541 train acc 0.7379199508778086\n",
      "epoch 2 batch id 79901 / 225000 loss 0.022927407175302505 train acc 0.7378756210810878\n",
      "epoch 2 batch id 80001 / 225000 loss 0.9915031790733337 train acc 0.7379157760527993\n",
      "epoch 2 batch id 80101 / 225000 loss 0.8415363430976868 train acc 0.7379558307636609\n",
      "epoch 2 batch id 80201 / 225000 loss 2.435825824737549 train acc 0.7379770825800177\n",
      "epoch 2 batch id 80301 / 225000 loss 1.3238321542739868 train acc 0.7380138478972864\n",
      "epoch 2 batch id 80401 / 225000 loss 2.1043686866760254 train acc 0.7380038805487494\n",
      "epoch 2 batch id 80501 / 225000 loss 0.0019294845405966043 train acc 0.7380218879268581\n",
      "epoch 2 batch id 80601 / 225000 loss 3.24904727935791 train acc 0.7380398506222007\n",
      "epoch 2 batch id 80701 / 225000 loss 4.2444868087768555 train acc 0.7380051052651144\n",
      "epoch 2 batch id 80801 / 225000 loss 2.7120611667633057 train acc 0.7380013861214589\n",
      "epoch 2 batch id 80901 / 225000 loss 1.8218508958816528 train acc 0.7380532997119936\n",
      "epoch 2 batch id 81001 / 225000 loss 0.3524460196495056 train acc 0.7380711349242602\n",
      "epoch 2 batch id 81101 / 225000 loss 1.7086125612258911 train acc 0.7380581003933367\n",
      "epoch 2 batch id 81201 / 225000 loss 1.7078678607940674 train acc 0.7380604918658638\n",
      "epoch 2 batch id 81301 / 225000 loss 0.3842407166957855 train acc 0.738093627384657\n",
      "epoch 2 batch id 81401 / 225000 loss 2.6685068607330322 train acc 0.7380898269063033\n",
      "epoch 2 batch id 81501 / 225000 loss 1.7619785070419312 train acc 0.7380584287309359\n",
      "epoch 2 batch id 81601 / 225000 loss 0.013907577842473984 train acc 0.7380945086457273\n",
      "epoch 2 batch id 81701 / 225000 loss 0.8253721594810486 train acc 0.738133560176742\n",
      "epoch 2 batch id 81801 / 225000 loss 1.6861917972564697 train acc 0.7381572352416229\n",
      "epoch 2 batch id 81901 / 225000 loss 1.7245686054229736 train acc 0.7381594852321706\n",
      "epoch 2 batch id 82001 / 225000 loss 1.7729017734527588 train acc 0.7381739247082353\n",
      "epoch 2 batch id 82101 / 225000 loss 0.20353135466575623 train acc 0.7381761488897821\n",
      "epoch 2 batch id 82201 / 225000 loss 2.301321029663086 train acc 0.7382026982640114\n",
      "epoch 2 batch id 82301 / 225000 loss 0.0960850641131401 train acc 0.7382139949696844\n",
      "epoch 2 batch id 82401 / 225000 loss 2.597226619720459 train acc 0.7382525697503671\n",
      "epoch 2 batch id 82501 / 225000 loss 3.4813010692596436 train acc 0.7382334759578671\n",
      "epoch 2 batch id 82601 / 225000 loss 1.0157830715179443 train acc 0.7381781092238593\n",
      "epoch 2 batch id 82701 / 225000 loss 1.4280600547790527 train acc 0.7381651975187724\n",
      "epoch 2 batch id 82801 / 225000 loss 2.08918833732605 train acc 0.7381432591393824\n",
      "epoch 2 batch id 82901 / 225000 loss 0.46711090207099915 train acc 0.7381304206221879\n",
      "epoch 2 batch id 83001 / 225000 loss 1.2290489673614502 train acc 0.7381236370646137\n",
      "epoch 2 batch id 83101 / 225000 loss 3.524550676345825 train acc 0.7381018278961745\n",
      "epoch 2 batch id 83201 / 225000 loss 2.341689109802246 train acc 0.7381221379550726\n",
      "epoch 2 batch id 83301 / 225000 loss 0.4137263000011444 train acc 0.7381754120598792\n",
      "epoch 2 batch id 83401 / 225000 loss 3.3939387798309326 train acc 0.7381716046570185\n",
      "epoch 2 batch id 83501 / 225000 loss 0.00219913967885077 train acc 0.738143854564616\n",
      "epoch 2 batch id 83601 / 225000 loss 1.016029953956604 train acc 0.738152055597421\n",
      "epoch 2 batch id 83701 / 225000 loss 1.3903348445892334 train acc 0.7381512765677829\n",
      "epoch 2 batch id 83801 / 225000 loss 1.2778728008270264 train acc 0.7381982315246834\n",
      "epoch 2 batch id 83901 / 225000 loss 0.011321655474603176 train acc 0.7382182572317374\n",
      "epoch 2 batch id 84001 / 225000 loss 2.7737021446228027 train acc 0.738226330638921\n",
      "epoch 2 batch id 84101 / 225000 loss 0.9491477608680725 train acc 0.7381630420565748\n",
      "epoch 2 batch id 84201 / 225000 loss 1.3114569187164307 train acc 0.7381652236909301\n",
      "epoch 2 batch id 84301 / 225000 loss 1.690994143486023 train acc 0.7381703657133367\n",
      "epoch 2 batch id 84401 / 225000 loss 0.7107929587364197 train acc 0.7381577232497245\n",
      "epoch 2 batch id 84501 / 225000 loss 2.5092570781707764 train acc 0.7381924474266577\n",
      "epoch 2 batch id 84601 / 225000 loss 0.1080600917339325 train acc 0.7382270895143084\n",
      "epoch 2 batch id 84701 / 225000 loss 0.004725519567728043 train acc 0.73827345603948\n",
      "epoch 2 batch id 84801 / 225000 loss 0.9954040050506592 train acc 0.7382489593283098\n",
      "epoch 2 batch id 84901 / 225000 loss 2.2293307781219482 train acc 0.7382362987479535\n",
      "epoch 2 batch id 85001 / 225000 loss 0.8679963946342468 train acc 0.7382677850848813\n",
      "epoch 2 batch id 85101 / 225000 loss 2.877385377883911 train acc 0.7382727582519595\n",
      "epoch 2 batch id 85201 / 225000 loss 0.0033640172332525253 train acc 0.7383158648372672\n",
      "epoch 2 batch id 85301 / 225000 loss 2.092301368713379 train acc 0.7383471471612291\n",
      "epoch 2 batch id 85401 / 225000 loss 1.6920663118362427 train acc 0.7383695741267666\n",
      "epoch 2 batch id 85501 / 225000 loss 2.1412417888641357 train acc 0.7383773289201296\n",
      "epoch 2 batch id 85601 / 225000 loss 0.41458389163017273 train acc 0.7383821450683987\n",
      "epoch 2 batch id 85701 / 225000 loss 2.504593849182129 train acc 0.7384132040466272\n",
      "epoch 2 batch id 85801 / 225000 loss 1.5946907997131348 train acc 0.7384150534376056\n",
      "epoch 2 batch id 85901 / 225000 loss 0.94240802526474 train acc 0.7384285398307354\n",
      "epoch 2 batch id 86001 / 225000 loss 1.4292911291122437 train acc 0.7383809490587319\n",
      "epoch 2 batch id 86101 / 225000 loss 0.020717719569802284 train acc 0.7384176722686148\n",
      "epoch 2 batch id 86201 / 225000 loss 5.754241466522217 train acc 0.7384601106715699\n",
      "epoch 2 batch id 86301 / 225000 loss 1.3903727531433105 train acc 0.7385372127785309\n",
      "epoch 2 batch id 86401 / 225000 loss 0.003654473926872015 train acc 0.7385620536799342\n",
      "epoch 2 batch id 86501 / 225000 loss 2.2590978145599365 train acc 0.7385897272863897\n",
      "epoch 2 batch id 86601 / 225000 loss 2.4041635990142822 train acc 0.7385942425607095\n",
      "epoch 2 batch id 86701 / 225000 loss 0.006296867970377207 train acc 0.7386073978385486\n",
      "epoch 2 batch id 86801 / 225000 loss 2.2217769622802734 train acc 0.7385773205377818\n",
      "epoch 2 batch id 86901 / 225000 loss 1.0536757707595825 train acc 0.7385933418487705\n",
      "epoch 2 batch id 87001 / 225000 loss 3.1239254474639893 train acc 0.7386035792692038\n",
      "epoch 2 batch id 87101 / 225000 loss 2.17431378364563 train acc 0.73859370156485\n",
      "epoch 2 batch id 87201 / 225000 loss 0.8443040251731873 train acc 0.7385351085423333\n",
      "epoch 2 batch id 87301 / 225000 loss 1.6436223983764648 train acc 0.7385110136195462\n",
      "epoch 2 batch id 87401 / 225000 loss 0.007215516641736031 train acc 0.7385556229333761\n",
      "epoch 2 batch id 87501 / 225000 loss 0.03870689123868942 train acc 0.7385372738597273\n",
      "epoch 2 batch id 87601 / 225000 loss 2.1138505935668945 train acc 0.7385161128297623\n",
      "epoch 2 batch id 87701 / 225000 loss 1.7798595428466797 train acc 0.7385149542194501\n",
      "epoch 2 batch id 87801 / 225000 loss 4.993347644805908 train acc 0.7384796300725505\n",
      "epoch 2 batch id 87901 / 225000 loss 1.1088496446609497 train acc 0.7384955802550597\n",
      "epoch 2 batch id 88001 / 225000 loss 1.3662660121917725 train acc 0.7384802445426757\n",
      "epoch 2 batch id 88101 / 225000 loss 0.009662323631346226 train acc 0.7384649436442265\n",
      "epoch 2 batch id 88201 / 225000 loss 0.016651412472128868 train acc 0.7384099953515266\n",
      "epoch 2 batch id 88301 / 225000 loss 1.4470542669296265 train acc 0.738397639890828\n",
      "epoch 2 batch id 88401 / 225000 loss 0.014588026329874992 train acc 0.7383768283164217\n",
      "epoch 2 batch id 88501 / 225000 loss 2.9414916038513184 train acc 0.7383899616953481\n",
      "epoch 2 batch id 88601 / 225000 loss 0.0033589708618819714 train acc 0.7383833139580818\n",
      "epoch 2 batch id 88701 / 225000 loss 3.0136332511901855 train acc 0.7383964104125095\n",
      "epoch 2 batch id 88801 / 225000 loss 1.458377480506897 train acc 0.738403846803527\n",
      "epoch 2 batch id 88901 / 225000 loss 3.2509469985961914 train acc 0.7384028301143969\n",
      "epoch 2 batch id 89001 / 225000 loss 2.803375482559204 train acc 0.7383681082235031\n",
      "epoch 2 batch id 89101 / 225000 loss 1.2266120910644531 train acc 0.7383699397313161\n",
      "epoch 2 batch id 89201 / 225000 loss 0.0024046641774475574 train acc 0.7383857804284706\n",
      "epoch 2 batch id 89301 / 225000 loss 0.05853387340903282 train acc 0.7383959866070928\n",
      "epoch 2 batch id 89401 / 225000 loss 1.4946458339691162 train acc 0.7384173555105648\n",
      "epoch 2 batch id 89501 / 225000 loss 1.172322154045105 train acc 0.7384163305437929\n",
      "epoch 2 batch id 89601 / 225000 loss 1.1134581565856934 train acc 0.7384432093391815\n",
      "epoch 2 batch id 89701 / 225000 loss 0.2351451814174652 train acc 0.7383864170967994\n",
      "epoch 2 batch id 89801 / 225000 loss 1.2929348945617676 train acc 0.7384104854066214\n",
      "epoch 2 batch id 89901 / 225000 loss 3.6886324882507324 train acc 0.7384317193357137\n",
      "epoch 2 batch id 90001 / 225000 loss 0.010547801852226257 train acc 0.738464017066477\n",
      "epoch 2 batch id 90101 / 225000 loss 0.8498679399490356 train acc 0.7384768204570427\n",
      "epoch 2 batch id 90201 / 225000 loss 0.010043422691524029 train acc 0.7384951386348266\n",
      "epoch 2 batch id 90301 / 225000 loss 1.975164771080017 train acc 0.7385715551322798\n",
      "epoch 2 batch id 90401 / 225000 loss 1.2473182678222656 train acc 0.7385841970774659\n",
      "epoch 2 batch id 90501 / 225000 loss 2.420077085494995 train acc 0.7386216726886996\n",
      "epoch 2 batch id 90601 / 225000 loss 0.8956263661384583 train acc 0.738612156598713\n",
      "epoch 2 batch id 90701 / 225000 loss 0.7133664488792419 train acc 0.7386164430381142\n",
      "epoch 2 batch id 90801 / 225000 loss 0.9259552359580994 train acc 0.7386427462252618\n",
      "epoch 2 batch id 90901 / 225000 loss 2.7736716270446777 train acc 0.7386552403163882\n",
      "epoch 2 batch id 91001 / 225000 loss 0.6764675974845886 train acc 0.7386237513873474\n",
      "epoch 2 batch id 91101 / 225000 loss 0.4172285199165344 train acc 0.7386362388996828\n",
      "epoch 2 batch id 91201 / 225000 loss 0.10339052975177765 train acc 0.7386377342353703\n",
      "epoch 2 batch id 91301 / 225000 loss 1.5885090827941895 train acc 0.7386529172736334\n",
      "epoch 2 batch id 91401 / 225000 loss 2.0027737617492676 train acc 0.738591481493638\n",
      "epoch 2 batch id 91501 / 225000 loss 1.1947731971740723 train acc 0.7385547698932252\n",
      "epoch 2 batch id 91601 / 225000 loss 2.3324384689331055 train acc 0.7385317845875045\n",
      "epoch 2 batch id 91701 / 225000 loss 1.716712236404419 train acc 0.7385388381806087\n",
      "epoch 2 batch id 91801 / 225000 loss 0.25776663422584534 train acc 0.7386057886079672\n",
      "epoch 2 batch id 91901 / 225000 loss 0.8804880976676941 train acc 0.7386453901480942\n",
      "epoch 2 batch id 92001 / 225000 loss 0.7641742825508118 train acc 0.7386468625341029\n",
      "epoch 2 batch id 92101 / 225000 loss 1.9596407413482666 train acc 0.7386429029000771\n",
      "epoch 2 batch id 92201 / 225000 loss 0.015186162665486336 train acc 0.7386958926692769\n",
      "epoch 2 batch id 92301 / 225000 loss 0.0018134090350940824 train acc 0.7387027226140562\n",
      "epoch 2 batch id 92401 / 225000 loss 1.9661585092544556 train acc 0.7386716593976256\n",
      "epoch 2 batch id 92501 / 225000 loss 0.21550717949867249 train acc 0.7387055275078107\n",
      "epoch 2 batch id 92601 / 225000 loss 0.014209296554327011 train acc 0.7386826276174123\n",
      "epoch 2 batch id 92701 / 225000 loss 0.8657743334770203 train acc 0.7386948360859106\n",
      "epoch 2 batch id 92801 / 225000 loss 2.2096714973449707 train acc 0.7386693031325093\n",
      "epoch 2 batch id 92901 / 225000 loss 1.8828099966049194 train acc 0.7386518982572846\n",
      "epoch 2 batch id 93001 / 225000 loss 1.57168447971344 train acc 0.7386184019526671\n",
      "epoch 2 batch id 93101 / 225000 loss 0.0031777876429259777 train acc 0.7386172006745363\n",
      "epoch 2 batch id 93201 / 225000 loss 0.15495163202285767 train acc 0.738642825720754\n",
      "epoch 2 batch id 93301 / 225000 loss 1.0575506687164307 train acc 0.738687152334916\n",
      "epoch 2 batch id 93401 / 225000 loss 4.250642776489258 train acc 0.7386939112000942\n",
      "epoch 2 batch id 93501 / 225000 loss 0.007656493224203587 train acc 0.7386498540122566\n",
      "epoch 2 batch id 93601 / 225000 loss 1.8809733390808105 train acc 0.738656638283779\n",
      "epoch 2 batch id 93701 / 225000 loss 1.1936625242233276 train acc 0.7386740803193136\n",
      "epoch 2 batch id 93801 / 225000 loss 2.5173845291137695 train acc 0.7386568373471498\n",
      "epoch 2 batch id 93901 / 225000 loss 0.004902196116745472 train acc 0.7386875539131639\n",
      "epoch 2 batch id 94001 / 225000 loss 0.026308171451091766 train acc 0.7386862905713769\n",
      "epoch 2 batch id 94101 / 225000 loss 1.4223791360855103 train acc 0.7386903433544808\n",
      "epoch 2 batch id 94201 / 225000 loss 0.22462724149227142 train acc 0.7387156187301621\n",
      "epoch 2 batch id 94301 / 225000 loss 1.7727292776107788 train acc 0.7387143296465573\n",
      "epoch 2 batch id 94401 / 225000 loss 0.4214564859867096 train acc 0.7387448226184045\n",
      "epoch 2 batch id 94501 / 225000 loss 0.007843531668186188 train acc 0.7387567327329869\n",
      "epoch 2 batch id 94601 / 225000 loss 1.1860272884368896 train acc 0.7387554042769104\n",
      "epoch 2 batch id 94701 / 225000 loss 0.0025280099362134933 train acc 0.7387857572781702\n",
      "epoch 2 batch id 94801 / 225000 loss 0.009504439309239388 train acc 0.738852965686016\n",
      "epoch 2 batch id 94901 / 225000 loss 0.03983614966273308 train acc 0.738875248943636\n",
      "epoch 2 batch id 95001 / 225000 loss 1.1062549352645874 train acc 0.7388711697771603\n",
      "epoch 2 batch id 95101 / 225000 loss 0.0029851740691810846 train acc 0.7388408113479353\n",
      "epoch 2 batch id 95201 / 225000 loss 1.0703409910202026 train acc 0.738842028970284\n",
      "epoch 2 batch id 95301 / 225000 loss 0.6825758814811707 train acc 0.7388511138393091\n",
      "epoch 2 batch id 95401 / 225000 loss 0.022040780633687973 train acc 0.738831353969036\n",
      "epoch 2 batch id 95501 / 225000 loss 0.070389524102211 train acc 0.7388299598957079\n",
      "epoch 2 batch id 95601 / 225000 loss 0.6194145083427429 train acc 0.738820723632598\n",
      "epoch 2 batch id 95701 / 225000 loss 1.9304858446121216 train acc 0.7388193435805268\n",
      "epoch 2 batch id 95801 / 225000 loss 2.0927932262420654 train acc 0.7388127472573355\n",
      "epoch 2 batch id 95901 / 225000 loss 2.4217400550842285 train acc 0.7388244126755716\n",
      "epoch 2 batch id 96001 / 225000 loss 1.6257712841033936 train acc 0.7388308455120259\n",
      "epoch 2 batch id 96101 / 225000 loss 1.0522950887680054 train acc 0.7388450692500599\n",
      "epoch 2 batch id 96201 / 225000 loss 1.1621932983398438 train acc 0.7388696583195601\n",
      "epoch 2 batch id 96301 / 225000 loss 0.8696269989013672 train acc 0.7388656400245065\n",
      "epoch 2 batch id 96401 / 225000 loss 3.00508189201355 train acc 0.7388279167228555\n",
      "epoch 2 batch id 96501 / 225000 loss 0.5012909173965454 train acc 0.7388317219510678\n",
      "epoch 2 batch id 96601 / 225000 loss 0.004728573374450207 train acc 0.7388536350555377\n",
      "epoch 2 batch id 96701 / 225000 loss 3.7091071605682373 train acc 0.7388599911066069\n",
      "epoch 2 batch id 96801 / 225000 loss 0.002200789051130414 train acc 0.7388534209357341\n",
      "epoch 2 batch id 96901 / 225000 loss 1.8419748544692993 train acc 0.7388855636164745\n",
      "epoch 2 batch id 97001 / 225000 loss 0.8784912824630737 train acc 0.7388918670941537\n",
      "epoch 2 batch id 97101 / 225000 loss 0.007331149652600288 train acc 0.738908456143603\n",
      "epoch 2 batch id 97201 / 225000 loss 0.005637737922370434 train acc 0.7388941471795558\n",
      "epoch 2 batch id 97301 / 225000 loss 1.2467784881591797 train acc 0.7389081304405916\n",
      "epoch 2 batch id 97401 / 225000 loss 1.671034812927246 train acc 0.7389195182800998\n",
      "epoch 2 batch id 97501 / 225000 loss 0.003022839082404971 train acc 0.7389642157516333\n",
      "epoch 2 batch id 97601 / 225000 loss 1.5613763332366943 train acc 0.7389422239526234\n",
      "epoch 2 batch id 97701 / 225000 loss 0.07128279656171799 train acc 0.7389740125484898\n",
      "epoch 2 batch id 97801 / 225000 loss 1.5423274040222168 train acc 0.7389955112933405\n",
      "epoch 2 batch id 97901 / 225000 loss 0.0028420365415513515 train acc 0.7390399485194227\n",
      "epoch 2 batch id 98001 / 225000 loss 0.002415745286270976 train acc 0.73905623412006\n",
      "epoch 2 batch id 98101 / 225000 loss 2.5542330741882324 train acc 0.7390903252770105\n",
      "epoch 2 batch id 98201 / 225000 loss 0.4124703109264374 train acc 0.7390836142198145\n",
      "epoch 2 batch id 98301 / 225000 loss 0.005600611213594675 train acc 0.739094719280577\n",
      "epoch 2 batch id 98401 / 225000 loss 0.783812403678894 train acc 0.7391439111391145\n",
      "epoch 2 batch id 98501 / 225000 loss 0.047556258738040924 train acc 0.7391853889808225\n",
      "epoch 2 batch id 98601 / 225000 loss 0.9715234637260437 train acc 0.7391988925061612\n",
      "epoch 2 batch id 98701 / 225000 loss 0.5528988838195801 train acc 0.7391870396449884\n",
      "epoch 2 batch id 98801 / 225000 loss 2.251479148864746 train acc 0.7392106355198834\n",
      "epoch 2 batch id 98901 / 225000 loss 1.726402759552002 train acc 0.7392089058755725\n",
      "epoch 2 batch id 99001 / 225000 loss 4.689298629760742 train acc 0.7392071797254574\n",
      "epoch 2 batch id 99101 / 225000 loss 2.0302212238311768 train acc 0.7391903209856611\n",
      "epoch 2 batch id 99201 / 225000 loss 0.8673765659332275 train acc 0.7391558552837169\n",
      "epoch 2 batch id 99301 / 225000 loss 0.02192540280520916 train acc 0.7391390821844694\n",
      "epoch 2 batch id 99401 / 225000 loss 0.7001434564590454 train acc 0.7391550386817034\n",
      "epoch 2 batch id 99501 / 225000 loss 2.87438702583313 train acc 0.7391458377302741\n",
      "epoch 2 batch id 99601 / 225000 loss 0.022911760956048965 train acc 0.7391994056284575\n",
      "epoch 2 batch id 99701 / 225000 loss 0.346993625164032 train acc 0.7391851636392814\n",
      "epoch 2 batch id 99801 / 225000 loss 0.8772207498550415 train acc 0.7392010100099198\n",
      "epoch 2 batch id 99901 / 225000 loss 0.26185211539268494 train acc 0.7392343419985786\n",
      "epoch 2 batch id 100001 / 225000 loss 0.05237351730465889 train acc 0.7392851071489285\n",
      "epoch 2 batch id 100101 / 225000 loss 1.663602352142334 train acc 0.7392933137531094\n",
      "epoch 2 batch id 100201 / 225000 loss 0.5865507125854492 train acc 0.7392940190217663\n",
      "epoch 2 batch id 100301 / 225000 loss 0.11785155534744263 train acc 0.7393171553623593\n",
      "epoch 2 batch id 100401 / 225000 loss 1.2908987998962402 train acc 0.7393327755699645\n",
      "epoch 2 batch id 100501 / 225000 loss 0.011022446677088737 train acc 0.7393409020805763\n",
      "epoch 2 batch id 100601 / 225000 loss 0.019575338810682297 train acc 0.7393092513990914\n",
      "epoch 2 batch id 100701 / 225000 loss 2.2876369953155518 train acc 0.7392875939662963\n",
      "epoch 2 batch id 100801 / 225000 loss 0.0028787567280232906 train acc 0.7393007013819307\n",
      "epoch 2 batch id 100901 / 225000 loss 1.9956562519073486 train acc 0.7393113051406824\n",
      "epoch 2 batch id 101001 / 225000 loss 0.8853468298912048 train acc 0.7393194126790824\n",
      "epoch 2 batch id 101101 / 225000 loss 2.1941442489624023 train acc 0.7393126675304893\n",
      "epoch 2 batch id 101201 / 225000 loss 1.0494505167007446 train acc 0.739315817037381\n",
      "epoch 2 batch id 101301 / 225000 loss 1.6972012519836426 train acc 0.7392992171844306\n",
      "epoch 2 batch id 101401 / 225000 loss 0.13172347843647003 train acc 0.7393122355795307\n",
      "epoch 2 batch id 101501 / 225000 loss 0.004034863319247961 train acc 0.739381878011054\n",
      "epoch 2 batch id 101601 / 225000 loss 0.9918752908706665 train acc 0.7393947894213639\n",
      "epoch 2 batch id 101701 / 225000 loss 4.433379173278809 train acc 0.739402759068249\n",
      "epoch 2 batch id 101801 / 225000 loss 0.0063778990879654884 train acc 0.739462284260469\n",
      "epoch 2 batch id 101901 / 225000 loss 3.343367338180542 train acc 0.7394824388376954\n",
      "epoch 2 batch id 102001 / 225000 loss 0.11690689623355865 train acc 0.7394412799874511\n",
      "epoch 2 batch id 102101 / 225000 loss 3.35726261138916 train acc 0.7393855104259508\n",
      "epoch 2 batch id 102201 / 225000 loss 2.938617467880249 train acc 0.7393445269615757\n",
      "epoch 2 batch id 102301 / 225000 loss 0.8151140809059143 train acc 0.7393622740735672\n",
      "epoch 2 batch id 102401 / 225000 loss 2.180764675140381 train acc 0.7393287174929932\n",
      "epoch 2 batch id 102501 / 225000 loss 1.6262470483779907 train acc 0.7392318123725622\n",
      "epoch 2 batch id 102601 / 225000 loss 2.9554073810577393 train acc 0.7391131665383378\n",
      "epoch 2 batch id 102701 / 225000 loss 0.37746864557266235 train acc 0.7389436324865386\n",
      "epoch 2 batch id 102801 / 225000 loss 1.5584981441497803 train acc 0.738908181827025\n",
      "epoch 2 batch id 102901 / 225000 loss 2.5602853298187256 train acc 0.738884947668147\n",
      "epoch 2 batch id 103001 / 225000 loss 0.21081861853599548 train acc 0.7388860302327162\n",
      "epoch 2 batch id 103101 / 225000 loss 1.059281587600708 train acc 0.7388919603107632\n",
      "epoch 2 batch id 103201 / 225000 loss 0.7435721755027771 train acc 0.7388034030677997\n",
      "epoch 2 batch id 103301 / 225000 loss 5.774785041809082 train acc 0.7387658396336918\n",
      "epoch 2 batch id 103401 / 225000 loss 2.394496202468872 train acc 0.7387573621144863\n",
      "epoch 2 batch id 103501 / 225000 loss 1.4725658893585205 train acc 0.7387368237988039\n",
      "epoch 2 batch id 103601 / 225000 loss 1.2442830801010132 train acc 0.7386849547784288\n",
      "epoch 2 batch id 103701 / 225000 loss 1.060787320137024 train acc 0.7386331857937725\n",
      "epoch 2 batch id 103801 / 225000 loss 5.102302551269531 train acc 0.7385983757381913\n",
      "epoch 2 batch id 103901 / 225000 loss 0.0016058343462646008 train acc 0.738570851098642\n",
      "epoch 2 batch id 104001 / 225000 loss 1.77189040184021 train acc 0.7384808799915386\n",
      "epoch 2 batch id 104101 / 225000 loss 1.5463935136795044 train acc 0.7384463165579581\n",
      "epoch 2 batch id 104201 / 225000 loss 1.0699864625930786 train acc 0.7384430091841729\n",
      "epoch 2 batch id 104301 / 225000 loss 2.194958448410034 train acc 0.7384133421539583\n",
      "epoch 2 batch id 104401 / 225000 loss 2.583073616027832 train acc 0.7383741535042768\n",
      "epoch 2 batch id 104501 / 225000 loss 1.288724660873413 train acc 0.7383804939665649\n",
      "epoch 2 batch id 104601 / 225000 loss 0.8506036996841431 train acc 0.7384155027198592\n",
      "epoch 2 batch id 104701 / 225000 loss 3.5985074043273926 train acc 0.738405077315403\n",
      "epoch 2 batch id 104801 / 225000 loss 0.005152503494173288 train acc 0.7383946718065667\n",
      "epoch 2 batch id 104901 / 225000 loss 2.5669867992401123 train acc 0.738431950124403\n",
      "epoch 2 batch id 105001 / 225000 loss 0.9418112635612488 train acc 0.7384524909286578\n",
      "epoch 2 batch id 105101 / 225000 loss 1.620481014251709 train acc 0.7384254193585218\n",
      "epoch 2 batch id 105201 / 225000 loss 0.04809538275003433 train acc 0.7384601857396793\n",
      "epoch 2 batch id 105301 / 225000 loss 0.007877315394580364 train acc 0.7384592738910362\n",
      "epoch 2 batch id 105401 / 225000 loss 3.117063283920288 train acc 0.7384607356666445\n",
      "epoch 2 batch id 105501 / 225000 loss 0.02523120678961277 train acc 0.7384882607747794\n",
      "epoch 2 batch id 105601 / 225000 loss 1.6235435009002686 train acc 0.738489692332459\n",
      "epoch 2 batch id 105701 / 225000 loss 0.32759159803390503 train acc 0.7385147728025279\n",
      "epoch 2 batch id 105801 / 225000 loss 0.03971845284104347 train acc 0.738513813669058\n",
      "epoch 2 batch id 105901 / 225000 loss 1.6311278343200684 train acc 0.7385836772079584\n",
      "epoch 2 batch id 106001 / 225000 loss 0.12794992327690125 train acc 0.7385920887538797\n",
      "epoch 2 batch id 106101 / 225000 loss 1.2611830234527588 train acc 0.7386146219168528\n",
      "epoch 2 batch id 106201 / 225000 loss 2.034553050994873 train acc 0.7386182804305044\n",
      "epoch 2 batch id 106301 / 225000 loss 1.1381093263626099 train acc 0.7386360429346854\n",
      "epoch 2 batch id 106401 / 225000 loss 3.7407963275909424 train acc 0.73863967443915\n",
      "epoch 2 batch id 106501 / 225000 loss 1.4101765155792236 train acc 0.7386550361029474\n",
      "epoch 2 batch id 106601 / 225000 loss 0.7514883875846863 train acc 0.7386938208834813\n",
      "epoch 2 batch id 106701 / 225000 loss 0.009490810334682465 train acc 0.7387301899701034\n",
      "epoch 2 batch id 106801 / 225000 loss 0.003562039230018854 train acc 0.7387781949607214\n",
      "epoch 2 batch id 106901 / 225000 loss 0.006305302493274212 train acc 0.7388261101392878\n",
      "epoch 2 batch id 107001 / 225000 loss 2.874876022338867 train acc 0.7388435622096989\n",
      "epoch 2 batch id 107101 / 225000 loss 2.5727274417877197 train acc 0.7388679844259157\n",
      "epoch 2 batch id 107201 / 225000 loss 0.03537515550851822 train acc 0.7388643762651468\n",
      "epoch 2 batch id 107301 / 225000 loss 1.4837806224822998 train acc 0.7388840737737765\n",
      "epoch 2 batch id 107401 / 225000 loss 0.2507489025592804 train acc 0.7388944237018278\n",
      "epoch 2 batch id 107501 / 225000 loss 2.0745553970336914 train acc 0.7389001032548534\n",
      "epoch 2 batch id 107601 / 225000 loss 2.714003801345825 train acc 0.738898802055743\n",
      "epoch 2 batch id 107701 / 225000 loss 0.3594719171524048 train acc 0.7388626846547386\n",
      "epoch 2 batch id 107801 / 225000 loss 1.4965983629226685 train acc 0.7388637396684632\n",
      "epoch 2 batch id 107901 / 225000 loss 1.6183677911758423 train acc 0.7388671096653414\n",
      "epoch 2 batch id 108001 / 225000 loss 0.8941572904586792 train acc 0.7388681586281608\n",
      "epoch 2 batch id 108101 / 225000 loss 0.1395118087530136 train acc 0.7388738309543853\n",
      "epoch 2 batch id 108201 / 225000 loss 1.482917070388794 train acc 0.7388794927958152\n",
      "epoch 2 batch id 108301 / 225000 loss 0.2444542646408081 train acc 0.7389013028503892\n",
      "epoch 2 batch id 108401 / 225000 loss 0.10073940455913544 train acc 0.7389115414064445\n",
      "epoch 2 batch id 108501 / 225000 loss 0.01494775339961052 train acc 0.7389540188569691\n",
      "epoch 2 batch id 108601 / 225000 loss 2.7254862785339355 train acc 0.7389480759845674\n",
      "epoch 2 batch id 108701 / 225000 loss 0.05333049222826958 train acc 0.7389329444991306\n",
      "epoch 2 batch id 108801 / 225000 loss 2.4276766777038574 train acc 0.7389316274666593\n",
      "epoch 2 batch id 108901 / 225000 loss 0.004233691841363907 train acc 0.7389486781572254\n",
      "epoch 2 batch id 109001 / 225000 loss 2.6242854595184326 train acc 0.7389290006513701\n",
      "epoch 2 batch id 109101 / 225000 loss 0.9541423916816711 train acc 0.7389139421270199\n",
      "epoch 2 batch id 109201 / 225000 loss 0.012300579808652401 train acc 0.7389218047453778\n",
      "epoch 2 batch id 109301 / 225000 loss 1.5593786239624023 train acc 0.7389616746415861\n",
      "epoch 2 batch id 109401 / 225000 loss 0.01772412471473217 train acc 0.7389831902816245\n",
      "epoch 2 batch id 109501 / 225000 loss 1.3032946586608887 train acc 0.7389658541931123\n",
      "epoch 2 batch id 109601 / 225000 loss 3.2538609504699707 train acc 0.738946268738424\n",
      "epoch 2 batch id 109701 / 225000 loss 1.6888476610183716 train acc 0.7389495082086763\n",
      "epoch 2 batch id 109801 / 225000 loss 1.0137180089950562 train acc 0.7389481880857187\n",
      "epoch 2 batch id 109901 / 225000 loss 0.05295739322900772 train acc 0.7389900910819738\n",
      "epoch 2 batch id 110001 / 225000 loss 1.1152504682540894 train acc 0.738961463986691\n",
      "epoch 2 batch id 110101 / 225000 loss 3.198223114013672 train acc 0.7389419714625662\n",
      "epoch 2 batch id 110201 / 225000 loss 0.8733130693435669 train acc 0.7389157085688878\n",
      "epoch 2 batch id 110301 / 225000 loss 1.7023801803588867 train acc 0.7389166915984443\n",
      "epoch 2 batch id 110401 / 225000 loss 1.473598837852478 train acc 0.7387818045126403\n",
      "epoch 2 batch id 110501 / 225000 loss 1.9433648586273193 train acc 0.7386629985249002\n",
      "epoch 2 batch id 110601 / 225000 loss 4.752168655395508 train acc 0.7386099583186408\n",
      "epoch 2 batch id 110701 / 225000 loss 1.388746738433838 train acc 0.7385818556291271\n",
      "epoch 2 batch id 110801 / 225000 loss 6.576231956481934 train acc 0.7385041651248635\n",
      "epoch 2 batch id 110901 / 225000 loss 1.6946438550949097 train acc 0.7383928007862869\n",
      "epoch 2 batch id 111001 / 225000 loss 2.1233813762664795 train acc 0.7381983045197791\n",
      "epoch 2 batch id 111101 / 225000 loss 3.555191993713379 train acc 0.7379996579688751\n",
      "epoch 2 batch id 111201 / 225000 loss 1.5091993808746338 train acc 0.73791827411624\n",
      "epoch 2 batch id 111301 / 225000 loss 0.10729694366455078 train acc 0.7378302980206827\n",
      "epoch 2 batch id 111401 / 225000 loss 3.317568063735962 train acc 0.7377851186255061\n",
      "epoch 2 batch id 111501 / 225000 loss 1.6788475513458252 train acc 0.7378005578425305\n",
      "epoch 2 batch id 111601 / 225000 loss 2.5585131645202637 train acc 0.7377308447056926\n",
      "epoch 2 batch id 111701 / 225000 loss 1.5972472429275513 train acc 0.7376388752115022\n",
      "epoch 2 batch id 111801 / 225000 loss 3.476942539215088 train acc 0.7376230981833793\n",
      "epoch 2 batch id 111901 / 225000 loss 1.4490342140197754 train acc 0.7375626670002949\n",
      "epoch 2 batch id 112001 / 225000 loss 0.0721864104270935 train acc 0.737446540655887\n",
      "epoch 2 batch id 112101 / 225000 loss 3.8042380809783936 train acc 0.7372570271451637\n",
      "epoch 2 batch id 112201 / 225000 loss 1.582094430923462 train acc 0.7370723077334427\n",
      "epoch 2 batch id 112301 / 225000 loss 1.9375183582305908 train acc 0.7368344894524537\n",
      "epoch 2 batch id 112401 / 225000 loss 2.1570751667022705 train acc 0.7366059910499017\n",
      "epoch 2 batch id 112501 / 225000 loss 0.008885927498340607 train acc 0.7365312308335037\n",
      "epoch 2 batch id 112601 / 225000 loss 0.3660362958908081 train acc 0.7365343114181935\n",
      "epoch 2 batch id 112701 / 225000 loss 0.2454121708869934 train acc 0.7364841483216653\n",
      "epoch 2 batch id 112801 / 225000 loss 1.932560682296753 train acc 0.7364252089963741\n",
      "epoch 2 batch id 112901 / 225000 loss 1.3849866390228271 train acc 0.7363818743855236\n",
      "epoch 2 batch id 113001 / 225000 loss 0.004744125530123711 train acc 0.7363386164724206\n",
      "epoch 2 batch id 113101 / 225000 loss 1.6230149269104004 train acc 0.7362843829851194\n",
      "epoch 2 batch id 113201 / 225000 loss 0.20899665355682373 train acc 0.73626558069275\n",
      "epoch 2 batch id 113301 / 225000 loss 1.3912651538848877 train acc 0.7362225399599297\n",
      "epoch 2 batch id 113401 / 225000 loss 1.929297685623169 train acc 0.736159734041146\n",
      "epoch 2 batch id 113501 / 225000 loss 1.041550636291504 train acc 0.7361454965154492\n",
      "epoch 2 batch id 113601 / 225000 loss 1.5571630001068115 train acc 0.7360806683039762\n",
      "epoch 2 batch id 113701 / 225000 loss 1.3046231269836426 train acc 0.7359104141564278\n",
      "epoch 2 batch id 113801 / 225000 loss 2.0565505027770996 train acc 0.7356108470048593\n",
      "epoch 2 batch id 113901 / 225000 loss 3.469109296798706 train acc 0.7353688729686306\n",
      "epoch 2 batch id 114001 / 225000 loss 3.4515740871429443 train acc 0.7351996912307787\n",
      "epoch 2 batch id 114101 / 225000 loss 3.936718463897705 train acc 0.7349453554307149\n",
      "epoch 2 batch id 114201 / 225000 loss 2.4556026458740234 train acc 0.7346848976804056\n",
      "epoch 2 batch id 114301 / 225000 loss 3.2634518146514893 train acc 0.7344905118940341\n",
      "epoch 2 batch id 114401 / 225000 loss 3.0754427909851074 train acc 0.7343073924178984\n",
      "epoch 2 batch id 114501 / 225000 loss 2.444502592086792 train acc 0.7340765582833337\n",
      "epoch 2 batch id 114601 / 225000 loss 4.6013312339782715 train acc 0.7338352195879617\n",
      "epoch 2 batch id 114701 / 225000 loss 2.7803709506988525 train acc 0.7335834038064184\n",
      "epoch 2 batch id 114801 / 225000 loss 3.1453299522399902 train acc 0.7333320267245059\n",
      "epoch 2 batch id 114901 / 225000 loss 1.431147813796997 train acc 0.7330854387690272\n",
      "epoch 2 batch id 115001 / 225000 loss 1.8978972434997559 train acc 0.7328218885053174\n",
      "epoch 2 batch id 115101 / 225000 loss 1.3277382850646973 train acc 0.7326608804441317\n",
      "epoch 2 batch id 115201 / 225000 loss 1.7172883749008179 train acc 0.7324827909479953\n",
      "epoch 2 batch id 115301 / 225000 loss 1.182133436203003 train acc 0.7323548798362547\n",
      "epoch 2 batch id 115401 / 225000 loss 2.555703639984131 train acc 0.7321600332752749\n",
      "epoch 2 batch id 115501 / 225000 loss 3.7748053073883057 train acc 0.7318897671881629\n",
      "epoch 2 batch id 115601 / 225000 loss 4.369501113891602 train acc 0.7316113182411916\n",
      "epoch 2 batch id 115701 / 225000 loss 2.869159460067749 train acc 0.7313895299089895\n",
      "epoch 2 batch id 115801 / 225000 loss 1.7376599311828613 train acc 0.7312026666436386\n",
      "epoch 2 batch id 115901 / 225000 loss 3.6687841415405273 train acc 0.7310247538847809\n",
      "epoch 2 batch id 116001 / 225000 loss 3.8262603282928467 train acc 0.7307781829466987\n",
      "epoch 2 batch id 116101 / 225000 loss 2.0868499279022217 train acc 0.7306052488781319\n",
      "epoch 2 batch id 116201 / 225000 loss 0.4672603905200958 train acc 0.7304390667894425\n",
      "epoch 2 batch id 116301 / 225000 loss 1.242222547531128 train acc 0.7303011152096714\n",
      "epoch 2 batch id 116401 / 225000 loss 3.6147851943969727 train acc 0.7301032637176657\n",
      "epoch 2 batch id 116501 / 225000 loss 2.220155715942383 train acc 0.729794164856954\n",
      "epoch 2 batch id 116601 / 225000 loss 4.231043338775635 train acc 0.7295113249457552\n",
      "epoch 2 batch id 116701 / 225000 loss 3.8261196613311768 train acc 0.7292396808939083\n",
      "epoch 2 batch id 116801 / 225000 loss 3.925053358078003 train acc 0.728983484730439\n",
      "epoch 2 batch id 116901 / 225000 loss 2.836120843887329 train acc 0.7287320040033874\n",
      "epoch 2 batch id 117001 / 225000 loss 1.757256269454956 train acc 0.7285001837591132\n",
      "epoch 2 batch id 117101 / 225000 loss 2.2203004360198975 train acc 0.7283755049060213\n",
      "epoch 2 batch id 117201 / 225000 loss 2.6757586002349854 train acc 0.7283256968797195\n",
      "epoch 2 batch id 117301 / 225000 loss 1.3162260055541992 train acc 0.7282887613916335\n",
      "epoch 2 batch id 117401 / 225000 loss 2.910146951675415 train acc 0.7281496750453573\n",
      "epoch 2 batch id 117501 / 225000 loss 0.9883140325546265 train acc 0.7279342303469758\n",
      "epoch 2 batch id 117601 / 225000 loss 1.1889657974243164 train acc 0.7277127745512368\n",
      "epoch 2 batch id 117701 / 225000 loss 3.1383838653564453 train acc 0.7275235554498263\n",
      "epoch 2 batch id 117801 / 225000 loss 5.73940372467041 train acc 0.7272985798083208\n",
      "epoch 2 batch id 117901 / 225000 loss 2.1207997798919678 train acc 0.7271163942629834\n",
      "epoch 2 batch id 118001 / 225000 loss 0.9655210971832275 train acc 0.7269747714002424\n",
      "epoch 2 batch id 118101 / 225000 loss 2.6900758743286133 train acc 0.7268482061963912\n",
      "epoch 2 batch id 118201 / 225000 loss 0.379613995552063 train acc 0.7266985896904425\n",
      "epoch 2 batch id 118301 / 225000 loss 1.7477003335952759 train acc 0.7265302068452507\n",
      "epoch 2 batch id 118401 / 225000 loss 1.0197618007659912 train acc 0.7263980033952416\n",
      "epoch 2 batch id 118501 / 225000 loss 3.35742449760437 train acc 0.7262385971426402\n",
      "epoch 2 batch id 118601 / 225000 loss 4.80219030380249 train acc 0.7261131862294584\n",
      "epoch 2 batch id 118701 / 225000 loss 2.276982307434082 train acc 0.7259816682252045\n",
      "epoch 2 batch id 118801 / 225000 loss 2.035703182220459 train acc 0.7258524759892594\n",
      "epoch 2 batch id 118901 / 225000 loss 2.5060997009277344 train acc 0.725691962220671\n",
      "epoch 2 batch id 119001 / 225000 loss 2.662166118621826 train acc 0.7255695330291342\n",
      "epoch 2 batch id 119101 / 225000 loss 1.6348251104354858 train acc 0.725436814132543\n",
      "epoch 2 batch id 119201 / 225000 loss 0.9812326431274414 train acc 0.7253169017038448\n",
      "epoch 2 batch id 119301 / 225000 loss 2.967613458633423 train acc 0.72520766799943\n",
      "epoch 2 batch id 119401 / 225000 loss 3.528036594390869 train acc 0.7251132737581762\n",
      "epoch 2 batch id 119501 / 225000 loss 2.5464842319488525 train acc 0.7250274056284047\n",
      "epoch 2 batch id 119601 / 225000 loss 2.7621967792510986 train acc 0.7250441049823998\n",
      "epoch 2 batch id 119701 / 225000 loss 0.005418271292001009 train acc 0.7250503337482561\n",
      "epoch 2 batch id 119801 / 225000 loss 0.01826915517449379 train acc 0.7250648992913248\n",
      "epoch 2 batch id 119901 / 225000 loss 0.0920315682888031 train acc 0.7250627601104245\n",
      "epoch 2 batch id 120001 / 225000 loss 0.00716321961954236 train acc 0.7250793743385472\n",
      "epoch 2 batch id 120101 / 225000 loss 0.3391270935535431 train acc 0.725054329272862\n",
      "epoch 2 batch id 120201 / 225000 loss 2.2849254608154297 train acc 0.7250730027204433\n",
      "epoch 2 batch id 120301 / 225000 loss 0.021605433896183968 train acc 0.7250812545199126\n",
      "epoch 2 batch id 120401 / 225000 loss 1.7887091636657715 train acc 0.7250811870333302\n",
      "epoch 2 batch id 120501 / 225000 loss 0.986111581325531 train acc 0.7251080903892914\n",
      "epoch 2 batch id 120601 / 225000 loss 2.467179775238037 train acc 0.7251100737141483\n",
      "epoch 2 batch id 120701 / 225000 loss 3.9387855529785156 train acc 0.7251037688171598\n",
      "epoch 2 batch id 120801 / 225000 loss 2.2459557056427 train acc 0.7251140305129924\n",
      "epoch 2 batch id 120901 / 225000 loss 1.506155252456665 train acc 0.7251263430410005\n",
      "epoch 2 batch id 121001 / 225000 loss 0.03188135102391243 train acc 0.7250911149494632\n",
      "epoch 2 batch id 121101 / 225000 loss 2.555196762084961 train acc 0.7250600738226769\n",
      "epoch 2 batch id 121201 / 225000 loss 1.4543311595916748 train acc 0.7250063943366803\n",
      "epoch 2 batch id 121301 / 225000 loss 2.0650651454925537 train acc 0.7250166940091178\n",
      "epoch 2 batch id 121401 / 225000 loss 0.19989131391048431 train acc 0.7250187395490976\n",
      "epoch 2 batch id 121501 / 225000 loss 2.3462719917297363 train acc 0.7250002057596234\n",
      "epoch 2 batch id 121601 / 225000 loss 0.020842015743255615 train acc 0.7250187087277242\n",
      "epoch 2 batch id 121701 / 225000 loss 1.982285737991333 train acc 0.7250084222808358\n",
      "epoch 2 batch id 121801 / 225000 loss 0.0035872068256139755 train acc 0.7250392032906133\n",
      "epoch 2 batch id 121901 / 225000 loss 2.628437042236328 train acc 0.7250289169079827\n",
      "epoch 2 batch id 122001 / 225000 loss 0.3111765682697296 train acc 0.7250186473881362\n",
      "epoch 2 batch id 122101 / 225000 loss 0.9885299205780029 train acc 0.7250165846307565\n",
      "epoch 2 batch id 122201 / 225000 loss 1.8095732927322388 train acc 0.7250042962005221\n",
      "epoch 2 batch id 122301 / 225000 loss 0.7129497528076172 train acc 0.725012469235738\n",
      "epoch 2 batch id 122401 / 225000 loss 1.1292517185211182 train acc 0.7250165439824838\n",
      "epoch 2 batch id 122501 / 225000 loss 0.013729012571275234 train acc 0.7250348976743047\n",
      "epoch 2 batch id 122601 / 225000 loss 1.323356032371521 train acc 0.7250348692098759\n",
      "epoch 2 batch id 122701 / 225000 loss 1.2966402769088745 train acc 0.7250429906846725\n",
      "epoch 2 batch id 122801 / 225000 loss 0.030799010768532753 train acc 0.7250307407920131\n",
      "epoch 2 batch id 122901 / 225000 loss 2.2283730506896973 train acc 0.7250246133066451\n",
      "epoch 2 batch id 123001 / 225000 loss 0.9977163076400757 train acc 0.7249900407313762\n",
      "epoch 2 batch id 123101 / 225000 loss 0.0657687857747078 train acc 0.7250083264961292\n",
      "epoch 2 batch id 123201 / 225000 loss 2.4407238960266113 train acc 0.7250083197376644\n",
      "epoch 2 batch id 123301 / 225000 loss 2.047891616821289 train acc 0.725040753927381\n",
      "epoch 2 batch id 123401 / 225000 loss 0.7000800967216492 train acc 0.7250245135776857\n",
      "epoch 2 batch id 123501 / 225000 loss 0.008122539147734642 train acc 0.7250346151043311\n",
      "epoch 2 batch id 123601 / 225000 loss 3.5542330741882324 train acc 0.7250123380878796\n",
      "epoch 2 batch id 123701 / 225000 loss 4.29655122756958 train acc 0.7250204121227799\n",
      "epoch 2 batch id 123801 / 225000 loss 0.7180827260017395 train acc 0.7250002019369796\n",
      "epoch 2 batch id 123901 / 225000 loss 0.03525187447667122 train acc 0.7249679179344799\n",
      "epoch 2 batch id 124001 / 225000 loss 0.043230023235082626 train acc 0.7249961693857307\n",
      "epoch 2 batch id 124101 / 225000 loss 0.0015977532602846622 train acc 0.7250062449134173\n",
      "epoch 2 batch id 124201 / 225000 loss 3.270012378692627 train acc 0.7250122784840701\n",
      "epoch 2 batch id 124301 / 225000 loss 0.016682492569088936 train acc 0.7250243360874008\n",
      "epoch 2 batch id 124401 / 225000 loss 0.004088434390723705 train acc 0.7250484320865588\n",
      "epoch 2 batch id 124501 / 225000 loss 0.5795507431030273 train acc 0.7250785134255949\n",
      "epoch 2 batch id 124601 / 225000 loss 0.3063872158527374 train acc 0.7250884824359355\n",
      "epoch 2 batch id 124701 / 225000 loss 2.752169609069824 train acc 0.7251084594349685\n",
      "epoch 2 batch id 124801 / 225000 loss 0.3303791284561157 train acc 0.7251384203652215\n",
      "epoch 2 batch id 124901 / 225000 loss 0.9199289083480835 train acc 0.7251583253937118\n",
      "epoch 2 batch id 125001 / 225000 loss 1.684411883354187 train acc 0.7251541987664099\n",
      "epoch 2 batch id 125101 / 225000 loss 0.010551330633461475 train acc 0.7251900464424745\n",
      "epoch 2 batch id 125201 / 225000 loss 0.8640746474266052 train acc 0.725201875384382\n",
      "epoch 2 batch id 125301 / 225000 loss 1.1752852201461792 train acc 0.7252376277922762\n",
      "epoch 2 batch id 125401 / 225000 loss 0.002914107870310545 train acc 0.7252434191114904\n",
      "epoch 2 batch id 125501 / 225000 loss 0.011611828580498695 train acc 0.7252492012015841\n",
      "epoch 2 batch id 125601 / 225000 loss 1.0712677240371704 train acc 0.7252888113948137\n",
      "epoch 2 batch id 125701 / 225000 loss 0.008725455030798912 train acc 0.7253204031789723\n",
      "epoch 2 batch id 125801 / 225000 loss 1.4329168796539307 train acc 0.7253280975508939\n",
      "epoch 2 batch id 125901 / 225000 loss 2.1753416061401367 train acc 0.7253576222587589\n",
      "epoch 2 batch id 126001 / 225000 loss 1.150027871131897 train acc 0.7253533702113475\n",
      "epoch 2 batch id 126101 / 225000 loss 1.0910534858703613 train acc 0.72533722968097\n",
      "epoch 2 batch id 126201 / 225000 loss 3.315612554550171 train acc 0.7253151718290664\n",
      "epoch 2 batch id 126301 / 225000 loss 1.9222925901412964 train acc 0.7253426338667153\n",
      "epoch 2 batch id 126401 / 225000 loss 4.35084867477417 train acc 0.7253384071328549\n",
      "epoch 2 batch id 126501 / 225000 loss 0.6961199641227722 train acc 0.7253243057367136\n",
      "epoch 2 batch id 126601 / 225000 loss 1.9784682989120483 train acc 0.7253240495730682\n",
      "epoch 2 batch id 126701 / 225000 loss 1.605366587638855 train acc 0.7253514179051468\n",
      "epoch 2 batch id 126801 / 225000 loss 0.46571701765060425 train acc 0.7253846578497015\n",
      "epoch 2 batch id 126901 / 225000 loss 1.6781716346740723 train acc 0.7254158753674124\n",
      "epoch 2 batch id 127001 / 225000 loss 0.017064467072486877 train acc 0.7254253903512571\n",
      "epoch 2 batch id 127101 / 225000 loss 3.3265533447265625 train acc 0.7254447250611719\n",
      "epoch 2 batch id 127201 / 225000 loss 2.2403175830841064 train acc 0.7254247215037618\n",
      "epoch 2 batch id 127301 / 225000 loss 1.677866816520691 train acc 0.7254381348143377\n",
      "epoch 2 batch id 127401 / 225000 loss 1.9835412502288818 train acc 0.7254848863038752\n",
      "epoch 2 batch id 127501 / 225000 loss 2.2227494716644287 train acc 0.725492349079615\n",
      "epoch 2 batch id 127601 / 225000 loss 1.1733571290969849 train acc 0.7254802078353618\n",
      "epoch 2 batch id 127701 / 225000 loss 0.0024002795107662678 train acc 0.7255170280577286\n",
      "epoch 2 batch id 127801 / 225000 loss 0.5739108324050903 train acc 0.7255146673343714\n",
      "epoch 2 batch id 127901 / 225000 loss 0.809733510017395 train acc 0.7254986278449739\n",
      "epoch 2 batch id 128001 / 225000 loss 1.1881624460220337 train acc 0.7255392535995813\n",
      "epoch 2 batch id 128101 / 225000 loss 1.5223815441131592 train acc 0.7255524937354119\n",
      "epoch 2 batch id 128201 / 225000 loss 0.026738613843917847 train acc 0.7255540128392134\n",
      "epoch 2 batch id 128301 / 225000 loss 2.056140899658203 train acc 0.7255691693751413\n",
      "epoch 2 batch id 128401 / 225000 loss 0.804500162601471 train acc 0.7255843023029416\n",
      "epoch 2 batch id 128501 / 225000 loss 1.4969903230667114 train acc 0.7255935751472751\n",
      "epoch 2 batch id 128601 / 225000 loss 4.716235637664795 train acc 0.725604777567826\n",
      "epoch 2 batch id 128701 / 225000 loss 1.767390489578247 train acc 0.7256392724221257\n",
      "epoch 2 batch id 128801 / 225000 loss 0.031021831557154655 train acc 0.7256562449049309\n",
      "epoch 2 batch id 128901 / 225000 loss 1.6058783531188965 train acc 0.7256809489453147\n",
      "epoch 2 batch id 129001 / 225000 loss 2.10092830657959 train acc 0.7256804210820071\n",
      "epoch 2 batch id 129101 / 225000 loss 1.7581524848937988 train acc 0.7256934493148774\n",
      "epoch 2 batch id 129201 / 225000 loss 0.020423443987965584 train acc 0.7257316119844274\n",
      "epoch 2 batch id 129301 / 225000 loss 1.5119552612304688 train acc 0.7257755160439594\n",
      "epoch 2 batch id 129401 / 225000 loss 0.8612775206565857 train acc 0.7257613928794986\n",
      "epoch 2 batch id 129501 / 225000 loss 1.4655321836471558 train acc 0.7257859012671717\n",
      "epoch 2 batch id 129601 / 225000 loss 4.575038909912109 train acc 0.7258258038132421\n",
      "epoch 2 batch id 129701 / 225000 loss 1.1076124906539917 train acc 0.7258694998496542\n",
      "epoch 2 batch id 129801 / 225000 loss 0.006778213195502758 train acc 0.7258861642052065\n",
      "epoch 2 batch id 129901 / 225000 loss 0.6099668145179749 train acc 0.7259201237865759\n",
      "epoch 2 batch id 130001 / 225000 loss 3.585557699203491 train acc 0.7259694156198798\n",
      "epoch 2 batch id 130101 / 225000 loss 0.26743701100349426 train acc 0.7260071021744644\n",
      "epoch 2 batch id 130201 / 225000 loss 0.0035345100332051516 train acc 0.7260543313799434\n",
      "epoch 2 batch id 130301 / 225000 loss 1.3262087106704712 train acc 0.7260496849602075\n",
      "epoch 2 batch id 130401 / 225000 loss 0.004395765718072653 train acc 0.7260603829725232\n",
      "epoch 2 batch id 130501 / 225000 loss 1.388573169708252 train acc 0.726082558754339\n",
      "epoch 2 batch id 130601 / 225000 loss 0.18935613334178925 train acc 0.7261027863492623\n",
      "epoch 2 batch id 130701 / 225000 loss 0.4577189087867737 train acc 0.7261153319408421\n",
      "epoch 2 batch id 130801 / 225000 loss 1.8761584758758545 train acc 0.7261202131482175\n",
      "epoch 2 batch id 130901 / 225000 loss 1.2692500352859497 train acc 0.7261556443419073\n",
      "epoch 2 batch id 131001 / 225000 loss 0.002673933980986476 train acc 0.7261566705597667\n",
      "epoch 2 batch id 131101 / 225000 loss 2.574148654937744 train acc 0.7261576952120884\n",
      "epoch 2 batch id 131201 / 225000 loss 1.751723051071167 train acc 0.7261701511421407\n",
      "epoch 2 batch id 131301 / 225000 loss 1.0560569763183594 train acc 0.7261692599447072\n",
      "epoch 2 batch id 131401 / 225000 loss 2.0673413276672363 train acc 0.7262007138454045\n",
      "epoch 2 batch id 131501 / 225000 loss 0.033597469329833984 train acc 0.7262397244127421\n",
      "epoch 2 batch id 131601 / 225000 loss 1.0072180032730103 train acc 0.7262596788778201\n",
      "epoch 2 batch id 131701 / 225000 loss 0.10232537239789963 train acc 0.7263099748673131\n",
      "epoch 2 batch id 131801 / 225000 loss 0.009541081264615059 train acc 0.726320361757498\n",
      "epoch 2 batch id 131901 / 225000 loss 1.3508963584899902 train acc 0.7263440004245608\n",
      "epoch 2 batch id 132001 / 225000 loss 5.304687976837158 train acc 0.7263619215005946\n",
      "epoch 2 batch id 132101 / 225000 loss 0.012477884069085121 train acc 0.7263571055480277\n",
      "epoch 2 batch id 132201 / 225000 loss 0.006598028354346752 train acc 0.7263806627786477\n",
      "epoch 2 batch id 132301 / 225000 loss 2.687812328338623 train acc 0.7263871777235243\n",
      "epoch 2 batch id 132401 / 225000 loss 0.021507656201720238 train acc 0.7264276704858724\n",
      "epoch 2 batch id 132501 / 225000 loss 0.007278779521584511 train acc 0.7264681021275311\n",
      "epoch 2 batch id 132601 / 225000 loss 0.5487135052680969 train acc 0.7264858485230127\n",
      "epoch 2 batch id 132701 / 225000 loss 3.0644094944000244 train acc 0.7264696573499823\n",
      "epoch 2 batch id 132801 / 225000 loss 1.1928329467773438 train acc 0.7264666681726795\n",
      "epoch 2 batch id 132901 / 225000 loss 1.7151007652282715 train acc 0.7264636834937284\n",
      "epoch 2 batch id 133001 / 225000 loss 0.0052132317796349525 train acc 0.7264795001541342\n",
      "epoch 2 batch id 133101 / 225000 loss 1.2208071947097778 train acc 0.7264802668650123\n",
      "epoch 2 batch id 133201 / 225000 loss 1.2735708951950073 train acc 0.7264998010525446\n",
      "epoch 2 batch id 133301 / 225000 loss 1.1864211559295654 train acc 0.7264592913781592\n",
      "epoch 2 batch id 133401 / 225000 loss 0.01487667765468359 train acc 0.7264994265410304\n",
      "epoch 2 batch id 133501 / 225000 loss 1.655144214630127 train acc 0.7264833222223055\n",
      "epoch 2 batch id 133601 / 225000 loss 0.11296206712722778 train acc 0.7265027956377572\n",
      "epoch 2 batch id 133701 / 225000 loss 1.4451686143875122 train acc 0.7265185002356004\n",
      "epoch 2 batch id 133801 / 225000 loss 0.3799465596675873 train acc 0.7265547342695495\n",
      "epoch 2 batch id 133901 / 225000 loss 3.9450156688690186 train acc 0.726579711876685\n",
      "epoch 2 batch id 134001 / 225000 loss 0.8524194359779358 train acc 0.7265897269423363\n",
      "epoch 2 batch id 134101 / 225000 loss 1.625537395477295 train acc 0.7266556550659578\n",
      "epoch 2 batch id 134201 / 225000 loss 3.2761285305023193 train acc 0.7266879531449095\n",
      "epoch 2 batch id 134301 / 225000 loss 1.4211105108261108 train acc 0.7267146186551106\n",
      "epoch 2 batch id 134401 / 225000 loss 0.09305579215288162 train acc 0.726741244484788\n",
      "epoch 2 batch id 134501 / 225000 loss 5.379403114318848 train acc 0.7267659720002082\n",
      "epoch 2 batch id 134601 / 225000 loss 1.9499940872192383 train acc 0.7267813760670426\n",
      "epoch 2 batch id 134701 / 225000 loss 0.037965331226587296 train acc 0.726776341675266\n",
      "epoch 2 batch id 134801 / 225000 loss 0.004760315641760826 train acc 0.7267472051394277\n",
      "epoch 2 batch id 134901 / 225000 loss 1.1281863451004028 train acc 0.7267422035418566\n",
      "epoch 2 batch id 135001 / 225000 loss 1.909306287765503 train acc 0.7267612832497538\n",
      "epoch 2 batch id 135101 / 225000 loss 1.3388824462890625 train acc 0.7267766337776922\n",
      "epoch 2 batch id 135201 / 225000 loss 2.0222079753875732 train acc 0.7268067543879113\n",
      "epoch 2 batch id 135301 / 225000 loss 0.02754122018814087 train acc 0.7268275918138077\n",
      "epoch 2 batch id 135401 / 225000 loss 2.4021685123443604 train acc 0.7268373202561281\n",
      "epoch 2 batch id 135501 / 225000 loss 0.029292691498994827 train acc 0.7268544143585656\n",
      "epoch 2 batch id 135601 / 225000 loss 1.8485140800476074 train acc 0.7268512031622185\n",
      "epoch 2 batch id 135701 / 225000 loss 0.021184125915169716 train acc 0.7268203624144258\n",
      "epoch 2 batch id 135801 / 225000 loss 0.9935347437858582 train acc 0.7266956797078078\n",
      "epoch 2 batch id 135901 / 225000 loss 1.4540115594863892 train acc 0.7265895762356421\n",
      "epoch 2 batch id 136001 / 225000 loss 4.607490062713623 train acc 0.726424805699958\n",
      "epoch 2 batch id 136101 / 225000 loss 3.9847311973571777 train acc 0.7262437454537439\n",
      "epoch 2 batch id 136201 / 225000 loss 1.643943190574646 train acc 0.7261014970521509\n",
      "epoch 2 batch id 136301 / 225000 loss 0.938542902469635 train acc 0.7260071459490393\n",
      "epoch 2 batch id 136401 / 225000 loss 0.03312768414616585 train acc 0.7260009090842443\n",
      "epoch 2 batch id 136501 / 225000 loss 0.008329126052558422 train acc 0.7259525571241237\n",
      "epoch 2 batch id 136601 / 225000 loss 0.9626933336257935 train acc 0.7259317281718289\n",
      "epoch 2 batch id 136701 / 225000 loss 0.016320092603564262 train acc 0.7259639651502183\n",
      "epoch 2 batch id 136801 / 225000 loss 0.4117541015148163 train acc 0.7259760528066316\n",
      "epoch 2 batch id 136901 / 225000 loss 2.089365005493164 train acc 0.7259388171014091\n",
      "epoch 2 batch id 137001 / 225000 loss 0.2200411707162857 train acc 0.7259600294888359\n",
      "epoch 2 batch id 137101 / 225000 loss 0.1801759898662567 train acc 0.7259210363162923\n",
      "epoch 2 batch id 137201 / 225000 loss 1.660441517829895 train acc 0.7258912107054614\n",
      "epoch 2 batch id 137301 / 225000 loss 0.002020944142714143 train acc 0.7258905616128069\n",
      "epoch 2 batch id 137401 / 225000 loss 1.6530978679656982 train acc 0.7259008304160814\n",
      "epoch 2 batch id 137501 / 225000 loss 4.882889270782471 train acc 0.7258874480912866\n",
      "epoch 2 batch id 137601 / 225000 loss 0.468025267124176 train acc 0.7258795357591878\n",
      "epoch 2 batch id 137701 / 225000 loss 2.98726487159729 train acc 0.7257917516938874\n",
      "epoch 2 batch id 137801 / 225000 loss 0.11762963980436325 train acc 0.7257530787149585\n",
      "epoch 2 batch id 137901 / 225000 loss 1.1320987939834595 train acc 0.7257199005083357\n",
      "epoch 2 batch id 138001 / 225000 loss 4.166145324707031 train acc 0.7256813356424954\n",
      "epoch 2 batch id 138101 / 225000 loss 0.0039077093824744225 train acc 0.7256283444725238\n",
      "epoch 2 batch id 138201 / 225000 loss 1.7841460704803467 train acc 0.7255754299896527\n",
      "epoch 2 batch id 138301 / 225000 loss 2.7358195781707764 train acc 0.7255189767246802\n",
      "epoch 2 batch id 138401 / 225000 loss 2.672461748123169 train acc 0.7254806684922797\n",
      "epoch 2 batch id 138501 / 225000 loss 1.1639742851257324 train acc 0.7254424155782269\n",
      "epoch 2 batch id 138601 / 225000 loss 0.4661143124103546 train acc 0.7254096290791553\n",
      "epoch 2 batch id 138701 / 225000 loss 2.4145455360412598 train acc 0.7253516557198578\n",
      "epoch 2 batch id 138801 / 225000 loss 0.00895281508564949 train acc 0.7253117772926708\n",
      "epoch 2 batch id 138901 / 225000 loss 0.9001930356025696 train acc 0.7252683565993046\n",
      "epoch 2 batch id 139001 / 225000 loss 0.004098826553672552 train acc 0.725250178056273\n",
      "epoch 2 batch id 139101 / 225000 loss 0.003658717731013894 train acc 0.7252176476085722\n",
      "epoch 2 batch id 139201 / 225000 loss 1.6576459407806396 train acc 0.7252067154689981\n",
      "epoch 2 batch id 139301 / 225000 loss 0.9369850158691406 train acc 0.725192209675451\n",
      "epoch 2 batch id 139401 / 225000 loss 2.256605863571167 train acc 0.7252171792167919\n",
      "epoch 2 batch id 139501 / 225000 loss 4.108997344970703 train acc 0.7251955183116967\n",
      "epoch 2 batch id 139601 / 225000 loss 0.038863055408000946 train acc 0.7251900058022507\n",
      "epoch 2 batch id 139701 / 225000 loss 4.37535285949707 train acc 0.7251558686050923\n",
      "epoch 2 batch id 139801 / 225000 loss 0.07280461490154266 train acc 0.725128933269433\n",
      "epoch 2 batch id 139901 / 225000 loss 0.293152391910553 train acc 0.7250931015503821\n",
      "epoch 2 batch id 140001 / 225000 loss 2.459678888320923 train acc 0.7250662495267891\n",
      "epoch 2 batch id 140101 / 225000 loss 2.410733222961426 train acc 0.7250786932284566\n",
      "epoch 2 batch id 140201 / 225000 loss 1.8409690856933594 train acc 0.7250875528705216\n",
      "epoch 2 batch id 140301 / 225000 loss 0.7375192046165466 train acc 0.7251053092992923\n",
      "epoch 2 batch id 140401 / 225000 loss 2.9930262565612793 train acc 0.7250429127997664\n",
      "epoch 2 batch id 140501 / 225000 loss 2.225379705429077 train acc 0.725019750749105\n",
      "epoch 2 batch id 140601 / 225000 loss 1.0082781314849854 train acc 0.7250090682143085\n",
      "epoch 2 batch id 140701 / 225000 loss 1.056976318359375 train acc 0.7250268299443501\n",
      "epoch 2 batch id 140801 / 225000 loss 0.5450925827026367 train acc 0.7250072797778425\n",
      "epoch 2 batch id 140901 / 225000 loss 0.08789506554603577 train acc 0.7249806601798426\n",
      "epoch 2 batch id 141001 / 225000 loss 1.1852205991744995 train acc 0.7249682626364352\n",
      "epoch 2 batch id 141101 / 225000 loss 0.0254904106259346 train acc 0.7249860029340685\n",
      "epoch 2 batch id 141201 / 225000 loss 1.5373432636260986 train acc 0.7249647665384806\n",
      "epoch 2 batch id 141301 / 225000 loss 3.5906012058258057 train acc 0.7249400216558977\n",
      "epoch 2 batch id 141401 / 225000 loss 0.7461580634117126 train acc 0.7249170797943437\n",
      "epoch 2 batch id 141501 / 225000 loss 0.020553424954414368 train acc 0.7249418732023095\n",
      "epoch 2 batch id 141601 / 225000 loss 3.968445062637329 train acc 0.7249525073975466\n",
      "epoch 2 batch id 141701 / 225000 loss 2.5372722148895264 train acc 0.7249384266871793\n",
      "epoch 2 batch id 141801 / 225000 loss 3.569974422454834 train acc 0.7249384701095197\n",
      "epoch 2 batch id 141901 / 225000 loss 0.13105879724025726 train acc 0.7249684639290773\n",
      "epoch 2 batch id 142001 / 225000 loss 1.6610435247421265 train acc 0.7249843310962599\n",
      "epoch 2 batch id 142101 / 225000 loss 2.505236864089966 train acc 0.7250142504275128\n",
      "epoch 2 batch id 142201 / 225000 loss 1.2088643312454224 train acc 0.7250036919571592\n",
      "epoch 2 batch id 142301 / 225000 loss 0.009613608941435814 train acc 0.7250247714351972\n",
      "epoch 2 batch id 142401 / 225000 loss 1.613237977027893 train acc 0.7250142204057556\n",
      "epoch 2 batch id 142501 / 225000 loss 2.169229507446289 train acc 0.7249984210637118\n",
      "epoch 2 batch id 142601 / 225000 loss 0.12386176735162735 train acc 0.7250142004614274\n",
      "epoch 2 batch id 142701 / 225000 loss 1.7355860471725464 train acc 0.7250352134883428\n",
      "epoch 2 batch id 142801 / 225000 loss 0.3256351053714752 train acc 0.7250631998375362\n",
      "epoch 2 batch id 142901 / 225000 loss 4.102663040161133 train acc 0.7251086416470144\n",
      "epoch 2 batch id 143001 / 225000 loss 1.4788432121276855 train acc 0.7251295445486395\n",
      "epoch 2 batch id 143101 / 225000 loss 0.9446382522583008 train acc 0.7251207189327817\n",
      "epoch 2 batch id 143201 / 225000 loss 4.0688934326171875 train acc 0.7251555505897305\n",
      "epoch 2 batch id 143301 / 225000 loss 0.05599403381347656 train acc 0.7251606757803505\n",
      "epoch 2 batch id 143401 / 225000 loss 2.9641761779785156 train acc 0.7251553336448142\n",
      "epoch 2 batch id 143501 / 225000 loss 3.167471170425415 train acc 0.7251621939916795\n",
      "epoch 2 batch id 143601 / 225000 loss 1.0090950727462769 train acc 0.7251655629139073\n",
      "epoch 2 batch id 143701 / 225000 loss 2.156280040740967 train acc 0.7251758860411549\n",
      "epoch 2 batch id 143801 / 225000 loss 0.004324003122746944 train acc 0.7251948873790863\n",
      "epoch 2 batch id 143901 / 225000 loss 1.8450927734375 train acc 0.7251686923648898\n",
      "epoch 2 batch id 144001 / 225000 loss 3.0143425464630127 train acc 0.7252067693974348\n",
      "epoch 2 batch id 144101 / 225000 loss 1.7478857040405273 train acc 0.7252239748509726\n",
      "epoch 2 batch id 144201 / 225000 loss 0.005514477379620075 train acc 0.7252550259706937\n",
      "epoch 2 batch id 144301 / 225000 loss 0.04239252582192421 train acc 0.7252791040949127\n",
      "epoch 2 batch id 144401 / 225000 loss 0.9802297949790955 train acc 0.7253066114500593\n",
      "epoch 2 batch id 144501 / 225000 loss 1.8912718296051025 train acc 0.7253271603656722\n",
      "epoch 2 batch id 144601 / 225000 loss 2.859994888305664 train acc 0.7253321208013775\n",
      "epoch 2 batch id 144701 / 225000 loss 3.4072275161743164 train acc 0.7253457128838087\n",
      "epoch 2 batch id 144801 / 225000 loss 0.4521138370037079 train acc 0.725381730789152\n",
      "epoch 2 batch id 144901 / 225000 loss 1.1169798374176025 train acc 0.7253849179784818\n",
      "epoch 2 batch id 145001 / 225000 loss 1.85123872756958 train acc 0.7254174109144075\n",
      "epoch 2 batch id 145101 / 225000 loss 0.013003756292164326 train acc 0.7254446902502395\n",
      "epoch 2 batch id 145201 / 225000 loss 3.750479221343994 train acc 0.7254357752357078\n",
      "epoch 2 batch id 145301 / 225000 loss 0.6541392803192139 train acc 0.7254595632514573\n",
      "epoch 2 batch id 145401 / 225000 loss 1.1870803833007812 train acc 0.7254695634830572\n",
      "epoch 2 batch id 145501 / 225000 loss 1.6322910785675049 train acc 0.7254554951512361\n",
      "epoch 2 batch id 145601 / 225000 loss 1.8041064739227295 train acc 0.7254689184827027\n",
      "epoch 2 batch id 145701 / 225000 loss 2.3275814056396484 train acc 0.725472028331995\n",
      "epoch 2 batch id 145801 / 225000 loss 0.5930358171463013 train acc 0.7254922805742073\n",
      "epoch 2 batch id 145901 / 225000 loss 3.454869031906128 train acc 0.7254936566575966\n",
      "epoch 2 batch id 146001 / 225000 loss 0.6850441098213196 train acc 0.7255035924411477\n",
      "epoch 2 batch id 146101 / 225000 loss 2.4798622131347656 train acc 0.7254758694327896\n",
      "epoch 2 batch id 146201 / 225000 loss 1.62690269947052 train acc 0.7254721239936799\n",
      "epoch 2 batch id 146301 / 225000 loss 0.2722558379173279 train acc 0.7254786365096616\n",
      "epoch 2 batch id 146401 / 225000 loss 1.6153769493103027 train acc 0.7255022165149145\n",
      "epoch 2 batch id 146501 / 225000 loss 1.313008189201355 train acc 0.7255052866533335\n",
      "epoch 2 batch id 146601 / 225000 loss 0.9342018961906433 train acc 0.7254947101315816\n",
      "epoch 2 batch id 146701 / 225000 loss 0.05148852989077568 train acc 0.7255097102269241\n",
      "epoch 2 batch id 146801 / 225000 loss 1.0516345500946045 train acc 0.725543422728728\n",
      "epoch 2 batch id 146901 / 225000 loss 4.956777572631836 train acc 0.7255685802002709\n",
      "epoch 2 batch id 147001 / 225000 loss 1.098760962486267 train acc 0.7255783974258678\n",
      "epoch 2 batch id 147101 / 225000 loss 1.5251407623291016 train acc 0.7255949993541853\n",
      "epoch 2 batch id 147201 / 225000 loss 2.6877546310424805 train acc 0.7256132770837155\n",
      "epoch 2 batch id 147301 / 225000 loss 1.6431077718734741 train acc 0.7256281355863164\n",
      "epoch 2 batch id 147401 / 225000 loss 0.008412983268499374 train acc 0.7256497581427535\n",
      "epoch 2 batch id 147501 / 225000 loss 2.1579489707946777 train acc 0.725659487054325\n",
      "epoch 2 batch id 147601 / 225000 loss 2.44439435005188 train acc 0.7256759778050285\n",
      "epoch 2 batch id 147701 / 225000 loss 1.1097819805145264 train acc 0.7257026018781186\n",
      "epoch 2 batch id 147801 / 225000 loss 1.4925614595413208 train acc 0.725713966752593\n",
      "epoch 2 batch id 147901 / 225000 loss 3.023399829864502 train acc 0.7257286968986011\n",
      "epoch 2 batch id 148001 / 225000 loss 4.385341644287109 train acc 0.7257484746724684\n",
      "epoch 2 batch id 148101 / 225000 loss 3.002610683441162 train acc 0.7257597855517518\n",
      "epoch 2 batch id 148201 / 225000 loss 0.874824047088623 train acc 0.7257727680649928\n",
      "epoch 2 batch id 148301 / 225000 loss 1.269271969795227 train acc 0.7257992191556362\n",
      "epoch 2 batch id 148401 / 225000 loss 1.7815860509872437 train acc 0.7258121576000162\n",
      "epoch 2 batch id 148501 / 225000 loss 0.9921791553497314 train acc 0.7258385465417742\n",
      "epoch 2 batch id 148601 / 225000 loss 1.4070872068405151 train acc 0.725839664605218\n",
      "epoch 2 batch id 148701 / 225000 loss 2.1954896450042725 train acc 0.72587104323441\n",
      "epoch 2 batch id 148801 / 225000 loss 3.591031312942505 train acc 0.7258469365125234\n",
      "epoch 2 batch id 148901 / 225000 loss 1.4251763820648193 train acc 0.7258765891431219\n",
      "epoch 2 batch id 149001 / 225000 loss 1.8640241622924805 train acc 0.7258625781035026\n",
      "epoch 2 batch id 149101 / 225000 loss 0.48470526933670044 train acc 0.7258485858579083\n",
      "epoch 2 batch id 149201 / 225000 loss 0.0010639704996719956 train acc 0.7258597462483496\n",
      "epoch 2 batch id 149301 / 225000 loss 0.008312254212796688 train acc 0.725907730021902\n",
      "epoch 2 batch id 149401 / 225000 loss 1.4322785139083862 train acc 0.7259154891868194\n",
      "epoch 2 batch id 149501 / 225000 loss 0.01937052048742771 train acc 0.7259483214159103\n",
      "epoch 2 batch id 149601 / 225000 loss 1.0139590501785278 train acc 0.7259694119691713\n",
      "epoch 2 batch id 149701 / 225000 loss 0.15238599479198456 train acc 0.7260205342649682\n",
      "epoch 2 batch id 149801 / 225000 loss 1.151681661605835 train acc 0.7260365418121374\n",
      "epoch 2 batch id 149901 / 225000 loss 0.007183183915913105 train acc 0.7260375180952762\n",
      "epoch 2 batch id 150001 / 225000 loss 1.5254000425338745 train acc 0.7260634929100472\n",
      "epoch 2 batch id 150101 / 225000 loss 3.564579486846924 train acc 0.7260994263862333\n",
      "epoch 2 batch id 150201 / 225000 loss 0.9024357199668884 train acc 0.726098694416149\n",
      "epoch 2 batch id 150301 / 225000 loss 0.0021779488306492567 train acc 0.7261162600381901\n",
      "epoch 2 batch id 150401 / 225000 loss 0.5321051478385925 train acc 0.7261238289639032\n",
      "epoch 2 batch id 150501 / 225000 loss 0.016613062471151352 train acc 0.726124743357187\n",
      "epoch 2 batch id 150601 / 225000 loss 0.9145773649215698 train acc 0.7261455767225982\n",
      "epoch 2 batch id 150701 / 225000 loss 2.18273663520813 train acc 0.7261497932993145\n",
      "epoch 2 batch id 150801 / 225000 loss 0.013344958424568176 train acc 0.7261805293068349\n",
      "epoch 2 batch id 150901 / 225000 loss 0.032728008925914764 train acc 0.7262211648696828\n",
      "epoch 2 batch id 151001 / 225000 loss 0.0034868395887315273 train acc 0.726241879192853\n",
      "epoch 2 batch id 151101 / 225000 loss 0.3170168399810791 train acc 0.7262675296655879\n",
      "epoch 2 batch id 151201 / 225000 loss 0.11026716232299805 train acc 0.726306373635095\n",
      "epoch 2 batch id 151301 / 225000 loss 2.7970616817474365 train acc 0.7263022055373064\n",
      "epoch 2 batch id 151401 / 225000 loss 1.9495141506195068 train acc 0.7263079504098388\n",
      "epoch 2 batch id 151501 / 225000 loss 4.06705379486084 train acc 0.7263285390855506\n",
      "epoch 2 batch id 151601 / 225000 loss 0.07862962782382965 train acc 0.7263210664837303\n",
      "epoch 2 batch id 151701 / 225000 loss 3.130599021911621 train acc 0.726302067883534\n",
      "epoch 2 batch id 151801 / 225000 loss 1.5950618982315063 train acc 0.7262847412072384\n",
      "epoch 2 batch id 151901 / 225000 loss 2.74983286857605 train acc 0.7262674373440596\n",
      "epoch 2 batch id 152001 / 225000 loss 0.9206841588020325 train acc 0.7262863402214459\n",
      "epoch 2 batch id 152101 / 225000 loss 0.8291853666305542 train acc 0.7262904254409899\n",
      "epoch 2 batch id 152201 / 225000 loss 0.7282081842422485 train acc 0.7263142160695396\n",
      "epoch 2 batch id 152301 / 225000 loss 1.2021479606628418 train acc 0.7262952968135469\n",
      "epoch 2 batch id 152401 / 225000 loss 0.031529128551483154 train acc 0.7263256146613212\n",
      "epoch 2 batch id 152501 / 225000 loss 0.01402946375310421 train acc 0.7263558927482443\n",
      "epoch 2 batch id 152601 / 225000 loss 1.6321897506713867 train acc 0.7263206007824327\n",
      "epoch 2 batch id 152701 / 225000 loss 1.1008492708206177 train acc 0.7263115500225932\n",
      "epoch 2 batch id 152801 / 225000 loss 1.3481340408325195 train acc 0.7263368695231052\n",
      "epoch 2 batch id 152901 / 225000 loss 2.28480863571167 train acc 0.7263572507701062\n",
      "epoch 2 batch id 153001 / 225000 loss 1.0906667709350586 train acc 0.7263776053751283\n",
      "epoch 2 batch id 153101 / 225000 loss 0.7109658122062683 train acc 0.7263685410284714\n",
      "epoch 2 batch id 153201 / 225000 loss 2.609496831893921 train acc 0.7263709114170273\n",
      "epoch 2 batch id 153301 / 225000 loss 1.7713897228240967 train acc 0.7263781710491125\n",
      "epoch 2 batch id 153401 / 225000 loss 0.04741339385509491 train acc 0.7263935697941996\n",
      "epoch 2 batch id 153501 / 225000 loss 1.7991948127746582 train acc 0.7264089484759056\n",
      "epoch 2 batch id 153601 / 225000 loss 0.0432952381670475 train acc 0.7264226795398467\n",
      "epoch 2 batch id 153701 / 225000 loss 0.007596111390739679 train acc 0.7264689234292555\n",
      "epoch 2 batch id 153801 / 225000 loss 0.4951264560222626 train acc 0.726476095734098\n",
      "epoch 2 batch id 153901 / 225000 loss 0.7097243666648865 train acc 0.7264897564018428\n",
      "epoch 2 batch id 154001 / 225000 loss 0.4165380597114563 train acc 0.7265001525964118\n",
      "epoch 2 batch id 154101 / 225000 loss 0.03250710666179657 train acc 0.7265154022361957\n",
      "epoch 2 batch id 154201 / 225000 loss 2.6506338119506836 train acc 0.7265533297449432\n",
      "epoch 2 batch id 154301 / 225000 loss 0.004552819300442934 train acc 0.7265847272538739\n",
      "epoch 2 batch id 154401 / 225000 loss 0.775297999382019 train acc 0.726575605080278\n",
      "epoch 2 batch id 154501 / 225000 loss 0.6683549284934998 train acc 0.7265923845153106\n",
      "epoch 2 batch id 154601 / 225000 loss 4.925732612609863 train acc 0.7266042910459829\n",
      "epoch 2 batch id 154701 / 225000 loss 0.02794908918440342 train acc 0.726595173916135\n",
      "epoch 2 batch id 154801 / 225000 loss 0.0051986523903906345 train acc 0.7266102932151601\n",
      "epoch 2 batch id 154901 / 225000 loss 0.7381045818328857 train acc 0.7266173233226383\n",
      "epoch 2 batch id 155001 / 225000 loss 1.9928762912750244 train acc 0.7266307959303488\n",
      "epoch 2 batch id 155101 / 225000 loss 1.4940277338027954 train acc 0.7266410274595264\n",
      "epoch 2 batch id 155201 / 225000 loss 0.018635988235473633 train acc 0.726685072905458\n",
      "epoch 2 batch id 155301 / 225000 loss 1.1569844484329224 train acc 0.7266727194287222\n",
      "epoch 2 batch id 155401 / 225000 loss 0.0038530933670699596 train acc 0.726681295487159\n",
      "epoch 2 batch id 155501 / 225000 loss 1.3291901350021362 train acc 0.726694683635475\n",
      "epoch 2 batch id 155601 / 225000 loss 0.8613173365592957 train acc 0.7267128745959216\n",
      "epoch 2 batch id 155701 / 225000 loss 2.4796745777130127 train acc 0.7267133801324334\n",
      "epoch 2 batch id 155801 / 225000 loss 1.4205044507980347 train acc 0.7267299311300954\n",
      "epoch 2 batch id 155901 / 225000 loss 0.2939925789833069 train acc 0.7267368394044939\n",
      "epoch 2 batch id 156001 / 225000 loss 0.9646602869033813 train acc 0.7267485464836764\n",
      "epoch 2 batch id 156101 / 225000 loss 0.007456633262336254 train acc 0.7267362156552488\n",
      "epoch 2 batch id 156201 / 225000 loss 1.5911865234375 train acc 0.7267687146689201\n",
      "epoch 2 batch id 156301 / 225000 loss 1.5015454292297363 train acc 0.7267771799284714\n",
      "epoch 2 batch id 156401 / 225000 loss 0.008614647202193737 train acc 0.7267840359076988\n",
      "epoch 2 batch id 156501 / 225000 loss 0.8366392850875854 train acc 0.7267892856914653\n",
      "epoch 2 batch id 156601 / 225000 loss 0.7312260866165161 train acc 0.7268088964949139\n",
      "epoch 2 batch id 156701 / 225000 loss 0.00661625899374485 train acc 0.7268189098984691\n",
      "epoch 2 batch id 156801 / 225000 loss 1.380649209022522 train acc 0.726846448683363\n",
      "epoch 2 batch id 156901 / 225000 loss 1.8858660459518433 train acc 0.7268500519435822\n",
      "epoch 2 batch id 157001 / 225000 loss 1.4248714447021484 train acc 0.726869574079146\n",
      "epoch 2 batch id 157101 / 225000 loss 0.05824635177850723 train acc 0.7268890713617354\n",
      "epoch 2 batch id 157201 / 225000 loss 0.013565550558269024 train acc 0.7269244470455023\n",
      "epoch 2 batch id 157301 / 225000 loss 0.008150792680680752 train acc 0.7269454739639291\n",
      "epoch 2 batch id 157401 / 225000 loss 0.018743840977549553 train acc 0.7269728273645021\n",
      "epoch 2 batch id 157501 / 225000 loss 3.3616209030151367 train acc 0.7269937968647818\n",
      "epoch 2 batch id 157601 / 225000 loss 1.0271449089050293 train acc 0.7269766689297656\n",
      "epoch 2 batch id 157701 / 225000 loss 2.8053128719329834 train acc 0.726977000779957\n",
      "epoch 2 batch id 157801 / 225000 loss 0.647118091583252 train acc 0.7270058491391056\n",
      "epoch 2 batch id 157901 / 225000 loss 2.946380615234375 train acc 0.7270219947942065\n",
      "epoch 2 batch id 158001 / 225000 loss 1.6448493003845215 train acc 0.7270539426965652\n",
      "epoch 2 batch id 158101 / 225000 loss 0.5581182837486267 train acc 0.7270811063813638\n",
      "epoch 2 batch id 158201 / 225000 loss 3.1261940002441406 train acc 0.7270876922396192\n",
      "epoch 2 batch id 158301 / 225000 loss 1.8717056512832642 train acc 0.7271084832060442\n",
      "epoch 2 batch id 158401 / 225000 loss 0.2210819274187088 train acc 0.7271245131028213\n",
      "epoch 2 batch id 158501 / 225000 loss 1.5012131929397583 train acc 0.7271499864354168\n",
      "epoch 2 batch id 158601 / 225000 loss 0.308525413274765 train acc 0.7271580885366422\n",
      "epoch 2 batch id 158701 / 225000 loss 2.0696218013763428 train acc 0.7271677557167252\n",
      "epoch 2 batch id 158801 / 225000 loss 0.0781542956829071 train acc 0.7271931536955057\n",
      "epoch 2 batch id 158901 / 225000 loss 0.007262144237756729 train acc 0.7272169464005891\n",
      "epoch 2 batch id 159001 / 225000 loss 0.0011587110348045826 train acc 0.7272108351519802\n",
      "epoch 2 batch id 159101 / 225000 loss 0.010358440689742565 train acc 0.7272173022168308\n",
      "epoch 2 batch id 159201 / 225000 loss 2.965862274169922 train acc 0.7272426052600172\n",
      "epoch 2 batch id 159301 / 225000 loss 0.18036654591560364 train acc 0.7272553216866184\n",
      "epoch 2 batch id 159401 / 225000 loss 1.543794870376587 train acc 0.7272790007590918\n",
      "epoch 2 batch id 159501 / 225000 loss 0.004733340814709663 train acc 0.7272901110337866\n",
      "epoch 2 batch id 159601 / 225000 loss 1.581602692604065 train acc 0.727293375354791\n",
      "epoch 2 batch id 159701 / 225000 loss 1.817596435546875 train acc 0.7273295095209172\n",
      "epoch 2 batch id 159801 / 225000 loss 2.8422110080718994 train acc 0.727339002884838\n",
      "epoch 2 batch id 159901 / 225000 loss 0.003238488920032978 train acc 0.7273719363856386\n",
      "epoch 2 batch id 160001 / 225000 loss 1.3565561771392822 train acc 0.7274001412491172\n",
      "epoch 2 batch id 160101 / 225000 loss 2.3336682319641113 train acc 0.7273986421071699\n",
      "epoch 2 batch id 160201 / 225000 loss 1.241153359413147 train acc 0.7274314767073864\n",
      "epoch 2 batch id 160301 / 225000 loss 0.07279451936483383 train acc 0.7274439959825578\n",
      "epoch 2 batch id 160401 / 225000 loss 3.5174829959869385 train acc 0.7274689683979526\n",
      "epoch 2 batch id 160501 / 225000 loss 1.8947300910949707 train acc 0.7274907944498789\n",
      "epoch 2 batch id 160601 / 225000 loss 0.40407103300094604 train acc 0.727529716502388\n",
      "epoch 2 batch id 160701 / 225000 loss 0.007379698101431131 train acc 0.7275592560096079\n",
      "epoch 2 batch id 160801 / 225000 loss 0.3049909770488739 train acc 0.7275934229264743\n",
      "epoch 2 batch id 160901 / 225000 loss 0.12899892032146454 train acc 0.7276228861225226\n",
      "epoch 2 batch id 161001 / 225000 loss 2.803501605987549 train acc 0.7276476543623953\n",
      "epoch 2 batch id 161101 / 225000 loss 0.8447482585906982 train acc 0.7276444590660517\n",
      "epoch 2 batch id 161201 / 225000 loss 0.038271985948085785 train acc 0.727684691782309\n",
      "epoch 2 batch id 161301 / 225000 loss 1.7773510217666626 train acc 0.7277202249211102\n",
      "epoch 2 batch id 161401 / 225000 loss 0.8557096719741821 train acc 0.7277231863495269\n",
      "epoch 2 batch id 161501 / 225000 loss 1.7766668796539307 train acc 0.727761747605278\n",
      "epoch 2 batch id 161601 / 225000 loss 0.11919959634542465 train acc 0.7277646796740119\n",
      "epoch 2 batch id 161701 / 225000 loss 2.7167749404907227 train acc 0.7277722463064545\n",
      "epoch 2 batch id 161801 / 225000 loss 1.1449668407440186 train acc 0.7277828938016452\n",
      "epoch 2 batch id 161901 / 225000 loss 1.2508975267410278 train acc 0.7277919839902163\n",
      "epoch 2 batch id 162001 / 225000 loss 1.9083759784698486 train acc 0.7278180381602583\n",
      "epoch 2 batch id 162101 / 225000 loss 5.219274520874023 train acc 0.7278193842110783\n",
      "epoch 2 batch id 162201 / 225000 loss 0.5715779662132263 train acc 0.7278238111972183\n",
      "epoch 2 batch id 162301 / 225000 loss 0.581929087638855 train acc 0.7278544186419061\n",
      "epoch 2 batch id 162401 / 225000 loss 0.6527177095413208 train acc 0.727875751996601\n",
      "epoch 2 batch id 162501 / 225000 loss 1.484139084815979 train acc 0.7278924437388078\n",
      "epoch 2 batch id 162601 / 225000 loss 0.008218947798013687 train acc 0.7279121899619313\n",
      "epoch 2 batch id 162701 / 225000 loss 0.49225184321403503 train acc 0.7279057903762116\n",
      "epoch 2 batch id 162801 / 225000 loss 2.210383653640747 train acc 0.7279147548233733\n",
      "epoch 2 batch id 162901 / 225000 loss 3.534968852996826 train acc 0.7279528670787779\n",
      "epoch 2 batch id 163001 / 225000 loss 0.7797336578369141 train acc 0.7279679265771376\n",
      "epoch 2 batch id 163101 / 225000 loss 1.5371949672698975 train acc 0.727975303646207\n",
      "epoch 2 batch id 163201 / 225000 loss 0.01892789639532566 train acc 0.7279780761147296\n",
      "epoch 2 batch id 163301 / 225000 loss 0.007907010614871979 train acc 0.7280114634937936\n",
      "epoch 2 batch id 163401 / 225000 loss 0.005522219464182854 train acc 0.7280188003745387\n",
      "epoch 2 batch id 163501 / 225000 loss 0.15706481039524078 train acc 0.7280322444511043\n",
      "epoch 2 batch id 163601 / 225000 loss 1.415149450302124 train acc 0.7280410877684121\n",
      "epoch 2 batch id 163701 / 225000 loss 1.1314873695373535 train acc 0.728039230059682\n",
      "epoch 2 batch id 163801 / 225000 loss 1.3490118980407715 train acc 0.7280495845568709\n",
      "epoch 2 batch id 163901 / 225000 loss 1.8086609840393066 train acc 0.7280873820171933\n",
      "epoch 2 batch id 164001 / 225000 loss 0.039071813225746155 train acc 0.7281190358595374\n",
      "epoch 2 batch id 164101 / 225000 loss 0.0346001461148262 train acc 0.7281430338632915\n",
      "epoch 2 batch id 164201 / 225000 loss 0.852745771408081 train acc 0.7281624350643419\n",
      "epoch 2 batch id 164301 / 225000 loss 0.043858617544174194 train acc 0.7281955070267375\n",
      "epoch 2 batch id 164401 / 225000 loss 0.017911022529006004 train acc 0.728204208003601\n",
      "epoch 2 batch id 164501 / 225000 loss 0.35046064853668213 train acc 0.7282387341110388\n",
      "epoch 2 batch id 164601 / 225000 loss 2.2976253032684326 train acc 0.728248917078268\n",
      "epoch 2 batch id 164701 / 225000 loss 0.007030852604657412 train acc 0.7282439086587209\n",
      "epoch 2 batch id 164801 / 225000 loss 0.5875424146652222 train acc 0.7282722799012142\n",
      "epoch 2 batch id 164901 / 225000 loss 0.3082233667373657 train acc 0.7282900043056136\n",
      "epoch 2 batch id 165001 / 225000 loss 1.187393069267273 train acc 0.7283183132223441\n",
      "epoch 2 batch id 165101 / 225000 loss 0.01291558425873518 train acc 0.7283132749044524\n",
      "epoch 2 batch id 165201 / 225000 loss 0.9995786547660828 train acc 0.7283264023825522\n",
      "epoch 2 batch id 165301 / 225000 loss 1.037692904472351 train acc 0.7283349767998983\n",
      "epoch 2 batch id 165401 / 225000 loss 2.602656841278076 train acc 0.7283359834583829\n",
      "epoch 2 batch id 165501 / 225000 loss 2.053534984588623 train acc 0.7283566262439501\n",
      "epoch 2 batch id 165601 / 225000 loss 1.353827714920044 train acc 0.7283772440987675\n",
      "epoch 2 batch id 165701 / 225000 loss 0.02082701586186886 train acc 0.7284129244844629\n",
      "epoch 2 batch id 165801 / 225000 loss 3.1969618797302246 train acc 0.7284259443549798\n",
      "epoch 2 batch id 165901 / 225000 loss 3.1674866676330566 train acc 0.7284253862243145\n",
      "epoch 2 batch id 166001 / 225000 loss 0.08191316574811935 train acc 0.728482057337004\n",
      "epoch 2 batch id 166101 / 225000 loss 1.3858157396316528 train acc 0.7284965171793065\n",
      "epoch 2 batch id 166201 / 225000 loss 1.843201756477356 train acc 0.7285064470129542\n",
      "epoch 2 batch id 166301 / 225000 loss 3.046046495437622 train acc 0.7285193715010734\n",
      "epoch 2 batch id 166401 / 225000 loss 0.02015182189643383 train acc 0.7285382900343147\n",
      "epoch 2 batch id 166501 / 225000 loss 1.7271445989608765 train acc 0.7285616903201783\n",
      "epoch 2 batch id 166601 / 225000 loss 1.9971706867218018 train acc 0.7285580518724377\n",
      "epoch 2 batch id 166701 / 225000 loss 0.005288333166390657 train acc 0.728567915009508\n",
      "epoch 2 batch id 166801 / 225000 loss 3.496715784072876 train acc 0.7285807639042932\n",
      "epoch 2 batch id 166901 / 225000 loss 3.086470365524292 train acc 0.7285771205684807\n",
      "epoch 2 batch id 167001 / 225000 loss 3.6056411266326904 train acc 0.7285914455602063\n",
      "epoch 2 batch id 167101 / 225000 loss 0.41002604365348816 train acc 0.7286222105193865\n",
      "epoch 2 batch id 167201 / 225000 loss 0.9250791072845459 train acc 0.728651443472228\n",
      "epoch 2 batch id 167301 / 225000 loss 0.9424734711647034 train acc 0.7286656983520721\n",
      "epoch 2 batch id 167401 / 225000 loss 0.748576283454895 train acc 0.7286739625211319\n",
      "epoch 2 batch id 167501 / 225000 loss 1.8878521919250488 train acc 0.7286866944077945\n",
      "epoch 2 batch id 167601 / 225000 loss 0.034394457936286926 train acc 0.7287038860149999\n",
      "epoch 2 batch id 167701 / 225000 loss 2.4046521186828613 train acc 0.7287150941258549\n",
      "epoch 2 batch id 167801 / 225000 loss 0.9401938319206238 train acc 0.7287426773380373\n",
      "epoch 2 batch id 167901 / 225000 loss 1.976253628730774 train acc 0.7287464041310058\n",
      "epoch 2 batch id 168001 / 225000 loss 0.004115886054933071 train acc 0.7287769120421902\n",
      "epoch 2 batch id 168101 / 225000 loss 0.9001229405403137 train acc 0.7288118452596951\n",
      "epoch 2 batch id 168201 / 225000 loss 0.03618237376213074 train acc 0.7288199832343446\n",
      "epoch 2 batch id 168301 / 225000 loss 1.2609277963638306 train acc 0.7288266261044201\n",
      "epoch 2 batch id 168401 / 225000 loss 2.37397837638855 train acc 0.7288302919816391\n",
      "epoch 2 batch id 168501 / 225000 loss 1.3702306747436523 train acc 0.728851757556335\n",
      "epoch 2 batch id 168601 / 225000 loss 1.1692742109298706 train acc 0.7288479902254436\n",
      "epoch 2 batch id 168701 / 225000 loss 0.9326339960098267 train acc 0.7288457092726184\n",
      "epoch 2 batch id 168801 / 225000 loss 1.5508772134780884 train acc 0.7288641654966499\n",
      "epoch 2 batch id 168901 / 225000 loss 0.1424136906862259 train acc 0.728912203006495\n",
      "epoch 2 batch id 169001 / 225000 loss 0.8509505987167358 train acc 0.7289291187626109\n",
      "epoch 2 batch id 169101 / 225000 loss 3.6524672508239746 train acc 0.7289267952288869\n",
      "epoch 2 batch id 169201 / 225000 loss 0.2552312910556793 train acc 0.72893629470275\n",
      "epoch 2 batch id 169301 / 225000 loss 0.003950939513742924 train acc 0.7289605495537533\n",
      "epoch 2 batch id 169401 / 225000 loss 5.092546463012695 train acc 0.7289405021221834\n",
      "epoch 2 batch id 169501 / 225000 loss 1.456080436706543 train acc 0.7289367024383338\n",
      "epoch 2 batch id 169601 / 225000 loss 0.7638421654701233 train acc 0.7289461736664289\n",
      "epoch 2 batch id 169701 / 225000 loss 0.006737670861184597 train acc 0.7289718387045451\n",
      "epoch 2 batch id 169801 / 225000 loss 2.1060638427734375 train acc 0.7290033627599366\n",
      "epoch 2 batch id 169901 / 225000 loss 0.9750667214393616 train acc 0.7290157209198298\n",
      "epoch 2 batch id 170001 / 225000 loss 4.615829944610596 train acc 0.7290221822224575\n",
      "epoch 2 batch id 170101 / 225000 loss 3.1495766639709473 train acc 0.7290359845033245\n",
      "epoch 2 batch id 170201 / 225000 loss 3.4652721881866455 train acc 0.7290600525261308\n",
      "epoch 2 batch id 170301 / 225000 loss 1.7317917346954346 train acc 0.7290826242946312\n",
      "epoch 2 batch id 170401 / 225000 loss 0.013115182518959045 train acc 0.7291066366981415\n",
      "epoch 2 batch id 170501 / 225000 loss 0.9061631560325623 train acc 0.7291218233324145\n",
      "epoch 2 batch id 170601 / 225000 loss 0.02290683053433895 train acc 0.7291194072719386\n",
      "epoch 2 batch id 170701 / 225000 loss 1.8058618307113647 train acc 0.7291389622790727\n",
      "epoch 2 batch id 170801 / 225000 loss 0.0036925282329320908 train acc 0.7291526396215479\n",
      "epoch 2 batch id 170901 / 225000 loss 0.0036070728674530983 train acc 0.7291794664747426\n",
      "epoch 2 batch id 171001 / 225000 loss 0.008117814548313618 train acc 0.729207723931439\n",
      "epoch 2 batch id 171101 / 225000 loss 0.9671644568443298 train acc 0.729222798230285\n",
      "epoch 2 batch id 171201 / 225000 loss 2.6823668479919434 train acc 0.7292582987248907\n",
      "epoch 2 batch id 171301 / 225000 loss 1.247719168663025 train acc 0.729298136029562\n",
      "epoch 2 batch id 171401 / 225000 loss 1.1733814477920532 train acc 0.7292970869481509\n",
      "epoch 2 batch id 171501 / 225000 loss 0.03085748665034771 train acc 0.7293077008297327\n",
      "epoch 2 batch id 171601 / 225000 loss 5.37758207321167 train acc 0.7293066473971597\n",
      "epoch 2 batch id 171701 / 225000 loss 0.5290173888206482 train acc 0.7293259794643013\n",
      "epoch 2 batch id 171801 / 225000 loss 3.2022194862365723 train acc 0.729338013166396\n",
      "epoch 2 batch id 171901 / 225000 loss 0.3757961392402649 train acc 0.7293733020750316\n",
      "epoch 2 batch id 172001 / 225000 loss 0.016305286437273026 train acc 0.7294114569101342\n",
      "epoch 2 batch id 172101 / 225000 loss 3.9996225833892822 train acc 0.7294132515209092\n",
      "epoch 2 batch id 172201 / 225000 loss 1.8505336046218872 train acc 0.7294266583817748\n",
      "epoch 2 batch id 172301 / 225000 loss 2.055607557296753 train acc 0.729437147782079\n",
      "epoch 2 batch id 172401 / 225000 loss 1.396315336227417 train acc 0.72944472479858\n",
      "epoch 2 batch id 172501 / 225000 loss 1.0820484161376953 train acc 0.7294769305685185\n",
      "epoch 2 batch id 172601 / 225000 loss 5.5334272384643555 train acc 0.7295018568837955\n",
      "epoch 2 batch id 172701 / 225000 loss 2.4551925659179688 train acc 0.7295195163895982\n",
      "epoch 2 batch id 172801 / 225000 loss 0.0025887007359415293 train acc 0.7295111139403129\n",
      "epoch 2 batch id 172901 / 225000 loss 1.5332331657409668 train acc 0.7295287476648487\n",
      "epoch 2 batch id 173001 / 225000 loss 1.7945871353149414 train acc 0.7295246848284114\n",
      "epoch 2 batch id 173101 / 225000 loss 0.1899026483297348 train acc 0.7295307363908932\n",
      "epoch 2 batch id 173201 / 225000 loss 0.003149603959172964 train acc 0.7295454414235484\n",
      "epoch 2 batch id 173301 / 225000 loss 0.002888031769543886 train acc 0.7295615720624808\n",
      "epoch 2 batch id 173401 / 225000 loss 1.560441255569458 train acc 0.7295560579235414\n",
      "epoch 2 batch id 173501 / 225000 loss 1.2482073307037354 train acc 0.7295505501409214\n",
      "epoch 2 batch id 173601 / 225000 loss 1.5571115016937256 train acc 0.7295781706326576\n",
      "epoch 2 batch id 173701 / 225000 loss 0.39555785059928894 train acc 0.7295769742258248\n",
      "epoch 2 batch id 173801 / 225000 loss 1.6785515546798706 train acc 0.7295613949286828\n",
      "epoch 2 batch id 173901 / 225000 loss 0.018118323758244514 train acc 0.7295731479404949\n",
      "epoch 2 batch id 174001 / 225000 loss 2.538888931274414 train acc 0.7295762668030643\n",
      "epoch 2 batch id 174101 / 225000 loss 3.057697057723999 train acc 0.7295822539790122\n",
      "epoch 2 batch id 174201 / 225000 loss 1.6398805379867554 train acc 0.7295882342810891\n",
      "epoch 2 batch id 174301 / 225000 loss 1.6676857471466064 train acc 0.7296228937298123\n",
      "epoch 2 batch id 174401 / 225000 loss 1.716004490852356 train acc 0.7296388782174414\n",
      "epoch 2 batch id 174501 / 225000 loss 1.3396775722503662 train acc 0.7296577096979386\n",
      "epoch 2 batch id 174601 / 225000 loss 1.2822723388671875 train acc 0.7296435873792246\n",
      "epoch 2 batch id 174701 / 225000 loss 3.581010341644287 train acc 0.7296652566384851\n",
      "epoch 2 batch id 174801 / 225000 loss 0.7163200974464417 train acc 0.729674029324775\n",
      "epoch 2 batch id 174901 / 225000 loss 3.18607497215271 train acc 0.7296899388797091\n",
      "epoch 2 batch id 175001 / 225000 loss 1.473319411277771 train acc 0.7296944017462758\n",
      "epoch 2 batch id 175101 / 225000 loss 1.70962655544281 train acc 0.7297017150101941\n",
      "epoch 2 batch id 175201 / 225000 loss 0.9048898220062256 train acc 0.7297033121957066\n",
      "epoch 2 batch id 175301 / 225000 loss 1.6461403369903564 train acc 0.729719168744046\n",
      "epoch 2 batch id 175401 / 225000 loss 0.025660408660769463 train acc 0.7297278806848307\n",
      "epoch 2 batch id 175501 / 225000 loss 0.6519646644592285 train acc 0.7297394316841499\n",
      "epoch 2 batch id 175601 / 225000 loss 1.069858193397522 train acc 0.7297580879379958\n",
      "epoch 2 batch id 175701 / 225000 loss 2.1038336753845215 train acc 0.7297596484937479\n",
      "epoch 2 batch id 175801 / 225000 loss 0.08296424895524979 train acc 0.7297981808977195\n",
      "epoch 2 batch id 175901 / 225000 loss 0.0026288649532943964 train acc 0.7298210356962155\n",
      "epoch 2 batch id 176001 / 225000 loss 0.9187819361686707 train acc 0.7298296600587497\n",
      "epoch 2 batch id 176101 / 225000 loss 0.2032572329044342 train acc 0.7298624085042107\n",
      "epoch 2 batch id 176201 / 225000 loss 2.1865522861480713 train acc 0.729866743094534\n",
      "epoch 2 batch id 176301 / 225000 loss 1.4344710111618042 train acc 0.7298739088263821\n",
      "epoch 2 batch id 176401 / 225000 loss 2.463947057723999 train acc 0.7298697286296563\n",
      "epoch 2 batch id 176501 / 225000 loss 1.4682612419128418 train acc 0.7298853830856482\n",
      "epoch 2 batch id 176601 / 225000 loss 1.8623504638671875 train acc 0.7298996041925018\n",
      "epoch 2 batch id 176701 / 225000 loss 0.12525935471057892 train acc 0.7299053202868122\n",
      "epoch 2 batch id 176801 / 225000 loss 0.004634685814380646 train acc 0.7299350682405642\n",
      "epoch 2 batch id 176901 / 225000 loss 3.63442063331604 train acc 0.729926625626763\n",
      "epoch 2 batch id 177001 / 225000 loss 3.790743827819824 train acc 0.7299379664521669\n",
      "epoch 2 batch id 177101 / 225000 loss 3.360142707824707 train acc 0.7299422363510087\n",
      "epoch 2 batch id 177201 / 225000 loss 0.002509616781026125 train acc 0.7299408581215682\n",
      "epoch 2 batch id 177301 / 225000 loss 1.2064669132232666 train acc 0.7299549917936166\n",
      "epoch 2 batch id 177401 / 225000 loss 0.7725991606712341 train acc 0.7299789741884206\n",
      "epoch 2 batch id 177501 / 225000 loss 1.7505252361297607 train acc 0.7299761691483428\n",
      "epoch 2 batch id 177601 / 225000 loss 1.2012877464294434 train acc 0.7299846284649298\n",
      "epoch 2 batch id 177701 / 225000 loss 0.005541170947253704 train acc 0.73000714683654\n",
      "epoch 2 batch id 177801 / 225000 loss 1.1885547637939453 train acc 0.7300197974139628\n",
      "epoch 2 batch id 177901 / 225000 loss 0.0017520654946565628 train acc 0.7300268126654712\n",
      "epoch 2 batch id 178001 / 225000 loss 1.0962421894073486 train acc 0.7300310110617356\n",
      "epoch 2 batch id 178101 / 225000 loss 0.00800466537475586 train acc 0.73004643432659\n",
      "epoch 2 batch id 178201 / 225000 loss 0.05369977280497551 train acc 0.7300800781140397\n",
      "epoch 2 batch id 178301 / 225000 loss 4.8351030349731445 train acc 0.7301192926567994\n",
      "epoch 2 batch id 178401 / 225000 loss 3.3787059783935547 train acc 0.7301416471880763\n",
      "epoch 2 batch id 178501 / 225000 loss 0.026708180084824562 train acc 0.7301611755676439\n",
      "epoch 2 batch id 178601 / 225000 loss 0.006015492137521505 train acc 0.7301820818472461\n",
      "epoch 2 batch id 178701 / 225000 loss 0.010757732205092907 train acc 0.7302099596532756\n",
      "epoch 2 batch id 178801 / 225000 loss 1.515640377998352 train acc 0.7302252224540131\n",
      "epoch 2 batch id 178901 / 225000 loss 1.5959426164627075 train acc 0.7302544424011045\n",
      "epoch 2 batch id 179001 / 225000 loss 0.14379532635211945 train acc 0.7302584901760325\n",
      "epoch 2 batch id 179101 / 225000 loss 0.7920438647270203 train acc 0.7302569499891123\n",
      "epoch 2 batch id 179201 / 225000 loss 3.61258864402771 train acc 0.7302582016841423\n",
      "epoch 2 batch id 179301 / 225000 loss 0.0013862396590411663 train acc 0.7302496918589411\n",
      "epoch 2 batch id 179401 / 225000 loss 1.258050799369812 train acc 0.7302593073617204\n",
      "epoch 2 batch id 179501 / 225000 loss 0.033179476857185364 train acc 0.730266126651105\n",
      "epoch 2 batch id 179601 / 225000 loss 2.1586432456970215 train acc 0.7302631945256429\n",
      "epoch 2 batch id 179701 / 225000 loss 3.2167105674743652 train acc 0.7302825248607409\n",
      "epoch 2 batch id 179801 / 225000 loss 3.2118942737579346 train acc 0.7303199092329854\n",
      "epoch 2 batch id 179901 / 225000 loss 0.004178425297141075 train acc 0.7303530830845855\n",
      "epoch 2 batch id 180001 / 225000 loss 4.21258020401001 train acc 0.7303598313342704\n",
      "epoch 2 batch id 180101 / 225000 loss 0.8479450345039368 train acc 0.7303804531901544\n",
      "epoch 2 batch id 180201 / 225000 loss 1.3253881931304932 train acc 0.7303982774790373\n",
      "epoch 2 batch id 180301 / 225000 loss 1.542950987815857 train acc 0.7304202417069234\n",
      "epoch 2 batch id 180401 / 225000 loss 3.062584400177002 train acc 0.730422780361528\n",
      "epoch 2 batch id 180501 / 225000 loss 0.003920938819646835 train acc 0.7304253162032344\n",
      "epoch 2 batch id 180601 / 225000 loss 0.39749598503112793 train acc 0.730458303110171\n",
      "epoch 2 batch id 180701 / 225000 loss 0.010930279269814491 train acc 0.7304552824832181\n",
      "epoch 2 batch id 180801 / 225000 loss 1.12442147731781 train acc 0.7304813026476623\n",
      "epoch 2 batch id 180901 / 225000 loss 0.1126929223537445 train acc 0.7305307875578355\n",
      "epoch 2 batch id 181001 / 225000 loss 1.557267665863037 train acc 0.7305042513577273\n",
      "epoch 2 batch id 181101 / 225000 loss 1.4171377420425415 train acc 0.7304984511405238\n",
      "epoch 2 batch id 181201 / 225000 loss 1.0967440605163574 train acc 0.7305105932086468\n",
      "epoch 2 batch id 181301 / 225000 loss 1.2720568180084229 train acc 0.7305282375717729\n",
      "epoch 2 batch id 181401 / 225000 loss 2.1557061672210693 train acc 0.7305610222655884\n",
      "epoch 2 batch id 181501 / 225000 loss 1.606698989868164 train acc 0.73057035498427\n",
      "epoch 2 batch id 181601 / 225000 loss 2.633166790008545 train acc 0.730563157691863\n",
      "epoch 2 batch id 181701 / 225000 loss 2.6815297603607178 train acc 0.7305766066229685\n",
      "epoch 2 batch id 181801 / 225000 loss 0.3598645329475403 train acc 0.7305804148492032\n",
      "epoch 2 batch id 181901 / 225000 loss 1.0898194313049316 train acc 0.7305952138800776\n",
      "epoch 2 batch id 182001 / 225000 loss 0.7823427319526672 train acc 0.7306168647425014\n",
      "epoch 2 batch id 182101 / 225000 loss 1.316636562347412 train acc 0.7306288817743999\n",
      "epoch 2 batch id 182201 / 225000 loss 0.8924752473831177 train acc 0.7306436298373774\n",
      "epoch 2 batch id 182301 / 225000 loss 0.0034612782765179873 train acc 0.7306542476453777\n",
      "epoch 2 batch id 182401 / 225000 loss 0.17846214771270752 train acc 0.7306689656306709\n",
      "epoch 2 batch id 182501 / 225000 loss 1.9489126205444336 train acc 0.7306658593651542\n",
      "epoch 2 batch id 182601 / 225000 loss 1.6902815103530884 train acc 0.7306791857656858\n",
      "epoch 2 batch id 182701 / 225000 loss 3.1106200218200684 train acc 0.7306829190863761\n",
      "epoch 2 batch id 182801 / 225000 loss 3.503469467163086 train acc 0.7307030596112712\n",
      "epoch 2 batch id 182901 / 225000 loss 0.24415552616119385 train acc 0.730720444393415\n",
      "epoch 2 batch id 183001 / 225000 loss 1.03739333152771 train acc 0.7307255151611194\n",
      "epoch 2 batch id 183101 / 225000 loss 0.13852256536483765 train acc 0.7307455994232691\n",
      "epoch 2 batch id 183201 / 225000 loss 0.9059710502624512 train acc 0.7307724848663489\n",
      "epoch 2 batch id 183301 / 225000 loss 2.4455320835113525 train acc 0.7307747911904463\n",
      "epoch 2 batch id 183401 / 225000 loss 1.2723302841186523 train acc 0.7307839106656997\n",
      "epoch 2 batch id 183501 / 225000 loss 0.7407305836677551 train acc 0.7307998321535033\n",
      "epoch 2 batch id 183601 / 225000 loss 2.7059326171875 train acc 0.7308062047592333\n",
      "epoch 2 batch id 183701 / 225000 loss 1.0896508693695068 train acc 0.7308438712908476\n",
      "epoch 2 batch id 183801 / 225000 loss 0.06722289323806763 train acc 0.7308801366695502\n",
      "epoch 2 batch id 183901 / 225000 loss 0.006624629721045494 train acc 0.7308946117748136\n",
      "epoch 2 batch id 184001 / 225000 loss 1.283777117729187 train acc 0.7309063537698165\n",
      "epoch 2 batch id 184101 / 225000 loss 0.6706079244613647 train acc 0.7309207989092944\n",
      "epoch 2 batch id 184201 / 225000 loss 0.050901059061288834 train acc 0.7309202990211779\n",
      "epoch 2 batch id 184301 / 225000 loss 3.0614936351776123 train acc 0.7309211561521641\n",
      "epoch 2 batch id 184401 / 225000 loss 1.5456480979919434 train acc 0.7309247238355541\n",
      "epoch 2 batch id 184501 / 225000 loss 0.9268227815628052 train acc 0.7309350626825871\n",
      "epoch 2 batch id 184601 / 225000 loss 0.007513910066336393 train acc 0.7309575787780132\n",
      "epoch 2 batch id 184701 / 225000 loss 0.004403736907988787 train acc 0.7309787169533463\n",
      "epoch 2 batch id 184801 / 225000 loss 0.08517730236053467 train acc 0.7310025378650549\n",
      "epoch 2 batch id 184901 / 225000 loss 1.178459882736206 train acc 0.7310236288608498\n",
      "epoch 2 batch id 185001 / 225000 loss 0.0017361149657517672 train acc 0.7310365889914109\n",
      "epoch 2 batch id 185101 / 225000 loss 3.8503432273864746 train acc 0.7310603400305778\n",
      "epoch 2 batch id 185201 / 225000 loss 0.17035338282585144 train acc 0.7310800157666535\n",
      "epoch 2 batch id 185301 / 225000 loss 2.792771339416504 train acc 0.7310969719537401\n",
      "epoch 2 batch id 185401 / 225000 loss 0.377252459526062 train acc 0.7311139098494615\n",
      "epoch 2 batch id 185501 / 225000 loss 0.7388564348220825 train acc 0.7311146570638434\n",
      "epoch 2 batch id 185601 / 225000 loss 0.924659252166748 train acc 0.7311396490320634\n",
      "epoch 2 batch id 185701 / 225000 loss 0.019134406000375748 train acc 0.7311551903328469\n",
      "epoch 2 batch id 185801 / 225000 loss 4.033236026763916 train acc 0.7311612962255316\n",
      "epoch 2 batch id 185901 / 225000 loss 1.766073226928711 train acc 0.7311673955492439\n",
      "epoch 2 batch id 186001 / 225000 loss 1.0993603467941284 train acc 0.7311949935753034\n",
      "epoch 2 batch id 186101 / 225000 loss 2.2025275230407715 train acc 0.7312171885159134\n",
      "epoch 2 batch id 186201 / 225000 loss 0.005493855103850365 train acc 0.7312433875220864\n",
      "epoch 2 batch id 186301 / 225000 loss 0.5864014625549316 train acc 0.7312628488306557\n",
      "epoch 2 batch id 186401 / 225000 loss 2.0581979751586914 train acc 0.7312822892581048\n",
      "epoch 2 batch id 186501 / 225000 loss 1.59963059425354 train acc 0.7313043897887948\n",
      "epoch 2 batch id 186601 / 225000 loss 1.183412790298462 train acc 0.7313036907626432\n",
      "epoch 2 batch id 186701 / 225000 loss 1.8019754886627197 train acc 0.7313257561555643\n",
      "epoch 2 batch id 186801 / 225000 loss 0.06143539771437645 train acc 0.7313317380527942\n",
      "epoch 2 batch id 186901 / 225000 loss 0.0725608691573143 train acc 0.7313189870573191\n",
      "epoch 2 batch id 187001 / 225000 loss 2.1500205993652344 train acc 0.7313289768503912\n",
      "epoch 2 batch id 187101 / 225000 loss 0.20048150420188904 train acc 0.7313269303745036\n",
      "epoch 2 batch id 187201 / 225000 loss 0.009267538785934448 train acc 0.7313342343256714\n",
      "epoch 2 batch id 187301 / 225000 loss 1.906636357307434 train acc 0.7313441999775762\n",
      "epoch 2 batch id 187401 / 225000 loss 1.5331968069076538 train acc 0.7313568230692472\n",
      "epoch 2 batch id 187501 / 225000 loss 1.6786487102508545 train acc 0.7313814326323593\n",
      "epoch 2 batch id 187601 / 225000 loss 0.45260384678840637 train acc 0.7313900245734298\n",
      "epoch 2 batch id 187701 / 225000 loss 0.0014708784874528646 train acc 0.7314039349816996\n",
      "epoch 2 batch id 187801 / 225000 loss 3.1007490158081055 train acc 0.7314098433980649\n",
      "epoch 2 batch id 187901 / 225000 loss 1.2184852361679077 train acc 0.7314157455255693\n",
      "epoch 2 batch id 188001 / 225000 loss 0.11184942722320557 train acc 0.7314229711544088\n",
      "epoch 2 batch id 188101 / 225000 loss 2.373589038848877 train acc 0.7314554414915391\n",
      "epoch 2 batch id 188201 / 225000 loss 0.00709695927798748 train acc 0.731454668147353\n",
      "epoch 2 batch id 188301 / 225000 loss 2.575474262237549 train acc 0.7314817765173844\n",
      "epoch 2 batch id 188401 / 225000 loss 0.5355643630027771 train acc 0.7314995674120626\n",
      "epoch 2 batch id 188501 / 225000 loss 1.8453072309494019 train acc 0.7315107081660044\n",
      "epoch 2 batch id 188601 / 225000 loss 0.3237155079841614 train acc 0.7315311159537861\n",
      "epoch 2 batch id 188701 / 225000 loss 1.404268741607666 train acc 0.7315647505842576\n",
      "epoch 2 batch id 188801 / 225000 loss 1.4006245136260986 train acc 0.7315745149654928\n",
      "epoch 2 batch id 188901 / 225000 loss 0.03308039531111717 train acc 0.7315617704511888\n",
      "epoch 2 batch id 189001 / 225000 loss 1.9110349416732788 train acc 0.731576817053878\n",
      "epoch 2 batch id 189101 / 225000 loss 2.705913543701172 train acc 0.7316103563704053\n",
      "epoch 2 batch id 189201 / 225000 loss 0.40763238072395325 train acc 0.7316200760038266\n",
      "epoch 2 batch id 189301 / 225000 loss 0.008183740079402924 train acc 0.7316443124970285\n",
      "epoch 2 batch id 189401 / 225000 loss 4.5387163162231445 train acc 0.731642124381603\n",
      "epoch 2 batch id 189501 / 225000 loss 1.1712939739227295 train acc 0.731641257829774\n",
      "epoch 2 batch id 189601 / 225000 loss 2.5949931144714355 train acc 0.7316483035427028\n",
      "epoch 2 batch id 189701 / 225000 loss 2.006511926651001 train acc 0.7316474346471553\n",
      "epoch 2 batch id 189801 / 225000 loss 1.224899172782898 train acc 0.731637346483949\n",
      "epoch 2 batch id 189901 / 225000 loss 3.202230453491211 train acc 0.7316312183716779\n",
      "epoch 2 batch id 190001 / 225000 loss 1.7565960884094238 train acc 0.7316408861005995\n",
      "epoch 2 batch id 190101 / 225000 loss 0.0009421422146260738 train acc 0.7316558040199683\n",
      "epoch 2 batch id 190201 / 225000 loss 0.38429775834083557 train acc 0.7316759638487705\n",
      "epoch 2 batch id 190301 / 225000 loss 1.6424092054367065 train acc 0.7316974161985487\n",
      "epoch 2 batch id 190401 / 225000 loss 1.6862061023712158 train acc 0.7317109679045803\n",
      "epoch 2 batch id 190501 / 225000 loss 0.4976271390914917 train acc 0.7317271300413121\n",
      "epoch 2 batch id 190601 / 225000 loss 0.732568085193634 train acc 0.7317327820945325\n",
      "epoch 2 batch id 190701 / 225000 loss 1.0377269983291626 train acc 0.7317541596530694\n",
      "epoch 2 batch id 190801 / 225000 loss 0.8947330713272095 train acc 0.7317676532093648\n",
      "epoch 2 batch id 190901 / 225000 loss 0.3110310435295105 train acc 0.7317785134703327\n",
      "epoch 2 batch id 191001 / 225000 loss 0.011163792572915554 train acc 0.7318011424023958\n",
      "epoch 2 batch id 191101 / 225000 loss 1.3752065896987915 train acc 0.7318185148167723\n",
      "epoch 2 batch id 191201 / 225000 loss 1.3541710376739502 train acc 0.731817563715671\n",
      "epoch 2 batch id 191301 / 225000 loss 0.794419527053833 train acc 0.731838829906796\n",
      "epoch 2 batch id 191401 / 225000 loss 1.6551762819290161 train acc 0.7318535430849369\n",
      "epoch 2 batch id 191501 / 225000 loss 2.0815911293029785 train acc 0.7318577970872214\n",
      "epoch 2 batch id 191601 / 225000 loss 1.4962869882583618 train acc 0.7318698754181867\n",
      "epoch 2 batch id 191701 / 225000 loss 0.9692330956459045 train acc 0.7318923740616898\n",
      "epoch 2 batch id 191801 / 225000 loss 2.1094770431518555 train acc 0.7318952977304602\n",
      "epoch 2 batch id 191901 / 225000 loss 0.0025549426209181547 train acc 0.7319086403927025\n",
      "epoch 2 batch id 192001 / 225000 loss 1.3497833013534546 train acc 0.7319258753860657\n",
      "epoch 2 batch id 192101 / 225000 loss 2.2140581607818604 train acc 0.7319339826445463\n",
      "epoch 2 batch id 192201 / 225000 loss 0.0035697086714208126 train acc 0.7319446829100785\n",
      "epoch 2 batch id 192301 / 225000 loss 0.1476900577545166 train acc 0.7319696725446045\n",
      "epoch 2 batch id 192401 / 225000 loss 0.01435986626893282 train acc 0.731989438724331\n",
      "epoch 2 batch id 192501 / 225000 loss 1.3777151107788086 train acc 0.7319845091713809\n",
      "epoch 2 batch id 192601 / 225000 loss 2.2321131229400635 train acc 0.7319860748386561\n",
      "epoch 2 batch id 192701 / 225000 loss 0.00606335885822773 train acc 0.732005801734293\n",
      "epoch 2 batch id 192801 / 225000 loss 6.1721014976501465 train acc 0.7320099480811821\n",
      "epoch 2 batch id 192901 / 225000 loss 2.276435136795044 train acc 0.732025754143317\n",
      "epoch 2 batch id 193001 / 225000 loss 0.5384888052940369 train acc 0.7320337718457417\n",
      "epoch 2 batch id 193101 / 225000 loss 1.2188093662261963 train acc 0.732054727836728\n",
      "epoch 2 batch id 193201 / 225000 loss 0.6805443167686462 train acc 0.732061428253477\n",
      "epoch 2 batch id 193301 / 225000 loss 0.0015808080788701773 train acc 0.7320797616153046\n",
      "epoch 2 batch id 193401 / 225000 loss 1.49440336227417 train acc 0.7320825642059762\n",
      "epoch 2 batch id 193501 / 225000 loss 0.0041613089852035046 train acc 0.7320879478659025\n",
      "epoch 2 batch id 193601 / 225000 loss 0.8352020978927612 train acc 0.7320959085955134\n",
      "epoch 2 batch id 193701 / 225000 loss 0.04660675674676895 train acc 0.7321141862974379\n",
      "epoch 2 batch id 193801 / 225000 loss 0.21494147181510925 train acc 0.7321427650012126\n",
      "epoch 2 batch id 193901 / 225000 loss 1.5340272188186646 train acc 0.7321506851434495\n",
      "epoch 2 batch id 194001 / 225000 loss 0.023206651210784912 train acc 0.7321624630800873\n",
      "epoch 2 batch id 194101 / 225000 loss 0.13544532656669617 train acc 0.7321729408915977\n",
      "epoch 2 batch id 194201 / 225000 loss 1.0803309679031372 train acc 0.7321834079124206\n",
      "epoch 2 batch id 194301 / 225000 loss 3.3991475105285645 train acc 0.7321848575148867\n",
      "epoch 2 batch id 194401 / 225000 loss 2.924497127532959 train acc 0.7321798756179237\n",
      "epoch 2 batch id 194501 / 225000 loss 5.9474663734436035 train acc 0.7321851815671899\n",
      "epoch 2 batch id 194601 / 225000 loss 1.6188726425170898 train acc 0.7322174603419304\n",
      "epoch 2 batch id 194701 / 225000 loss 1.7976467609405518 train acc 0.7322253095772492\n",
      "epoch 2 batch id 194801 / 225000 loss 0.0014888305449858308 train acc 0.7322344341148146\n",
      "epoch 2 batch id 194901 / 225000 loss 1.051196575164795 train acc 0.7322589417191292\n",
      "epoch 2 batch id 195001 / 225000 loss 0.002283776178956032 train acc 0.732241116712222\n",
      "epoch 2 batch id 195101 / 225000 loss 0.009858574718236923 train acc 0.7322450935669218\n",
      "epoch 2 batch id 195201 / 225000 loss 0.810038685798645 train acc 0.7322541892715714\n",
      "epoch 2 batch id 195301 / 225000 loss 0.02944072335958481 train acc 0.7322683959631543\n",
      "epoch 2 batch id 195401 / 225000 loss 1.645533561706543 train acc 0.732283867533943\n",
      "epoch 2 batch id 195501 / 225000 loss 0.17029133439064026 train acc 0.7323287348913816\n",
      "epoch 2 batch id 195601 / 225000 loss 2.8279263973236084 train acc 0.732342881682609\n",
      "epoch 2 batch id 195701 / 225000 loss 2.106436252593994 train acc 0.7323634013111839\n",
      "epoch 2 batch id 195801 / 225000 loss 0.40410757064819336 train acc 0.7323609174621172\n",
      "epoch 2 batch id 195901 / 225000 loss 0.9815108180046082 train acc 0.7323928923282679\n",
      "epoch 2 batch id 196001 / 225000 loss 0.38994038105010986 train acc 0.7323967734858495\n",
      "epoch 2 batch id 196101 / 225000 loss 3.145643949508667 train acc 0.7324070249514281\n",
      "epoch 2 batch id 196201 / 225000 loss 0.2769150137901306 train acc 0.7324185401705394\n",
      "epoch 2 batch id 196301 / 225000 loss 0.24791930615901947 train acc 0.7324262229942792\n",
      "epoch 2 batch id 196401 / 225000 loss 0.010679537430405617 train acc 0.7324453541478914\n",
      "epoch 2 batch id 196501 / 225000 loss 1.5895559787750244 train acc 0.7324581045389083\n",
      "epoch 2 batch id 196601 / 225000 loss 0.862737774848938 train acc 0.732456854237771\n",
      "epoch 2 batch id 196701 / 225000 loss 0.006806038785725832 train acc 0.7324695858180691\n",
      "epoch 2 batch id 196801 / 225000 loss 0.1012110561132431 train acc 0.7324899263723254\n",
      "epoch 2 batch id 196901 / 225000 loss 0.6350454092025757 train acc 0.7325051675715207\n",
      "epoch 2 batch id 197001 / 225000 loss 0.46807780861854553 train acc 0.7324975507738539\n",
      "epoch 2 batch id 197101 / 225000 loss 0.05341293290257454 train acc 0.732498820401723\n",
      "epoch 2 batch id 197201 / 225000 loss 1.245769739151001 train acc 0.7325064274521934\n",
      "epoch 2 batch id 197301 / 225000 loss 2.7385709285736084 train acc 0.732522896488107\n",
      "epoch 2 batch id 197401 / 225000 loss 0.725506067276001 train acc 0.7325596121600194\n",
      "epoch 2 batch id 197501 / 225000 loss 2.544179677963257 train acc 0.7325684426914294\n",
      "epoch 2 batch id 197601 / 225000 loss 0.004987772554159164 train acc 0.7325823249882338\n",
      "epoch 2 batch id 197701 / 225000 loss 0.07172124832868576 train acc 0.7325721670603588\n",
      "epoch 2 batch id 197801 / 225000 loss 1.323270559310913 train acc 0.7325974085065293\n",
      "epoch 2 batch id 197901 / 225000 loss 0.25569266080856323 train acc 0.7326011490593781\n",
      "epoch 2 batch id 198001 / 225000 loss 0.002072762232273817 train acc 0.7325947848748239\n",
      "epoch 2 batch id 198101 / 225000 loss 0.9624195098876953 train acc 0.7326098808183704\n",
      "epoch 2 batch id 198201 / 225000 loss 2.8768317699432373 train acc 0.7326148707625088\n",
      "epoch 2 batch id 198301 / 225000 loss 1.5312674045562744 train acc 0.732609769996117\n",
      "epoch 2 batch id 198401 / 225000 loss 0.006873571779578924 train acc 0.7326298758574805\n",
      "epoch 2 batch id 198501 / 225000 loss 3.357267141342163 train acc 0.732641145384658\n",
      "epoch 2 batch id 198601 / 225000 loss 0.48358529806137085 train acc 0.7326473683415491\n",
      "epoch 2 batch id 198701 / 225000 loss 0.006631266325712204 train acc 0.7326711994403652\n",
      "epoch 2 batch id 198801 / 225000 loss 2.6544675827026367 train acc 0.7326862037917314\n",
      "epoch 2 batch id 198901 / 225000 loss 0.8565509915351868 train acc 0.7327024499625442\n",
      "epoch 2 batch id 199001 / 225000 loss 1.4440150260925293 train acc 0.7326960668539354\n",
      "epoch 2 batch id 199101 / 225000 loss 1.7234588861465454 train acc 0.7326947127337382\n",
      "epoch 2 batch id 199201 / 225000 loss 2.1130988597869873 train acc 0.732707165124673\n",
      "epoch 2 batch id 199301 / 225000 loss 0.3743489980697632 train acc 0.7327208594036156\n",
      "epoch 2 batch id 199401 / 225000 loss 1.9432135820388794 train acc 0.7327383012121303\n",
      "epoch 2 batch id 199501 / 225000 loss 2.571772575378418 train acc 0.7327306630041954\n",
      "epoch 2 batch id 199601 / 225000 loss 2.5199036598205566 train acc 0.732730547442147\n",
      "epoch 2 batch id 199701 / 225000 loss 1.3381277322769165 train acc 0.7327279282527378\n",
      "epoch 2 batch id 199801 / 225000 loss 0.008974166586995125 train acc 0.7327403266249919\n",
      "epoch 2 batch id 199901 / 225000 loss 3.763050079345703 train acc 0.7327552138308463\n",
      "epoch 2 batch id 200001 / 225000 loss 0.027259420603513718 train acc 0.7327813360933195\n",
      "epoch 2 batch id 200101 / 225000 loss 2.4772989749908447 train acc 0.7327874423416175\n",
      "epoch 2 batch id 200201 / 225000 loss 0.04001753032207489 train acc 0.7328110249199554\n",
      "epoch 2 batch id 200301 / 225000 loss 1.5224390029907227 train acc 0.7328370801943076\n",
      "epoch 2 batch id 200401 / 225000 loss 4.0924072265625 train acc 0.7328581194704618\n",
      "epoch 2 batch id 200501 / 225000 loss 0.0058951303362846375 train acc 0.732869162747318\n",
      "epoch 2 batch id 200601 / 225000 loss 2.883329391479492 train acc 0.7328864262890016\n",
      "epoch 2 batch id 200701 / 225000 loss 1.6972413063049316 train acc 0.732909900797704\n",
      "epoch 2 batch id 200801 / 225000 loss 0.23245449364185333 train acc 0.7329507821176189\n",
      "epoch 2 batch id 200901 / 225000 loss 0.9872209429740906 train acc 0.7329605128894331\n",
      "epoch 2 batch id 201001 / 225000 loss 1.908934473991394 train acc 0.7329864030527211\n",
      "epoch 2 batch id 201101 / 225000 loss 1.0862526893615723 train acc 0.7329936201212326\n",
      "epoch 2 batch id 201201 / 225000 loss 0.019087597727775574 train acc 0.7329958598615315\n",
      "epoch 2 batch id 201301 / 225000 loss 1.7392367124557495 train acc 0.7330204519600002\n",
      "epoch 2 batch id 201401 / 225000 loss 0.3116418123245239 train acc 0.7330226761535444\n",
      "epoch 2 batch id 201501 / 225000 loss 0.003062549978494644 train acc 0.7330360643371497\n",
      "epoch 2 batch id 201601 / 225000 loss 1.4642000198364258 train acc 0.7330556396049622\n",
      "epoch 2 batch id 201701 / 225000 loss 2.0357327461242676 train acc 0.7330739560041845\n",
      "epoch 2 batch id 201801 / 225000 loss 2.514910936355591 train acc 0.7330959707830982\n",
      "epoch 2 batch id 201901 / 225000 loss 1.355101466178894 train acc 0.7331154872932774\n",
      "epoch 2 batch id 202001 / 225000 loss 1.660954475402832 train acc 0.7331139449804704\n",
      "epoch 2 batch id 202101 / 225000 loss 0.003654799424111843 train acc 0.7331408553149168\n",
      "epoch 2 batch id 202201 / 225000 loss 0.6429388523101807 train acc 0.7331467203426294\n",
      "epoch 2 batch id 202301 / 225000 loss 1.961338758468628 train acc 0.7331501080073751\n",
      "epoch 2 batch id 202401 / 225000 loss 0.004734911024570465 train acc 0.7331781957599024\n",
      "epoch 2 batch id 202501 / 225000 loss 1.6833292245864868 train acc 0.7331852682208977\n",
      "epoch 2 batch id 202601 / 225000 loss 3.5849835872650146 train acc 0.7331910997477801\n",
      "epoch 2 batch id 202701 / 225000 loss 3.333160400390625 train acc 0.7332006255519213\n",
      "epoch 2 batch id 202801 / 225000 loss 0.7489655017852783 train acc 0.7332138401684409\n",
      "epoch 2 batch id 202901 / 225000 loss 0.5078102350234985 train acc 0.7332221132473472\n",
      "epoch 2 batch id 203001 / 225000 loss 2.5514883995056152 train acc 0.733224220570342\n",
      "epoch 2 batch id 203101 / 225000 loss 0.19870249927043915 train acc 0.7332337113061974\n",
      "epoch 2 batch id 203201 / 225000 loss 3.47438907623291 train acc 0.7332444230097293\n",
      "epoch 2 batch id 203301 / 225000 loss 0.004798071924597025 train acc 0.7332563538792234\n",
      "epoch 2 batch id 203401 / 225000 loss 0.35238412022590637 train acc 0.7332695021165088\n",
      "epoch 2 batch id 203501 / 225000 loss 0.02340679056942463 train acc 0.7332936938884821\n",
      "epoch 2 batch id 203601 / 225000 loss 0.040828339755535126 train acc 0.7333104945457046\n",
      "epoch 2 batch id 203701 / 225000 loss 2.082732915878296 train acc 0.733305187505216\n",
      "epoch 2 batch id 203801 / 225000 loss 0.00830753892660141 train acc 0.7333170592882272\n",
      "epoch 2 batch id 203901 / 225000 loss 1.0659427642822266 train acc 0.7333252411709604\n",
      "epoch 2 batch id 204001 / 225000 loss 0.0052184490486979485 train acc 0.7333334150322792\n",
      "epoch 2 batch id 204101 / 225000 loss 0.6985482573509216 train acc 0.7333391311164571\n",
      "epoch 2 batch id 204201 / 225000 loss 1.2468457221984863 train acc 0.7333546358734776\n",
      "epoch 2 batch id 204301 / 225000 loss 1.0390446186065674 train acc 0.7333627833441834\n",
      "epoch 2 batch id 204401 / 225000 loss 0.796389102935791 train acc 0.7333623612408942\n",
      "epoch 2 batch id 204501 / 225000 loss 3.5740222930908203 train acc 0.7333851668207001\n",
      "epoch 2 batch id 204601 / 225000 loss 3.337958574295044 train acc 0.7333908436420155\n",
      "epoch 2 batch id 204701 / 225000 loss 4.333639144897461 train acc 0.7334221620803025\n",
      "epoch 2 batch id 204801 / 225000 loss 0.039527248591184616 train acc 0.7334143876250604\n",
      "epoch 2 batch id 204901 / 225000 loss 0.7112821340560913 train acc 0.7334176016710509\n",
      "epoch 2 batch id 205001 / 225000 loss 1.616086721420288 train acc 0.7334500807313135\n",
      "epoch 2 batch id 205101 / 225000 loss 0.09329146146774292 train acc 0.7334825281202919\n",
      "epoch 2 batch id 205201 / 225000 loss 3.0356268882751465 train acc 0.733482049307752\n",
      "epoch 2 batch id 205301 / 225000 loss 1.3020433187484741 train acc 0.7334767000647829\n",
      "epoch 2 batch id 205401 / 225000 loss 0.4254221022129059 train acc 0.733479875949971\n",
      "epoch 2 batch id 205501 / 225000 loss 0.20840270817279816 train acc 0.7334891314397497\n",
      "epoch 2 batch id 205601 / 225000 loss 0.5000367760658264 train acc 0.7334922981892111\n",
      "epoch 2 batch id 205701 / 225000 loss 0.010046301409602165 train acc 0.7335039693535763\n",
      "epoch 2 batch id 205801 / 225000 loss 1.0840678215026855 train acc 0.7334986224556732\n",
      "epoch 2 batch id 205901 / 225000 loss 0.9777014255523682 train acc 0.733493280751429\n",
      "epoch 2 batch id 206001 / 225000 loss 0.01344946026802063 train acc 0.7335146431328003\n",
      "epoch 2 batch id 206101 / 225000 loss 0.009007299318909645 train acc 0.7335262808040718\n",
      "epoch 2 batch id 206201 / 225000 loss 2.161369562149048 train acc 0.7335403320061493\n",
      "epoch 2 batch id 206301 / 225000 loss 0.7389815449714661 train acc 0.7335422513705702\n",
      "epoch 2 batch id 206401 / 225000 loss 0.8144526481628418 train acc 0.7335526475162426\n",
      "epoch 2 batch id 206501 / 225000 loss 1.5084761381149292 train acc 0.7335751400719609\n",
      "epoch 2 batch id 206601 / 225000 loss 0.019738657400012016 train acc 0.7335976108537713\n",
      "epoch 2 batch id 206701 / 225000 loss 1.5709271430969238 train acc 0.7335874040280405\n",
      "epoch 2 batch id 206801 / 225000 loss 0.2903525233268738 train acc 0.7335844604233055\n",
      "epoch 2 batch id 206901 / 225000 loss 0.036597732454538345 train acc 0.7335875612007675\n",
      "epoch 2 batch id 207001 / 225000 loss 0.03490966558456421 train acc 0.7335906589823238\n",
      "epoch 2 batch id 207101 / 225000 loss 1.4412003755569458 train acc 0.7336034108961328\n",
      "epoch 2 batch id 207201 / 225000 loss 0.030063023790717125 train acc 0.7336101177117871\n",
      "epoch 2 batch id 207301 / 225000 loss 0.0376642569899559 train acc 0.7336288778153506\n",
      "epoch 2 batch id 207401 / 225000 loss 0.5347621440887451 train acc 0.7336331550956842\n",
      "epoch 2 batch id 207501 / 225000 loss 0.08996059745550156 train acc 0.7336458619476532\n",
      "epoch 2 batch id 207601 / 225000 loss 1.3612151145935059 train acc 0.73364651422681\n",
      "epoch 2 batch id 207701 / 225000 loss 0.0020524542778730392 train acc 0.7336519804911869\n",
      "epoch 2 batch id 207801 / 225000 loss 1.175155520439148 train acc 0.7336514261240321\n",
      "epoch 2 batch id 207901 / 225000 loss 0.04711129143834114 train acc 0.7336701122168725\n",
      "epoch 2 batch id 208001 / 225000 loss 1.0186761617660522 train acc 0.733695991846193\n",
      "epoch 2 batch id 208101 / 225000 loss 1.826236367225647 train acc 0.7337014238278529\n",
      "epoch 2 batch id 208201 / 225000 loss 2.1564671993255615 train acc 0.7337080513542202\n",
      "epoch 2 batch id 208301 / 225000 loss 0.9659102559089661 train acc 0.733709871772099\n",
      "epoch 2 batch id 208401 / 225000 loss 0.6327480673789978 train acc 0.7337212873258766\n",
      "epoch 2 batch id 208501 / 225000 loss 2.1965243816375732 train acc 0.733742284209668\n",
      "epoch 2 batch id 208601 / 225000 loss 2.93351674079895 train acc 0.7337464825192592\n",
      "epoch 2 batch id 208701 / 225000 loss 0.8454753756523132 train acc 0.7337494789196027\n",
      "epoch 2 batch id 208801 / 225000 loss 0.0033975245896726847 train acc 0.7337620509480318\n",
      "epoch 2 batch id 208901 / 225000 loss 0.5973246097564697 train acc 0.7337602500706076\n",
      "epoch 2 batch id 209001 / 225000 loss 1.1607011556625366 train acc 0.7337716087482835\n",
      "epoch 2 batch id 209101 / 225000 loss 2.8713488578796387 train acc 0.7337853477506086\n",
      "epoch 2 batch id 209201 / 225000 loss 2.0867791175842285 train acc 0.7337907084574166\n",
      "epoch 2 batch id 209301 / 225000 loss 0.3193136751651764 train acc 0.7337900917816924\n",
      "epoch 2 batch id 209401 / 225000 loss 2.2868897914886475 train acc 0.7337990267477232\n",
      "epoch 2 batch id 209501 / 225000 loss 0.4980878233909607 train acc 0.7338222729247116\n",
      "epoch 2 batch id 209601 / 225000 loss 0.9782476425170898 train acc 0.7338311840115267\n",
      "epoch 2 batch id 209701 / 225000 loss 3.3603761196136475 train acc 0.7338365100786358\n",
      "epoch 2 batch id 209801 / 225000 loss 2.0524325370788574 train acc 0.7338740044137063\n",
      "epoch 2 batch id 209901 / 225000 loss 0.7343941330909729 train acc 0.7338876422694508\n",
      "epoch 2 batch id 210001 / 225000 loss 0.0019595790654420853 train acc 0.7339012671368231\n",
      "epoch 2 batch id 210101 / 225000 loss 0.8592323064804077 train acc 0.7339220184577894\n",
      "epoch 2 batch id 210201 / 225000 loss 3.411585807800293 train acc 0.7339284779805996\n",
      "epoch 2 batch id 210301 / 225000 loss 2.478543758392334 train acc 0.733940875221706\n",
      "epoch 2 batch id 210401 / 225000 loss 0.710891842842102 train acc 0.733941378605615\n",
      "epoch 2 batch id 210501 / 225000 loss 2.0806119441986084 train acc 0.7339585085106484\n",
      "epoch 2 batch id 210601 / 225000 loss 0.5889527797698975 train acc 0.7339744350691593\n",
      "epoch 2 batch id 210701 / 225000 loss 0.7968819737434387 train acc 0.7339879734790058\n",
      "epoch 2 batch id 210801 / 225000 loss 0.0445713996887207 train acc 0.7339979411862373\n",
      "epoch 2 batch id 210901 / 225000 loss 0.7491215467453003 train acc 0.7340173825633828\n",
      "epoch 2 batch id 211001 / 225000 loss 0.5724989771842957 train acc 0.7340308813702304\n",
      "epoch 2 batch id 211101 / 225000 loss 0.008961079642176628 train acc 0.7340491044571082\n",
      "epoch 2 batch id 211201 / 225000 loss 0.003613242879509926 train acc 0.7340471872765754\n",
      "epoch 2 batch id 211301 / 225000 loss 2.0245823860168457 train acc 0.7340452719106867\n",
      "epoch 2 batch id 211401 / 225000 loss 1.3761107921600342 train acc 0.7340622797432368\n",
      "epoch 2 batch id 211501 / 225000 loss 0.0027111873496323824 train acc 0.7340674512177248\n",
      "epoch 2 batch id 211601 / 225000 loss 2.675053119659424 train acc 0.7340797066176435\n",
      "epoch 2 batch id 211701 / 225000 loss 0.38575389981269836 train acc 0.7340801413314061\n",
      "epoch 2 batch id 211801 / 225000 loss 0.003124898299574852 train acc 0.7340687721021147\n",
      "epoch 2 batch id 211901 / 225000 loss 0.001768452231772244 train acc 0.734064492380876\n",
      "epoch 2 batch id 212001 / 225000 loss 0.0020499832462519407 train acc 0.7340826222517818\n",
      "epoch 2 batch id 212101 / 225000 loss 0.003635276574641466 train acc 0.7340818760873358\n",
      "epoch 2 batch id 212201 / 225000 loss 1.9715336561203003 train acc 0.7340693493433113\n",
      "epoch 2 batch id 212301 / 225000 loss 2.3482346534729004 train acc 0.734089806454044\n",
      "epoch 2 batch id 212401 / 225000 loss 1.06865394115448 train acc 0.7340925890179425\n",
      "epoch 2 batch id 212501 / 225000 loss 2.307277202606201 train acc 0.734104780683385\n",
      "epoch 2 batch id 212601 / 225000 loss 0.024752037599682808 train acc 0.7341134331447171\n",
      "epoch 2 batch id 212701 / 225000 loss 1.0117589235305786 train acc 0.7341314803409481\n",
      "epoch 2 batch id 212801 / 225000 loss 0.013032851740717888 train acc 0.7341530349951363\n",
      "epoch 2 batch id 212901 / 225000 loss 0.777309000492096 train acc 0.7341510843067904\n",
      "epoch 2 batch id 213001 / 225000 loss 0.6596654653549194 train acc 0.7341467880432486\n",
      "epoch 2 batch id 213101 / 225000 loss 1.2269264459609985 train acc 0.7341413226592085\n",
      "epoch 2 batch id 213201 / 225000 loss 3.0008623600006104 train acc 0.7341464158235655\n",
      "epoch 2 batch id 213301 / 225000 loss 1.428808331489563 train acc 0.7341643967913887\n",
      "epoch 2 batch id 213401 / 225000 loss 1.267910361289978 train acc 0.7341823609073996\n",
      "epoch 2 batch id 213501 / 225000 loss 2.563236713409424 train acc 0.7341850857841415\n",
      "epoch 2 batch id 213601 / 225000 loss 0.016121691092848778 train acc 0.7341796152639735\n",
      "epoch 2 batch id 213701 / 225000 loss 3.4872190952301025 train acc 0.7341846785929874\n",
      "epoch 2 batch id 213801 / 225000 loss 1.42391037940979 train acc 0.7341862292505648\n",
      "epoch 2 batch id 213901 / 225000 loss 1.6898105144500732 train acc 0.7342076474630788\n",
      "epoch 2 batch id 214001 / 225000 loss 1.2310441732406616 train acc 0.7342138588137439\n",
      "epoch 2 batch id 214101 / 225000 loss 0.93156498670578 train acc 0.7342422501529652\n",
      "epoch 2 batch id 214201 / 225000 loss 0.42120039463043213 train acc 0.73424960667784\n",
      "epoch 2 batch id 214301 / 225000 loss 1.520005226135254 train acc 0.7342569563371146\n",
      "epoch 2 batch id 214401 / 225000 loss 0.897512674331665 train acc 0.7342584689437083\n",
      "epoch 2 batch id 214501 / 225000 loss 0.658279538154602 train acc 0.7342599801399528\n",
      "epoch 2 batch id 214601 / 225000 loss 0.6649374961853027 train acc 0.7342603249751866\n",
      "epoch 2 batch id 214701 / 225000 loss 0.009460927918553352 train acc 0.7342583406691165\n",
      "epoch 2 batch id 214801 / 225000 loss 0.028335515409708023 train acc 0.7342784717017146\n",
      "epoch 2 batch id 214901 / 225000 loss 0.8630685210227966 train acc 0.7342834607563483\n",
      "epoch 2 batch id 215001 / 225000 loss 0.4136674106121063 train acc 0.7342896079553118\n",
      "epoch 2 batch id 215101 / 225000 loss 0.08618605881929398 train acc 0.7343015606622005\n",
      "epoch 2 batch id 215201 / 225000 loss 1.1274709701538086 train acc 0.734315825669955\n",
      "epoch 2 batch id 215301 / 225000 loss 2.1213443279266357 train acc 0.73432891626142\n",
      "epoch 2 batch id 215401 / 225000 loss 0.08988861739635468 train acc 0.7343419946982604\n",
      "epoch 2 batch id 215501 / 225000 loss 0.7251014113426208 train acc 0.7343341794237613\n",
      "epoch 2 batch id 215601 / 225000 loss 1.1823110580444336 train acc 0.7343356477938414\n",
      "epoch 2 batch id 215701 / 225000 loss 1.1434158086776733 train acc 0.7343452278848962\n",
      "epoch 2 batch id 215801 / 225000 loss 4.086314678192139 train acc 0.7343547990973165\n",
      "epoch 2 batch id 215901 / 225000 loss 0.9066076278686523 train acc 0.7343481503096326\n",
      "epoch 2 batch id 216001 / 225000 loss 1.4084978103637695 train acc 0.7343449798843524\n",
      "epoch 2 batch id 216101 / 225000 loss 0.005596010014414787 train acc 0.7343533810579312\n",
      "epoch 2 batch id 216201 / 225000 loss 1.0879923105239868 train acc 0.7343548364716167\n",
      "epoch 2 batch id 216301 / 225000 loss 0.8086091876029968 train acc 0.734367848507404\n",
      "epoch 2 batch id 216401 / 225000 loss 2.072200059890747 train acc 0.7343820037800195\n",
      "epoch 2 batch id 216501 / 225000 loss 1.1943453550338745 train acc 0.7343973007053085\n",
      "epoch 2 batch id 216601 / 225000 loss 2.908121347427368 train acc 0.734407966722222\n",
      "epoch 2 batch id 216701 / 225000 loss 0.007215196266770363 train acc 0.7344151619051135\n",
      "epoch 2 batch id 216801 / 225000 loss 3.0566563606262207 train acc 0.7344235035816256\n",
      "epoch 2 batch id 216901 / 225000 loss 2.653818130493164 train acc 0.7344387531638858\n",
      "epoch 2 batch id 217001 / 225000 loss 3.804563522338867 train acc 0.7344413159386363\n",
      "epoch 2 batch id 217101 / 225000 loss 2.6437571048736572 train acc 0.7344404217391906\n",
      "epoch 2 batch id 217201 / 225000 loss 2.376833438873291 train acc 0.7344418303783131\n",
      "epoch 2 batch id 217301 / 225000 loss 0.10259693115949631 train acc 0.7344386358093152\n",
      "epoch 2 batch id 217401 / 225000 loss 1.1296764612197876 train acc 0.7344492435637371\n",
      "epoch 2 batch id 217501 / 225000 loss 1.1357096433639526 train acc 0.7344460485239148\n",
      "epoch 2 batch id 217601 / 225000 loss 0.05251273512840271 train acc 0.7344589409056025\n",
      "epoch 2 batch id 217701 / 225000 loss 0.004104971885681152 train acc 0.7344764148993345\n",
      "epoch 2 batch id 217801 / 225000 loss 0.3260475993156433 train acc 0.7344674726011359\n",
      "epoch 2 batch id 217901 / 225000 loss 2.6535162925720215 train acc 0.7344734535408282\n",
      "epoch 2 batch id 218001 / 225000 loss 3.8216943740844727 train acc 0.7344748418585236\n",
      "epoch 2 batch id 218101 / 225000 loss 0.0292329341173172 train acc 0.7344831064506812\n",
      "epoch 2 batch id 218201 / 225000 loss 0.20401988923549652 train acc 0.7344856348046067\n",
      "epoch 2 batch id 218301 / 225000 loss 0.9696975350379944 train acc 0.7344847252188492\n",
      "epoch 2 batch id 218401 / 225000 loss 0.18415799736976624 train acc 0.7344906845664626\n",
      "epoch 2 batch id 218501 / 225000 loss 1.555342435836792 train acc 0.7344932059807506\n",
      "epoch 2 batch id 218601 / 225000 loss 0.061098430305719376 train acc 0.7345037305410314\n",
      "epoch 2 batch id 218701 / 225000 loss 1.1092736721038818 train acc 0.7345302490615041\n",
      "epoch 2 batch id 218801 / 225000 loss 0.7491012811660767 train acc 0.7345373192992719\n",
      "epoch 2 batch id 218901 / 225000 loss 1.6508281230926514 train acc 0.7345695085906414\n",
      "epoch 2 batch id 219001 / 225000 loss 0.002752530388534069 train acc 0.7345765544449568\n",
      "epoch 2 batch id 219101 / 225000 loss 0.006274860817939043 train acc 0.7345950041305152\n",
      "epoch 2 batch id 219201 / 225000 loss 2.0679433345794678 train acc 0.7346145774882414\n",
      "epoch 2 batch id 219301 / 225000 loss 0.0019003336783498526 train acc 0.7345999334248362\n",
      "epoch 2 batch id 219401 / 225000 loss 3.867149829864502 train acc 0.7346035341680303\n",
      "epoch 2 batch id 219501 / 225000 loss 2.2781271934509277 train acc 0.7346139653122309\n",
      "epoch 2 batch id 219601 / 225000 loss 0.018413608893752098 train acc 0.7346130026730298\n",
      "epoch 2 batch id 219701 / 225000 loss 3.4465596675872803 train acc 0.7346143167304655\n",
      "epoch 2 batch id 219801 / 225000 loss 0.6553407907485962 train acc 0.7346486139735487\n",
      "epoch 2 batch id 219901 / 225000 loss 1.104029655456543 train acc 0.7346624162691393\n",
      "epoch 2 batch id 220001 / 225000 loss 3.87326717376709 train acc 0.7346784787341876\n",
      "epoch 2 batch id 220101 / 225000 loss 0.05446677654981613 train acc 0.7346831681818802\n",
      "epoch 2 batch id 220201 / 225000 loss 0.6298976540565491 train acc 0.7346946653284954\n",
      "epoch 2 batch id 220301 / 225000 loss 2.5665194988250732 train acc 0.7346993431713882\n",
      "epoch 2 batch id 220401 / 225000 loss 0.0038400329649448395 train acc 0.7347255683957877\n",
      "epoch 2 batch id 220501 / 225000 loss 1.9319785833358765 train acc 0.7347449671430062\n",
      "epoch 2 batch id 220601 / 225000 loss 2.0038352012634277 train acc 0.7347496158222311\n",
      "epoch 2 batch id 220701 / 225000 loss 1.0588690042495728 train acc 0.7347395344833054\n",
      "epoch 2 batch id 220801 / 225000 loss 1.1229207515716553 train acc 0.7347509748597153\n",
      "epoch 2 batch id 220901 / 225000 loss 1.8495374917984009 train acc 0.7347510875912739\n",
      "epoch 2 batch id 221001 / 225000 loss 0.2623935639858246 train acc 0.7347613811702209\n",
      "epoch 2 batch id 221101 / 225000 loss 2.5540153980255127 train acc 0.7347886260125464\n",
      "epoch 2 batch id 221201 / 225000 loss 2.0754470825195312 train acc 0.7347921121513917\n",
      "epoch 2 batch id 221301 / 225000 loss 1.390397548675537 train acc 0.7348046326044618\n",
      "epoch 2 batch id 221401 / 225000 loss 0.06373246014118195 train acc 0.7348092375373192\n",
      "epoch 2 batch id 221501 / 225000 loss 3.021304130554199 train acc 0.7348206102906985\n",
      "epoch 2 batch id 221601 / 225000 loss 0.03382030129432678 train acc 0.7348240757036295\n",
      "epoch 2 batch id 221701 / 225000 loss 4.344906806945801 train acc 0.7348286656352475\n",
      "epoch 2 batch id 221801 / 225000 loss 0.057171814143657684 train acc 0.734833251428082\n",
      "epoch 2 batch id 221901 / 225000 loss 3.805835247039795 train acc 0.7348502260016855\n",
      "epoch 2 batch id 222001 / 225000 loss 0.006682727951556444 train acc 0.7348638069197887\n",
      "epoch 2 batch id 222101 / 225000 loss 3.2771353721618652 train acc 0.7348773756083944\n",
      "epoch 2 batch id 222201 / 225000 loss 2.716179370880127 train acc 0.7348999329435961\n",
      "epoch 2 batch id 222301 / 225000 loss 0.9221583604812622 train acc 0.734912348572431\n",
      "epoch 2 batch id 222401 / 225000 loss 0.007880929857492447 train acc 0.7349090156968718\n",
      "epoch 2 batch id 222501 / 225000 loss 1.8469582796096802 train acc 0.7349180453121559\n",
      "epoch 2 batch id 222601 / 225000 loss 1.6169936656951904 train acc 0.7349248206432136\n",
      "epoch 2 batch id 222701 / 225000 loss 0.0774095207452774 train acc 0.7349450608663635\n",
      "epoch 2 batch id 222801 / 225000 loss 0.5423935651779175 train acc 0.7349518179900449\n",
      "epoch 2 batch id 222901 / 225000 loss 1.0374858379364014 train acc 0.7349608121991378\n",
      "epoch 2 batch id 223001 / 225000 loss 2.667672634124756 train acc 0.7349608297720638\n",
      "epoch 2 batch id 223101 / 225000 loss 4.082747459411621 train acc 0.7349608473292365\n",
      "epoch 2 batch id 223201 / 225000 loss 0.00460008392110467 train acc 0.7349653451373426\n",
      "epoch 2 batch id 223301 / 225000 loss 2.06807804107666 train acc 0.7349776758724771\n",
      "epoch 2 batch id 223401 / 225000 loss 0.006677835714071989 train acc 0.7349922336963577\n",
      "epoch 2 batch id 223501 / 225000 loss 1.4750527143478394 train acc 0.735009015619617\n",
      "epoch 2 batch id 223601 / 225000 loss 0.5186175107955933 train acc 0.735028018658235\n",
      "epoch 2 batch id 223701 / 225000 loss 0.006281107664108276 train acc 0.7350313588227142\n",
      "epoch 2 batch id 223801 / 225000 loss 0.001902884105220437 train acc 0.7350402813213525\n",
      "epoch 2 batch id 223901 / 225000 loss 0.03511873260140419 train acc 0.7350491958499515\n",
      "epoch 2 batch id 224001 / 225000 loss 1.2988338470458984 train acc 0.7350502899540627\n",
      "epoch 2 batch id 224101 / 225000 loss 2.395571231842041 train acc 0.7350558453554424\n",
      "epoch 2 batch id 224201 / 225000 loss 1.1844218969345093 train acc 0.7350625108719409\n",
      "epoch 2 batch id 224301 / 225000 loss 2.5435707569122314 train acc 0.7350736287399521\n",
      "epoch 2 batch id 224401 / 225000 loss 0.505572497844696 train acc 0.7350769381598121\n",
      "epoch 2 batch id 224501 / 225000 loss 0.04809248819947243 train acc 0.7350858125353562\n",
      "epoch 2 batch id 224601 / 225000 loss 0.9180591702461243 train acc 0.7350957920935347\n",
      "epoch 2 batch id 224701 / 225000 loss 1.2145789861679077 train acc 0.7351191138446201\n",
      "epoch 2 batch id 224801 / 225000 loss 1.0880489349365234 train acc 0.7351235092370586\n",
      "epoch 2 batch id 224901 / 225000 loss 2.2532670497894287 train acc 0.7351201195192552\n",
      "epoch 2 train acc 0.7351188888888889\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a23ff864c34ca0b0c4b056da410eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 test acc 0.76256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b354616b3654628a119dec088b8b16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 / 225000 loss 2.4099667072296143 train acc 0.5\n",
      "epoch 3 batch id 101 / 225000 loss 1.3127397298812866 train acc 0.7722772277227723\n",
      "epoch 3 batch id 201 / 225000 loss 2.5447657108306885 train acc 0.7699004975124378\n",
      "epoch 3 batch id 301 / 225000 loss 0.02385057508945465 train acc 0.776578073089701\n",
      "epoch 3 batch id 401 / 225000 loss 1.126328468322754 train acc 0.763715710723192\n",
      "epoch 3 batch id 501 / 225000 loss 0.284065306186676 train acc 0.7614770459081837\n",
      "epoch 3 batch id 601 / 225000 loss 2.8095784187316895 train acc 0.7624792013311148\n",
      "epoch 3 batch id 701 / 225000 loss 2.035944700241089 train acc 0.7592724679029957\n",
      "epoch 3 batch id 801 / 225000 loss 1.7036843299865723 train acc 0.7599875156054932\n",
      "epoch 3 batch id 901 / 225000 loss 0.09911338239908218 train acc 0.7561043285238623\n",
      "epoch 3 batch id 1001 / 225000 loss 2.3898813724517822 train acc 0.7594905094905094\n",
      "epoch 3 batch id 1101 / 225000 loss 0.02375490963459015 train acc 0.7604450499545867\n",
      "epoch 3 batch id 1201 / 225000 loss 0.014032084494829178 train acc 0.7606161532056619\n",
      "epoch 3 batch id 1301 / 225000 loss 1.2514957189559937 train acc 0.7617217524980784\n",
      "epoch 3 batch id 1401 / 225000 loss 0.07172733545303345 train acc 0.7635617416131335\n",
      "epoch 3 batch id 1501 / 225000 loss 3.2886595726013184 train acc 0.7628247834776816\n",
      "epoch 3 batch id 1601 / 225000 loss 0.1890598088502884 train acc 0.7621798875702686\n",
      "epoch 3 batch id 1701 / 225000 loss 0.0045911031775176525 train acc 0.7616108171663727\n",
      "epoch 3 batch id 1801 / 225000 loss 2.6823232173919678 train acc 0.7615213770127707\n",
      "epoch 3 batch id 1901 / 225000 loss 1.6508718729019165 train acc 0.761572856391373\n",
      "epoch 3 batch id 2001 / 225000 loss 0.0008884783601388335 train acc 0.7638680659670165\n",
      "epoch 3 batch id 2101 / 225000 loss 1.318891167640686 train acc 0.7653498334126606\n",
      "epoch 3 batch id 2201 / 225000 loss 0.0016335661057382822 train acc 0.7670377101317583\n",
      "epoch 3 batch id 2301 / 225000 loss 1.1736289262771606 train acc 0.7674923946110387\n",
      "epoch 3 batch id 2401 / 225000 loss 1.9365458488464355 train acc 0.7685339441899208\n",
      "epoch 3 batch id 2501 / 225000 loss 0.004824587143957615 train acc 0.7690923630547781\n",
      "epoch 3 batch id 2601 / 225000 loss 1.382889747619629 train acc 0.7689350249903883\n",
      "epoch 3 batch id 2701 / 225000 loss 1.7586289644241333 train acc 0.7681414291003332\n",
      "epoch 3 batch id 2801 / 225000 loss 2.6352531909942627 train acc 0.7667797215280258\n",
      "epoch 3 batch id 2901 / 225000 loss 0.3477153182029724 train acc 0.7659427783522923\n",
      "epoch 3 batch id 3001 / 225000 loss 0.5569952726364136 train acc 0.7665778073975341\n",
      "epoch 3 batch id 3101 / 225000 loss 2.32639217376709 train acc 0.7667687842631409\n",
      "epoch 3 batch id 3201 / 225000 loss 0.00281877932138741 train acc 0.7665573258356764\n",
      "epoch 3 batch id 3301 / 225000 loss 0.6810017824172974 train acc 0.7668130869433505\n",
      "epoch 3 batch id 3401 / 225000 loss 0.4453161060810089 train acc 0.7657306674507498\n",
      "epoch 3 batch id 3501 / 225000 loss 0.6500424742698669 train acc 0.7647814910025706\n",
      "epoch 3 batch id 3601 / 225000 loss 0.05441799759864807 train acc 0.7647875590113857\n",
      "epoch 3 batch id 3701 / 225000 loss 2.2900383472442627 train acc 0.7641853553093758\n",
      "epoch 3 batch id 3801 / 225000 loss 0.06182021647691727 train acc 0.7650618258353065\n",
      "epoch 3 batch id 3901 / 225000 loss 3.4997942447662354 train acc 0.7633940015380671\n",
      "epoch 3 batch id 4001 / 225000 loss 1.940932273864746 train acc 0.7623719070232442\n",
      "epoch 3 batch id 4101 / 225000 loss 1.3057506084442139 train acc 0.7620092660326749\n",
      "epoch 3 batch id 4201 / 225000 loss 0.05694979801774025 train acc 0.7619019281123542\n",
      "epoch 3 batch id 4301 / 225000 loss 0.10375036299228668 train acc 0.7623227156475239\n",
      "epoch 3 batch id 4401 / 225000 loss 0.003913348075002432 train acc 0.76204271756419\n",
      "epoch 3 batch id 4501 / 225000 loss 0.0064319223165512085 train acc 0.7622195067762719\n",
      "epoch 3 batch id 4601 / 225000 loss 1.5549265146255493 train acc 0.7620625950880243\n",
      "epoch 3 batch id 4701 / 225000 loss 0.030453242361545563 train acc 0.761540097851521\n",
      "epoch 3 batch id 4801 / 225000 loss 1.7479430437088013 train acc 0.7610914392834827\n",
      "epoch 3 batch id 4901 / 225000 loss 0.4833306074142456 train acc 0.7610691695572332\n",
      "epoch 3 batch id 5001 / 225000 loss 0.9244343042373657 train acc 0.7606978604279144\n",
      "epoch 3 batch id 5101 / 225000 loss 1.2764043807983398 train acc 0.761272299549108\n",
      "epoch 3 batch id 5201 / 225000 loss 1.8774064779281616 train acc 0.7609113631993847\n",
      "epoch 3 batch id 5301 / 225000 loss 0.0021231314167380333 train acc 0.7599037917374081\n",
      "epoch 3 batch id 5401 / 225000 loss 1.617903470993042 train acc 0.7599981484910202\n",
      "epoch 3 batch id 5501 / 225000 loss 0.023424819111824036 train acc 0.7609525540810762\n",
      "epoch 3 batch id 5601 / 225000 loss 2.112212896347046 train acc 0.76093554722371\n",
      "epoch 3 batch id 5701 / 225000 loss 1.6334288120269775 train acc 0.7600859498333625\n",
      "epoch 3 batch id 5801 / 225000 loss 2.2215702533721924 train acc 0.7602568522668506\n",
      "epoch 3 batch id 5901 / 225000 loss 0.540956974029541 train acc 0.7596593797661413\n",
      "epoch 3 batch id 6001 / 225000 loss 0.693196177482605 train acc 0.7602899516747209\n",
      "epoch 3 batch id 6101 / 225000 loss 0.445477157831192 train acc 0.7607769218160957\n",
      "epoch 3 batch id 6201 / 225000 loss 1.637480616569519 train acc 0.7610062893081762\n",
      "epoch 3 batch id 6301 / 225000 loss 2.7191081047058105 train acc 0.76114902396445\n",
      "epoch 3 batch id 6401 / 225000 loss 0.5092999339103699 train acc 0.7608186220902984\n",
      "epoch 3 batch id 6501 / 225000 loss 0.03783029317855835 train acc 0.7604599292416552\n",
      "epoch 3 batch id 6601 / 225000 loss 0.0020682888571172953 train acc 0.7601121042266323\n",
      "epoch 3 batch id 6701 / 225000 loss 0.006400147918611765 train acc 0.7597373526339353\n",
      "epoch 3 batch id 6801 / 225000 loss 2.1683757305145264 train acc 0.7593001029260403\n",
      "epoch 3 batch id 6901 / 225000 loss 2.893280029296875 train acc 0.7596000579626141\n",
      "epoch 3 batch id 7001 / 225000 loss 0.9520428776741028 train acc 0.7596414797886016\n",
      "epoch 3 batch id 7101 / 225000 loss 1.490422248840332 train acc 0.7596465286579355\n",
      "epoch 3 batch id 7201 / 225000 loss 0.010078959167003632 train acc 0.7599638939036245\n",
      "epoch 3 batch id 7301 / 225000 loss 0.0031491066329181194 train acc 0.7598274209012464\n",
      "epoch 3 batch id 7401 / 225000 loss 0.7978770732879639 train acc 0.759694635860019\n",
      "epoch 3 batch id 7501 / 225000 loss 1.1162370443344116 train acc 0.7593987468337555\n",
      "epoch 3 batch id 7601 / 225000 loss 0.5428266525268555 train acc 0.7591764241547165\n",
      "epoch 3 batch id 7701 / 225000 loss 1.1502944231033325 train acc 0.7592845085053889\n",
      "epoch 3 batch id 7801 / 225000 loss 0.810326099395752 train acc 0.7587168311754903\n",
      "epoch 3 batch id 7901 / 225000 loss 1.7462894916534424 train acc 0.7584482976838375\n",
      "epoch 3 batch id 8001 / 225000 loss 0.7683339715003967 train acc 0.7579052618422697\n",
      "epoch 3 batch id 8101 / 225000 loss 2.5057756900787354 train acc 0.7578076780644365\n",
      "epoch 3 batch id 8201 / 225000 loss 0.023187773302197456 train acc 0.757803926350445\n",
      "epoch 3 batch id 8301 / 225000 loss 0.15397433936595917 train acc 0.7577099144681364\n",
      "epoch 3 batch id 8401 / 225000 loss 1.3035533428192139 train acc 0.7578859659564338\n",
      "epoch 3 batch id 8501 / 225000 loss 0.33952832221984863 train acc 0.7582049170685802\n",
      "epoch 3 batch id 8601 / 225000 loss 1.5326100587844849 train acc 0.7581967213114754\n",
      "epoch 3 batch id 8701 / 225000 loss 2.4385993480682373 train acc 0.7578151936559017\n",
      "epoch 3 batch id 8801 / 225000 loss 0.37662792205810547 train acc 0.7579536416316328\n",
      "epoch 3 batch id 8901 / 225000 loss 0.002204767893999815 train acc 0.758510279743849\n",
      "epoch 3 batch id 9001 / 225000 loss 0.6981359124183655 train acc 0.7586101544272859\n",
      "epoch 3 batch id 9101 / 225000 loss 0.8014585971832275 train acc 0.758460608724316\n",
      "epoch 3 batch id 9201 / 225000 loss 0.7361395359039307 train acc 0.7584773394196282\n",
      "epoch 3 batch id 9301 / 225000 loss 0.024236444383859634 train acc 0.7584130738630255\n",
      "epoch 3 batch id 9401 / 225000 loss 0.0018385006114840508 train acc 0.7585629188384214\n",
      "epoch 3 batch id 9501 / 225000 loss 2.7755751609802246 train acc 0.7588938006525628\n",
      "epoch 3 batch id 9601 / 225000 loss 0.07448326051235199 train acc 0.7590615560879075\n",
      "epoch 3 batch id 9701 / 225000 loss 3.179185152053833 train acc 0.7591227708483661\n",
      "epoch 3 batch id 9801 / 225000 loss 0.010076822713017464 train acc 0.7590551984491378\n",
      "epoch 3 batch id 9901 / 225000 loss 0.9534490704536438 train acc 0.759039490960509\n",
      "epoch 3 batch id 10001 / 225000 loss 1.3821156024932861 train acc 0.7591740825917408\n",
      "epoch 3 batch id 10101 / 225000 loss 3.0959792137145996 train acc 0.759009009009009\n",
      "epoch 3 batch id 10201 / 225000 loss 0.05217902734875679 train acc 0.7591167532594844\n",
      "epoch 3 batch id 10301 / 225000 loss 0.01753528229892254 train acc 0.7591253276380934\n",
      "epoch 3 batch id 10401 / 225000 loss 0.02625025250017643 train acc 0.7592058455917701\n",
      "epoch 3 batch id 10501 / 225000 loss 2.724229335784912 train acc 0.7594038662984478\n",
      "epoch 3 batch id 10601 / 225000 loss 0.03299463540315628 train acc 0.75929157626639\n",
      "epoch 3 batch id 10701 / 225000 loss 2.4582958221435547 train acc 0.7594617325483599\n",
      "epoch 3 batch id 10801 / 225000 loss 0.2724315822124481 train acc 0.7594435700398111\n",
      "epoch 3 batch id 10901 / 225000 loss 1.5328826904296875 train acc 0.7591734703238235\n",
      "epoch 3 batch id 11001 / 225000 loss 1.2224857807159424 train acc 0.759226433960549\n",
      "epoch 3 batch id 11101 / 225000 loss 6.168898582458496 train acc 0.7589406359787406\n",
      "epoch 3 batch id 11201 / 225000 loss 1.7747125625610352 train acc 0.7589724131773948\n",
      "epoch 3 batch id 11301 / 225000 loss 1.3097890615463257 train acc 0.7589593841252986\n",
      "epoch 3 batch id 11401 / 225000 loss 0.004202840384095907 train acc 0.7592097184457504\n",
      "epoch 3 batch id 11501 / 225000 loss 0.001479388098232448 train acc 0.7592383271019911\n",
      "epoch 3 batch id 11601 / 225000 loss 3.297260046005249 train acc 0.7591802430824929\n",
      "epoch 3 batch id 11701 / 225000 loss 0.008736115880310535 train acc 0.7592727117340399\n",
      "epoch 3 batch id 11801 / 225000 loss 0.013388611376285553 train acc 0.7591729514447928\n",
      "epoch 3 batch id 11901 / 225000 loss 0.7789125442504883 train acc 0.7592639274010587\n",
      "epoch 3 batch id 12001 / 225000 loss 0.8231392502784729 train acc 0.7591242396466961\n",
      "epoch 3 batch id 12101 / 225000 loss 1.7605725526809692 train acc 0.7593380712337824\n",
      "epoch 3 batch id 12201 / 225000 loss 0.9332086443901062 train acc 0.7596303581673634\n",
      "epoch 3 batch id 12301 / 225000 loss 0.01023670844733715 train acc 0.7598162750995854\n",
      "epoch 3 batch id 12401 / 225000 loss 1.2980079650878906 train acc 0.759858075961616\n",
      "epoch 3 batch id 12501 / 225000 loss 3.971573829650879 train acc 0.7600591952643788\n",
      "epoch 3 batch id 12601 / 225000 loss 2.2208101749420166 train acc 0.7600785651932387\n",
      "epoch 3 batch id 12701 / 225000 loss 2.8313446044921875 train acc 0.7599007952129754\n",
      "epoch 3 batch id 12801 / 225000 loss 0.09641727805137634 train acc 0.7599406296383096\n",
      "epoch 3 batch id 12901 / 225000 loss 0.35256731510162354 train acc 0.7601542516084024\n",
      "epoch 3 batch id 13001 / 225000 loss 1.6907455921173096 train acc 0.7601530651488347\n",
      "epoch 3 batch id 13101 / 225000 loss 1.5167348384857178 train acc 0.7601328142889856\n",
      "epoch 3 batch id 13201 / 225000 loss 0.00610401900485158 train acc 0.7600749943186123\n",
      "epoch 3 batch id 13301 / 225000 loss 1.555310606956482 train acc 0.7601120216525074\n",
      "epoch 3 batch id 13401 / 225000 loss 1.5837548971176147 train acc 0.7601298410566376\n",
      "epoch 3 batch id 13501 / 225000 loss 1.8633135557174683 train acc 0.7602029479297829\n",
      "epoch 3 batch id 13601 / 225000 loss 1.8535232543945312 train acc 0.7599257407543563\n",
      "epoch 3 batch id 13701 / 225000 loss 0.0019843685440719128 train acc 0.7599080359097876\n",
      "epoch 3 batch id 13801 / 225000 loss 0.09672039747238159 train acc 0.7599630461560757\n",
      "epoch 3 batch id 13901 / 225000 loss 1.1286638975143433 train acc 0.7598554060858931\n",
      "epoch 3 batch id 14001 / 225000 loss 0.009559081867337227 train acc 0.7594814656095993\n",
      "epoch 3 batch id 14101 / 225000 loss 1.6452884674072266 train acc 0.7593255797461173\n",
      "epoch 3 batch id 14201 / 225000 loss 1.8959157466888428 train acc 0.7596119991549891\n",
      "epoch 3 batch id 14301 / 225000 loss 3.7496657371520996 train acc 0.759562268372841\n",
      "epoch 3 batch id 14401 / 225000 loss 0.029792167246341705 train acc 0.7593396291924172\n",
      "epoch 3 batch id 14501 / 225000 loss 0.0020417876075953245 train acc 0.759292462588787\n",
      "epoch 3 batch id 14601 / 225000 loss 1.97529137134552 train acc 0.7590233545647559\n",
      "epoch 3 batch id 14701 / 225000 loss 3.3433611392974854 train acc 0.7589109584382014\n",
      "epoch 3 batch id 14801 / 225000 loss 0.009336752817034721 train acc 0.7590872238362273\n",
      "epoch 3 batch id 14901 / 225000 loss 0.002898432780057192 train acc 0.7589087980672438\n",
      "epoch 3 batch id 15001 / 225000 loss 1.233249306678772 train acc 0.7587827478168122\n",
      "epoch 3 batch id 15101 / 225000 loss 3.099809169769287 train acc 0.7590060260909873\n",
      "epoch 3 batch id 15201 / 225000 loss 2.4997048377990723 train acc 0.7588645483849746\n",
      "epoch 3 batch id 15301 / 225000 loss 0.8944374918937683 train acc 0.7589209855564996\n",
      "epoch 3 batch id 15401 / 225000 loss 1.59904944896698 train acc 0.7590253879618206\n",
      "epoch 3 batch id 15501 / 225000 loss 1.250127911567688 train acc 0.7589349074253274\n",
      "epoch 3 batch id 15601 / 225000 loss 2.7682764530181885 train acc 0.7589096852765849\n",
      "epoch 3 batch id 15701 / 225000 loss 0.06107402965426445 train acc 0.7590280873829692\n",
      "epoch 3 batch id 15801 / 225000 loss 0.1359604001045227 train acc 0.7591766343902284\n",
      "epoch 3 batch id 15901 / 225000 loss 0.9494472146034241 train acc 0.7593547575624174\n",
      "epoch 3 batch id 16001 / 225000 loss 2.6646313667297363 train acc 0.7596243984750953\n",
      "epoch 3 batch id 16101 / 225000 loss 1.6052274703979492 train acc 0.7596733122166325\n",
      "epoch 3 batch id 16201 / 225000 loss 1.886829137802124 train acc 0.7598605024381211\n",
      "epoch 3 batch id 16301 / 225000 loss 0.9138117432594299 train acc 0.7599840500582786\n",
      "epoch 3 batch id 16401 / 225000 loss 0.02321300096809864 train acc 0.7598622035241753\n",
      "epoch 3 batch id 16501 / 225000 loss 2.648588180541992 train acc 0.7596963820374523\n",
      "epoch 3 batch id 16601 / 225000 loss 0.004832006525248289 train acc 0.7599241009577736\n",
      "epoch 3 batch id 16701 / 225000 loss 0.006819436326622963 train acc 0.7598347404347046\n",
      "epoch 3 batch id 16801 / 225000 loss 1.249975323677063 train acc 0.7595530027974525\n",
      "epoch 3 batch id 16901 / 225000 loss 0.04881493002176285 train acc 0.7597035678362227\n",
      "epoch 3 batch id 17001 / 225000 loss 1.959853172302246 train acc 0.7596759014175637\n",
      "epoch 3 batch id 17101 / 225000 loss 0.4482976794242859 train acc 0.7596631775919537\n",
      "epoch 3 batch id 17201 / 225000 loss 2.939258098602295 train acc 0.7598104761351084\n",
      "epoch 3 batch id 17301 / 225000 loss 0.18528299033641815 train acc 0.7598260216172475\n",
      "epoch 3 batch id 17401 / 225000 loss 1.0270774364471436 train acc 0.7601574622148153\n",
      "epoch 3 batch id 17501 / 225000 loss 1.801220417022705 train acc 0.7600279984000914\n",
      "epoch 3 batch id 17601 / 225000 loss 1.931473970413208 train acc 0.7599852281120391\n",
      "epoch 3 batch id 17701 / 225000 loss 0.008123109117150307 train acc 0.7601124230269476\n",
      "epoch 3 batch id 17801 / 225000 loss 1.8195799589157104 train acc 0.7599573057693388\n",
      "epoch 3 batch id 17901 / 225000 loss 0.5683643221855164 train acc 0.75997150997151\n",
      "epoch 3 batch id 18001 / 225000 loss 0.012945061549544334 train acc 0.7598188989500583\n",
      "epoch 3 batch id 18101 / 225000 loss 5.3995819091796875 train acc 0.7599027678028838\n",
      "epoch 3 batch id 18201 / 225000 loss 0.02678864262998104 train acc 0.759793417944069\n",
      "epoch 3 batch id 18301 / 225000 loss 0.7936298847198486 train acc 0.7597125840118026\n",
      "epoch 3 batch id 18401 / 225000 loss 0.011230140924453735 train acc 0.7596462148796261\n",
      "epoch 3 batch id 18501 / 225000 loss 0.9834235906600952 train acc 0.7598643316577482\n",
      "epoch 3 batch id 18601 / 225000 loss 0.003493655938655138 train acc 0.7600263426697489\n",
      "epoch 3 batch id 18701 / 225000 loss 0.004748604726046324 train acc 0.7599593604620074\n",
      "epoch 3 batch id 18801 / 225000 loss 0.005798047408461571 train acc 0.7598531992979097\n",
      "epoch 3 batch id 18901 / 225000 loss 0.0027986355125904083 train acc 0.759642346965769\n",
      "epoch 3 batch id 19001 / 225000 loss 1.4943344593048096 train acc 0.7598415872848797\n",
      "epoch 3 batch id 19101 / 225000 loss 4.120597839355469 train acc 0.7597638867075023\n",
      "epoch 3 batch id 19201 / 225000 loss 0.0989295244216919 train acc 0.7599734388833915\n",
      "epoch 3 batch id 19301 / 225000 loss 0.032262325286865234 train acc 0.7600771980726387\n",
      "epoch 3 batch id 19401 / 225000 loss 0.0034113130532205105 train acc 0.760179887634658\n",
      "epoch 3 batch id 19501 / 225000 loss 0.9334972500801086 train acc 0.7601020460489206\n",
      "epoch 3 batch id 19601 / 225000 loss 0.0024214740842580795 train acc 0.7602928422019285\n",
      "epoch 3 batch id 19701 / 225000 loss 1.6489137411117554 train acc 0.7602659763463784\n",
      "epoch 3 batch id 19801 / 225000 loss 0.8028489947319031 train acc 0.7603277612241806\n",
      "epoch 3 batch id 19901 / 225000 loss 2.256728172302246 train acc 0.7602256168031757\n",
      "epoch 3 batch id 20001 / 225000 loss 1.3328150510787964 train acc 0.7599495025248738\n",
      "epoch 3 batch id 20101 / 225000 loss 0.0051689413376152515 train acc 0.7599497537435949\n",
      "epoch 3 batch id 20201 / 225000 loss 0.024318845942616463 train acc 0.7598757487253106\n",
      "epoch 3 batch id 20301 / 225000 loss 0.0024724167305976152 train acc 0.7600118220777302\n",
      "epoch 3 batch id 20401 / 225000 loss 2.846494674682617 train acc 0.7600730356355081\n",
      "epoch 3 batch id 20501 / 225000 loss 3.325798511505127 train acc 0.7600604848543974\n",
      "epoch 3 batch id 20601 / 225000 loss 1.579648494720459 train acc 0.7600601912528518\n",
      "epoch 3 batch id 20701 / 225000 loss 1.4609496593475342 train acc 0.7598666731075794\n",
      "epoch 3 batch id 20801 / 225000 loss 1.1558890342712402 train acc 0.759903370030287\n",
      "epoch 3 batch id 20901 / 225000 loss 1.091811180114746 train acc 0.7599755992536242\n",
      "epoch 3 batch id 21001 / 225000 loss 0.00707178795710206 train acc 0.7599042902718918\n",
      "epoch 3 batch id 21101 / 225000 loss 1.1569350957870483 train acc 0.7599047438510024\n",
      "epoch 3 batch id 21201 / 225000 loss 1.6268168687820435 train acc 0.759952360737701\n",
      "epoch 3 batch id 21301 / 225000 loss 2.9901506900787354 train acc 0.7599643209239003\n",
      "epoch 3 batch id 21401 / 225000 loss 0.07084140926599503 train acc 0.7600112144292323\n",
      "epoch 3 batch id 21501 / 225000 loss 0.004035766236484051 train acc 0.759848379145156\n",
      "epoch 3 batch id 21601 / 225000 loss 4.8621745109558105 train acc 0.7599185222906347\n",
      "epoch 3 batch id 21701 / 225000 loss 0.850915789604187 train acc 0.7599649785724161\n",
      "epoch 3 batch id 21801 / 225000 loss 0.6840730905532837 train acc 0.7598160634833264\n",
      "epoch 3 batch id 21901 / 225000 loss 1.6796058416366577 train acc 0.7599424683804392\n",
      "epoch 3 batch id 22001 / 225000 loss 2.2926950454711914 train acc 0.760135902913504\n",
      "epoch 3 batch id 22101 / 225000 loss 0.008832119405269623 train acc 0.7601239762906655\n",
      "epoch 3 batch id 22201 / 225000 loss 0.4707666039466858 train acc 0.760224764650241\n",
      "epoch 3 batch id 22301 / 225000 loss 1.7290170192718506 train acc 0.760111654185911\n",
      "epoch 3 batch id 22401 / 225000 loss 1.9588665962219238 train acc 0.7600999955359136\n",
      "epoch 3 batch id 22501 / 225000 loss 0.020870685577392578 train acc 0.7601662148348962\n",
      "epoch 3 batch id 22601 / 225000 loss 1.744613528251648 train acc 0.7602650325206849\n",
      "epoch 3 batch id 22701 / 225000 loss 0.6996734142303467 train acc 0.760164750451522\n",
      "epoch 3 batch id 22801 / 225000 loss 1.0801366567611694 train acc 0.760174992324898\n",
      "epoch 3 batch id 22901 / 225000 loss 0.924887478351593 train acc 0.7599668136762586\n",
      "epoch 3 batch id 23001 / 225000 loss 1.858828067779541 train acc 0.7600756488848311\n",
      "epoch 3 batch id 23101 / 225000 loss 0.9508175849914551 train acc 0.7600536773299857\n",
      "epoch 3 batch id 23201 / 225000 loss 3.8292076587677 train acc 0.7599349165984225\n",
      "epoch 3 batch id 23301 / 225000 loss 0.6437065005302429 train acc 0.7598815501480624\n",
      "epoch 3 batch id 23401 / 225000 loss 0.14482660591602325 train acc 0.7597538566727917\n",
      "epoch 3 batch id 23501 / 225000 loss 0.08331380784511566 train acc 0.7596059742138632\n",
      "epoch 3 batch id 23601 / 225000 loss 4.029565334320068 train acc 0.7595864582009237\n",
      "epoch 3 batch id 23701 / 225000 loss 1.271053433418274 train acc 0.7594510780135859\n",
      "epoch 3 batch id 23801 / 225000 loss 1.4093672037124634 train acc 0.7595059031133146\n",
      "epoch 3 batch id 23901 / 225000 loss 0.051789287477731705 train acc 0.759424291870633\n",
      "epoch 3 batch id 24001 / 225000 loss 1.8026450872421265 train acc 0.7593225282279905\n",
      "epoch 3 batch id 24101 / 225000 loss 1.3445110321044922 train acc 0.759180117007593\n",
      "epoch 3 batch id 24201 / 225000 loss 1.4494496583938599 train acc 0.7591938349654973\n",
      "epoch 3 batch id 24301 / 225000 loss 1.7647998332977295 train acc 0.7591457141681413\n",
      "epoch 3 batch id 24401 / 225000 loss 1.4996799230575562 train acc 0.7591901971230687\n",
      "epoch 3 batch id 24501 / 225000 loss 2.257294178009033 train acc 0.7590302436635239\n",
      "epoch 3 batch id 24601 / 225000 loss 1.997316837310791 train acc 0.7588817527742775\n",
      "epoch 3 batch id 24701 / 225000 loss 0.0029567366000264883 train acc 0.7589571272418121\n",
      "epoch 3 batch id 24801 / 225000 loss 0.003239118494093418 train acc 0.7589310914882464\n",
      "epoch 3 batch id 24901 / 225000 loss 2.2587087154388428 train acc 0.7590257419380748\n",
      "epoch 3 batch id 25001 / 225000 loss 1.8020824193954468 train acc 0.7591896324147034\n",
      "epoch 3 batch id 25101 / 225000 loss 0.0057573141530156136 train acc 0.7592028206047567\n",
      "epoch 3 batch id 25201 / 225000 loss 0.15139228105545044 train acc 0.7591365422007064\n",
      "epoch 3 batch id 25301 / 225000 loss 0.01827302947640419 train acc 0.75905102565116\n",
      "epoch 3 batch id 25401 / 225000 loss 4.04882287979126 train acc 0.7590646037557577\n",
      "epoch 3 batch id 25501 / 225000 loss 1.86658775806427 train acc 0.7592447355005686\n",
      "epoch 3 batch id 25601 / 225000 loss 2.5726871490478516 train acc 0.7593941642904574\n",
      "epoch 3 batch id 25701 / 225000 loss 0.011865807697176933 train acc 0.759367339792226\n",
      "epoch 3 batch id 25801 / 225000 loss 0.0050536892376840115 train acc 0.7593697918685323\n",
      "epoch 3 batch id 25901 / 225000 loss 0.00243811565451324 train acc 0.7593625728736342\n",
      "epoch 3 batch id 26001 / 225000 loss 0.0036239796318113804 train acc 0.7593746394369447\n",
      "epoch 3 batch id 26101 / 225000 loss 3.1093406677246094 train acc 0.759300409945979\n",
      "epoch 3 batch id 26201 / 225000 loss 0.7764755487442017 train acc 0.7593221632762108\n",
      "epoch 3 batch id 26301 / 225000 loss 0.016066208481788635 train acc 0.7593437511881678\n",
      "epoch 3 batch id 26401 / 225000 loss 0.004182923585176468 train acc 0.7593367675466839\n",
      "epoch 3 batch id 26501 / 225000 loss 3.412609815597534 train acc 0.7592638013659861\n",
      "epoch 3 batch id 26601 / 225000 loss 0.5878273844718933 train acc 0.7592759670689072\n",
      "epoch 3 batch id 26701 / 225000 loss 0.006566052325069904 train acc 0.7593254934272125\n",
      "epoch 3 batch id 26801 / 225000 loss 0.004501911345869303 train acc 0.7592906981082795\n",
      "epoch 3 batch id 26901 / 225000 loss 2.2199766635894775 train acc 0.759330508159548\n",
      "epoch 3 batch id 27001 / 225000 loss 0.9936786890029907 train acc 0.7591385504240584\n",
      "epoch 3 batch id 27101 / 225000 loss 2.7424230575561523 train acc 0.7590956053282166\n",
      "epoch 3 batch id 27201 / 225000 loss 0.017558785155415535 train acc 0.7592735561192603\n",
      "epoch 3 batch id 27301 / 225000 loss 0.4030337929725647 train acc 0.7593952602468774\n",
      "epoch 3 batch id 27401 / 225000 loss 1.249575138092041 train acc 0.7593336009634685\n",
      "epoch 3 batch id 27501 / 225000 loss 2.0430290699005127 train acc 0.7593542053016253\n",
      "epoch 3 batch id 27601 / 225000 loss 1.751964807510376 train acc 0.7593474874098765\n",
      "epoch 3 batch id 27701 / 225000 loss 0.29221493005752563 train acc 0.7594671672502797\n",
      "epoch 3 batch id 27801 / 225000 loss 2.311152458190918 train acc 0.7595320312218985\n",
      "epoch 3 batch id 27901 / 225000 loss 1.436070442199707 train acc 0.7595068277122684\n",
      "epoch 3 batch id 28001 / 225000 loss 2.9551916122436523 train acc 0.759419306453341\n",
      "epoch 3 batch id 28101 / 225000 loss 0.9541445374488831 train acc 0.7592968221771467\n",
      "epoch 3 batch id 28201 / 225000 loss 0.5175175666809082 train acc 0.7592904506932379\n",
      "epoch 3 batch id 28301 / 225000 loss 2.8628439903259277 train acc 0.7593017914561323\n",
      "epoch 3 batch id 28401 / 225000 loss 0.5044934749603271 train acc 0.7592162247808176\n",
      "epoch 3 batch id 28501 / 225000 loss 1.1733574867248535 train acc 0.7590874004420898\n",
      "epoch 3 batch id 28601 / 225000 loss 0.8574917912483215 train acc 0.7590206636131603\n",
      "epoch 3 batch id 28701 / 225000 loss 0.9393509030342102 train acc 0.7591024702972022\n",
      "epoch 3 batch id 28801 / 225000 loss 3.668501377105713 train acc 0.7590708655949446\n",
      "epoch 3 batch id 28901 / 225000 loss 0.9611260294914246 train acc 0.7591778831182312\n",
      "epoch 3 batch id 29001 / 225000 loss 0.002376246964558959 train acc 0.7593272645770835\n",
      "epoch 3 batch id 29101 / 225000 loss 0.44249993562698364 train acc 0.7593209855331432\n",
      "epoch 3 batch id 29201 / 225000 loss 2.0726521015167236 train acc 0.759323310845519\n",
      "epoch 3 batch id 29301 / 225000 loss 0.008105826564133167 train acc 0.7592744274939421\n",
      "epoch 3 batch id 29401 / 225000 loss 0.008396308869123459 train acc 0.7592513860072787\n",
      "epoch 3 batch id 29501 / 225000 loss 2.873366355895996 train acc 0.7592793464628318\n",
      "epoch 3 batch id 29601 / 225000 loss 3.116882801055908 train acc 0.7592648896996723\n",
      "epoch 3 batch id 29701 / 225000 loss 1.4136168956756592 train acc 0.7593178680852497\n",
      "epoch 3 batch id 29801 / 225000 loss 0.010692089796066284 train acc 0.7592698231602967\n",
      "epoch 3 batch id 29901 / 225000 loss 0.003951310645788908 train acc 0.7592555432928665\n",
      "epoch 3 batch id 30001 / 225000 loss 0.5709465146064758 train acc 0.7592246925102497\n",
      "epoch 3 batch id 30101 / 225000 loss 0.7965723276138306 train acc 0.7593352380319591\n",
      "epoch 3 batch id 30201 / 225000 loss 1.585978388786316 train acc 0.7593374391576437\n",
      "epoch 3 batch id 30301 / 225000 loss 0.003360882168635726 train acc 0.7591663641463978\n",
      "epoch 3 batch id 30401 / 225000 loss 1.046452283859253 train acc 0.7592677872438407\n",
      "epoch 3 batch id 30501 / 225000 loss 2.5094621181488037 train acc 0.7592046162420905\n",
      "epoch 3 batch id 30601 / 225000 loss 1.6614453792572021 train acc 0.7591255187738962\n",
      "epoch 3 batch id 30701 / 225000 loss 0.8081259727478027 train acc 0.7590876518680173\n",
      "epoch 3 batch id 30801 / 225000 loss 0.6881440877914429 train acc 0.7590906139411058\n",
      "epoch 3 batch id 30901 / 225000 loss 1.088189959526062 train acc 0.7591825507265137\n",
      "epoch 3 batch id 31001 / 225000 loss 1.3206939697265625 train acc 0.7591932518305861\n",
      "epoch 3 batch id 31101 / 225000 loss 0.5785759687423706 train acc 0.7591878074659979\n",
      "epoch 3 batch id 31201 / 225000 loss 1.645314335823059 train acc 0.7591663728726643\n",
      "epoch 3 batch id 31301 / 225000 loss 0.002497762907296419 train acc 0.7591051404108495\n",
      "epoch 3 batch id 31401 / 225000 loss 2.3754141330718994 train acc 0.75909206713162\n",
      "epoch 3 batch id 31501 / 225000 loss 1.1960536241531372 train acc 0.7590870131106949\n",
      "epoch 3 batch id 31601 / 225000 loss 1.5363327264785767 train acc 0.7591057245023891\n",
      "epoch 3 batch id 31701 / 225000 loss 1.2478785514831543 train acc 0.759037569792751\n",
      "epoch 3 batch id 31801 / 225000 loss 0.238058403134346 train acc 0.7591113486997264\n",
      "epoch 3 batch id 31901 / 225000 loss 2.3278627395629883 train acc 0.7590906241183661\n",
      "epoch 3 batch id 32001 / 225000 loss 1.4363049268722534 train acc 0.7589372207118528\n",
      "epoch 3 batch id 32101 / 225000 loss 2.9457316398620605 train acc 0.7589794710445158\n",
      "epoch 3 batch id 32201 / 225000 loss 0.552111029624939 train acc 0.7588972392161734\n",
      "epoch 3 batch id 32301 / 225000 loss 2.3718039989471436 train acc 0.7589083929290115\n",
      "epoch 3 batch id 32401 / 225000 loss 2.4185352325439453 train acc 0.7588963303601741\n",
      "epoch 3 batch id 32501 / 225000 loss 0.48932358622550964 train acc 0.758976646872404\n",
      "epoch 3 batch id 32601 / 225000 loss 1.1798875331878662 train acc 0.7589951228489924\n",
      "epoch 3 batch id 32701 / 225000 loss 0.0023334617726504803 train acc 0.7590593559829975\n",
      "epoch 3 batch id 32801 / 225000 loss 0.01198271382600069 train acc 0.7589783848053413\n",
      "epoch 3 batch id 32901 / 225000 loss 0.03751293197274208 train acc 0.7589890884775539\n",
      "epoch 3 batch id 33001 / 225000 loss 1.778905987739563 train acc 0.7590527559770917\n",
      "epoch 3 batch id 33101 / 225000 loss 2.80895733833313 train acc 0.7589951965197426\n",
      "epoch 3 batch id 33201 / 225000 loss 0.12634748220443726 train acc 0.7589906930514141\n",
      "epoch 3 batch id 33301 / 225000 loss 0.02443881332874298 train acc 0.759008738476322\n",
      "epoch 3 batch id 33401 / 225000 loss 0.941864013671875 train acc 0.7589368581778989\n",
      "epoch 3 batch id 33501 / 225000 loss 0.7141163945198059 train acc 0.7589624190322677\n",
      "epoch 3 batch id 33601 / 225000 loss 0.5238433480262756 train acc 0.7589952679979762\n",
      "epoch 3 batch id 33701 / 225000 loss 1.2913501262664795 train acc 0.7590650129076288\n",
      "epoch 3 batch id 33801 / 225000 loss 3.2843852043151855 train acc 0.7590381941362682\n",
      "epoch 3 batch id 33901 / 225000 loss 0.12009207159280777 train acc 0.7590115335830802\n",
      "epoch 3 batch id 34001 / 225000 loss 2.161182403564453 train acc 0.7589482662274639\n",
      "epoch 3 batch id 34101 / 225000 loss 2.5411434173583984 train acc 0.7589660127268995\n",
      "epoch 3 batch id 34201 / 225000 loss 2.184206962585449 train acc 0.7588301511651706\n",
      "epoch 3 batch id 34301 / 225000 loss 1.3559612035751343 train acc 0.7588918690417189\n",
      "epoch 3 batch id 34401 / 225000 loss 2.06707763671875 train acc 0.7589532281038341\n",
      "epoch 3 batch id 34501 / 225000 loss 1.70268976688385 train acc 0.7589200313034404\n",
      "epoch 3 batch id 34601 / 225000 loss 1.9585514068603516 train acc 0.7589881795323835\n",
      "epoch 3 batch id 34701 / 225000 loss 0.1499963104724884 train acc 0.7589982997608138\n",
      "epoch 3 batch id 34801 / 225000 loss 1.8236591815948486 train acc 0.758914973707652\n",
      "epoch 3 batch id 34901 / 225000 loss 0.03910652920603752 train acc 0.7590112031173892\n",
      "epoch 3 batch id 35001 / 225000 loss 0.003392471931874752 train acc 0.7591140253135624\n",
      "epoch 3 batch id 35101 / 225000 loss 0.1647631824016571 train acc 0.7591236716902653\n",
      "epoch 3 batch id 35201 / 225000 loss 0.6667582988739014 train acc 0.7592753046788443\n",
      "epoch 3 batch id 35301 / 225000 loss 1.4310497045516968 train acc 0.7593694229625223\n",
      "epoch 3 batch id 35401 / 225000 loss 1.4034358263015747 train acc 0.7594065139402841\n",
      "epoch 3 batch id 35501 / 225000 loss 0.02295125275850296 train acc 0.7594997324019042\n",
      "epoch 3 batch id 35601 / 225000 loss 1.9927408695220947 train acc 0.7595151821578046\n",
      "epoch 3 batch id 35701 / 225000 loss 3.6636319160461426 train acc 0.7594605193131845\n",
      "epoch 3 batch id 35801 / 225000 loss 1.260079264640808 train acc 0.7594969414262172\n",
      "epoch 3 batch id 35901 / 225000 loss 0.08150047808885574 train acc 0.7594983426645497\n",
      "epoch 3 batch id 36001 / 225000 loss 2.3612961769104004 train acc 0.7594650148606983\n",
      "epoch 3 batch id 36101 / 225000 loss 1.5338903665542603 train acc 0.7594387967092324\n",
      "epoch 3 batch id 36201 / 225000 loss 2.4728076457977295 train acc 0.7594679704980526\n",
      "epoch 3 batch id 36301 / 225000 loss 0.002958151511847973 train acc 0.759448775515826\n",
      "epoch 3 batch id 36401 / 225000 loss 0.2537842094898224 train acc 0.7594502898272025\n",
      "epoch 3 batch id 36501 / 225000 loss 1.0109524726867676 train acc 0.759499739733158\n",
      "epoch 3 batch id 36601 / 225000 loss 1.133651852607727 train acc 0.7594464632113876\n",
      "epoch 3 batch id 36701 / 225000 loss 1.2639046907424927 train acc 0.7594207242309474\n",
      "epoch 3 batch id 36801 / 225000 loss 0.7989347577095032 train acc 0.7594019184261297\n",
      "epoch 3 batch id 36901 / 225000 loss 0.16328099370002747 train acc 0.7593493401262839\n",
      "epoch 3 batch id 37001 / 225000 loss 0.0016693203942850232 train acc 0.7595605524175022\n",
      "epoch 3 batch id 37101 / 225000 loss 0.09059983491897583 train acc 0.7595213067033234\n",
      "epoch 3 batch id 37201 / 225000 loss 0.8094602227210999 train acc 0.7595225934786699\n",
      "epoch 3 batch id 37301 / 225000 loss 0.2695312798023224 train acc 0.7595104688882336\n",
      "epoch 3 batch id 37401 / 225000 loss 1.8335250616073608 train acc 0.7595050934466993\n",
      "epoch 3 batch id 37501 / 225000 loss 0.6647627353668213 train acc 0.7594530812511666\n",
      "epoch 3 batch id 37601 / 225000 loss 0.000971238303463906 train acc 0.7595010770990134\n",
      "epoch 3 batch id 37701 / 225000 loss 0.5641225576400757 train acc 0.7594891382191454\n",
      "epoch 3 batch id 37801 / 225000 loss 2.520779609680176 train acc 0.7594309674347239\n",
      "epoch 3 batch id 37901 / 225000 loss 0.49683284759521484 train acc 0.7593928920081264\n",
      "epoch 3 batch id 38001 / 225000 loss 0.10268828272819519 train acc 0.7593813320702086\n",
      "epoch 3 batch id 38101 / 225000 loss 3.194422721862793 train acc 0.7593501482900711\n",
      "epoch 3 batch id 38201 / 225000 loss 2.2856225967407227 train acc 0.759338760765425\n",
      "epoch 3 batch id 38301 / 225000 loss 3.2621302604675293 train acc 0.7593665961724237\n",
      "epoch 3 batch id 38401 / 225000 loss 0.0037663262337446213 train acc 0.7594528788312804\n",
      "epoch 3 batch id 38501 / 225000 loss 2.6830837726593018 train acc 0.7594413132126439\n",
      "epoch 3 batch id 38601 / 225000 loss 0.061421867460012436 train acc 0.7595528613248361\n",
      "epoch 3 batch id 38701 / 225000 loss 1.3574085235595703 train acc 0.7595217177850702\n",
      "epoch 3 batch id 38801 / 225000 loss 0.7974878549575806 train acc 0.7594585191103322\n",
      "epoch 3 batch id 38901 / 225000 loss 2.193336248397827 train acc 0.7594470579162489\n",
      "epoch 3 batch id 39001 / 225000 loss 0.0024151282850652933 train acc 0.7594741160483065\n",
      "epoch 3 batch id 39101 / 225000 loss 1.9473226070404053 train acc 0.7594818546840234\n",
      "epoch 3 batch id 39201 / 225000 loss 1.0421303510665894 train acc 0.7595341955562358\n",
      "epoch 3 batch id 39301 / 225000 loss 2.14667010307312 train acc 0.7595353807791151\n",
      "epoch 3 batch id 39401 / 225000 loss 1.9912151098251343 train acc 0.7596507702850182\n",
      "epoch 3 batch id 39501 / 225000 loss 0.12469472736120224 train acc 0.7596073517126148\n",
      "epoch 3 batch id 39601 / 225000 loss 1.292623519897461 train acc 0.7596272821393399\n",
      "epoch 3 batch id 39701 / 225000 loss 2.3151917457580566 train acc 0.7596723004458326\n",
      "epoch 3 batch id 39801 / 225000 loss 0.7946809530258179 train acc 0.759773623778297\n",
      "epoch 3 batch id 39901 / 225000 loss 2.069718837738037 train acc 0.7597804566301597\n",
      "epoch 3 batch id 40001 / 225000 loss 3.79150652885437 train acc 0.759787255318617\n",
      "epoch 3 batch id 40101 / 225000 loss 2.875014305114746 train acc 0.7597690830652603\n",
      "epoch 3 batch id 40201 / 225000 loss 2.2309834957122803 train acc 0.7597447824680978\n",
      "epoch 3 batch id 40301 / 225000 loss 2.3637309074401855 train acc 0.7597392124264907\n",
      "epoch 3 batch id 40401 / 225000 loss 2.3505916595458984 train acc 0.7597893616494641\n",
      "epoch 3 batch id 40501 / 225000 loss 2.598539113998413 train acc 0.7597219821732797\n",
      "epoch 3 batch id 40601 / 225000 loss 1.1855990886688232 train acc 0.7597288244131918\n",
      "epoch 3 batch id 40701 / 225000 loss 0.5885835289955139 train acc 0.7596926365445567\n",
      "epoch 3 batch id 40801 / 225000 loss 1.2739840745925903 train acc 0.759564716551065\n",
      "epoch 3 batch id 40901 / 225000 loss 2.0139832496643066 train acc 0.759504657587834\n",
      "epoch 3 batch id 41001 / 225000 loss 4.460020542144775 train acc 0.7594570864125265\n",
      "epoch 3 batch id 41101 / 225000 loss 3.5092897415161133 train acc 0.7594401596068222\n",
      "epoch 3 batch id 41201 / 225000 loss 1.0111305713653564 train acc 0.7595628746875076\n",
      "epoch 3 batch id 41301 / 225000 loss 3.6478500366210938 train acc 0.7596547299096874\n",
      "epoch 3 batch id 41401 / 225000 loss 0.012860274873673916 train acc 0.7596555638752687\n",
      "epoch 3 batch id 41501 / 225000 loss 0.004912771750241518 train acc 0.7597166333341365\n",
      "epoch 3 batch id 41601 / 225000 loss 0.03156674653291702 train acc 0.7596932766039278\n",
      "epoch 3 batch id 41701 / 225000 loss 0.01769411936402321 train acc 0.759616076353085\n",
      "epoch 3 batch id 41801 / 225000 loss 0.029393743723630905 train acc 0.7597007248630415\n",
      "epoch 3 batch id 41901 / 225000 loss 0.003645581193268299 train acc 0.759725304885325\n",
      "epoch 3 batch id 42001 / 225000 loss 1.0328789949417114 train acc 0.7596961977095783\n",
      "epoch 3 batch id 42101 / 225000 loss 2.9691243171691895 train acc 0.7596969193130805\n",
      "epoch 3 batch id 42201 / 225000 loss 4.688933372497559 train acc 0.7597154095874505\n",
      "epoch 3 batch id 42301 / 225000 loss 4.342146873474121 train acc 0.7596924422590482\n",
      "epoch 3 batch id 42401 / 225000 loss 0.19801124930381775 train acc 0.75964599891512\n",
      "epoch 3 batch id 42501 / 225000 loss 0.0010533469030633569 train acc 0.7597115361991482\n",
      "epoch 3 batch id 42601 / 225000 loss 0.5308318734169006 train acc 0.7596828712941011\n",
      "epoch 3 batch id 42701 / 225000 loss 4.279684543609619 train acc 0.7597070326221869\n",
      "epoch 3 batch id 42801 / 225000 loss 0.005259297322481871 train acc 0.7597544449896031\n",
      "epoch 3 batch id 42901 / 225000 loss 1.08119535446167 train acc 0.7597375352555884\n",
      "epoch 3 batch id 43001 / 225000 loss 0.005821918603032827 train acc 0.7598020976256367\n",
      "epoch 3 batch id 43101 / 225000 loss 1.1578246355056763 train acc 0.7599127630449409\n",
      "epoch 3 batch id 43201 / 225000 loss 0.05924973636865616 train acc 0.759970834008472\n",
      "epoch 3 batch id 43301 / 225000 loss 3.3792076110839844 train acc 0.7599651278261472\n",
      "epoch 3 batch id 43401 / 225000 loss 0.04470539465546608 train acc 0.7599824888827447\n",
      "epoch 3 batch id 43501 / 225000 loss 0.16551363468170166 train acc 0.7598790832394657\n",
      "epoch 3 batch id 43601 / 225000 loss 0.309089720249176 train acc 0.7599825692071283\n",
      "epoch 3 batch id 43701 / 225000 loss 0.5078981518745422 train acc 0.7599768884007231\n",
      "epoch 3 batch id 43801 / 225000 loss 3.219759941101074 train acc 0.759936987740006\n",
      "epoch 3 batch id 43901 / 225000 loss 3.5539731979370117 train acc 0.7599485205348397\n",
      "epoch 3 batch id 44001 / 225000 loss 0.0031814067624509335 train acc 0.7599372741528602\n",
      "epoch 3 batch id 44101 / 225000 loss 1.1683536767959595 train acc 0.7598863971338519\n",
      "epoch 3 batch id 44201 / 225000 loss 0.0030117405112832785 train acc 0.759903622089998\n",
      "epoch 3 batch id 44301 / 225000 loss 1.7845121622085571 train acc 0.7599320557098034\n",
      "epoch 3 batch id 44401 / 225000 loss 5.157120704650879 train acc 0.7599040562149502\n",
      "epoch 3 batch id 44501 / 225000 loss 3.500218391418457 train acc 0.7598986539628323\n",
      "epoch 3 batch id 44601 / 225000 loss 3.342068910598755 train acc 0.7599156969574673\n",
      "epoch 3 batch id 44701 / 225000 loss 1.214384913444519 train acc 0.759899107402519\n",
      "epoch 3 batch id 44801 / 225000 loss 1.3073499202728271 train acc 0.7598881721390147\n",
      "epoch 3 batch id 44901 / 225000 loss 0.9471763372421265 train acc 0.7599273958263736\n",
      "epoch 3 batch id 45001 / 225000 loss 0.07118630409240723 train acc 0.759999777782716\n",
      "epoch 3 batch id 45101 / 225000 loss 0.0030540970619767904 train acc 0.7600496663045165\n",
      "epoch 3 batch id 45201 / 225000 loss 0.0013664381112903357 train acc 0.7600661489790049\n",
      "epoch 3 batch id 45301 / 225000 loss 0.029442572966217995 train acc 0.7600715215999647\n",
      "epoch 3 batch id 45401 / 225000 loss 0.844897449016571 train acc 0.7600988965000771\n",
      "epoch 3 batch id 45501 / 225000 loss 0.0065331291407346725 train acc 0.7600876903804312\n",
      "epoch 3 batch id 45601 / 225000 loss 2.2926201820373535 train acc 0.7599833336988224\n",
      "epoch 3 batch id 45701 / 225000 loss 2.7313034534454346 train acc 0.7599177260891447\n",
      "epoch 3 batch id 45801 / 225000 loss 2.9059133529663086 train acc 0.759890613742058\n",
      "epoch 3 batch id 45901 / 225000 loss 1.9139143228530884 train acc 0.7600106751486896\n",
      "epoch 3 batch id 46001 / 225000 loss 2.0273590087890625 train acc 0.7600486945935958\n",
      "epoch 3 batch id 46101 / 225000 loss 2.3192548751831055 train acc 0.7600160517125442\n",
      "epoch 3 batch id 46201 / 225000 loss 0.04845620319247246 train acc 0.7600809506287742\n",
      "epoch 3 batch id 46301 / 225000 loss 1.204803228378296 train acc 0.7601131725016739\n",
      "epoch 3 batch id 46401 / 225000 loss 0.6794092059135437 train acc 0.7600267235619922\n",
      "epoch 3 batch id 46501 / 225000 loss 0.03316618129611015 train acc 0.7599460226661793\n",
      "epoch 3 batch id 46601 / 225000 loss 3.9305248260498047 train acc 0.7597100920581104\n",
      "epoch 3 batch id 46701 / 225000 loss 1.8062758445739746 train acc 0.7595447634954283\n",
      "epoch 3 batch id 46801 / 225000 loss 0.8396820425987244 train acc 0.7595243691374116\n",
      "epoch 3 batch id 46901 / 225000 loss 1.5126776695251465 train acc 0.7594880706168312\n",
      "epoch 3 batch id 47001 / 225000 loss 2.870105266571045 train acc 0.7594997978766409\n",
      "epoch 3 batch id 47101 / 225000 loss 5.446142196655273 train acc 0.7595273985690325\n",
      "epoch 3 batch id 47201 / 225000 loss 0.006798708811402321 train acc 0.7595283998220377\n",
      "epoch 3 batch id 47301 / 225000 loss 1.3351483345031738 train acc 0.7595716792456819\n",
      "epoch 3 batch id 47401 / 225000 loss 1.9903569221496582 train acc 0.7595040189025548\n",
      "epoch 3 batch id 47501 / 225000 loss 0.09911288321018219 train acc 0.7595734826635229\n",
      "epoch 3 batch id 47601 / 225000 loss 0.7174614667892456 train acc 0.7595638747085145\n",
      "epoch 3 batch id 47701 / 225000 loss 0.9479129910469055 train acc 0.75948617429404\n",
      "epoch 3 batch id 47801 / 225000 loss 0.00355778937228024 train acc 0.7594872492207276\n",
      "epoch 3 batch id 47901 / 225000 loss 1.2494951486587524 train acc 0.7594517859752405\n",
      "epoch 3 batch id 48001 / 225000 loss 3.3789334297180176 train acc 0.7595050103122851\n",
      "epoch 3 batch id 48101 / 225000 loss 0.0011966571910306811 train acc 0.7594332758154716\n",
      "epoch 3 batch id 48201 / 225000 loss 1.3657574653625488 train acc 0.7594863177112509\n",
      "epoch 3 batch id 48301 / 225000 loss 3.568735122680664 train acc 0.7594304465746051\n",
      "epoch 3 batch id 48401 / 225000 loss 0.11813787370920181 train acc 0.7594109625834177\n",
      "epoch 3 batch id 48501 / 225000 loss 0.008060608059167862 train acc 0.7594173316014102\n",
      "epoch 3 batch id 48601 / 225000 loss 3.169080972671509 train acc 0.7594802576078682\n",
      "epoch 3 batch id 48701 / 225000 loss 1.10712730884552 train acc 0.7594659247243383\n",
      "epoch 3 batch id 48801 / 225000 loss 1.7616009712219238 train acc 0.7595080018852073\n",
      "epoch 3 batch id 48901 / 225000 loss 0.005027138628065586 train acc 0.7595550193247582\n",
      "epoch 3 batch id 49001 / 225000 loss 0.0031063458882272243 train acc 0.7595304177465766\n",
      "epoch 3 batch id 49101 / 225000 loss 0.5496582984924316 train acc 0.7595619233824158\n",
      "epoch 3 batch id 49201 / 225000 loss 2.147871255874634 train acc 0.759532326578728\n",
      "epoch 3 batch id 49301 / 225000 loss 0.2912730872631073 train acc 0.7595687714245147\n",
      "epoch 3 batch id 49401 / 225000 loss 1.4400968551635742 train acc 0.759594947470699\n",
      "epoch 3 batch id 49501 / 225000 loss 2.5132133960723877 train acc 0.7595402113088624\n",
      "epoch 3 batch id 49601 / 225000 loss 0.8423402309417725 train acc 0.7595461785044656\n",
      "epoch 3 batch id 49701 / 225000 loss 2.3284950256347656 train acc 0.7595873322468361\n",
      "epoch 3 batch id 49801 / 225000 loss 0.0033545640762895346 train acc 0.7595931808598221\n",
      "epoch 3 batch id 49901 / 225000 loss 0.9375756978988647 train acc 0.7595388869962526\n",
      "epoch 3 batch id 50001 / 225000 loss 0.46918201446533203 train acc 0.7595298094038119\n",
      "epoch 3 batch id 50101 / 225000 loss 0.03760800138115883 train acc 0.759555697491068\n",
      "epoch 3 batch id 50201 / 225000 loss 1.3232132196426392 train acc 0.7595366626162825\n",
      "epoch 3 batch id 50301 / 225000 loss 1.018133521080017 train acc 0.7595624341464384\n",
      "epoch 3 batch id 50401 / 225000 loss 1.248471736907959 train acc 0.7594988194678677\n",
      "epoch 3 batch id 50501 / 225000 loss 2.4785735607147217 train acc 0.7594602087087384\n",
      "epoch 3 batch id 50601 / 225000 loss 1.0580451488494873 train acc 0.7595008003794391\n",
      "epoch 3 batch id 50701 / 225000 loss 1.1640007495880127 train acc 0.7595609554052188\n",
      "epoch 3 batch id 50801 / 225000 loss 0.016775362193584442 train acc 0.7595568984862503\n",
      "epoch 3 batch id 50901 / 225000 loss 0.012890934944152832 train acc 0.7595823264768865\n",
      "epoch 3 batch id 51001 / 225000 loss 0.3874204754829407 train acc 0.7596125566165369\n",
      "epoch 3 batch id 51101 / 225000 loss 0.0018015406094491482 train acc 0.7595790689027612\n",
      "epoch 3 batch id 51201 / 225000 loss 3.254394769668579 train acc 0.75965313177477\n",
      "epoch 3 batch id 51301 / 225000 loss 0.06133894622325897 train acc 0.7596586811173272\n",
      "epoch 3 batch id 51401 / 225000 loss 0.002688598819077015 train acc 0.7596788000233459\n",
      "epoch 3 batch id 51501 / 225000 loss 0.5186458230018616 train acc 0.7597182578979049\n",
      "epoch 3 batch id 51601 / 225000 loss 0.6372119188308716 train acc 0.7596461308889363\n",
      "epoch 3 batch id 51701 / 225000 loss 0.07087591290473938 train acc 0.7596129668671786\n",
      "epoch 3 batch id 51801 / 225000 loss 2.6077799797058105 train acc 0.7596378448292505\n",
      "epoch 3 batch id 51901 / 225000 loss 0.006609700154513121 train acc 0.7597685979075548\n",
      "epoch 3 batch id 52001 / 225000 loss 0.9467424154281616 train acc 0.7597642353031673\n",
      "epoch 3 batch id 52101 / 225000 loss 1.2633602619171143 train acc 0.7597934780522447\n",
      "epoch 3 batch id 52201 / 225000 loss 0.00681917741894722 train acc 0.759836976303136\n",
      "epoch 3 batch id 52301 / 225000 loss 0.5310848355293274 train acc 0.7599042083325367\n",
      "epoch 3 batch id 52401 / 225000 loss 0.7543995380401611 train acc 0.759885307532299\n",
      "epoch 3 batch id 52501 / 225000 loss 0.02898337133228779 train acc 0.759856955105617\n",
      "epoch 3 batch id 52601 / 225000 loss 0.007976391352713108 train acc 0.7598334632421437\n",
      "epoch 3 batch id 52701 / 225000 loss 0.5496271252632141 train acc 0.7598148042731637\n",
      "epoch 3 batch id 52801 / 225000 loss 0.0043763406574726105 train acc 0.7598814416393629\n",
      "epoch 3 batch id 52901 / 225000 loss 0.010394509881734848 train acc 0.7599147464131113\n",
      "epoch 3 batch id 53001 / 225000 loss 2.1037697792053223 train acc 0.7599054734816324\n",
      "epoch 3 batch id 53101 / 225000 loss 0.6809518933296204 train acc 0.7599480235777104\n",
      "epoch 3 batch id 53201 / 225000 loss 2.2522685527801514 train acc 0.7599763162346572\n",
      "epoch 3 batch id 53301 / 225000 loss 5.200319290161133 train acc 0.7599388379204893\n",
      "epoch 3 batch id 53401 / 225000 loss 0.9967312812805176 train acc 0.7598874552910995\n",
      "epoch 3 batch id 53501 / 225000 loss 0.2929553985595703 train acc 0.7599811218481898\n",
      "epoch 3 batch id 53601 / 225000 loss 1.2427705526351929 train acc 0.7599718288837894\n",
      "epoch 3 batch id 53701 / 225000 loss 0.3110293745994568 train acc 0.7600463678516228\n",
      "epoch 3 batch id 53801 / 225000 loss 0.09338509291410446 train acc 0.7600927492054051\n",
      "epoch 3 batch id 53901 / 225000 loss 0.008022461086511612 train acc 0.7601343203280088\n",
      "epoch 3 batch id 54001 / 225000 loss 1.2322285175323486 train acc 0.7602081442936242\n",
      "epoch 3 batch id 54101 / 225000 loss 1.4118257761001587 train acc 0.7602585904142253\n",
      "epoch 3 batch id 54201 / 225000 loss 0.694988489151001 train acc 0.7602904005461154\n",
      "epoch 3 batch id 54301 / 225000 loss 0.4144098162651062 train acc 0.7603082816154398\n",
      "epoch 3 batch id 54401 / 225000 loss 0.6047130823135376 train acc 0.760275546405397\n",
      "epoch 3 batch id 54501 / 225000 loss 2.3748600482940674 train acc 0.7602566925377516\n",
      "epoch 3 batch id 54601 / 225000 loss 3.7968909740448 train acc 0.7603020091207121\n",
      "epoch 3 batch id 54701 / 225000 loss 1.2270342111587524 train acc 0.7602786055099541\n",
      "epoch 3 batch id 54801 / 225000 loss 0.5896878242492676 train acc 0.7601959818251491\n",
      "epoch 3 batch id 54901 / 225000 loss 3.415956497192383 train acc 0.7601819638986539\n",
      "epoch 3 batch id 55001 / 225000 loss 0.0056821079924702644 train acc 0.7601770876893147\n",
      "epoch 3 batch id 55101 / 225000 loss 3.153721332550049 train acc 0.760231211774741\n",
      "epoch 3 batch id 55201 / 225000 loss 2.9435675144195557 train acc 0.7602624952446514\n",
      "epoch 3 batch id 55301 / 225000 loss 0.7960666418075562 train acc 0.760239417008734\n",
      "epoch 3 batch id 55401 / 225000 loss 1.4821557998657227 train acc 0.760238984855869\n",
      "epoch 3 batch id 55501 / 225000 loss 1.379372000694275 train acc 0.7603061206104395\n",
      "epoch 3 batch id 55601 / 225000 loss 1.0603611469268799 train acc 0.760341540619773\n",
      "epoch 3 batch id 55701 / 225000 loss 1.2923470735549927 train acc 0.7603768334500278\n",
      "epoch 3 batch id 55801 / 225000 loss 0.008473660796880722 train acc 0.7603806383398147\n",
      "epoch 3 batch id 55901 / 225000 loss 1.093865990638733 train acc 0.7603531242732688\n",
      "epoch 3 batch id 56001 / 225000 loss 2.591174364089966 train acc 0.7602810664095284\n",
      "epoch 3 batch id 56101 / 225000 loss 0.5551626086235046 train acc 0.7602716529117128\n",
      "epoch 3 batch id 56201 / 225000 loss 0.0026180909480899572 train acc 0.7602978594686928\n",
      "epoch 3 batch id 56301 / 225000 loss 0.0009803184075281024 train acc 0.7602840091650237\n",
      "epoch 3 batch id 56401 / 225000 loss 2.0469861030578613 train acc 0.7603544263399585\n",
      "epoch 3 batch id 56501 / 225000 loss 0.1513100117444992 train acc 0.7603537990478044\n",
      "epoch 3 batch id 56601 / 225000 loss 0.33557623624801636 train acc 0.7603266726736276\n",
      "epoch 3 batch id 56701 / 225000 loss 1.75367271900177 train acc 0.760308460168251\n",
      "epoch 3 batch id 56801 / 225000 loss 2.7526345252990723 train acc 0.7603299237689477\n",
      "epoch 3 batch id 56901 / 225000 loss 0.9102051854133606 train acc 0.7603513119277341\n",
      "epoch 3 batch id 57001 / 225000 loss 0.0029180566780269146 train acc 0.7603945544815003\n",
      "epoch 3 batch id 57101 / 225000 loss 1.2575017213821411 train acc 0.7604157545402007\n",
      "epoch 3 batch id 57201 / 225000 loss 0.009090084582567215 train acc 0.760393174944494\n",
      "epoch 3 batch id 57301 / 225000 loss 2.2113940715789795 train acc 0.7603750370848676\n",
      "epoch 3 batch id 57401 / 225000 loss 0.006251541897654533 train acc 0.760339541122977\n",
      "epoch 3 batch id 57501 / 225000 loss 3.4371886253356934 train acc 0.7603563416288412\n",
      "epoch 3 batch id 57601 / 225000 loss 0.029267163947224617 train acc 0.7603296817763581\n",
      "epoch 3 batch id 57701 / 225000 loss 1.3060985803604126 train acc 0.760350773816745\n",
      "epoch 3 batch id 57801 / 225000 loss 2.168100357055664 train acc 0.7603242158440165\n",
      "epoch 3 batch id 57901 / 225000 loss 2.9450325965881348 train acc 0.7603452444690074\n",
      "epoch 3 batch id 58001 / 225000 loss 0.9481744170188904 train acc 0.7603748211237737\n",
      "epoch 3 batch id 58101 / 225000 loss 0.06058144196867943 train acc 0.7603655702999949\n",
      "epoch 3 batch id 58201 / 225000 loss 0.08037329465150833 train acc 0.760364942183124\n",
      "epoch 3 batch id 58301 / 225000 loss 4.2818379402160645 train acc 0.7603857566765578\n",
      "epoch 3 batch id 58401 / 225000 loss 3.144982099533081 train acc 0.7603465694080581\n",
      "epoch 3 batch id 58501 / 225000 loss 0.0015956824645400047 train acc 0.7603929847353037\n",
      "epoch 3 batch id 58601 / 225000 loss 0.004451371263712645 train acc 0.7604221770959539\n",
      "epoch 3 batch id 58701 / 225000 loss 0.8143665194511414 train acc 0.7603873869269688\n",
      "epoch 3 batch id 58801 / 225000 loss 0.7761274576187134 train acc 0.7603782248601214\n",
      "epoch 3 batch id 58901 / 225000 loss 0.733083963394165 train acc 0.7604200268246719\n",
      "epoch 3 batch id 59001 / 225000 loss 1.4702157974243164 train acc 0.7603896544126371\n",
      "epoch 3 batch id 59101 / 225000 loss 0.06780490279197693 train acc 0.760431295578755\n",
      "epoch 3 batch id 59201 / 225000 loss 3.14825701713562 train acc 0.7604516815594331\n",
      "epoch 3 batch id 59301 / 225000 loss 1.951578140258789 train acc 0.7603961147366823\n",
      "epoch 3 batch id 59401 / 225000 loss 0.5918123126029968 train acc 0.7603996565714382\n",
      "epoch 3 batch id 59501 / 225000 loss 1.5667344331741333 train acc 0.760428396161409\n",
      "epoch 3 batch id 59601 / 225000 loss 1.7844526767730713 train acc 0.7604738175533967\n",
      "epoch 3 batch id 59701 / 225000 loss 1.2499995231628418 train acc 0.7605065241788245\n",
      "epoch 3 batch id 59801 / 225000 loss 3.4540529251098633 train acc 0.7604220665206267\n",
      "epoch 3 batch id 59901 / 225000 loss 2.737388849258423 train acc 0.7604756181032036\n",
      "epoch 3 batch id 60001 / 225000 loss 1.208483099937439 train acc 0.7604789920167997\n",
      "epoch 3 batch id 60101 / 225000 loss 0.0028675836510956287 train acc 0.7604241193990117\n",
      "epoch 3 batch id 60201 / 225000 loss 0.0057725743390619755 train acc 0.760348665304563\n",
      "epoch 3 batch id 60301 / 225000 loss 0.0011788883712142706 train acc 0.760360524701083\n",
      "epoch 3 batch id 60401 / 225000 loss 2.345998764038086 train acc 0.7603516498071224\n",
      "epoch 3 batch id 60501 / 225000 loss 1.7385427951812744 train acc 0.7603345399249599\n",
      "epoch 3 batch id 60601 / 225000 loss 0.010809240862727165 train acc 0.7603422385769212\n",
      "epoch 3 batch id 60701 / 225000 loss 0.00940890982747078 train acc 0.7603499118630666\n",
      "epoch 3 batch id 60801 / 225000 loss 0.006998921278864145 train acc 0.7603740070064637\n",
      "epoch 3 batch id 60901 / 225000 loss 0.6439962387084961 train acc 0.7604103380896865\n",
      "epoch 3 batch id 61001 / 225000 loss 3.248232126235962 train acc 0.7604383534696153\n",
      "epoch 3 batch id 61101 / 225000 loss 1.422785997390747 train acc 0.7604335444591741\n",
      "epoch 3 batch id 61201 / 225000 loss 0.004444674588739872 train acc 0.7604573454682113\n",
      "epoch 3 batch id 61301 / 225000 loss 3.6021132469177246 train acc 0.7604851470612225\n",
      "epoch 3 batch id 61401 / 225000 loss 0.0025257300585508347 train acc 0.7604639989576717\n",
      "epoch 3 batch id 61501 / 225000 loss 1.6193424463272095 train acc 0.7604998292710687\n",
      "epoch 3 batch id 61601 / 225000 loss 0.024286635220050812 train acc 0.7605030762487622\n",
      "epoch 3 batch id 61701 / 225000 loss 3.4433846473693848 train acc 0.7604576911233205\n",
      "epoch 3 batch id 61801 / 225000 loss 0.7318167090415955 train acc 0.7605054934386175\n",
      "epoch 3 batch id 61901 / 225000 loss 1.7499629259109497 train acc 0.760557180013247\n",
      "epoch 3 batch id 62001 / 225000 loss 2.7886857986450195 train acc 0.7605159594200094\n",
      "epoch 3 batch id 62101 / 225000 loss 1.8333464860916138 train acc 0.7605151285808602\n",
      "epoch 3 batch id 62201 / 225000 loss 0.0012571411207318306 train acc 0.7606147811128439\n",
      "epoch 3 batch id 62301 / 225000 loss 0.9803329706192017 train acc 0.7606338582045232\n",
      "epoch 3 batch id 62401 / 225000 loss 2.4267354011535645 train acc 0.7606929376131792\n",
      "epoch 3 batch id 62501 / 225000 loss 1.3956843614578247 train acc 0.760667829314731\n",
      "epoch 3 batch id 62601 / 225000 loss 1.1923706531524658 train acc 0.7606867302439259\n",
      "epoch 3 batch id 62701 / 225000 loss 0.03800274431705475 train acc 0.760725506770227\n",
      "epoch 3 batch id 62801 / 225000 loss 1.0454176664352417 train acc 0.7607362940080572\n",
      "epoch 3 batch id 62901 / 225000 loss 0.8305140137672424 train acc 0.7607708939444524\n",
      "epoch 3 batch id 63001 / 225000 loss 0.12115158885717392 train acc 0.7607379247948445\n",
      "epoch 3 batch id 63101 / 225000 loss 0.92531418800354 train acc 0.7607922219933123\n",
      "epoch 3 batch id 63201 / 225000 loss 0.9835997223854065 train acc 0.7608067910317875\n",
      "epoch 3 batch id 63301 / 225000 loss 0.6501404643058777 train acc 0.7608529091167596\n",
      "epoch 3 batch id 63401 / 225000 loss 0.6779240965843201 train acc 0.7608200186116938\n",
      "epoch 3 batch id 63501 / 225000 loss 1.0906445980072021 train acc 0.7608029794806381\n",
      "epoch 3 batch id 63601 / 225000 loss 0.3981780409812927 train acc 0.7608567475354161\n",
      "epoch 3 batch id 63701 / 225000 loss 1.5850098133087158 train acc 0.7608711009246323\n",
      "epoch 3 batch id 63801 / 225000 loss 0.010368213057518005 train acc 0.7608697355840818\n",
      "epoch 3 batch id 63901 / 225000 loss 0.006820985581725836 train acc 0.7609192344407756\n",
      "epoch 3 batch id 64001 / 225000 loss 1.5565623044967651 train acc 0.7609256105373353\n",
      "epoch 3 batch id 64101 / 225000 loss 0.02375885471701622 train acc 0.7609163663593391\n",
      "epoch 3 batch id 64201 / 225000 loss 2.8827857971191406 train acc 0.7609071509789567\n",
      "epoch 3 batch id 64301 / 225000 loss 0.6824072003364563 train acc 0.7609329559415873\n",
      "epoch 3 batch id 64401 / 225000 loss 1.5002772808074951 train acc 0.7609819723296222\n",
      "epoch 3 batch id 64501 / 225000 loss 3.2812838554382324 train acc 0.7609029317374925\n",
      "epoch 3 batch id 64601 / 225000 loss 1.4755859375 train acc 0.7608667048497701\n",
      "epoch 3 batch id 64701 / 225000 loss 0.2725539803504944 train acc 0.760857637439916\n",
      "epoch 3 batch id 64801 / 225000 loss 1.9284865856170654 train acc 0.7608640298760821\n",
      "epoch 3 batch id 64901 / 225000 loss 0.012686477042734623 train acc 0.760797214218579\n",
      "epoch 3 batch id 65001 / 225000 loss 0.22718994319438934 train acc 0.7607767572806572\n",
      "epoch 3 batch id 65101 / 225000 loss 2.2544491291046143 train acc 0.7607986052441591\n",
      "epoch 3 batch id 65201 / 225000 loss 2.5711171627044678 train acc 0.7608165518933758\n",
      "epoch 3 batch id 65301 / 225000 loss 1.9043012857437134 train acc 0.7607923308984549\n",
      "epoch 3 batch id 65401 / 225000 loss 0.030044404789805412 train acc 0.7608255225455268\n",
      "epoch 3 batch id 65501 / 225000 loss 2.793767213821411 train acc 0.7608318956962489\n",
      "epoch 3 batch id 65601 / 225000 loss 3.8288323879241943 train acc 0.7608001402417646\n",
      "epoch 3 batch id 65701 / 225000 loss 1.2226741313934326 train acc 0.7608027275079527\n",
      "epoch 3 batch id 65801 / 225000 loss 0.5393691658973694 train acc 0.7607597148979499\n",
      "epoch 3 batch id 65901 / 225000 loss 0.003032543696463108 train acc 0.7607851170695437\n",
      "epoch 3 batch id 66001 / 225000 loss 0.008266301825642586 train acc 0.7607649884092665\n",
      "epoch 3 batch id 66101 / 225000 loss 1.888013482093811 train acc 0.7607903057442399\n",
      "epoch 3 batch id 66201 / 225000 loss 0.0020700031891465187 train acc 0.7608533103729551\n",
      "epoch 3 batch id 66301 / 225000 loss 0.004473703447729349 train acc 0.7608256285727214\n",
      "epoch 3 batch id 66401 / 225000 loss 0.002856028266251087 train acc 0.7608319151820002\n",
      "epoch 3 batch id 66501 / 225000 loss 2.410388946533203 train acc 0.7608757763041157\n",
      "epoch 3 batch id 66601 / 225000 loss 2.4816157817840576 train acc 0.7609044909235597\n",
      "epoch 3 batch id 66701 / 225000 loss 0.004867181181907654 train acc 0.760951859792207\n",
      "epoch 3 batch id 66801 / 225000 loss 2.8659465312957764 train acc 0.7609691471684555\n",
      "epoch 3 batch id 66901 / 225000 loss 0.6129283308982849 train acc 0.760971435404553\n",
      "epoch 3 batch id 67001 / 225000 loss 2.1911256313323975 train acc 0.7609699855226041\n",
      "epoch 3 batch id 67101 / 225000 loss 0.43405500054359436 train acc 0.7609387341470321\n",
      "epoch 3 batch id 67201 / 225000 loss 1.2436823844909668 train acc 0.7609782592520945\n",
      "epoch 3 batch id 67301 / 225000 loss 0.7655952572822571 train acc 0.760995378969109\n",
      "epoch 3 batch id 67401 / 225000 loss 1.4103862047195435 train acc 0.7609716473049362\n",
      "epoch 3 batch id 67501 / 225000 loss 3.7639899253845215 train acc 0.7608776166279018\n",
      "epoch 3 batch id 67601 / 225000 loss 0.0031860165763646364 train acc 0.7608800165678022\n",
      "epoch 3 batch id 67701 / 225000 loss 1.1731078624725342 train acc 0.7608602531720359\n",
      "epoch 3 batch id 67801 / 225000 loss 0.08667637407779694 train acc 0.76088848247076\n",
      "epoch 3 batch id 67901 / 225000 loss 0.0018728598952293396 train acc 0.7608761284811711\n",
      "epoch 3 batch id 68001 / 225000 loss 3.929628849029541 train acc 0.7608123409949854\n",
      "epoch 3 batch id 68101 / 225000 loss 0.005038360133767128 train acc 0.7608405162919781\n",
      "epoch 3 batch id 68201 / 225000 loss 4.160129070281982 train acc 0.7608099587982581\n",
      "epoch 3 batch id 68301 / 225000 loss 0.7207544445991516 train acc 0.7608600166908245\n",
      "epoch 3 batch id 68401 / 225000 loss 0.015419960021972656 train acc 0.7608185552842794\n",
      "epoch 3 batch id 68501 / 225000 loss 0.05661090835928917 train acc 0.7608319586575378\n",
      "epoch 3 batch id 68601 / 225000 loss 0.024994947016239166 train acc 0.760838034430985\n",
      "epoch 3 batch id 68701 / 225000 loss 0.05084877833724022 train acc 0.7608477314740688\n",
      "epoch 3 batch id 68801 / 225000 loss 0.32094305753707886 train acc 0.7608719350009447\n",
      "epoch 3 batch id 68901 / 225000 loss 0.8406963348388672 train acc 0.7608924398775054\n",
      "epoch 3 batch id 69001 / 225000 loss 0.37401822209358215 train acc 0.7609418704076752\n",
      "epoch 3 batch id 69101 / 225000 loss 0.5833461880683899 train acc 0.760882621090867\n",
      "epoch 3 batch id 69201 / 225000 loss 1.1545889377593994 train acc 0.7608777329807372\n",
      "epoch 3 batch id 69301 / 225000 loss 0.001023478340357542 train acc 0.7609161483961271\n",
      "epoch 3 batch id 69401 / 225000 loss 0.0005777794867753983 train acc 0.7609292373308741\n",
      "epoch 3 batch id 69501 / 225000 loss 0.7109106183052063 train acc 0.760913512035798\n",
      "epoch 3 batch id 69601 / 225000 loss 0.008922136388719082 train acc 0.7609445266590997\n",
      "epoch 3 batch id 69701 / 225000 loss 0.1322173923254013 train acc 0.7609754522890633\n",
      "epoch 3 batch id 69801 / 225000 loss 1.1018555164337158 train acc 0.7609740548129683\n",
      "epoch 3 batch id 69901 / 225000 loss 0.8599954843521118 train acc 0.7609833907955537\n",
      "epoch 3 batch id 70001 / 225000 loss 0.007064999081194401 train acc 0.7610069856144912\n",
      "epoch 3 batch id 70101 / 225000 loss 0.9557334780693054 train acc 0.7610483445314618\n",
      "epoch 3 batch id 70201 / 225000 loss 4.0843353271484375 train acc 0.7610575347929517\n",
      "epoch 3 batch id 70301 / 225000 loss 0.8116523027420044 train acc 0.7610631427717955\n",
      "epoch 3 batch id 70401 / 225000 loss 1.9158741235733032 train acc 0.7610509793894973\n",
      "epoch 3 batch id 70501 / 225000 loss 2.563657283782959 train acc 0.7610636728557042\n",
      "epoch 3 batch id 70601 / 225000 loss 2.127669334411621 train acc 0.7610763303635926\n",
      "epoch 3 batch id 70701 / 225000 loss 3.6044464111328125 train acc 0.7611101681730102\n",
      "epoch 3 batch id 70801 / 225000 loss 2.802196979522705 train acc 0.7610838829960029\n",
      "epoch 3 batch id 70901 / 225000 loss 1.2658425569534302 train acc 0.7610823542686281\n",
      "epoch 3 batch id 71001 / 225000 loss 0.01768658310174942 train acc 0.7611230827734821\n",
      "epoch 3 batch id 71101 / 225000 loss 0.025480758398771286 train acc 0.7611215032137382\n",
      "epoch 3 batch id 71201 / 225000 loss 1.9703502655029297 train acc 0.7611725958905071\n",
      "epoch 3 batch id 71301 / 225000 loss 0.006128658074885607 train acc 0.7612095202030827\n",
      "epoch 3 batch id 71401 / 225000 loss 2.705995559692383 train acc 0.7611868181117911\n",
      "epoch 3 batch id 71501 / 225000 loss 0.014166373759508133 train acc 0.7612026405225102\n",
      "epoch 3 batch id 71601 / 225000 loss 0.0033810792956501245 train acc 0.7612533344506361\n",
      "epoch 3 batch id 71701 / 225000 loss 3.1204185485839844 train acc 0.7612585598527217\n",
      "epoch 3 batch id 71801 / 225000 loss 1.3881350755691528 train acc 0.7612602888539157\n",
      "epoch 3 batch id 71901 / 225000 loss 1.565724492073059 train acc 0.7612689670519186\n",
      "epoch 3 batch id 72001 / 225000 loss 1.8919507265090942 train acc 0.7613331759281121\n",
      "epoch 3 batch id 72101 / 225000 loss 1.3590580224990845 train acc 0.7612966533057794\n",
      "epoch 3 batch id 72201 / 225000 loss 0.8685008883476257 train acc 0.7613364080829905\n",
      "epoch 3 batch id 72301 / 225000 loss 0.7406713962554932 train acc 0.7613414752216429\n",
      "epoch 3 batch id 72401 / 225000 loss 0.12479467689990997 train acc 0.7613706992997334\n",
      "epoch 3 batch id 72501 / 225000 loss 2.320344924926758 train acc 0.7613791533909877\n",
      "epoch 3 batch id 72601 / 225000 loss 0.004300626926124096 train acc 0.7613531494056556\n",
      "epoch 3 batch id 72701 / 225000 loss 2.3734617233276367 train acc 0.761306584503652\n",
      "epoch 3 batch id 72801 / 225000 loss 1.3433551788330078 train acc 0.7613253938819522\n",
      "epoch 3 batch id 72901 / 225000 loss 0.8522580862045288 train acc 0.7613647275071672\n",
      "epoch 3 batch id 73001 / 225000 loss 0.9081998467445374 train acc 0.7613491596005534\n",
      "epoch 3 batch id 73101 / 225000 loss 1.044326663017273 train acc 0.7613541538419447\n",
      "epoch 3 batch id 73201 / 225000 loss 0.28967398405075073 train acc 0.7613420581686042\n",
      "epoch 3 batch id 73301 / 225000 loss 0.5202483534812927 train acc 0.7613641014447279\n",
      "epoch 3 batch id 73401 / 225000 loss 1.2516486644744873 train acc 0.7613384013841773\n",
      "epoch 3 batch id 73501 / 225000 loss 0.11261645704507828 train acc 0.7613841988544373\n",
      "epoch 3 batch id 73601 / 225000 loss 1.105081558227539 train acc 0.7613517479382074\n",
      "epoch 3 batch id 73701 / 225000 loss 1.8438260555267334 train acc 0.761343129672596\n",
      "epoch 3 batch id 73801 / 225000 loss 0.9676935076713562 train acc 0.7613311472744272\n",
      "epoch 3 batch id 73901 / 225000 loss 0.023764407262206078 train acc 0.7613124314961909\n",
      "epoch 3 batch id 74001 / 225000 loss 3.1800482273101807 train acc 0.7613241712949825\n",
      "epoch 3 batch id 74101 / 225000 loss 0.6222135424613953 train acc 0.7613257580869354\n",
      "epoch 3 batch id 74201 / 225000 loss 4.64555549621582 train acc 0.7612869098799208\n",
      "epoch 3 batch id 74301 / 225000 loss 0.6546703577041626 train acc 0.7613457423184076\n",
      "epoch 3 batch id 74401 / 225000 loss 2.3421692848205566 train acc 0.7613237725299391\n",
      "epoch 3 batch id 74501 / 225000 loss 0.18224279582500458 train acc 0.7613052173796325\n",
      "epoch 3 batch id 74601 / 225000 loss 1.062788486480713 train acc 0.7613068189434458\n",
      "epoch 3 batch id 74701 / 225000 loss 1.4551640748977661 train acc 0.7613318429472162\n",
      "epoch 3 batch id 74801 / 225000 loss 1.893985629081726 train acc 0.7613501156401652\n",
      "epoch 3 batch id 74901 / 225000 loss 1.0508955717086792 train acc 0.7613382998891871\n",
      "epoch 3 batch id 75001 / 225000 loss 0.015691425651311874 train acc 0.7613665151131318\n",
      "epoch 3 batch id 75101 / 225000 loss 1.703016996383667 train acc 0.7614645610577755\n",
      "epoch 3 batch id 75201 / 225000 loss 1.1814931631088257 train acc 0.7614559646813207\n",
      "epoch 3 batch id 75301 / 225000 loss 2.5025181770324707 train acc 0.7614141910465997\n",
      "epoch 3 batch id 75401 / 225000 loss 0.3878054916858673 train acc 0.761448787151364\n",
      "epoch 3 batch id 75501 / 225000 loss 0.7383346557617188 train acc 0.7614534906822427\n",
      "epoch 3 batch id 75601 / 225000 loss 4.349656105041504 train acc 0.7614978637848706\n",
      "epoch 3 batch id 75701 / 225000 loss 1.024665117263794 train acc 0.7614793727956037\n",
      "epoch 3 batch id 75801 / 225000 loss 0.961150050163269 train acc 0.7614510362660123\n",
      "epoch 3 batch id 75901 / 225000 loss 1.15503990650177 train acc 0.7614886496884099\n",
      "epoch 3 batch id 76001 / 225000 loss 1.6172598600387573 train acc 0.7614866909645925\n",
      "epoch 3 batch id 76101 / 225000 loss 0.6352960467338562 train acc 0.7615044480361625\n",
      "epoch 3 batch id 76201 / 225000 loss 0.2497919797897339 train acc 0.761515596908177\n",
      "epoch 3 batch id 76301 / 225000 loss 0.005088300444185734 train acc 0.7615660345211728\n",
      "epoch 3 batch id 76401 / 225000 loss 0.16306117177009583 train acc 0.7615672569730763\n",
      "epoch 3 batch id 76501 / 225000 loss 0.0027590098325163126 train acc 0.7616109593338649\n",
      "epoch 3 batch id 76601 / 225000 loss 0.0018216795288026333 train acc 0.7616512839257973\n",
      "epoch 3 batch id 76701 / 225000 loss 0.9620815515518188 train acc 0.7616230557619849\n",
      "epoch 3 batch id 76801 / 225000 loss 2.0785508155822754 train acc 0.7616437285972839\n",
      "epoch 3 batch id 76901 / 225000 loss 3.434300184249878 train acc 0.7616578458017451\n",
      "epoch 3 batch id 77001 / 225000 loss 1.865241527557373 train acc 0.761681666471864\n",
      "epoch 3 batch id 77101 / 225000 loss 0.00832309853285551 train acc 0.7616892128506764\n",
      "epoch 3 batch id 77201 / 225000 loss 1.9309303760528564 train acc 0.7617194077796919\n",
      "epoch 3 batch id 77301 / 225000 loss 0.0015170134138315916 train acc 0.7617398222532696\n",
      "epoch 3 batch id 77401 / 225000 loss 1.270768404006958 train acc 0.7617795635715301\n",
      "epoch 3 batch id 77501 / 225000 loss 0.9559900164604187 train acc 0.7617869446845847\n",
      "epoch 3 batch id 77601 / 225000 loss 1.7872995138168335 train acc 0.7618039715983042\n",
      "epoch 3 batch id 77701 / 225000 loss 0.002526944037526846 train acc 0.7618402594561202\n",
      "epoch 3 batch id 77801 / 225000 loss 0.22254571318626404 train acc 0.7618925206616881\n",
      "epoch 3 batch id 77901 / 225000 loss 1.8667627573013306 train acc 0.7619574844995571\n",
      "epoch 3 batch id 78001 / 225000 loss 2.575824737548828 train acc 0.7619389495006474\n",
      "epoch 3 batch id 78101 / 225000 loss 0.12027422338724136 train acc 0.7620036875328101\n",
      "epoch 3 batch id 78201 / 225000 loss 0.0016568552237004042 train acc 0.7620043221953684\n",
      "epoch 3 batch id 78301 / 225000 loss 0.002078952267765999 train acc 0.7619953768151109\n",
      "epoch 3 batch id 78401 / 225000 loss 0.04006022959947586 train acc 0.7620055866634354\n",
      "epoch 3 batch id 78501 / 225000 loss 0.0024344392586499453 train acc 0.7619743697532515\n",
      "epoch 3 batch id 78601 / 225000 loss 2.269751787185669 train acc 0.761949593516622\n",
      "epoch 3 batch id 78701 / 225000 loss 1.4343485832214355 train acc 0.7619502928806495\n",
      "epoch 3 batch id 78801 / 225000 loss 1.9553989171981812 train acc 0.7619668532125227\n",
      "epoch 3 batch id 78901 / 225000 loss 1.7780258655548096 train acc 0.7619675289286574\n",
      "epoch 3 batch id 79001 / 225000 loss 1.0218478441238403 train acc 0.7620093416539031\n",
      "epoch 3 batch id 79101 / 225000 loss 1.0983562469482422 train acc 0.7620162829799876\n",
      "epoch 3 batch id 79201 / 225000 loss 0.0026170904748141766 train acc 0.7619947980454792\n",
      "epoch 3 batch id 79301 / 225000 loss 2.1121950149536133 train acc 0.761985977478216\n",
      "epoch 3 batch id 79401 / 225000 loss 0.13446485996246338 train acc 0.7620149620281861\n",
      "epoch 3 batch id 79501 / 225000 loss 1.4076427221298218 train acc 0.7619998490585024\n",
      "epoch 3 batch id 79601 / 225000 loss 2.738161087036133 train acc 0.7620475873418676\n",
      "epoch 3 batch id 79701 / 225000 loss 0.3221293091773987 train acc 0.7620920691082922\n",
      "epoch 3 batch id 79801 / 225000 loss 2.9211723804473877 train acc 0.7621239082217015\n",
      "epoch 3 batch id 79901 / 225000 loss 0.006038485560566187 train acc 0.7620711880952679\n",
      "epoch 3 batch id 80001 / 225000 loss 0.8198837637901306 train acc 0.7620904738690767\n",
      "epoch 3 batch id 80101 / 225000 loss 0.6631062626838684 train acc 0.7621221957278935\n",
      "epoch 3 batch id 80201 / 225000 loss 2.4827792644500732 train acc 0.7621320183040112\n",
      "epoch 3 batch id 80301 / 225000 loss 2.2542812824249268 train acc 0.7621511562745171\n",
      "epoch 3 batch id 80401 / 225000 loss 1.5493369102478027 train acc 0.7621453713262273\n",
      "epoch 3 batch id 80501 / 225000 loss 0.0013297110563144088 train acc 0.7621364951988174\n",
      "epoch 3 batch id 80601 / 225000 loss 2.9746339321136475 train acc 0.7621679631766355\n",
      "epoch 3 batch id 80701 / 225000 loss 4.713907718658447 train acc 0.7621559831972342\n",
      "epoch 3 batch id 80801 / 225000 loss 2.3591713905334473 train acc 0.76217806710313\n",
      "epoch 3 batch id 80901 / 225000 loss 1.129041314125061 train acc 0.7622402689707173\n",
      "epoch 3 batch id 81001 / 225000 loss 2.046173334121704 train acc 0.7622375032407007\n",
      "epoch 3 batch id 81101 / 225000 loss 1.3679144382476807 train acc 0.762222414026954\n",
      "epoch 3 batch id 81201 / 225000 loss 3.7271034717559814 train acc 0.7621919680792109\n",
      "epoch 3 batch id 81301 / 225000 loss 0.27497008442878723 train acc 0.7622292468727322\n",
      "epoch 3 batch id 81401 / 225000 loss 2.671220064163208 train acc 0.7622234370585128\n",
      "epoch 3 batch id 81501 / 225000 loss 1.4631483554840088 train acc 0.7621900344781045\n",
      "epoch 3 batch id 81601 / 225000 loss 0.32895326614379883 train acc 0.7622026690849377\n",
      "epoch 3 batch id 81701 / 225000 loss 0.7679492831230164 train acc 0.7622458721435478\n",
      "epoch 3 batch id 81801 / 225000 loss 1.57237708568573 train acc 0.7622553514015721\n",
      "epoch 3 batch id 81901 / 225000 loss 0.8852459192276001 train acc 0.7622495451825985\n",
      "epoch 3 batch id 82001 / 225000 loss 1.745015025138855 train acc 0.7622468018682699\n",
      "epoch 3 batch id 82101 / 225000 loss 0.45855677127838135 train acc 0.762234930147014\n",
      "epoch 3 batch id 82201 / 225000 loss 2.854447364807129 train acc 0.7622322112869673\n",
      "epoch 3 batch id 82301 / 225000 loss 0.06412026286125183 train acc 0.7622538000753333\n",
      "epoch 3 batch id 82401 / 225000 loss 0.7851351499557495 train acc 0.7623178116770427\n",
      "epoch 3 batch id 82501 / 225000 loss 1.38070547580719 train acc 0.7623028811771978\n",
      "epoch 3 batch id 82601 / 225000 loss 1.2809631824493408 train acc 0.7622789070350238\n",
      "epoch 3 batch id 82701 / 225000 loss 1.4282348155975342 train acc 0.7622670826229428\n",
      "epoch 3 batch id 82801 / 225000 loss 1.7419227361679077 train acc 0.7622703832079323\n",
      "epoch 3 batch id 82901 / 225000 loss 0.5763920545578003 train acc 0.7622555819592044\n",
      "epoch 3 batch id 83001 / 225000 loss 1.850079894065857 train acc 0.762231780339996\n",
      "epoch 3 batch id 83101 / 225000 loss 2.5163164138793945 train acc 0.7622140527791482\n",
      "epoch 3 batch id 83201 / 225000 loss 1.5961565971374512 train acc 0.7622083869184264\n",
      "epoch 3 batch id 83301 / 225000 loss 0.2605934143066406 train acc 0.7622987719235064\n",
      "epoch 3 batch id 83401 / 225000 loss 2.510810375213623 train acc 0.762322993729092\n",
      "epoch 3 batch id 83501 / 225000 loss 0.002003883011639118 train acc 0.762302247877271\n",
      "epoch 3 batch id 83601 / 225000 loss 1.0961956977844238 train acc 0.7623084652097463\n",
      "epoch 3 batch id 83701 / 225000 loss 0.23426423966884613 train acc 0.7623176545083094\n",
      "epoch 3 batch id 83801 / 225000 loss 1.8548110723495483 train acc 0.7623536711972411\n",
      "epoch 3 batch id 83901 / 225000 loss 0.0049317036755383015 train acc 0.762368744115088\n",
      "epoch 3 batch id 84001 / 225000 loss 3.655320167541504 train acc 0.7623956857656456\n",
      "epoch 3 batch id 84101 / 225000 loss 0.03866375610232353 train acc 0.762360138405013\n",
      "epoch 3 batch id 84201 / 225000 loss 2.6837916374206543 train acc 0.7623632735953255\n",
      "epoch 3 batch id 84301 / 225000 loss 0.7060562372207642 train acc 0.7624108848056369\n",
      "epoch 3 batch id 84401 / 225000 loss 0.09343860298395157 train acc 0.7623991421902584\n",
      "epoch 3 batch id 84501 / 225000 loss 2.6641364097595215 train acc 0.7624525153548479\n",
      "epoch 3 batch id 84601 / 225000 loss 2.5674872398376465 train acc 0.7624407512913559\n",
      "epoch 3 batch id 84701 / 225000 loss 0.002470910781994462 train acc 0.7624969008630359\n",
      "epoch 3 batch id 84801 / 225000 loss 0.02280823513865471 train acc 0.7625116449098478\n",
      "epoch 3 batch id 84901 / 225000 loss 2.944920063018799 train acc 0.7624880743454141\n",
      "epoch 3 batch id 85001 / 225000 loss 0.8881990909576416 train acc 0.7625057352266444\n",
      "epoch 3 batch id 85101 / 225000 loss 2.4100282192230225 train acc 0.76252041691637\n",
      "epoch 3 batch id 85201 / 225000 loss 0.006322155240923166 train acc 0.7625673407589113\n",
      "epoch 3 batch id 85301 / 225000 loss 0.8664504885673523 train acc 0.7625877774000305\n",
      "epoch 3 batch id 85401 / 225000 loss 0.002450408414006233 train acc 0.7626023114483437\n",
      "epoch 3 batch id 85501 / 225000 loss 3.723525285720825 train acc 0.7626021917872305\n",
      "epoch 3 batch id 85601 / 225000 loss 0.8517159819602966 train acc 0.7625933108258081\n",
      "epoch 3 batch id 85701 / 225000 loss 1.3541746139526367 train acc 0.7626369587286029\n",
      "epoch 3 batch id 85801 / 225000 loss 1.434836983680725 train acc 0.7626338853859512\n",
      "epoch 3 batch id 85901 / 225000 loss 0.9511806964874268 train acc 0.7626511914878755\n",
      "epoch 3 batch id 86001 / 225000 loss 0.16735249757766724 train acc 0.7626103184846688\n",
      "epoch 3 batch id 86101 / 225000 loss 0.008065886795520782 train acc 0.7626653581259218\n",
      "epoch 3 batch id 86201 / 225000 loss 4.03578519821167 train acc 0.7626883678843633\n",
      "epoch 3 batch id 86301 / 225000 loss 1.7770415544509888 train acc 0.7627460863721162\n",
      "epoch 3 batch id 86401 / 225000 loss 0.0016577556962147355 train acc 0.7627573754933392\n",
      "epoch 3 batch id 86501 / 225000 loss 2.82126522064209 train acc 0.7627830892128414\n",
      "epoch 3 batch id 86601 / 225000 loss 1.6505910158157349 train acc 0.7627769887183751\n",
      "epoch 3 batch id 86701 / 225000 loss 0.0032956150826066732 train acc 0.7628026205003402\n",
      "epoch 3 batch id 86801 / 225000 loss 1.873858094215393 train acc 0.7627705902005737\n",
      "epoch 3 batch id 86901 / 225000 loss 1.1584585905075073 train acc 0.7628048008653525\n",
      "epoch 3 batch id 87001 / 225000 loss 0.012193584814667702 train acc 0.7628245652348824\n",
      "epoch 3 batch id 87101 / 225000 loss 1.4933913946151733 train acc 0.7628414139906545\n",
      "epoch 3 batch id 87201 / 225000 loss 0.6185288429260254 train acc 0.7628553571633353\n",
      "epoch 3 batch id 87301 / 225000 loss 1.2418923377990723 train acc 0.7628234499032085\n",
      "epoch 3 batch id 87401 / 225000 loss 0.002297478262335062 train acc 0.7628860081692429\n",
      "epoch 3 batch id 87501 / 225000 loss 0.0098866056650877 train acc 0.7628798528016822\n",
      "epoch 3 batch id 87601 / 225000 loss 2.3368523120880127 train acc 0.7628537345464093\n",
      "epoch 3 batch id 87701 / 225000 loss 1.7636786699295044 train acc 0.7628618829887914\n",
      "epoch 3 batch id 87801 / 225000 loss 3.1476376056671143 train acc 0.7628386920422319\n",
      "epoch 3 batch id 87901 / 225000 loss 0.8100633025169373 train acc 0.7628639037098554\n",
      "epoch 3 batch id 88001 / 225000 loss 0.9843274354934692 train acc 0.7628521266803786\n",
      "epoch 3 batch id 88101 / 225000 loss 0.014087499119341373 train acc 0.7628574022996334\n",
      "epoch 3 batch id 88201 / 225000 loss 0.0037433872930705547 train acc 0.7628541626512171\n",
      "epoch 3 batch id 88301 / 225000 loss 1.2135387659072876 train acc 0.7628424366654964\n",
      "epoch 3 batch id 88401 / 225000 loss 0.0026486751157790422 train acc 0.7628392212757774\n",
      "epoch 3 batch id 88501 / 225000 loss 0.5301339030265808 train acc 0.7628275386718795\n",
      "epoch 3 batch id 88601 / 225000 loss 0.00910154078155756 train acc 0.7628158824392501\n",
      "epoch 3 batch id 88701 / 225000 loss 2.235245943069458 train acc 0.7628211632337855\n",
      "epoch 3 batch id 88801 / 225000 loss 2.986863851547241 train acc 0.7628123557167149\n",
      "epoch 3 batch id 88901 / 225000 loss 2.4670865535736084 train acc 0.7628260649486508\n",
      "epoch 3 batch id 89001 / 225000 loss 1.1681362390518188 train acc 0.7628200806732509\n",
      "epoch 3 batch id 89101 / 225000 loss 1.035894513130188 train acc 0.7628253330490118\n",
      "epoch 3 batch id 89201 / 225000 loss 0.0011659900192171335 train acc 0.7628053497158104\n",
      "epoch 3 batch id 89301 / 225000 loss 0.14474014937877655 train acc 0.7628162058655558\n",
      "epoch 3 batch id 89401 / 225000 loss 1.3040302991867065 train acc 0.7628494088433015\n",
      "epoch 3 batch id 89501 / 225000 loss 0.4445376396179199 train acc 0.762851811711601\n",
      "epoch 3 batch id 89601 / 225000 loss 1.1950163841247559 train acc 0.7628737402484347\n",
      "epoch 3 batch id 89701 / 225000 loss 0.13409563899040222 train acc 0.7628092217478066\n",
      "epoch 3 batch id 89801 / 225000 loss 1.1670202016830444 train acc 0.7628673400073496\n",
      "epoch 3 batch id 89901 / 225000 loss 4.040639877319336 train acc 0.7628724930757166\n",
      "epoch 3 batch id 90001 / 225000 loss 0.5260744690895081 train acc 0.7628887456806035\n",
      "epoch 3 batch id 90101 / 225000 loss 0.610485315322876 train acc 0.762927159520982\n",
      "epoch 3 batch id 90201 / 225000 loss 0.05578435957431793 train acc 0.7629627165995942\n",
      "epoch 3 batch id 90301 / 225000 loss 1.7657835483551025 train acc 0.7630341856679328\n",
      "epoch 3 batch id 90401 / 225000 loss 1.6588387489318848 train acc 0.7630474220417915\n",
      "epoch 3 batch id 90501 / 225000 loss 2.5867767333984375 train acc 0.7630993027701352\n",
      "epoch 3 batch id 90601 / 225000 loss 0.9205840229988098 train acc 0.76309864129535\n",
      "epoch 3 batch id 90701 / 225000 loss 0.3124946355819702 train acc 0.7631034938975314\n",
      "epoch 3 batch id 90801 / 225000 loss 0.8151466846466064 train acc 0.7631413750949879\n",
      "epoch 3 batch id 90901 / 225000 loss 3.0170347690582275 train acc 0.7631461700091308\n",
      "epoch 3 batch id 91001 / 225000 loss 0.6580873131752014 train acc 0.7631482071625586\n",
      "epoch 3 batch id 91101 / 225000 loss 1.2180743217468262 train acc 0.7631694492925435\n",
      "epoch 3 batch id 91201 / 225000 loss 0.010969712398946285 train acc 0.7631879036414074\n",
      "epoch 3 batch id 91301 / 225000 loss 1.0953123569488525 train acc 0.763209055760616\n",
      "epoch 3 batch id 91401 / 225000 loss 1.394194483757019 train acc 0.7631836631984332\n",
      "epoch 3 batch id 91501 / 225000 loss 1.194992184638977 train acc 0.7631829160337046\n",
      "epoch 3 batch id 91601 / 225000 loss 1.264813780784607 train acc 0.7631739828167815\n",
      "epoch 3 batch id 91701 / 225000 loss 0.03923851251602173 train acc 0.7631677953348383\n",
      "epoch 3 batch id 91801 / 225000 loss 0.11123485863208771 train acc 0.763226980098256\n",
      "epoch 3 batch id 91901 / 225000 loss 0.9445819854736328 train acc 0.7632588328745062\n",
      "epoch 3 batch id 92001 / 225000 loss 0.19335037469863892 train acc 0.7632634427886653\n",
      "epoch 3 batch id 92101 / 225000 loss 2.1249499320983887 train acc 0.7632680426922618\n",
      "epoch 3 batch id 92201 / 225000 loss 0.010885151103138924 train acc 0.7633105931605948\n",
      "epoch 3 batch id 92301 / 225000 loss 0.0009412127546966076 train acc 0.7633178405434394\n",
      "epoch 3 batch id 92401 / 225000 loss 2.246957778930664 train acc 0.7633034274520839\n",
      "epoch 3 batch id 92501 / 225000 loss 0.015089812688529491 train acc 0.7633430989935244\n",
      "epoch 3 batch id 92601 / 225000 loss 0.020438406616449356 train acc 0.7633016922063477\n",
      "epoch 3 batch id 92701 / 225000 loss 1.0018292665481567 train acc 0.76329273686368\n",
      "epoch 3 batch id 92801 / 225000 loss 2.924243688583374 train acc 0.7632622493292098\n",
      "epoch 3 batch id 92901 / 225000 loss 1.571915864944458 train acc 0.7632264453558089\n",
      "epoch 3 batch id 93001 / 225000 loss 5.034188747406006 train acc 0.7631987828087871\n",
      "epoch 3 batch id 93101 / 225000 loss 0.005810840986669064 train acc 0.7632302553141213\n",
      "epoch 3 batch id 93201 / 225000 loss 0.0014873618492856622 train acc 0.7632402012853939\n",
      "epoch 3 batch id 93301 / 225000 loss 1.1238524913787842 train acc 0.763266202934588\n",
      "epoch 3 batch id 93401 / 225000 loss 3.331784725189209 train acc 0.7632519994432608\n",
      "epoch 3 batch id 93501 / 225000 loss 0.003988578915596008 train acc 0.7632298050288232\n",
      "epoch 3 batch id 93601 / 225000 loss 0.8925696015357971 train acc 0.7632423798891037\n",
      "epoch 3 batch id 93701 / 225000 loss 1.1144840717315674 train acc 0.7632495917866405\n",
      "epoch 3 batch id 93801 / 225000 loss 1.8958179950714111 train acc 0.7632514578735834\n",
      "epoch 3 batch id 93901 / 225000 loss 0.030109113082289696 train acc 0.7633092299336536\n",
      "epoch 3 batch id 94001 / 225000 loss 0.03454529121518135 train acc 0.7632897522366784\n",
      "epoch 3 batch id 94101 / 225000 loss 1.3016432523727417 train acc 0.7632809428167607\n",
      "epoch 3 batch id 94201 / 225000 loss 0.5071107149124146 train acc 0.7632986910966975\n",
      "epoch 3 batch id 94301 / 225000 loss 1.317341685295105 train acc 0.7632951930520355\n",
      "epoch 3 batch id 94401 / 225000 loss 0.6569979190826416 train acc 0.7633181851887162\n",
      "epoch 3 batch id 94501 / 225000 loss 0.005816744640469551 train acc 0.763333192241352\n",
      "epoch 3 batch id 94601 / 225000 loss 0.9873817563056946 train acc 0.7633428822105475\n",
      "epoch 3 batch id 94701 / 225000 loss 0.0033313417807221413 train acc 0.7634053494683266\n",
      "epoch 3 batch id 94801 / 225000 loss 0.01228672731667757 train acc 0.7634729591460006\n",
      "epoch 3 batch id 94901 / 225000 loss 0.006828259211033583 train acc 0.7634982771519794\n",
      "epoch 3 batch id 95001 / 225000 loss 1.4021613597869873 train acc 0.7634867001399985\n",
      "epoch 3 batch id 95101 / 225000 loss 0.06894532591104507 train acc 0.7634804050430595\n",
      "epoch 3 batch id 95201 / 225000 loss 2.720876693725586 train acc 0.7634793752166469\n",
      "epoch 3 batch id 95301 / 225000 loss 0.6776639819145203 train acc 0.7634704777494465\n",
      "epoch 3 batch id 95401 / 225000 loss 0.8738453388214111 train acc 0.7634589784174171\n",
      "epoch 3 batch id 95501 / 225000 loss 0.005901306867599487 train acc 0.7634762986775008\n",
      "epoch 3 batch id 95601 / 225000 loss 0.7768373489379883 train acc 0.7634935827031099\n",
      "epoch 3 batch id 95701 / 225000 loss 1.6904178857803345 train acc 0.7635056060020271\n",
      "epoch 3 batch id 95801 / 225000 loss 1.0089415311813354 train acc 0.763525432928675\n",
      "epoch 3 batch id 95901 / 225000 loss 2.5526251792907715 train acc 0.7635347910866415\n",
      "epoch 3 batch id 96001 / 225000 loss 2.419121265411377 train acc 0.763502463516005\n",
      "epoch 3 batch id 96101 / 225000 loss 1.654647946357727 train acc 0.7635170289591159\n",
      "epoch 3 batch id 96201 / 225000 loss 1.038925290107727 train acc 0.7635341628465401\n",
      "epoch 3 batch id 96301 / 225000 loss 3.322326421737671 train acc 0.7635201088254535\n",
      "epoch 3 batch id 96401 / 225000 loss 3.4855921268463135 train acc 0.7635086772958787\n",
      "epoch 3 batch id 96501 / 225000 loss 0.6316554546356201 train acc 0.7635257665723671\n",
      "epoch 3 batch id 96601 / 225000 loss 0.0008069133618846536 train acc 0.7635402325027691\n",
      "epoch 3 batch id 96701 / 225000 loss 3.640043258666992 train acc 0.763552083225613\n",
      "epoch 3 batch id 96801 / 225000 loss 0.0044814180582761765 train acc 0.7635561616099007\n",
      "epoch 3 batch id 96901 / 225000 loss 3.237987995147705 train acc 0.7635576516238223\n",
      "epoch 3 batch id 97001 / 225000 loss 1.197890281677246 train acc 0.7635617158585994\n",
      "epoch 3 batch id 97101 / 225000 loss 0.07464297860860825 train acc 0.7635786449161183\n",
      "epoch 3 batch id 97201 / 225000 loss 0.019531577825546265 train acc 0.7635852511805434\n",
      "epoch 3 batch id 97301 / 225000 loss 0.12426711618900299 train acc 0.7635867051726087\n",
      "epoch 3 batch id 97401 / 225000 loss 2.2259604930877686 train acc 0.7636009897228981\n",
      "epoch 3 batch id 97501 / 225000 loss 0.0027344890404492617 train acc 0.7636408857345053\n",
      "epoch 3 batch id 97601 / 225000 loss 1.5328389406204224 train acc 0.7636141023145254\n",
      "epoch 3 batch id 97701 / 225000 loss 0.002046635840088129 train acc 0.7636436679256098\n",
      "epoch 3 batch id 97801 / 225000 loss 1.0256068706512451 train acc 0.7636578358094498\n",
      "epoch 3 batch id 97901 / 225000 loss 0.009918466210365295 train acc 0.7637000643507217\n",
      "epoch 3 batch id 98001 / 225000 loss 0.0004674223600886762 train acc 0.7637115947796451\n",
      "epoch 3 batch id 98101 / 225000 loss 1.7387944459915161 train acc 0.7637409404593225\n",
      "epoch 3 batch id 98201 / 225000 loss 1.229818344116211 train acc 0.7637473141821366\n",
      "epoch 3 batch id 98301 / 225000 loss 0.003751062788069248 train acc 0.7637485885189368\n",
      "epoch 3 batch id 98401 / 225000 loss 0.05008034408092499 train acc 0.7638057540065649\n",
      "epoch 3 batch id 98501 / 225000 loss 0.00885961577296257 train acc 0.7638323468797271\n",
      "epoch 3 batch id 98601 / 225000 loss 0.9807791709899902 train acc 0.7638538148700318\n",
      "epoch 3 batch id 98701 / 225000 loss 0.7452200055122375 train acc 0.7638676406520704\n",
      "epoch 3 batch id 98801 / 225000 loss 1.3363832235336304 train acc 0.7638915598020263\n",
      "epoch 3 batch id 98901 / 225000 loss 2.0293946266174316 train acc 0.763905319460875\n",
      "epoch 3 batch id 99001 / 225000 loss 4.163926601409912 train acc 0.7638937990525348\n",
      "epoch 3 batch id 99101 / 225000 loss 1.621528148651123 train acc 0.7638797792151442\n",
      "epoch 3 batch id 99201 / 225000 loss 0.860049843788147 train acc 0.7638607473714982\n",
      "epoch 3 batch id 99301 / 225000 loss 0.007854076102375984 train acc 0.763846789055498\n",
      "epoch 3 batch id 99401 / 225000 loss 0.696228563785553 train acc 0.7638429190853211\n",
      "epoch 3 batch id 99501 / 225000 loss 2.5607924461364746 train acc 0.763841569431463\n",
      "epoch 3 batch id 99601 / 225000 loss 0.002466009696945548 train acc 0.7638753626971617\n",
      "epoch 3 batch id 99701 / 225000 loss 0.21094410121440887 train acc 0.7638664607175455\n",
      "epoch 3 batch id 99801 / 225000 loss 0.010563935153186321 train acc 0.7638826264265889\n",
      "epoch 3 batch id 99901 / 225000 loss 0.18838563561439514 train acc 0.7638887498623638\n",
      "epoch 3 batch id 100001 / 225000 loss 0.021699223667383194 train acc 0.763939860601394\n",
      "epoch 3 batch id 100101 / 225000 loss 0.8800274133682251 train acc 0.7639234373282984\n",
      "epoch 3 batch id 100201 / 225000 loss 0.3963024616241455 train acc 0.7639270067164998\n",
      "epoch 3 batch id 100301 / 225000 loss 1.467484951019287 train acc 0.7639355539825127\n",
      "epoch 3 batch id 100401 / 225000 loss 1.3413810729980469 train acc 0.7639490642523481\n",
      "epoch 3 batch id 100501 / 225000 loss 0.0033303690142929554 train acc 0.7639650351737793\n",
      "epoch 3 batch id 100601 / 225000 loss 0.006821105256676674 train acc 0.7639312730489757\n",
      "epoch 3 batch id 100701 / 225000 loss 2.3211867809295654 train acc 0.7639199213513272\n",
      "epoch 3 batch id 100801 / 225000 loss 0.5938812494277954 train acc 0.7639209928472932\n",
      "epoch 3 batch id 100901 / 225000 loss 1.9338490962982178 train acc 0.7639022408102992\n",
      "epoch 3 batch id 101001 / 225000 loss 0.1105603575706482 train acc 0.763920654250948\n",
      "epoch 3 batch id 101101 / 225000 loss 1.018543004989624 train acc 0.763914303518264\n",
      "epoch 3 batch id 101201 / 225000 loss 0.1975458264350891 train acc 0.7639351389808401\n",
      "epoch 3 batch id 101301 / 225000 loss 1.2092665433883667 train acc 0.7639559333076672\n",
      "epoch 3 batch id 101401 / 225000 loss 0.008256635628640652 train acc 0.7639495665723218\n",
      "epoch 3 batch id 101501 / 225000 loss 0.02887185662984848 train acc 0.7640171032797707\n",
      "epoch 3 batch id 101601 / 225000 loss 1.145896077156067 train acc 0.7640205312939833\n",
      "epoch 3 batch id 101701 / 225000 loss 2.8772072792053223 train acc 0.7640239525668381\n",
      "epoch 3 batch id 101801 / 225000 loss 0.0036130896769464016 train acc 0.7640642036915158\n",
      "epoch 3 batch id 101901 / 225000 loss 3.723952531814575 train acc 0.7640381350526492\n",
      "epoch 3 batch id 102001 / 225000 loss 0.0048290640115737915 train acc 0.7640488818737071\n",
      "epoch 3 batch id 102101 / 225000 loss 0.11799119412899017 train acc 0.7640351220849942\n",
      "epoch 3 batch id 102201 / 225000 loss 1.4614884853363037 train acc 0.7640531893034315\n",
      "epoch 3 batch id 102301 / 225000 loss 0.8117942214012146 train acc 0.7640858838134524\n",
      "epoch 3 batch id 102401 / 225000 loss 0.9829519391059875 train acc 0.7641038661731819\n",
      "epoch 3 batch id 102501 / 225000 loss 0.9260590076446533 train acc 0.7641291304475079\n",
      "epoch 3 batch id 102601 / 225000 loss 2.824753522872925 train acc 0.7641104862525706\n",
      "epoch 3 batch id 102701 / 225000 loss 1.4703174829483032 train acc 0.7640918783653519\n",
      "epoch 3 batch id 102801 / 225000 loss 1.757034420967102 train acc 0.7640927617435628\n",
      "epoch 3 batch id 102901 / 225000 loss 1.2625195980072021 train acc 0.7641009319637321\n",
      "epoch 3 batch id 103001 / 225000 loss 0.5801769495010376 train acc 0.7641090863195503\n",
      "epoch 3 batch id 103101 / 225000 loss 0.09158004820346832 train acc 0.7641099504369502\n",
      "epoch 3 batch id 103201 / 225000 loss 0.7478470206260681 train acc 0.7640696311082257\n",
      "epoch 3 batch id 103301 / 225000 loss 5.693648815155029 train acc 0.7640705317470305\n",
      "epoch 3 batch id 103401 / 225000 loss 0.9353582262992859 train acc 0.7640811017301573\n",
      "epoch 3 batch id 103501 / 225000 loss 0.001372216735035181 train acc 0.7640916512883934\n",
      "epoch 3 batch id 103601 / 225000 loss 1.6172288656234741 train acc 0.7641118328973658\n",
      "epoch 3 batch id 103701 / 225000 loss 1.068529486656189 train acc 0.7641175109208205\n",
      "epoch 3 batch id 103801 / 225000 loss 4.953335762023926 train acc 0.7641496710050963\n",
      "epoch 3 batch id 103901 / 225000 loss 0.002968513173982501 train acc 0.7641649262278515\n",
      "epoch 3 batch id 104001 / 225000 loss 1.9100492000579834 train acc 0.7641344794761589\n",
      "epoch 3 batch id 104101 / 225000 loss 1.3339898586273193 train acc 0.764152121497392\n",
      "epoch 3 batch id 104201 / 225000 loss 0.39459747076034546 train acc 0.7641961209585321\n",
      "epoch 3 batch id 104301 / 225000 loss 2.5680174827575684 train acc 0.7641849071437474\n",
      "epoch 3 batch id 104401 / 225000 loss 2.738905668258667 train acc 0.7641856878765529\n",
      "epoch 3 batch id 104501 / 225000 loss 1.1838186979293823 train acc 0.7642079980095884\n",
      "epoch 3 batch id 104601 / 225000 loss 0.9005047678947449 train acc 0.7642422156575941\n",
      "epoch 3 batch id 104701 / 225000 loss 4.378505229949951 train acc 0.7642572659286921\n",
      "epoch 3 batch id 104801 / 225000 loss 0.00789298303425312 train acc 0.7642508182173834\n",
      "epoch 3 batch id 104901 / 225000 loss 3.2650651931762695 train acc 0.764289663587573\n",
      "epoch 3 batch id 105001 / 225000 loss 0.5483028292655945 train acc 0.7643070065999371\n",
      "epoch 3 batch id 105101 / 225000 loss 1.256966233253479 train acc 0.7642719859944244\n",
      "epoch 3 batch id 105201 / 225000 loss 0.040536124259233475 train acc 0.7643083240653606\n",
      "epoch 3 batch id 105301 / 225000 loss 0.0050887553952634335 train acc 0.7643161033608418\n",
      "epoch 3 batch id 105401 / 225000 loss 3.7395472526550293 train acc 0.7643001489549435\n",
      "epoch 3 batch id 105501 / 225000 loss 0.004981175065040588 train acc 0.7643292480639994\n",
      "epoch 3 batch id 105601 / 225000 loss 1.427014708518982 train acc 0.7643346180433898\n",
      "epoch 3 batch id 105701 / 225000 loss 0.013288499787449837 train acc 0.7643447081862991\n",
      "epoch 3 batch id 105801 / 225000 loss 0.07832525670528412 train acc 0.7643287870625042\n",
      "epoch 3 batch id 105901 / 225000 loss 1.4937939643859863 train acc 0.7643813561722741\n",
      "epoch 3 batch id 106001 / 225000 loss 0.12351346760988235 train acc 0.7643842982613371\n",
      "epoch 3 batch id 106101 / 225000 loss 0.2575503885746002 train acc 0.7644060847682869\n",
      "epoch 3 batch id 106201 / 225000 loss 0.6623263955116272 train acc 0.7644019359516389\n",
      "epoch 3 batch id 106301 / 225000 loss 1.2485867738723755 train acc 0.7643883876915551\n",
      "epoch 3 batch id 106401 / 225000 loss 0.6087881326675415 train acc 0.7643795641018412\n",
      "epoch 3 batch id 106501 / 225000 loss 0.35101771354675293 train acc 0.7643777992694905\n",
      "epoch 3 batch id 106601 / 225000 loss 0.6093423366546631 train acc 0.7643830733295185\n",
      "epoch 3 batch id 106701 / 225000 loss 0.012524012476205826 train acc 0.7644023954789552\n",
      "epoch 3 batch id 106801 / 225000 loss 0.0029653660021722317 train acc 0.764442748663402\n",
      "epoch 3 batch id 106901 / 225000 loss 0.00513186352327466 train acc 0.764492380800928\n",
      "epoch 3 batch id 107001 / 225000 loss 1.0945591926574707 train acc 0.7645022009140101\n",
      "epoch 3 batch id 107101 / 225000 loss 2.539536952972412 train acc 0.7645236739152762\n",
      "epoch 3 batch id 107201 / 225000 loss 0.12512347102165222 train acc 0.7645311144485593\n",
      "epoch 3 batch id 107301 / 225000 loss 1.5735769271850586 train acc 0.7645268916412709\n",
      "epoch 3 batch id 107401 / 225000 loss 0.34729301929473877 train acc 0.7645366430480163\n",
      "epoch 3 batch id 107501 / 225000 loss 0.29520562291145325 train acc 0.7645649807908763\n",
      "epoch 3 batch id 107601 / 225000 loss 1.145898461341858 train acc 0.7645770020724715\n",
      "epoch 3 batch id 107701 / 225000 loss 0.0632467120885849 train acc 0.7645750735833465\n",
      "epoch 3 batch id 107801 / 225000 loss 0.9624620079994202 train acc 0.7645963395515811\n",
      "epoch 3 batch id 107901 / 225000 loss 1.2928218841552734 train acc 0.7646453693663636\n",
      "epoch 3 batch id 108001 / 225000 loss 0.8499272465705872 train acc 0.7646688456588365\n",
      "epoch 3 batch id 108101 / 225000 loss 0.11822175979614258 train acc 0.7646668393446869\n",
      "epoch 3 batch id 108201 / 225000 loss 1.6073253154754639 train acc 0.7646971839446955\n",
      "epoch 3 batch id 108301 / 225000 loss 0.016276748850941658 train acc 0.7647113138382841\n",
      "epoch 3 batch id 108401 / 225000 loss 0.04006996378302574 train acc 0.7647461739282848\n",
      "epoch 3 batch id 108501 / 225000 loss 0.043711088597774506 train acc 0.7647763615081888\n",
      "epoch 3 batch id 108601 / 225000 loss 2.329967737197876 train acc 0.7647788694395079\n",
      "epoch 3 batch id 108701 / 225000 loss 0.0023281932808458805 train acc 0.7647652735485414\n",
      "epoch 3 batch id 108801 / 225000 loss 0.08060586452484131 train acc 0.7647792759257728\n",
      "epoch 3 batch id 108901 / 225000 loss 0.008623477071523666 train acc 0.7647702959568783\n",
      "epoch 3 batch id 109001 / 225000 loss 2.0567405223846436 train acc 0.7647888551481179\n",
      "epoch 3 batch id 109101 / 225000 loss 1.7359997034072876 train acc 0.7648050888626136\n",
      "epoch 3 batch id 109201 / 225000 loss 0.037912655621767044 train acc 0.7647892418567596\n",
      "epoch 3 batch id 109301 / 225000 loss 0.5635188221931458 train acc 0.7648237436071034\n",
      "epoch 3 batch id 109401 / 225000 loss 0.007158687803894281 train acc 0.7648330454017788\n",
      "epoch 3 batch id 109501 / 225000 loss 1.001785397529602 train acc 0.7648240655336481\n",
      "epoch 3 batch id 109601 / 225000 loss 3.1699912548065186 train acc 0.7648128210509029\n",
      "epoch 3 batch id 109701 / 225000 loss 0.3833610713481903 train acc 0.7648084338337846\n",
      "epoch 3 batch id 109801 / 225000 loss 0.9065959453582764 train acc 0.7647995009152923\n",
      "epoch 3 batch id 109901 / 225000 loss 0.013414107263088226 train acc 0.7648451788427767\n",
      "epoch 3 batch id 110001 / 225000 loss 1.0780450105667114 train acc 0.7648385014681685\n",
      "epoch 3 batch id 110101 / 225000 loss 3.056976795196533 train acc 0.764797776586952\n",
      "epoch 3 batch id 110201 / 225000 loss 0.008821417577564716 train acc 0.7647820800174228\n",
      "epoch 3 batch id 110301 / 225000 loss 1.5488848686218262 train acc 0.7647777445354077\n",
      "epoch 3 batch id 110401 / 225000 loss 0.003959529101848602 train acc 0.7647756813796976\n",
      "epoch 3 batch id 110501 / 225000 loss 0.9944047331809998 train acc 0.7647713595352078\n",
      "epoch 3 batch id 110601 / 225000 loss 3.6052708625793457 train acc 0.7647670455059177\n",
      "epoch 3 batch id 110701 / 225000 loss 1.6375826597213745 train acc 0.7647740309482299\n",
      "epoch 3 batch id 110801 / 225000 loss 6.371491432189941 train acc 0.7647967978628352\n",
      "epoch 3 batch id 110901 / 225000 loss 0.6265382170677185 train acc 0.7647879640399996\n",
      "epoch 3 batch id 111001 / 225000 loss 0.07816661149263382 train acc 0.7648016684534373\n",
      "epoch 3 batch id 111101 / 225000 loss 2.9661922454833984 train acc 0.7647995967633054\n",
      "epoch 3 batch id 111201 / 225000 loss 0.004871780518442392 train acc 0.7648290033363009\n",
      "epoch 3 batch id 111301 / 225000 loss 0.008757214993238449 train acc 0.7648066953576338\n",
      "epoch 3 batch id 111401 / 225000 loss 1.1078561544418335 train acc 0.7648248220392995\n",
      "epoch 3 batch id 111501 / 225000 loss 0.5998067259788513 train acc 0.7648630953982476\n",
      "epoch 3 batch id 111601 / 225000 loss 1.5556304454803467 train acc 0.7648564977016336\n",
      "epoch 3 batch id 111701 / 225000 loss 0.19258271157741547 train acc 0.7648611024073195\n",
      "epoch 3 batch id 111801 / 225000 loss 2.7334251403808594 train acc 0.7648835878033291\n",
      "epoch 3 batch id 111901 / 225000 loss 1.621062159538269 train acc 0.7648859259524043\n",
      "epoch 3 batch id 112001 / 225000 loss 0.0036805574782192707 train acc 0.7648480817135561\n",
      "epoch 3 batch id 112101 / 225000 loss 1.5857830047607422 train acc 0.764834836442137\n",
      "epoch 3 batch id 112201 / 225000 loss 4.04177188873291 train acc 0.7648149303482144\n",
      "epoch 3 batch id 112301 / 225000 loss 0.08894120901823044 train acc 0.7648395829066527\n",
      "epoch 3 batch id 112401 / 225000 loss 1.3970832824707031 train acc 0.7648263805482157\n",
      "epoch 3 batch id 112501 / 225000 loss 0.0011161240981891751 train acc 0.7648465346974693\n",
      "epoch 3 batch id 112601 / 225000 loss 0.0044832853600382805 train acc 0.7648733137361124\n",
      "epoch 3 batch id 112701 / 225000 loss 0.2546399235725403 train acc 0.7648601165916895\n",
      "epoch 3 batch id 112801 / 225000 loss 1.0867289304733276 train acc 0.7648535917234777\n",
      "epoch 3 batch id 112901 / 225000 loss 0.2553018033504486 train acc 0.7648780790249865\n",
      "epoch 3 batch id 113001 / 225000 loss 0.0024480472784489393 train acc 0.7648538508508774\n",
      "epoch 3 batch id 113101 / 225000 loss 1.5932486057281494 train acc 0.7648716633805183\n",
      "epoch 3 batch id 113201 / 225000 loss 0.6706488728523254 train acc 0.7648761936732008\n",
      "epoch 3 batch id 113301 / 225000 loss 1.0770033597946167 train acc 0.7648807159689677\n",
      "epoch 3 batch id 113401 / 225000 loss 2.347991704940796 train acc 0.7648874348550718\n",
      "epoch 3 batch id 113501 / 225000 loss 0.00243479129858315 train acc 0.7649007497731297\n",
      "epoch 3 batch id 113601 / 225000 loss 0.003751623211428523 train acc 0.7649140412496369\n",
      "epoch 3 batch id 113701 / 225000 loss 0.2009490430355072 train acc 0.7648943281061732\n",
      "epoch 3 batch id 113801 / 225000 loss 0.0033763982355594635 train acc 0.7649141923181695\n",
      "epoch 3 batch id 113901 / 225000 loss 0.8331126570701599 train acc 0.7649054880993144\n",
      "epoch 3 batch id 114001 / 225000 loss 1.1976217031478882 train acc 0.764947237304936\n",
      "epoch 3 batch id 114101 / 225000 loss 2.90261173248291 train acc 0.7649144179279761\n",
      "epoch 3 batch id 114201 / 225000 loss 2.24794864654541 train acc 0.7649013581317151\n",
      "epoch 3 batch id 114301 / 225000 loss 2.2684803009033203 train acc 0.7648970700168852\n",
      "epoch 3 batch id 114401 / 225000 loss 0.005794485565274954 train acc 0.764919012945691\n",
      "epoch 3 batch id 114501 / 225000 loss 0.29788699746131897 train acc 0.7649081667409018\n",
      "epoch 3 batch id 114601 / 225000 loss 2.56984281539917 train acc 0.7649213357649585\n",
      "epoch 3 batch id 114701 / 225000 loss 0.12630252540111542 train acc 0.764932302246711\n",
      "epoch 3 batch id 114801 / 225000 loss 0.40773722529411316 train acc 0.7649432496232611\n",
      "epoch 3 batch id 114901 / 225000 loss 0.8709058165550232 train acc 0.7649411232278223\n",
      "epoch 3 batch id 115001 / 225000 loss 1.4556610584259033 train acc 0.7649433483187102\n",
      "epoch 3 batch id 115101 / 225000 loss 0.1593468338251114 train acc 0.7649955256687605\n",
      "epoch 3 batch id 115201 / 225000 loss 0.003727617906406522 train acc 0.7649955295526949\n",
      "epoch 3 batch id 115301 / 225000 loss 0.002839587861672044 train acc 0.7650193840469727\n",
      "epoch 3 batch id 115401 / 225000 loss 0.11861617863178253 train acc 0.7650215336088942\n",
      "epoch 3 batch id 115501 / 225000 loss 0.07707193493843079 train acc 0.7650388308326335\n",
      "epoch 3 batch id 115601 / 225000 loss 3.0954136848449707 train acc 0.7650431224643386\n",
      "epoch 3 batch id 115701 / 225000 loss 0.016297416761517525 train acc 0.7650560496452061\n",
      "epoch 3 batch id 115801 / 225000 loss 0.8185904026031494 train acc 0.765073272251535\n",
      "epoch 3 batch id 115901 / 225000 loss 0.0017800340428948402 train acc 0.7650796800717854\n",
      "epoch 3 batch id 116001 / 225000 loss 1.8568395376205444 train acc 0.7650860768441652\n",
      "epoch 3 batch id 116101 / 225000 loss 0.0034829790238291025 train acc 0.7650881560021017\n",
      "epoch 3 batch id 116201 / 225000 loss 0.0031353216618299484 train acc 0.7650966859149233\n",
      "epoch 3 batch id 116301 / 225000 loss 0.028615739196538925 train acc 0.7650923035915427\n",
      "epoch 3 batch id 116401 / 225000 loss 1.1392083168029785 train acc 0.7650793378063763\n",
      "epoch 3 batch id 116501 / 225000 loss 0.0030797587241977453 train acc 0.7651007287491095\n",
      "epoch 3 batch id 116601 / 225000 loss 0.06046715006232262 train acc 0.7650984982976132\n",
      "epoch 3 batch id 116701 / 225000 loss 1.336207628250122 train acc 0.7651284050693653\n",
      "epoch 3 batch id 116801 / 225000 loss 1.1257895231246948 train acc 0.7651304355270931\n",
      "epoch 3 batch id 116901 / 225000 loss 0.9952910542488098 train acc 0.7651324625110136\n",
      "epoch 3 batch id 117001 / 225000 loss 0.02564384415745735 train acc 0.7651216656267895\n",
      "epoch 3 batch id 117101 / 225000 loss 1.3451619148254395 train acc 0.7651322362746689\n",
      "epoch 3 batch id 117201 / 225000 loss 1.8489307165145874 train acc 0.7651619866724687\n",
      "epoch 3 batch id 117301 / 225000 loss 0.004583711735904217 train acc 0.765176767461488\n",
      "epoch 3 batch id 117401 / 225000 loss 0.9399816989898682 train acc 0.7651893936167494\n",
      "epoch 3 batch id 117501 / 225000 loss 0.0012973626144230366 train acc 0.7652083812052664\n",
      "epoch 3 batch id 117601 / 225000 loss 0.0033568728249520063 train acc 0.7652400914958206\n",
      "epoch 3 batch id 117701 / 225000 loss 3.2416768074035645 train acc 0.7652802440081222\n",
      "epoch 3 batch id 117801 / 225000 loss 3.7947680950164795 train acc 0.7653182061272824\n",
      "epoch 3 batch id 117901 / 225000 loss 1.5130729675292969 train acc 0.7653285383499716\n",
      "epoch 3 batch id 118001 / 225000 loss 1.2879068851470947 train acc 0.7653324971822273\n",
      "epoch 3 batch id 118101 / 225000 loss 0.9415475130081177 train acc 0.7653512671357566\n",
      "epoch 3 batch id 118201 / 225000 loss 0.004638997837901115 train acc 0.7653446248339693\n",
      "epoch 3 batch id 118301 / 225000 loss 1.3880226612091064 train acc 0.7653020684525067\n",
      "epoch 3 batch id 118401 / 225000 loss 0.001316377893090248 train acc 0.7653187050785044\n",
      "epoch 3 batch id 118501 / 225000 loss 0.0029480301309376955 train acc 0.7653374233128835\n",
      "epoch 3 batch id 118601 / 225000 loss 3.1758904457092285 train acc 0.765366649522348\n",
      "epoch 3 batch id 118701 / 225000 loss 0.001732688513584435 train acc 0.7653431731830398\n",
      "epoch 3 batch id 118801 / 225000 loss 1.54739511013031 train acc 0.7653470930379374\n",
      "epoch 3 batch id 118901 / 225000 loss 0.13011908531188965 train acc 0.7653468011202597\n",
      "epoch 3 batch id 119001 / 225000 loss 1.2868032455444336 train acc 0.7653633162746531\n",
      "epoch 3 batch id 119101 / 225000 loss 1.5244922637939453 train acc 0.76534621875551\n",
      "epoch 3 batch id 119201 / 225000 loss 0.8280881643295288 train acc 0.7653396364124462\n",
      "epoch 3 batch id 119301 / 225000 loss 1.3247476816177368 train acc 0.7653624026621738\n",
      "epoch 3 batch id 119401 / 225000 loss 1.0426017045974731 train acc 0.7653767556385624\n",
      "epoch 3 batch id 119501 / 225000 loss 2.419419527053833 train acc 0.7653910845934344\n",
      "epoch 3 batch id 119601 / 225000 loss 2.456721067428589 train acc 0.7653991187364654\n",
      "epoch 3 batch id 119701 / 225000 loss 0.003119369735941291 train acc 0.7654259362912591\n",
      "epoch 3 batch id 119801 / 225000 loss 0.4852549731731415 train acc 0.7654214071668851\n",
      "epoch 3 batch id 119901 / 225000 loss 0.0036042355932295322 train acc 0.7654168855972844\n",
      "epoch 3 batch id 120001 / 225000 loss 0.011279667727649212 train acc 0.765433204723294\n",
      "epoch 3 batch id 120101 / 225000 loss 0.005602864548563957 train acc 0.7654182729535974\n",
      "epoch 3 batch id 120201 / 225000 loss 1.8333348035812378 train acc 0.7654262443740069\n",
      "epoch 3 batch id 120301 / 225000 loss 1.8630825281143188 train acc 0.7654425150248128\n",
      "epoch 3 batch id 120401 / 225000 loss 1.2393383979797363 train acc 0.7655002865424706\n",
      "epoch 3 batch id 120501 / 225000 loss 2.056265115737915 train acc 0.7655060953851005\n",
      "epoch 3 batch id 120601 / 225000 loss 2.6130619049072266 train acc 0.7654911650815499\n",
      "epoch 3 batch id 120701 / 225000 loss 2.8891215324401855 train acc 0.7655073280254513\n",
      "epoch 3 batch id 120801 / 225000 loss 2.057485818862915 train acc 0.765546228921946\n",
      "epoch 3 batch id 120901 / 225000 loss 0.8846954703330994 train acc 0.7655313024706164\n",
      "epoch 3 batch id 121001 / 225000 loss 0.0037680906243622303 train acc 0.7655370616771762\n",
      "epoch 3 batch id 121101 / 225000 loss 2.314866542816162 train acc 0.7655428113723256\n",
      "epoch 3 batch id 121201 / 225000 loss 1.2539403438568115 train acc 0.7655485515796074\n",
      "epoch 3 batch id 121301 / 225000 loss 2.124439239501953 train acc 0.7655625262776069\n",
      "epoch 3 batch id 121401 / 225000 loss 0.005361043848097324 train acc 0.7655744186621197\n",
      "epoch 3 batch id 121501 / 225000 loss 2.5076382160186768 train acc 0.7655430819499428\n",
      "epoch 3 batch id 121601 / 225000 loss 0.01379341073334217 train acc 0.7655652502857707\n",
      "epoch 3 batch id 121701 / 225000 loss 0.3244510889053345 train acc 0.765581219546265\n",
      "epoch 3 batch id 121801 / 225000 loss 0.0019363609608262777 train acc 0.7656033201697852\n",
      "epoch 3 batch id 121901 / 225000 loss 1.934308409690857 train acc 0.7655843676425952\n",
      "epoch 3 batch id 122001 / 225000 loss 0.2602120041847229 train acc 0.7655756920025246\n",
      "epoch 3 batch id 122101 / 225000 loss 1.899229884147644 train acc 0.7655895529111145\n",
      "epoch 3 batch id 122201 / 225000 loss 1.9171770811080933 train acc 0.7655890704658718\n",
      "epoch 3 batch id 122301 / 225000 loss 1.021435260772705 train acc 0.7656233391386824\n",
      "epoch 3 batch id 122401 / 225000 loss 1.3492803573608398 train acc 0.7656269148127874\n",
      "epoch 3 batch id 122501 / 225000 loss 0.0042207022197544575 train acc 0.765663137443776\n",
      "epoch 3 batch id 122601 / 225000 loss 2.0479092597961426 train acc 0.7656748313635289\n",
      "epoch 3 batch id 122701 / 225000 loss 1.3107523918151855 train acc 0.7656946561152721\n",
      "epoch 3 batch id 122801 / 225000 loss 0.023444797843694687 train acc 0.7656920546249624\n",
      "epoch 3 batch id 122901 / 225000 loss 2.541820526123047 train acc 0.7656935256832735\n",
      "epoch 3 batch id 123001 / 225000 loss 0.872469425201416 train acc 0.7656584092812253\n",
      "epoch 3 batch id 123101 / 225000 loss 0.0018194629810750484 train acc 0.7656741212500304\n",
      "epoch 3 batch id 123201 / 225000 loss 2.1770224571228027 train acc 0.7656816908953661\n",
      "epoch 3 batch id 123301 / 225000 loss 3.422358751296997 train acc 0.7657115514067201\n",
      "epoch 3 batch id 123401 / 225000 loss 0.6431331634521484 train acc 0.7657130007050186\n",
      "epoch 3 batch id 123501 / 225000 loss 0.005376478191465139 train acc 0.7657164719314014\n",
      "epoch 3 batch id 123601 / 225000 loss 0.9357316493988037 train acc 0.7657158922662438\n",
      "epoch 3 batch id 123701 / 225000 loss 2.59443998336792 train acc 0.7657153135382899\n",
      "epoch 3 batch id 123801 / 225000 loss 0.05388800799846649 train acc 0.7657268519640391\n",
      "epoch 3 batch id 123901 / 225000 loss 0.015771454200148582 train acc 0.7657101234049766\n",
      "epoch 3 batch id 124001 / 225000 loss 0.00237806374207139 train acc 0.7657095507294296\n",
      "epoch 3 batch id 124101 / 225000 loss 0.0016586692072451115 train acc 0.7657291238587924\n",
      "epoch 3 batch id 124201 / 225000 loss 3.097616672515869 train acc 0.7657305496735131\n",
      "epoch 3 batch id 124301 / 225000 loss 0.0036529775243252516 train acc 0.7657259394534236\n",
      "epoch 3 batch id 124401 / 225000 loss 0.007038556970655918 train acc 0.7657414329466805\n",
      "epoch 3 batch id 124501 / 225000 loss 0.03156263008713722 train acc 0.7657669416309909\n",
      "epoch 3 batch id 124601 / 225000 loss 0.10536753386259079 train acc 0.7657823773484964\n",
      "epoch 3 batch id 124701 / 225000 loss 2.835737705230713 train acc 0.7657897691277535\n",
      "epoch 3 batch id 124801 / 225000 loss 0.15391288697719574 train acc 0.7658091681957676\n",
      "epoch 3 batch id 124901 / 225000 loss 1.087091326713562 train acc 0.7658125235186267\n",
      "epoch 3 batch id 125001 / 225000 loss 2.0342226028442383 train acc 0.7658038735690115\n",
      "epoch 3 batch id 125101 / 225000 loss 0.013081330806016922 train acc 0.765825213227712\n",
      "epoch 3 batch id 125201 / 225000 loss 0.5923501253128052 train acc 0.765834538062795\n",
      "epoch 3 batch id 125301 / 225000 loss 1.5390546321868896 train acc 0.7658618047741039\n",
      "epoch 3 batch id 125401 / 225000 loss 0.0017837821505963802 train acc 0.7658830471846317\n",
      "epoch 3 batch id 125501 / 225000 loss 0.5538007020950317 train acc 0.7658823435669835\n",
      "epoch 3 batch id 125601 / 225000 loss 1.154976725578308 train acc 0.7659134879499367\n",
      "epoch 3 batch id 125701 / 225000 loss 0.0029042509850114584 train acc 0.7659167389280913\n",
      "epoch 3 batch id 125801 / 225000 loss 1.129167079925537 train acc 0.7659199847378002\n",
      "epoch 3 batch id 125901 / 225000 loss 2.359816789627075 train acc 0.7659450679502149\n",
      "epoch 3 batch id 126001 / 225000 loss 2.19317626953125 train acc 0.7659681272370854\n",
      "epoch 3 batch id 126101 / 225000 loss 0.517270565032959 train acc 0.7659574468085106\n",
      "epoch 3 batch id 126201 / 225000 loss 2.9579226970672607 train acc 0.7659190497698116\n",
      "epoch 3 batch id 126301 / 225000 loss 0.91361004114151 train acc 0.7659539512751284\n",
      "epoch 3 batch id 126401 / 225000 loss 3.2337827682495117 train acc 0.7659492409079042\n",
      "epoch 3 batch id 126501 / 225000 loss 0.9597629308700562 train acc 0.7659366329119928\n",
      "epoch 3 batch id 126601 / 225000 loss 2.133979320526123 train acc 0.7659220701258284\n",
      "epoch 3 batch id 126701 / 225000 loss 2.0972471237182617 train acc 0.7659627785100355\n",
      "epoch 3 batch id 126801 / 225000 loss 0.32164430618286133 train acc 0.7659955363128051\n",
      "epoch 3 batch id 126901 / 225000 loss 1.6418019533157349 train acc 0.7660006619333181\n",
      "epoch 3 batch id 127001 / 225000 loss 0.006458333693444729 train acc 0.7660057794820513\n",
      "epoch 3 batch id 127101 / 225000 loss 2.094658851623535 train acc 0.7660187567367684\n",
      "epoch 3 batch id 127201 / 225000 loss 1.9387997388839722 train acc 0.7660041980802038\n",
      "epoch 3 batch id 127301 / 225000 loss 2.6512765884399414 train acc 0.7660151923394161\n",
      "epoch 3 batch id 127401 / 225000 loss 1.3242244720458984 train acc 0.7660418678032355\n",
      "epoch 3 batch id 127501 / 225000 loss 2.0414204597473145 train acc 0.766050854503102\n",
      "epoch 3 batch id 127601 / 225000 loss 0.9525311589241028 train acc 0.7660343570975149\n",
      "epoch 3 batch id 127701 / 225000 loss 0.0010224159341305494 train acc 0.7660511663965043\n",
      "epoch 3 batch id 127801 / 225000 loss 0.16211967170238495 train acc 0.7660366507304325\n",
      "epoch 3 batch id 127901 / 225000 loss 0.8300582766532898 train acc 0.7660202031258552\n",
      "epoch 3 batch id 128001 / 225000 loss 1.4758754968643188 train acc 0.7660487027445098\n",
      "epoch 3 batch id 128101 / 225000 loss 1.4965343475341797 train acc 0.7660459325063816\n",
      "epoch 3 batch id 128201 / 225000 loss 0.014394457451999187 train acc 0.766031466213212\n",
      "epoch 3 batch id 128301 / 225000 loss 1.594603180885315 train acc 0.7660228680992354\n",
      "epoch 3 batch id 128401 / 225000 loss 0.9537147879600525 train acc 0.7660357006565369\n",
      "epoch 3 batch id 128501 / 225000 loss 1.8516663312911987 train acc 0.7660485132411421\n",
      "epoch 3 batch id 128601 / 225000 loss 3.8249528408050537 train acc 0.7660496419156927\n",
      "epoch 3 batch id 128701 / 225000 loss 2.5632405281066895 train acc 0.7660682512179392\n",
      "epoch 3 batch id 128801 / 225000 loss 0.005661361385136843 train acc 0.7660771267303825\n",
      "epoch 3 batch id 128901 / 225000 loss 2.4741780757904053 train acc 0.7660918068905594\n",
      "epoch 3 batch id 129001 / 225000 loss 1.1302950382232666 train acc 0.7660890225657165\n",
      "epoch 3 batch id 129101 / 225000 loss 1.3918763399124146 train acc 0.7661036707693976\n",
      "epoch 3 batch id 129201 / 225000 loss 0.004657100886106491 train acc 0.7661395809629956\n",
      "epoch 3 batch id 129301 / 225000 loss 0.9535229206085205 train acc 0.7661483669886544\n",
      "epoch 3 batch id 129401 / 225000 loss 0.5314936637878418 train acc 0.7661262277725829\n",
      "epoch 3 batch id 129501 / 225000 loss 0.5256242752075195 train acc 0.7661369410274824\n",
      "epoch 3 batch id 129601 / 225000 loss 4.184343338012695 train acc 0.7661437797547859\n",
      "epoch 3 batch id 129701 / 225000 loss 0.6758344173431396 train acc 0.7661814480998604\n",
      "epoch 3 batch id 129801 / 225000 loss 0.034572701901197433 train acc 0.7662036502030031\n",
      "epoch 3 batch id 129901 / 225000 loss 0.08294817060232162 train acc 0.7662142708678147\n",
      "epoch 3 batch id 130001 / 225000 loss 3.43259334564209 train acc 0.7662517980630918\n",
      "epoch 3 batch id 130101 / 225000 loss 0.013919038698077202 train acc 0.7662700517290413\n",
      "epoch 3 batch id 130201 / 225000 loss 0.005753020755946636 train acc 0.7663055583290451\n",
      "epoch 3 batch id 130301 / 225000 loss 0.9283576011657715 train acc 0.7662892072969509\n",
      "epoch 3 batch id 130401 / 225000 loss 0.017655741423368454 train acc 0.7662920529750539\n",
      "epoch 3 batch id 130501 / 225000 loss 2.3588318824768066 train acc 0.7663159669274565\n",
      "epoch 3 batch id 130601 / 225000 loss 0.010951961390674114 train acc 0.7663283588946486\n",
      "epoch 3 batch id 130701 / 225000 loss 0.16848039627075195 train acc 0.7663502957131162\n",
      "epoch 3 batch id 130801 / 225000 loss 1.2187442779541016 train acc 0.7663492633848366\n",
      "epoch 3 batch id 130901 / 225000 loss 1.3231353759765625 train acc 0.7663635113559102\n",
      "epoch 3 batch id 131001 / 225000 loss 1.7368580102920532 train acc 0.7663758291921435\n",
      "epoch 3 batch id 131101 / 225000 loss 1.5048141479492188 train acc 0.766378593603405\n",
      "epoch 3 batch id 131201 / 225000 loss 0.4223281145095825 train acc 0.7663832592739385\n",
      "epoch 3 batch id 131301 / 225000 loss 0.02392789162695408 train acc 0.766386013815584\n",
      "epoch 3 batch id 131401 / 225000 loss 1.5987424850463867 train acc 0.7664096924680939\n",
      "epoch 3 batch id 131501 / 225000 loss 0.2658361792564392 train acc 0.7664181260979004\n",
      "epoch 3 batch id 131601 / 225000 loss 0.0062227267771959305 train acc 0.7664246472291244\n",
      "epoch 3 batch id 131701 / 225000 loss 0.08676350861787796 train acc 0.7664558355669281\n",
      "epoch 3 batch id 131801 / 225000 loss 0.0056030405685305595 train acc 0.766450937398047\n",
      "epoch 3 batch id 131901 / 225000 loss 0.963894784450531 train acc 0.7664517327389482\n",
      "epoch 3 batch id 132001 / 225000 loss 5.527319431304932 train acc 0.7664468450996583\n",
      "epoch 3 batch id 132101 / 225000 loss 0.004395077470690012 train acc 0.7664476423342745\n",
      "epoch 3 batch id 132201 / 225000 loss 0.006189651787281036 train acc 0.766461675781575\n",
      "epoch 3 batch id 132301 / 225000 loss 0.28577756881713867 train acc 0.7664662398621326\n",
      "epoch 3 batch id 132401 / 225000 loss 0.004800452385097742 train acc 0.7664840144711897\n",
      "epoch 3 batch id 132501 / 225000 loss 0.4558136463165283 train acc 0.7665130829201289\n",
      "epoch 3 batch id 132601 / 225000 loss 0.5512178540229797 train acc 0.7665383368149562\n",
      "epoch 3 batch id 132701 / 225000 loss 2.374110221862793 train acc 0.766510802480765\n",
      "epoch 3 batch id 132801 / 225000 loss 0.6694597601890564 train acc 0.7664889571614671\n",
      "epoch 3 batch id 132901 / 225000 loss 1.5741071701049805 train acc 0.7664878368108592\n",
      "epoch 3 batch id 133001 / 225000 loss 0.0019961968064308167 train acc 0.7664979962556673\n",
      "epoch 3 batch id 133101 / 225000 loss 1.3441838026046753 train acc 0.7664856011600213\n",
      "epoch 3 batch id 133201 / 225000 loss 1.2779791355133057 train acc 0.7664807321266357\n",
      "epoch 3 batch id 133301 / 225000 loss 1.5341761112213135 train acc 0.7664458631218071\n",
      "epoch 3 batch id 133401 / 225000 loss 0.00431561516597867 train acc 0.766454149519119\n",
      "epoch 3 batch id 133501 / 225000 loss 1.6705304384231567 train acc 0.7664305885349173\n",
      "epoch 3 batch id 133601 / 225000 loss 0.005299581214785576 train acc 0.7664257752561733\n",
      "epoch 3 batch id 133701 / 225000 loss 0.025814741849899292 train acc 0.7664340580848311\n",
      "epoch 3 batch id 133801 / 225000 loss 1.1132758855819702 train acc 0.7664535392112166\n",
      "epoch 3 batch id 133901 / 225000 loss 1.2746341228485107 train acc 0.7664673900867058\n",
      "epoch 3 batch id 134001 / 225000 loss 0.05790065973997116 train acc 0.7664625637122111\n",
      "epoch 3 batch id 134101 / 225000 loss 0.3894924819469452 train acc 0.7665062154644634\n",
      "epoch 3 batch id 134201 / 225000 loss 4.320810794830322 train acc 0.7664976415973055\n",
      "epoch 3 batch id 134301 / 225000 loss 1.5320559740066528 train acc 0.7665039724201607\n",
      "epoch 3 batch id 134401 / 225000 loss 0.051752038300037384 train acc 0.7665121539274261\n",
      "epoch 3 batch id 134501 / 225000 loss 3.6526503562927246 train acc 0.7665258994356919\n",
      "epoch 3 batch id 134601 / 225000 loss 1.1451715230941772 train acc 0.7665247657892587\n",
      "epoch 3 batch id 134701 / 225000 loss 0.009219642728567123 train acc 0.7665199219010995\n",
      "epoch 3 batch id 134801 / 225000 loss 0.016114316880702972 train acc 0.766492830171883\n",
      "epoch 3 batch id 134901 / 225000 loss 1.2130879163742065 train acc 0.7664991364037331\n",
      "epoch 3 batch id 135001 / 225000 loss 1.895931601524353 train acc 0.7665183961600285\n",
      "epoch 3 batch id 135101 / 225000 loss 1.3698928356170654 train acc 0.7665394778721105\n",
      "epoch 3 batch id 135201 / 225000 loss 2.7647712230682373 train acc 0.7665753211884527\n",
      "epoch 3 batch id 135301 / 225000 loss 0.024589484557509422 train acc 0.7666037205933437\n",
      "epoch 3 batch id 135401 / 225000 loss 0.42650294303894043 train acc 0.7666154607425352\n",
      "epoch 3 batch id 135501 / 225000 loss 0.17156235873699188 train acc 0.766625338558387\n",
      "epoch 3 batch id 135601 / 225000 loss 0.08543415367603302 train acc 0.7666278272284127\n",
      "epoch 3 batch id 135701 / 225000 loss 0.005278279073536396 train acc 0.7666266276593393\n",
      "epoch 3 batch id 135801 / 225000 loss 0.0006665505352430046 train acc 0.766603338708846\n",
      "epoch 3 batch id 135901 / 225000 loss 0.014669401571154594 train acc 0.7665911214781348\n",
      "epoch 3 batch id 136001 / 225000 loss 3.415008544921875 train acc 0.7665825986573628\n",
      "epoch 3 batch id 136101 / 225000 loss 3.0190529823303223 train acc 0.7665814358454384\n",
      "epoch 3 batch id 136201 / 225000 loss 1.4207721948623657 train acc 0.7665619195160094\n",
      "epoch 3 batch id 136301 / 225000 loss 0.8903861045837402 train acc 0.7665717786369872\n",
      "epoch 3 batch id 136401 / 225000 loss 0.00840090960264206 train acc 0.7665852889641571\n",
      "epoch 3 batch id 136501 / 225000 loss 0.0024571334943175316 train acc 0.7665987794961209\n",
      "epoch 3 batch id 136601 / 225000 loss 0.9324706196784973 train acc 0.7666085899810396\n",
      "epoch 3 batch id 136701 / 225000 loss 0.017889639362692833 train acc 0.7666458182456602\n",
      "epoch 3 batch id 136801 / 225000 loss 0.014486139640212059 train acc 0.7666610624191343\n",
      "epoch 3 batch id 136901 / 225000 loss 1.155466914176941 train acc 0.7666251524824508\n",
      "epoch 3 batch id 137001 / 225000 loss 0.04620453715324402 train acc 0.7666531631155977\n",
      "epoch 3 batch id 137101 / 225000 loss 0.08155429363250732 train acc 0.7666410164769039\n",
      "epoch 3 batch id 137201 / 225000 loss 1.6787359714508057 train acc 0.766623421112091\n",
      "epoch 3 batch id 137301 / 225000 loss 0.0032157108653336763 train acc 0.7666131346457783\n",
      "epoch 3 batch id 137401 / 225000 loss 1.7196930646896362 train acc 0.766621058070902\n",
      "epoch 3 batch id 137501 / 225000 loss 1.1590956449508667 train acc 0.7666180609595566\n",
      "epoch 3 batch id 137601 / 225000 loss 0.30439066886901855 train acc 0.7666386872188429\n",
      "epoch 3 batch id 137701 / 225000 loss 2.7072229385375977 train acc 0.7666066332125402\n",
      "epoch 3 batch id 137801 / 225000 loss 0.2580660879611969 train acc 0.7666036530939543\n",
      "epoch 3 batch id 137901 / 225000 loss 0.407272070646286 train acc 0.766606115981755\n",
      "epoch 3 batch id 138001 / 225000 loss 1.746464490890503 train acc 0.76661219846233\n",
      "epoch 3 batch id 138101 / 225000 loss 0.005211921408772469 train acc 0.7666255132113453\n",
      "epoch 3 batch id 138201 / 225000 loss 2.3400158882141113 train acc 0.7666207190975464\n",
      "epoch 3 batch id 138301 / 225000 loss 1.8776869773864746 train acc 0.7666195472194706\n",
      "epoch 3 batch id 138401 / 225000 loss 1.9194977283477783 train acc 0.7666111516535286\n",
      "epoch 3 batch id 138501 / 225000 loss 1.1451807022094727 train acc 0.7666045732521787\n",
      "epoch 3 batch id 138601 / 225000 loss 0.00664079375565052 train acc 0.7666088267761416\n",
      "epoch 3 batch id 138701 / 225000 loss 0.9493879675865173 train acc 0.7665842351533154\n",
      "epoch 3 batch id 138801 / 225000 loss 0.0055794622749090195 train acc 0.7666011051793575\n",
      "epoch 3 batch id 138901 / 225000 loss 0.023293010890483856 train acc 0.7666053520133045\n",
      "epoch 3 batch id 139001 / 225000 loss 0.005146279465407133 train acc 0.7666095927367429\n",
      "epoch 3 batch id 139101 / 225000 loss 0.0015651616267859936 train acc 0.7665976520657651\n",
      "epoch 3 batch id 139201 / 225000 loss 1.6543080806732178 train acc 0.7666126680124424\n",
      "epoch 3 batch id 139301 / 225000 loss 0.9591366052627563 train acc 0.7666133050013998\n",
      "epoch 3 batch id 139401 / 225000 loss 3.6260128021240234 train acc 0.7666336683381038\n",
      "epoch 3 batch id 139501 / 225000 loss 2.872389316558838 train acc 0.7666145762395968\n",
      "epoch 3 batch id 139601 / 225000 loss 0.0044395215809345245 train acc 0.7666187921289962\n",
      "epoch 3 batch id 139701 / 225000 loss 4.029975414276123 train acc 0.7665961589394492\n",
      "epoch 3 batch id 139801 / 225000 loss 0.015448853373527527 train acc 0.766605746740009\n",
      "epoch 3 batch id 139901 / 225000 loss 0.7295541167259216 train acc 0.7666081729222808\n",
      "epoch 3 batch id 140001 / 225000 loss 2.576451539993286 train acc 0.7665909529217648\n",
      "epoch 3 batch id 140101 / 225000 loss 2.176438808441162 train acc 0.7666183681772436\n",
      "epoch 3 batch id 140201 / 225000 loss 1.6983771324157715 train acc 0.7666296959365483\n",
      "epoch 3 batch id 140301 / 225000 loss 0.02501092106103897 train acc 0.7666445713145309\n",
      "epoch 3 batch id 140401 / 225000 loss 4.454080104827881 train acc 0.7666060070797217\n",
      "epoch 3 batch id 140501 / 225000 loss 2.129697322845459 train acc 0.7665977466352553\n",
      "epoch 3 batch id 140601 / 225000 loss 1.9628039598464966 train acc 0.7665948321846928\n",
      "epoch 3 batch id 140701 / 225000 loss 1.2229233980178833 train acc 0.7666096900519541\n",
      "epoch 3 batch id 140801 / 225000 loss 0.0072503224946558475 train acc 0.7666138734810122\n",
      "epoch 3 batch id 140901 / 225000 loss 0.010263442993164062 train acc 0.7666233738582409\n",
      "epoch 3 batch id 141001 / 225000 loss 0.023935848847031593 train acc 0.7666293146857115\n",
      "epoch 3 batch id 141101 / 225000 loss 0.01634669117629528 train acc 0.7666511931169872\n",
      "epoch 3 batch id 141201 / 225000 loss 1.0387002229690552 train acc 0.7666553353021579\n",
      "epoch 3 batch id 141301 / 225000 loss 2.1504499912261963 train acc 0.7666683179878415\n",
      "epoch 3 batch id 141401 / 225000 loss 0.8803409934043884 train acc 0.7666689061604939\n",
      "epoch 3 batch id 141501 / 225000 loss 0.13255463540554047 train acc 0.7666924615373742\n",
      "epoch 3 batch id 141601 / 225000 loss 2.425961971282959 train acc 0.7667195146926928\n",
      "epoch 3 batch id 141701 / 225000 loss 2.6889798641204834 train acc 0.7667059512635761\n",
      "epoch 3 batch id 141801 / 225000 loss 3.530102252960205 train acc 0.7667100373058018\n",
      "epoch 3 batch id 141901 / 225000 loss 0.1775844246149063 train acc 0.7667229265473816\n",
      "epoch 3 batch id 142001 / 225000 loss 2.084376573562622 train acc 0.7667093893704974\n",
      "epoch 3 batch id 142101 / 225000 loss 1.5508131980895996 train acc 0.7667205016150485\n",
      "epoch 3 batch id 142201 / 225000 loss 0.7457584738731384 train acc 0.7667034690332698\n",
      "epoch 3 batch id 142301 / 225000 loss 0.003694494254887104 train acc 0.7667110561415591\n",
      "epoch 3 batch id 142401 / 225000 loss 1.760221242904663 train acc 0.7667080989599793\n",
      "epoch 3 batch id 142501 / 225000 loss 0.07616666704416275 train acc 0.7666963740605329\n",
      "epoch 3 batch id 142601 / 225000 loss 0.26606854796409607 train acc 0.7667197284731524\n",
      "epoch 3 batch id 142701 / 225000 loss 0.9581601619720459 train acc 0.7667377944092894\n",
      "epoch 3 batch id 142801 / 225000 loss 1.414974570274353 train acc 0.7667610871072331\n",
      "epoch 3 batch id 142901 / 225000 loss 1.8591431379318237 train acc 0.7667773493537484\n",
      "epoch 3 batch id 143001 / 225000 loss 1.4610930681228638 train acc 0.7667813511793624\n",
      "epoch 3 batch id 143101 / 225000 loss 2.0126898288726807 train acc 0.7667783593406056\n",
      "epoch 3 batch id 143201 / 225000 loss 4.023481845855713 train acc 0.7668172708291143\n",
      "epoch 3 batch id 143301 / 225000 loss 0.01788649708032608 train acc 0.7668020460429446\n",
      "epoch 3 batch id 143401 / 225000 loss 1.9159409999847412 train acc 0.7668060194838251\n",
      "epoch 3 batch id 143501 / 225000 loss 3.3440699577331543 train acc 0.7668030187942941\n",
      "epoch 3 batch id 143601 / 225000 loss 0.029704805463552475 train acc 0.7668069860237742\n",
      "epoch 3 batch id 143701 / 225000 loss 1.9149004220962524 train acc 0.7668144271786557\n",
      "epoch 3 batch id 143801 / 225000 loss 0.0018177286256104708 train acc 0.7668079498751748\n",
      "epoch 3 batch id 143901 / 225000 loss 2.058357000350952 train acc 0.7667719473804907\n",
      "epoch 3 batch id 144001 / 225000 loss 2.0977325439453125 train acc 0.7668019666530094\n",
      "epoch 3 batch id 144101 / 225000 loss 1.0830750465393066 train acc 0.7668093906357346\n",
      "epoch 3 batch id 144201 / 225000 loss 0.002493846695870161 train acc 0.76683240754225\n",
      "epoch 3 batch id 144301 / 225000 loss 0.5304021239280701 train acc 0.7668294052016271\n",
      "epoch 3 batch id 144401 / 225000 loss 0.9774971008300781 train acc 0.7668385260489886\n",
      "epoch 3 batch id 144501 / 225000 loss 2.1172077655792236 train acc 0.7668510944560938\n",
      "epoch 3 batch id 144601 / 225000 loss 2.6878809928894043 train acc 0.7668498143166368\n",
      "epoch 3 batch id 144701 / 225000 loss 2.1429004669189453 train acc 0.7668640852516568\n",
      "epoch 3 batch id 144801 / 225000 loss 0.5581952929496765 train acc 0.7668938750422994\n",
      "epoch 3 batch id 144901 / 225000 loss 1.3630132675170898 train acc 0.7668753148701527\n",
      "epoch 3 batch id 145001 / 225000 loss 1.697712779045105 train acc 0.7668860904407556\n",
      "epoch 3 batch id 145101 / 225000 loss 0.0022435239516198635 train acc 0.766896851158848\n",
      "epoch 3 batch id 145201 / 225000 loss 2.10251784324646 train acc 0.7669007100502062\n",
      "epoch 3 batch id 145301 / 225000 loss 1.8975002765655518 train acc 0.766918328160164\n",
      "epoch 3 batch id 145401 / 225000 loss 0.13727739453315735 train acc 0.7669238863556647\n",
      "epoch 3 batch id 145501 / 225000 loss 1.680535912513733 train acc 0.7669019456910949\n",
      "epoch 3 batch id 145601 / 225000 loss 1.8467357158660889 train acc 0.7668869032492909\n",
      "epoch 3 batch id 145701 / 225000 loss 2.3931548595428467 train acc 0.7668753131412962\n",
      "epoch 3 batch id 145801 / 225000 loss 0.39283469319343567 train acc 0.7668963175835557\n",
      "epoch 3 batch id 145901 / 225000 loss 3.0727860927581787 train acc 0.7669001583265365\n",
      "epoch 3 batch id 146001 / 225000 loss 0.017321350052952766 train acc 0.7669125553934563\n",
      "epoch 3 batch id 146101 / 225000 loss 3.2781546115875244 train acc 0.7668941348792958\n",
      "epoch 3 batch id 146201 / 225000 loss 2.1017253398895264 train acc 0.7668945492848886\n",
      "epoch 3 batch id 146301 / 225000 loss 0.022013666108250618 train acc 0.7668915455123342\n",
      "epoch 3 batch id 146401 / 225000 loss 1.3487763404846191 train acc 0.7669056222293563\n",
      "epoch 3 batch id 146501 / 225000 loss 1.0365902185440063 train acc 0.7669043214722083\n",
      "epoch 3 batch id 146601 / 225000 loss 0.03336457535624504 train acc 0.7668927906358074\n",
      "epoch 3 batch id 146701 / 225000 loss 0.03581549972295761 train acc 0.7669034294244756\n",
      "epoch 3 batch id 146801 / 225000 loss 1.438582420349121 train acc 0.7669344895470739\n",
      "epoch 3 batch id 146901 / 225000 loss 3.585420608520508 train acc 0.7669433836393217\n",
      "epoch 3 batch id 147001 / 225000 loss 1.0207622051239014 train acc 0.7669454629560343\n",
      "epoch 3 batch id 147101 / 225000 loss 0.5375106334686279 train acc 0.766956037008586\n",
      "epoch 3 batch id 147201 / 225000 loss 1.780944585800171 train acc 0.7669547081881237\n",
      "epoch 3 batch id 147301 / 225000 loss 1.3754849433898926 train acc 0.7669618671970998\n",
      "epoch 3 batch id 147401 / 225000 loss 0.002934859599918127 train acc 0.7669690164924254\n",
      "epoch 3 batch id 147501 / 225000 loss 2.208246946334839 train acc 0.7669727662863303\n",
      "epoch 3 batch id 147601 / 225000 loss 1.6861997842788696 train acc 0.7669917547984092\n",
      "epoch 3 batch id 147701 / 225000 loss 0.9182722568511963 train acc 0.7669904062937962\n",
      "epoch 3 batch id 147801 / 225000 loss 0.7488844990730286 train acc 0.7669890596139404\n",
      "epoch 3 batch id 147901 / 225000 loss 3.5338082313537598 train acc 0.7669944760346448\n",
      "epoch 3 batch id 148001 / 225000 loss 2.6930460929870605 train acc 0.7669965067803596\n",
      "epoch 3 batch id 148101 / 225000 loss 3.7029225826263428 train acc 0.7669951587092593\n",
      "epoch 3 batch id 148201 / 225000 loss 0.6741739511489868 train acc 0.766998873152003\n",
      "epoch 3 batch id 148301 / 225000 loss 1.5279769897460938 train acc 0.7670228117140141\n",
      "epoch 3 batch id 148401 / 225000 loss 1.3061631917953491 train acc 0.7670298717663627\n",
      "epoch 3 batch id 148501 / 225000 loss 0.9994591474533081 train acc 0.7670301883489\n",
      "epoch 3 batch id 148601 / 225000 loss 3.0703577995300293 train acc 0.7670305045053533\n",
      "epoch 3 batch id 148701 / 225000 loss 2.4652180671691895 train acc 0.7670442700452587\n",
      "epoch 3 batch id 148801 / 225000 loss 5.829464912414551 train acc 0.7670092942923771\n",
      "epoch 3 batch id 148901 / 225000 loss 1.6417267322540283 train acc 0.7670180186835548\n",
      "epoch 3 batch id 149001 / 225000 loss 1.7412422895431519 train acc 0.7670116307944242\n",
      "epoch 3 batch id 149101 / 225000 loss 1.382170557975769 train acc 0.7670052514738331\n",
      "epoch 3 batch id 149201 / 225000 loss 0.002536441432312131 train acc 0.7670156366244194\n",
      "epoch 3 batch id 149301 / 225000 loss 0.960055947303772 train acc 0.7670427525602642\n",
      "epoch 3 batch id 149401 / 225000 loss 1.3967243432998657 train acc 0.767049752009692\n",
      "epoch 3 batch id 149501 / 225000 loss 0.007582937832921743 train acc 0.767051725406519\n",
      "epoch 3 batch id 149601 / 225000 loss 0.941059410572052 train acc 0.7670620517242532\n",
      "epoch 3 batch id 149701 / 225000 loss 1.1252906322479248 train acc 0.7671024241655032\n",
      "epoch 3 batch id 149801 / 225000 loss 0.6781506538391113 train acc 0.7671110339717359\n",
      "epoch 3 batch id 149901 / 225000 loss 0.002615801291540265 train acc 0.7670996190819274\n",
      "epoch 3 batch id 150001 / 225000 loss 1.4482897520065308 train acc 0.7671198858674275\n",
      "epoch 3 batch id 150101 / 225000 loss 2.94166898727417 train acc 0.7671484533747277\n",
      "epoch 3 batch id 150201 / 225000 loss 1.1053491830825806 train acc 0.7671486874255165\n",
      "epoch 3 batch id 150301 / 225000 loss 0.0019109604181721807 train acc 0.7671655544540622\n",
      "epoch 3 batch id 150401 / 225000 loss 0.02519465796649456 train acc 0.7671558034853492\n",
      "epoch 3 batch id 150501 / 225000 loss 0.005800742190331221 train acc 0.7671493877117096\n",
      "epoch 3 batch id 150601 / 225000 loss 0.03715796023607254 train acc 0.7671595806136745\n",
      "epoch 3 batch id 150701 / 225000 loss 2.3880279064178467 train acc 0.767156488676253\n",
      "epoch 3 batch id 150801 / 225000 loss 0.011244794353842735 train acc 0.7671848993043813\n",
      "epoch 3 batch id 150901 / 225000 loss 0.016255779191851616 train acc 0.7672099588471912\n",
      "epoch 3 batch id 151001 / 225000 loss 0.016295118257403374 train acc 0.7672333295805988\n",
      "epoch 3 batch id 151101 / 225000 loss 0.5612863898277283 train acc 0.7672566693800835\n",
      "epoch 3 batch id 151201 / 225000 loss 0.13084633648395538 train acc 0.7672981660174205\n",
      "epoch 3 batch id 151301 / 225000 loss 1.8867709636688232 train acc 0.7672982994163952\n",
      "epoch 3 batch id 151401 / 225000 loss 1.4054902791976929 train acc 0.7672984326391503\n",
      "epoch 3 batch id 151501 / 225000 loss 3.471346139907837 train acc 0.7673068164566571\n",
      "epoch 3 batch id 151601 / 225000 loss 0.0031722020357847214 train acc 0.7672970494917579\n",
      "epoch 3 batch id 151701 / 225000 loss 2.644821882247925 train acc 0.7673021272107633\n",
      "epoch 3 batch id 151801 / 225000 loss 1.5314366817474365 train acc 0.7672660259155079\n",
      "epoch 3 batch id 151901 / 225000 loss 2.0722978115081787 train acc 0.7672464302407489\n",
      "epoch 3 batch id 152001 / 225000 loss 0.9753894805908203 train acc 0.7672663337741199\n",
      "epoch 3 batch id 152101 / 225000 loss 1.23252534866333 train acc 0.7672516945976686\n",
      "epoch 3 batch id 152201 / 225000 loss 0.44976431131362915 train acc 0.7672502151759844\n",
      "epoch 3 batch id 152301 / 225000 loss 1.1681392192840576 train acc 0.7672306813481199\n",
      "epoch 3 batch id 152401 / 225000 loss 0.024622436612844467 train acc 0.7672489025662561\n",
      "epoch 3 batch id 152501 / 225000 loss 0.25135594606399536 train acc 0.7672474278857188\n",
      "epoch 3 batch id 152601 / 225000 loss 0.0023089104797691107 train acc 0.7672361255824012\n",
      "epoch 3 batch id 152701 / 225000 loss 0.768842339515686 train acc 0.7672461215054256\n",
      "epoch 3 batch id 152801 / 225000 loss 1.149121642112732 train acc 0.7672593765747606\n",
      "epoch 3 batch id 152901 / 225000 loss 2.2375900745391846 train acc 0.7672726143059888\n",
      "epoch 3 batch id 153001 / 225000 loss 1.1269150972366333 train acc 0.7672842007568578\n",
      "epoch 3 batch id 153101 / 225000 loss 0.15982778370380402 train acc 0.767277810073089\n",
      "epoch 3 batch id 153201 / 225000 loss 2.9668946266174316 train acc 0.7672681640459266\n",
      "epoch 3 batch id 153301 / 225000 loss 2.802530527114868 train acc 0.7672780999471628\n",
      "epoch 3 batch id 153401 / 225000 loss 0.050474461168050766 train acc 0.7672880228942445\n",
      "epoch 3 batch id 153501 / 225000 loss 1.0131683349609375 train acc 0.7672914182969492\n",
      "epoch 3 batch id 153601 / 225000 loss 0.45366084575653076 train acc 0.7672980644657261\n",
      "epoch 3 batch id 153701 / 225000 loss 0.007994480431079865 train acc 0.7673242204019493\n",
      "epoch 3 batch id 153801 / 225000 loss 0.015476085245609283 train acc 0.7673357130317748\n",
      "epoch 3 batch id 153901 / 225000 loss 1.3764779567718506 train acc 0.7673325709384604\n",
      "epoch 3 batch id 154001 / 225000 loss 0.1699654459953308 train acc 0.7673375497561704\n",
      "epoch 3 batch id 154101 / 225000 loss 0.11153560876846313 train acc 0.7673441444247604\n",
      "epoch 3 batch id 154201 / 225000 loss 2.5728206634521484 train acc 0.7673604581033845\n",
      "epoch 3 batch id 154301 / 225000 loss 0.005612170789390802 train acc 0.7673735102170434\n",
      "epoch 3 batch id 154401 / 225000 loss 1.1133344173431396 train acc 0.7673574005349706\n",
      "epoch 3 batch id 154501 / 225000 loss 0.08818651735782623 train acc 0.767375292069307\n",
      "epoch 3 batch id 154601 / 225000 loss 2.4421932697296143 train acc 0.7673818409971475\n",
      "epoch 3 batch id 154701 / 225000 loss 0.007770630996674299 train acc 0.7673479809438853\n",
      "epoch 3 batch id 154801 / 225000 loss 0.00929222535341978 train acc 0.7673561540300127\n",
      "epoch 3 batch id 154901 / 225000 loss 0.6580807566642761 train acc 0.7673627026294214\n",
      "epoch 3 batch id 155001 / 225000 loss 2.8709707260131836 train acc 0.7673789201359992\n",
      "epoch 3 batch id 155101 / 225000 loss 1.1152955293655396 train acc 0.767388669318702\n",
      "epoch 3 batch id 155201 / 225000 loss 0.0030444080475717783 train acc 0.767403238381196\n",
      "epoch 3 batch id 155301 / 225000 loss 1.4749021530151367 train acc 0.767400081132768\n",
      "epoch 3 batch id 155401 / 225000 loss 0.0076859379187226295 train acc 0.7674146241015181\n",
      "epoch 3 batch id 155501 / 225000 loss 0.485678106546402 train acc 0.7674178944186855\n",
      "epoch 3 batch id 155601 / 225000 loss 0.7475566267967224 train acc 0.7674275872263032\n",
      "epoch 3 batch id 155701 / 225000 loss 2.3269481658935547 train acc 0.7674324506586342\n",
      "epoch 3 batch id 155801 / 225000 loss 1.4485418796539307 train acc 0.7674308894037908\n",
      "epoch 3 batch id 155901 / 225000 loss 1.6854530572891235 train acc 0.7674405552241487\n",
      "epoch 3 batch id 156001 / 225000 loss 1.904648780822754 train acc 0.7674389907757001\n",
      "epoch 3 batch id 156101 / 225000 loss 0.017448790371418 train acc 0.7674166084778444\n",
      "epoch 3 batch id 156201 / 225000 loss 1.6415424346923828 train acc 0.7674214633709131\n",
      "epoch 3 batch id 156301 / 225000 loss 0.20419293642044067 train acc 0.7674375083972591\n",
      "epoch 3 batch id 156401 / 225000 loss 0.0068699209950864315 train acc 0.7674503359952941\n",
      "epoch 3 batch id 156501 / 225000 loss 0.73759925365448 train acc 0.7674280036549287\n",
      "epoch 3 batch id 156601 / 225000 loss 3.406668186187744 train acc 0.7674488030089207\n",
      "epoch 3 batch id 156701 / 225000 loss 0.9580977559089661 train acc 0.767450431075743\n",
      "epoch 3 batch id 156801 / 225000 loss 1.1112713813781738 train acc 0.7674616233314838\n",
      "epoch 3 batch id 156901 / 225000 loss 0.9566695690155029 train acc 0.7674616477906451\n",
      "epoch 3 batch id 157001 / 225000 loss 1.826897144317627 train acc 0.7674632645651939\n",
      "epoch 3 batch id 157101 / 225000 loss 0.004178354516625404 train acc 0.7674776099451945\n",
      "epoch 3 batch id 157201 / 225000 loss 0.003528003580868244 train acc 0.7675078402809142\n",
      "epoch 3 batch id 157301 / 225000 loss 0.004372068680822849 train acc 0.7675189604643328\n",
      "epoch 3 batch id 157401 / 225000 loss 0.002758750692009926 train acc 0.767531654817949\n",
      "epoch 3 batch id 157501 / 225000 loss 1.980212926864624 train acc 0.7675427457603444\n",
      "epoch 3 batch id 157601 / 225000 loss 0.2310071885585785 train acc 0.7675252695097112\n",
      "epoch 3 batch id 157701 / 225000 loss 4.588717937469482 train acc 0.7675046448659172\n",
      "epoch 3 batch id 157801 / 225000 loss 0.013765253126621246 train acc 0.7675268217565161\n",
      "epoch 3 batch id 157901 / 225000 loss 2.974846124649048 train acc 0.7675268047700775\n",
      "epoch 3 batch id 158001 / 225000 loss 1.9291056394577026 train acc 0.7675362814159404\n",
      "epoch 3 batch id 158101 / 225000 loss 0.522695779800415 train acc 0.7675536524120657\n",
      "epoch 3 batch id 158201 / 225000 loss 1.8432343006134033 train acc 0.7675457171572873\n",
      "epoch 3 batch id 158301 / 225000 loss 1.586061954498291 train acc 0.7675520053568834\n",
      "epoch 3 batch id 158401 / 225000 loss 0.5639538168907166 train acc 0.7675551290711549\n",
      "epoch 3 batch id 158501 / 225000 loss 2.2048180103302 train acc 0.7675708670607756\n",
      "epoch 3 batch id 158601 / 225000 loss 1.1437673568725586 train acc 0.7675582121171998\n",
      "epoch 3 batch id 158701 / 225000 loss 2.174671173095703 train acc 0.7675502989899244\n",
      "epoch 3 batch id 158801 / 225000 loss 0.021192071959376335 train acc 0.7675644359922167\n",
      "epoch 3 batch id 158901 / 225000 loss 0.006796549074351788 train acc 0.767575408587737\n",
      "epoch 3 batch id 159001 / 225000 loss 0.002471338724717498 train acc 0.7675737888440953\n",
      "epoch 3 batch id 159101 / 225000 loss 0.001445617526769638 train acc 0.7675705998076694\n",
      "epoch 3 batch id 159201 / 225000 loss 2.651622772216797 train acc 0.7675988216154421\n",
      "epoch 3 batch id 159301 / 225000 loss 0.8251352310180664 train acc 0.7676034676492929\n",
      "epoch 3 batch id 159401 / 225000 loss 1.1958078145980835 train acc 0.7676143813401421\n",
      "epoch 3 batch id 159501 / 225000 loss 0.007393682841211557 train acc 0.7676190117930295\n",
      "epoch 3 batch id 159601 / 225000 loss 1.6394450664520264 train acc 0.7676032731624488\n",
      "epoch 3 batch id 159701 / 225000 loss 1.5157638788223267 train acc 0.7676313861528732\n",
      "epoch 3 batch id 159801 / 225000 loss 1.9206284284591675 train acc 0.7676313039342683\n",
      "epoch 3 batch id 159901 / 225000 loss 0.0021231244318187237 train acc 0.7676468564924547\n",
      "epoch 3 batch id 160001 / 225000 loss 1.9057278633117676 train acc 0.7676655145905338\n",
      "epoch 3 batch id 160101 / 225000 loss 2.0691072940826416 train acc 0.7676747802949389\n",
      "epoch 3 batch id 160201 / 225000 loss 0.8904425501823425 train acc 0.7676887160504616\n",
      "epoch 3 batch id 160301 / 225000 loss 0.05029794201254845 train acc 0.7676698835316061\n",
      "epoch 3 batch id 160401 / 225000 loss 3.4153971672058105 train acc 0.7676806877762608\n",
      "epoch 3 batch id 160501 / 225000 loss 2.042809009552002 train acc 0.7676821328216024\n",
      "epoch 3 batch id 160601 / 225000 loss 1.0939500331878662 train acc 0.7677038125540937\n",
      "epoch 3 batch id 160701 / 225000 loss 0.0023078026715666056 train acc 0.7677239096209731\n",
      "epoch 3 batch id 160801 / 225000 loss 0.005275737959891558 train acc 0.7677330986747595\n",
      "epoch 3 batch id 160901 / 225000 loss 0.002116055227816105 train acc 0.7677531525596485\n",
      "epoch 3 batch id 161001 / 225000 loss 1.9656707048416138 train acc 0.7677716287476475\n",
      "epoch 3 batch id 161101 / 225000 loss 0.28129711747169495 train acc 0.7677605973892154\n",
      "epoch 3 batch id 161201 / 225000 loss 0.22503435611724854 train acc 0.7677790460356946\n",
      "epoch 3 batch id 161301 / 225000 loss 1.2824033498764038 train acc 0.7678052212943504\n",
      "epoch 3 batch id 161401 / 225000 loss 0.6362490653991699 train acc 0.7678220704952262\n",
      "epoch 3 batch id 161501 / 225000 loss 1.7241969108581543 train acc 0.7678435427644411\n",
      "epoch 3 batch id 161601 / 225000 loss 0.03651557117700577 train acc 0.7678417831572825\n",
      "epoch 3 batch id 161701 / 225000 loss 2.9865450859069824 train acc 0.7678400257264952\n",
      "epoch 3 batch id 161801 / 225000 loss 1.204172134399414 train acc 0.7678382704680441\n",
      "epoch 3 batch id 161901 / 225000 loss 1.036712884902954 train acc 0.7678411498384815\n",
      "epoch 3 batch id 162001 / 225000 loss 0.8453022241592407 train acc 0.7678656304590712\n",
      "epoch 3 batch id 162101 / 225000 loss 3.8269896507263184 train acc 0.7678576936601255\n",
      "epoch 3 batch id 162201 / 225000 loss 0.16777946054935455 train acc 0.7678451427549768\n",
      "epoch 3 batch id 162301 / 225000 loss 0.0071237292140722275 train acc 0.7678526318383744\n",
      "epoch 3 batch id 162401 / 225000 loss 0.6554445028305054 train acc 0.7678570329000437\n",
      "epoch 3 batch id 162501 / 225000 loss 0.04239099100232124 train acc 0.767858351640913\n",
      "epoch 3 batch id 162601 / 225000 loss 0.08076329529285431 train acc 0.7678704313011605\n",
      "epoch 3 batch id 162701 / 225000 loss 0.024588823318481445 train acc 0.7678655939422622\n",
      "epoch 3 batch id 162801 / 225000 loss 1.8064961433410645 train acc 0.7678546200576164\n",
      "epoch 3 batch id 162901 / 225000 loss 3.4888439178466797 train acc 0.7678881652046335\n",
      "epoch 3 batch id 163001 / 225000 loss 1.0874508619308472 train acc 0.7678879270679321\n",
      "epoch 3 batch id 163101 / 225000 loss 1.01506769657135 train acc 0.7678846236381138\n",
      "epoch 3 batch id 163201 / 225000 loss 0.006891261786222458 train acc 0.7678736649897978\n",
      "epoch 3 batch id 163301 / 225000 loss 0.005858125630766153 train acc 0.767891807153661\n",
      "epoch 3 batch id 163401 / 225000 loss 0.005809470545500517 train acc 0.7678885074142753\n",
      "epoch 3 batch id 163501 / 225000 loss 0.06885205209255219 train acc 0.7678943859670583\n",
      "epoch 3 batch id 163601 / 225000 loss 1.350945234298706 train acc 0.7678926167932959\n",
      "epoch 3 batch id 163701 / 225000 loss 0.8094955682754517 train acc 0.7678801595591963\n",
      "epoch 3 batch id 163801 / 225000 loss 0.9769182205200195 train acc 0.7678753487463447\n",
      "epoch 3 batch id 163901 / 225000 loss 0.7328822612762451 train acc 0.7679025753351109\n",
      "epoch 3 batch id 164001 / 225000 loss 0.0026567266322672367 train acc 0.7679267199590246\n",
      "epoch 3 batch id 164101 / 225000 loss 0.002714417176321149 train acc 0.767937124088214\n",
      "epoch 3 batch id 164201 / 225000 loss 0.5013501644134521 train acc 0.7679353353511854\n",
      "epoch 3 batch id 164301 / 225000 loss 0.04340021312236786 train acc 0.7679548511573271\n",
      "epoch 3 batch id 164401 / 225000 loss 0.003808440174907446 train acc 0.7679500124695106\n",
      "epoch 3 batch id 164501 / 225000 loss 0.06737318634986877 train acc 0.7679846931021695\n",
      "epoch 3 batch id 164601 / 225000 loss 1.234296202659607 train acc 0.7679889551096287\n",
      "epoch 3 batch id 164701 / 225000 loss 0.011216485872864723 train acc 0.7679780329202616\n",
      "epoch 3 batch id 164801 / 225000 loss 0.5497795343399048 train acc 0.7679929126643649\n",
      "epoch 3 batch id 164901 / 225000 loss 0.09662317484617233 train acc 0.7679986779946756\n",
      "epoch 3 batch id 165001 / 225000 loss 1.2045974731445312 train acc 0.7680074666214144\n",
      "epoch 3 batch id 165101 / 225000 loss 0.003850475652143359 train acc 0.7679980739062755\n",
      "epoch 3 batch id 165201 / 225000 loss 0.9563419222831726 train acc 0.7679992857186094\n",
      "epoch 3 batch id 165301 / 225000 loss 1.2335680723190308 train acc 0.7679914217094875\n",
      "epoch 3 batch id 165401 / 225000 loss 1.2629448175430298 train acc 0.7679896131220488\n",
      "epoch 3 batch id 165501 / 225000 loss 2.3628804683685303 train acc 0.7679817644606377\n",
      "epoch 3 batch id 165601 / 225000 loss 1.0928927659988403 train acc 0.7679935507635823\n",
      "epoch 3 batch id 165701 / 225000 loss 1.1593374013900757 train acc 0.768030971448573\n",
      "epoch 3 batch id 165801 / 225000 loss 3.6014628410339355 train acc 0.7680502530141555\n",
      "epoch 3 batch id 165901 / 225000 loss 2.3092939853668213 train acc 0.7680589628754498\n",
      "epoch 3 batch id 166001 / 225000 loss 0.0488152913749218 train acc 0.7680962765284547\n",
      "epoch 3 batch id 166101 / 225000 loss 1.0626530647277832 train acc 0.768104948194171\n",
      "epoch 3 batch id 166201 / 225000 loss 1.550185203552246 train acc 0.7681075926137628\n",
      "epoch 3 batch id 166301 / 225000 loss 1.5160365104675293 train acc 0.7681192536424917\n",
      "epoch 3 batch id 166401 / 225000 loss 0.004689915105700493 train acc 0.7681278958660104\n",
      "epoch 3 batch id 166501 / 225000 loss 1.9643502235412598 train acc 0.7681455366634434\n",
      "epoch 3 batch id 166601 / 225000 loss 1.5923166275024414 train acc 0.7681586545098769\n",
      "epoch 3 batch id 166701 / 225000 loss 0.00604064529761672 train acc 0.768174756000264\n",
      "epoch 3 batch id 166801 / 225000 loss 4.1833391189575195 train acc 0.768178847848634\n",
      "epoch 3 batch id 166901 / 225000 loss 3.330092191696167 train acc 0.7681694537480303\n",
      "epoch 3 batch id 167001 / 225000 loss 1.123258352279663 train acc 0.7681855198471865\n",
      "epoch 3 batch id 167101 / 225000 loss 1.0358291864395142 train acc 0.7682060550206162\n",
      "epoch 3 batch id 167201 / 225000 loss 1.0378749370574951 train acc 0.7682280608369567\n",
      "epoch 3 batch id 167301 / 225000 loss 0.893598735332489 train acc 0.7682276256567504\n",
      "epoch 3 batch id 167401 / 225000 loss 0.9608910083770752 train acc 0.7682361515164187\n",
      "epoch 3 batch id 167501 / 225000 loss 2.5310754776000977 train acc 0.7682357120255998\n",
      "epoch 3 batch id 167601 / 225000 loss 0.007305107079446316 train acc 0.7682472061622544\n",
      "epoch 3 batch id 167701 / 225000 loss 2.304921865463257 train acc 0.7682482513521088\n",
      "epoch 3 batch id 167801 / 225000 loss 0.5250563621520996 train acc 0.7682597243163033\n",
      "epoch 3 batch id 167901 / 225000 loss 1.1844152212142944 train acc 0.7682458710787905\n",
      "epoch 3 batch id 168001 / 225000 loss 0.7996789813041687 train acc 0.7682603079743573\n",
      "epoch 3 batch id 168101 / 225000 loss 0.29783549904823303 train acc 0.7682687788888822\n",
      "epoch 3 batch id 168201 / 225000 loss 0.05232233926653862 train acc 0.768269808146206\n",
      "epoch 3 batch id 168301 / 225000 loss 1.3021619319915771 train acc 0.7682767779157581\n",
      "epoch 3 batch id 168401 / 225000 loss 1.5909429788589478 train acc 0.7682822548559688\n",
      "epoch 3 batch id 168501 / 225000 loss 0.008222307078540325 train acc 0.7682966273197191\n",
      "epoch 3 batch id 168601 / 225000 loss 1.1348063945770264 train acc 0.7682946720363462\n",
      "epoch 3 batch id 168701 / 225000 loss 1.0373409986495972 train acc 0.7682823456885258\n",
      "epoch 3 batch id 168801 / 225000 loss 1.1525052785873413 train acc 0.7683055787584196\n",
      "epoch 3 batch id 168901 / 225000 loss 0.3797960877418518 train acc 0.7683376652595307\n",
      "epoch 3 batch id 169001 / 225000 loss 0.7338758707046509 train acc 0.7683519624144236\n",
      "epoch 3 batch id 169101 / 225000 loss 2.6518123149871826 train acc 0.7683573722213352\n",
      "epoch 3 batch id 169201 / 225000 loss 0.568739652633667 train acc 0.7683583430357976\n",
      "epoch 3 batch id 169301 / 225000 loss 0.0018689275020733476 train acc 0.7683844159219378\n",
      "epoch 3 batch id 169401 / 225000 loss 4.5813822746276855 train acc 0.7683691359555138\n",
      "epoch 3 batch id 169501 / 225000 loss 1.621389389038086 train acc 0.7683568238535465\n",
      "epoch 3 batch id 169601 / 225000 loss 1.5796241760253906 train acc 0.7683681110370811\n",
      "epoch 3 batch id 169701 / 225000 loss 0.012800835072994232 train acc 0.768382331276775\n",
      "epoch 3 batch id 169801 / 225000 loss 2.374271869659424 train acc 0.7684053686374049\n",
      "epoch 3 batch id 169901 / 225000 loss 0.9487100839614868 train acc 0.7684077786475654\n",
      "epoch 3 batch id 170001 / 225000 loss 6.504122734069824 train acc 0.768404303504097\n",
      "epoch 3 batch id 170101 / 225000 loss 4.010185718536377 train acc 0.7684169993121733\n",
      "epoch 3 batch id 170201 / 225000 loss 4.1065874099731445 train acc 0.7684208670924377\n",
      "epoch 3 batch id 170301 / 225000 loss 1.6065958738327026 train acc 0.7684350062536333\n",
      "epoch 3 batch id 170401 / 225000 loss 0.007261243648827076 train acc 0.7684447274370455\n",
      "epoch 3 batch id 170501 / 225000 loss 0.7360393404960632 train acc 0.768447105882077\n",
      "epoch 3 batch id 170601 / 225000 loss 0.052073992788791656 train acc 0.7684421545008528\n",
      "epoch 3 batch id 170701 / 225000 loss 1.7966276407241821 train acc 0.7684445316664812\n",
      "epoch 3 batch id 170801 / 225000 loss 0.001989425625652075 train acc 0.7684439786652303\n",
      "epoch 3 batch id 170901 / 225000 loss 0.004671624395996332 train acc 0.7684595174984348\n",
      "epoch 3 batch id 171001 / 225000 loss 0.003324967809021473 train acc 0.7684838100361986\n",
      "epoch 3 batch id 171101 / 225000 loss 0.3707078695297241 train acc 0.7684773905471037\n",
      "epoch 3 batch id 171201 / 225000 loss 2.18357515335083 train acc 0.7685031045379408\n",
      "epoch 3 batch id 171301 / 225000 loss 1.004207730293274 train acc 0.7685346261843188\n",
      "epoch 3 batch id 171401 / 225000 loss 2.8356711864471436 train acc 0.7685281882836156\n",
      "epoch 3 batch id 171501 / 225000 loss 0.2405875325202942 train acc 0.7685450813697879\n",
      "epoch 3 batch id 171601 / 225000 loss 4.957401275634766 train acc 0.7685459292195267\n",
      "epoch 3 batch id 171701 / 225000 loss 2.3062901496887207 train acc 0.7685671603543369\n",
      "epoch 3 batch id 171801 / 225000 loss 3.502410650253296 train acc 0.7685694495375464\n",
      "epoch 3 batch id 171901 / 225000 loss 0.8588082790374756 train acc 0.7686008225664772\n",
      "epoch 3 batch id 172001 / 225000 loss 0.010411872528493404 train acc 0.768620531275981\n",
      "epoch 3 batch id 172101 / 225000 loss 3.868100166320801 train acc 0.7686242380927478\n",
      "epoch 3 batch id 172201 / 225000 loss 0.0381074920296669 train acc 0.7686410067305068\n",
      "epoch 3 batch id 172301 / 225000 loss 0.9808976650238037 train acc 0.7686272859704819\n",
      "epoch 3 batch id 172401 / 225000 loss 0.3541402518749237 train acc 0.7686309824188955\n",
      "epoch 3 batch id 172501 / 225000 loss 1.054418683052063 train acc 0.7686506165181651\n",
      "epoch 3 batch id 172601 / 225000 loss 2.9267661571502686 train acc 0.7686644341573919\n",
      "epoch 3 batch id 172701 / 225000 loss 1.1579865217208862 train acc 0.7686796833834199\n",
      "epoch 3 batch id 172801 / 225000 loss 0.003059778595343232 train acc 0.7686688734440195\n",
      "epoch 3 batch id 172901 / 225000 loss 1.4457342624664307 train acc 0.7686797647208519\n",
      "epoch 3 batch id 173001 / 225000 loss 2.1754627227783203 train acc 0.7686790827798683\n",
      "epoch 3 batch id 173101 / 225000 loss 0.013699786737561226 train acc 0.7686697361655912\n",
      "epoch 3 batch id 173201 / 225000 loss 0.0018249232089146972 train acc 0.76868060807963\n",
      "epoch 3 batch id 173301 / 225000 loss 0.003502646228298545 train acc 0.7687102209450609\n",
      "epoch 3 batch id 173401 / 225000 loss 1.4814707040786743 train acc 0.7686936638197012\n",
      "epoch 3 batch id 173501 / 225000 loss 1.387372374534607 train acc 0.7686886530913366\n",
      "epoch 3 batch id 173601 / 225000 loss 1.3737318515777588 train acc 0.7686922886388903\n",
      "epoch 3 batch id 173701 / 225000 loss 0.5016926527023315 train acc 0.7686844059619692\n",
      "epoch 3 batch id 173801 / 225000 loss 1.1333967447280884 train acc 0.7686563943820807\n",
      "epoch 3 batch id 173901 / 225000 loss 0.012630108743906021 train acc 0.7686499790110465\n",
      "epoch 3 batch id 174001 / 225000 loss 0.8262776136398315 train acc 0.7686406974672559\n",
      "epoch 3 batch id 174101 / 225000 loss 1.4224809408187866 train acc 0.768640042274312\n",
      "epoch 3 batch id 174201 / 225000 loss 1.8082146644592285 train acc 0.7686465634525634\n",
      "epoch 3 batch id 174301 / 225000 loss 0.8795135021209717 train acc 0.7686831974572722\n",
      "epoch 3 batch id 174401 / 225000 loss 3.420846462249756 train acc 0.7686782185881962\n",
      "epoch 3 batch id 174501 / 225000 loss 1.8110679388046265 train acc 0.7686832740213523\n",
      "epoch 3 batch id 174601 / 225000 loss 2.3774561882019043 train acc 0.7686754371395352\n",
      "epoch 3 batch id 174701 / 225000 loss 2.605433464050293 train acc 0.768690505492241\n",
      "epoch 3 batch id 174801 / 225000 loss 0.7897301316261292 train acc 0.7686941150222253\n",
      "epoch 3 batch id 174901 / 225000 loss 2.8935680389404297 train acc 0.7687077260850423\n",
      "epoch 3 batch id 175001 / 225000 loss 1.861579418182373 train acc 0.7687084645230599\n",
      "epoch 3 batch id 175101 / 225000 loss 1.0693182945251465 train acc 0.7687106298650493\n",
      "epoch 3 batch id 175201 / 225000 loss 0.8919475078582764 train acc 0.7687013772752439\n",
      "epoch 3 batch id 175301 / 225000 loss 1.0295790433883667 train acc 0.7687006919526985\n",
      "epoch 3 batch id 175401 / 225000 loss 0.02063808962702751 train acc 0.7687014327170313\n",
      "epoch 3 batch id 175501 / 225000 loss 0.003963811323046684 train acc 0.7686993236505775\n",
      "epoch 3 batch id 175601 / 225000 loss 0.9747503399848938 train acc 0.7687071827609182\n",
      "epoch 3 batch id 175701 / 225000 loss 1.9243531227111816 train acc 0.7686993813353368\n",
      "epoch 3 batch id 175801 / 225000 loss 0.04040905833244324 train acc 0.7687228741588501\n",
      "epoch 3 batch id 175901 / 225000 loss 0.0006949430098757148 train acc 0.7687434977629461\n",
      "epoch 3 batch id 176001 / 225000 loss 0.7969911694526672 train acc 0.7687555752524133\n",
      "epoch 3 batch id 176101 / 225000 loss 0.001643127528950572 train acc 0.7687747372246608\n",
      "epoch 3 batch id 176201 / 225000 loss 1.8350070714950562 train acc 0.7687725949341945\n",
      "epoch 3 batch id 176301 / 225000 loss 1.931734323501587 train acc 0.7687718731033857\n",
      "epoch 3 batch id 176401 / 225000 loss 1.7660048007965088 train acc 0.7687697348654486\n",
      "epoch 3 batch id 176501 / 225000 loss 0.975585401058197 train acc 0.7687860125438383\n",
      "epoch 3 batch id 176601 / 225000 loss 1.7771334648132324 train acc 0.7687980249262462\n",
      "epoch 3 batch id 176701 / 225000 loss 0.2545117437839508 train acc 0.7687987051572996\n",
      "epoch 3 batch id 176801 / 225000 loss 0.311884343624115 train acc 0.7688220089252888\n",
      "epoch 3 batch id 176901 / 225000 loss 3.1136367321014404 train acc 0.768800063312248\n",
      "epoch 3 batch id 177001 / 225000 loss 3.7507879734039307 train acc 0.7688078033457438\n",
      "epoch 3 batch id 177101 / 225000 loss 2.2601420879364014 train acc 0.7688014183996702\n",
      "epoch 3 batch id 177201 / 225000 loss 0.0012489714426919818 train acc 0.7687964514872941\n",
      "epoch 3 batch id 177301 / 225000 loss 1.1866618394851685 train acc 0.7688041804614751\n",
      "epoch 3 batch id 177401 / 225000 loss 0.6947954893112183 train acc 0.7688161284321959\n",
      "epoch 3 batch id 177501 / 225000 loss 0.7105100750923157 train acc 0.7688027109706425\n",
      "epoch 3 batch id 177601 / 225000 loss 1.09346342086792 train acc 0.768811831014465\n",
      "epoch 3 batch id 177701 / 225000 loss 0.0038072799798101187 train acc 0.768829381939325\n",
      "epoch 3 batch id 177801 / 225000 loss 1.1694492101669312 train acc 0.7688525373873037\n",
      "epoch 3 batch id 177901 / 225000 loss 0.0005368728307075799 train acc 0.7688377243523083\n",
      "epoch 3 batch id 178001 / 225000 loss 1.3887509107589722 train acc 0.7688355683395037\n",
      "epoch 3 batch id 178101 / 225000 loss 0.0038849678821861744 train acc 0.7688348184457134\n",
      "epoch 3 batch id 178201 / 225000 loss 0.5357803702354431 train acc 0.7688551130465037\n",
      "epoch 3 batch id 178301 / 225000 loss 4.302383899688721 train acc 0.768889406116623\n",
      "epoch 3 batch id 178401 / 225000 loss 1.4300262928009033 train acc 0.7689054433551381\n",
      "epoch 3 batch id 178501 / 225000 loss 0.013556926511228085 train acc 0.7689186615201036\n",
      "epoch 3 batch id 178601 / 225000 loss 0.02873213402926922 train acc 0.768930465114977\n",
      "epoch 3 batch id 178701 / 225000 loss 0.004736576694995165 train acc 0.7689534473785821\n",
      "epoch 3 batch id 178801 / 225000 loss 1.3814185857772827 train acc 0.7689680147202756\n",
      "epoch 3 batch id 178901 / 225000 loss 1.5477782487869263 train acc 0.7689811683556828\n",
      "epoch 3 batch id 179001 / 225000 loss 0.004212949424982071 train acc 0.7689775476114659\n",
      "epoch 3 batch id 179101 / 225000 loss 0.8645405173301697 train acc 0.7689655557478741\n",
      "epoch 3 batch id 179201 / 225000 loss 1.6025460958480835 train acc 0.7689689231644913\n",
      "epoch 3 batch id 179301 / 225000 loss 0.0015998313901945949 train acc 0.7689639210043446\n",
      "epoch 3 batch id 179401 / 225000 loss 1.6855183839797974 train acc 0.7689575308944766\n",
      "epoch 3 batch id 179501 / 225000 loss 0.009601299650967121 train acc 0.7689469696547652\n",
      "epoch 3 batch id 179601 / 225000 loss 1.137377142906189 train acc 0.7689475559712919\n",
      "epoch 3 batch id 179701 / 225000 loss 4.491621017456055 train acc 0.768959271233883\n",
      "epoch 3 batch id 179801 / 225000 loss 2.600663661956787 train acc 0.768973754317273\n",
      "epoch 3 batch id 179901 / 225000 loss 0.005496203899383545 train acc 0.7689951695654832\n",
      "epoch 3 batch id 180001 / 225000 loss 3.9589104652404785 train acc 0.7689971166826851\n",
      "epoch 3 batch id 180101 / 225000 loss 0.17951034009456635 train acc 0.7690087784076712\n",
      "epoch 3 batch id 180201 / 225000 loss 1.3795922994613647 train acc 0.7690204271896383\n",
      "epoch 3 batch id 180301 / 225000 loss 1.6673879623413086 train acc 0.769041769041769\n",
      "epoch 3 batch id 180401 / 225000 loss 2.353917360305786 train acc 0.7690159699779935\n",
      "epoch 3 batch id 180501 / 225000 loss 0.002949584275484085 train acc 0.7690082049406929\n",
      "epoch 3 batch id 180601 / 225000 loss 0.02239726111292839 train acc 0.7690447450457085\n",
      "epoch 3 batch id 180701 / 225000 loss 0.01207194197922945 train acc 0.7690314386749382\n",
      "epoch 3 batch id 180801 / 225000 loss 1.9214251041412354 train acc 0.7690554808878269\n",
      "epoch 3 batch id 180901 / 225000 loss 0.20514561235904694 train acc 0.7690974621478046\n",
      "epoch 3 batch id 181001 / 225000 loss 0.5624681115150452 train acc 0.7690855299141993\n",
      "epoch 3 batch id 181101 / 225000 loss 0.888719916343689 train acc 0.769090176200021\n",
      "epoch 3 batch id 181201 / 225000 loss 0.2615635395050049 train acc 0.7691072345075358\n",
      "epoch 3 batch id 181301 / 225000 loss 1.204634666442871 train acc 0.769111863696284\n",
      "epoch 3 batch id 181401 / 225000 loss 0.552131175994873 train acc 0.7691385383763044\n",
      "epoch 3 batch id 181501 / 225000 loss 0.648914635181427 train acc 0.7691376356053135\n",
      "epoch 3 batch id 181601 / 225000 loss 1.8399162292480469 train acc 0.7691257206733443\n",
      "epoch 3 batch id 181701 / 225000 loss 2.029886245727539 train acc 0.76913170538412\n",
      "epoch 3 batch id 181801 / 225000 loss 0.010108930990099907 train acc 0.7691294327313931\n",
      "epoch 3 batch id 181901 / 225000 loss 1.7466987371444702 train acc 0.7691244138295007\n",
      "epoch 3 batch id 182001 / 225000 loss 0.8664413094520569 train acc 0.7691400047252488\n",
      "epoch 3 batch id 182101 / 225000 loss 1.1543763875961304 train acc 0.7691445955815729\n",
      "epoch 3 batch id 182201 / 225000 loss 0.9268866777420044 train acc 0.7691519256206059\n",
      "epoch 3 batch id 182301 / 225000 loss 0.0012257143389433622 train acc 0.7691578762595926\n",
      "epoch 3 batch id 182401 / 225000 loss 0.00673610670492053 train acc 0.769155596734667\n",
      "epoch 3 batch id 182501 / 225000 loss 1.1947263479232788 train acc 0.7691601689853754\n",
      "epoch 3 batch id 182601 / 225000 loss 1.9265958070755005 train acc 0.7691661053334867\n",
      "epoch 3 batch id 182701 / 225000 loss 3.8316400051116943 train acc 0.7691597199796388\n",
      "epoch 3 batch id 182801 / 225000 loss 3.4796228408813477 train acc 0.7691793261524827\n",
      "epoch 3 batch id 182901 / 225000 loss 0.09846892952919006 train acc 0.7691948103072154\n",
      "epoch 3 batch id 183001 / 225000 loss 1.1568450927734375 train acc 0.7691925180736717\n",
      "epoch 3 batch id 183101 / 225000 loss 0.6929437518119812 train acc 0.7692093434770974\n",
      "epoch 3 batch id 183201 / 225000 loss 0.6178706884384155 train acc 0.7692220566481625\n",
      "epoch 3 batch id 183301 / 225000 loss 2.2956717014312744 train acc 0.7692211171788479\n",
      "epoch 3 batch id 183401 / 225000 loss 2.899306058883667 train acc 0.7692188156007873\n",
      "epoch 3 batch id 183501 / 225000 loss 0.0020296620205044746 train acc 0.7692410395583675\n",
      "epoch 3 batch id 183601 / 225000 loss 2.131269693374634 train acc 0.769246899526691\n",
      "epoch 3 batch id 183701 / 225000 loss 1.2592326402664185 train acc 0.7692677230935052\n",
      "epoch 3 batch id 183801 / 225000 loss 0.007536229211837053 train acc 0.7692762825011833\n",
      "epoch 3 batch id 183901 / 225000 loss 0.0016050462145358324 train acc 0.7692780354647337\n",
      "epoch 3 batch id 184001 / 225000 loss 1.0359721183776855 train acc 0.7692879386525073\n",
      "epoch 3 batch id 184101 / 225000 loss 0.03630577772855759 train acc 0.7692978310818518\n",
      "epoch 3 batch id 184201 / 225000 loss 0.0028543872758746147 train acc 0.7692968550659334\n",
      "epoch 3 batch id 184301 / 225000 loss 1.8190157413482666 train acc 0.7692918106792692\n",
      "epoch 3 batch id 184401 / 225000 loss 2.163646697998047 train acc 0.769279993058606\n",
      "epoch 3 batch id 184501 / 225000 loss 1.8200888633728027 train acc 0.7692803833041555\n",
      "epoch 3 batch id 184601 / 225000 loss 0.912582278251648 train acc 0.7692875444878413\n",
      "epoch 3 batch id 184701 / 225000 loss 0.0011570872738957405 train acc 0.7692946979171742\n",
      "epoch 3 batch id 184801 / 225000 loss 0.29785043001174927 train acc 0.7693031964112749\n",
      "epoch 3 batch id 184901 / 225000 loss 1.2590826749801636 train acc 0.7693157419375775\n",
      "epoch 3 batch id 185001 / 225000 loss 0.0019749472849071026 train acc 0.7693120577726607\n",
      "epoch 3 batch id 185101 / 225000 loss 4.0820488929748535 train acc 0.7693232343423321\n",
      "epoch 3 batch id 185201 / 225000 loss 0.0782293826341629 train acc 0.7693357487270587\n",
      "epoch 3 batch id 185301 / 225000 loss 1.9660446643829346 train acc 0.7693549953858857\n",
      "epoch 3 batch id 185401 / 225000 loss 0.9029541015625 train acc 0.7693486011402312\n",
      "epoch 3 batch id 185501 / 225000 loss 0.9724975824356079 train acc 0.7693368229820864\n",
      "epoch 3 batch id 185601 / 225000 loss 1.3574942350387573 train acc 0.7693546909768805\n",
      "epoch 3 batch id 185701 / 225000 loss 0.007383610121905804 train acc 0.7693469609749005\n",
      "epoch 3 batch id 185801 / 225000 loss 4.497165679931641 train acc 0.7693513490239557\n",
      "epoch 3 batch id 185901 / 225000 loss 1.2405048608779907 train acc 0.7693584219557722\n",
      "epoch 3 batch id 186001 / 225000 loss 0.9677435159683228 train acc 0.7693748958338934\n",
      "epoch 3 batch id 186101 / 225000 loss 1.7471859455108643 train acc 0.7693940387209096\n",
      "epoch 3 batch id 186201 / 225000 loss 0.008219026029109955 train acc 0.7694171889517242\n",
      "epoch 3 batch id 186301 / 225000 loss 0.8888943195343018 train acc 0.7694282371001766\n",
      "epoch 3 batch id 186401 / 225000 loss 1.396775722503662 train acc 0.769441955783499\n",
      "epoch 3 batch id 186501 / 225000 loss 2.004138708114624 train acc 0.7694596811813341\n",
      "epoch 3 batch id 186601 / 225000 loss 1.895161747932434 train acc 0.7694572912256633\n",
      "epoch 3 batch id 186701 / 225000 loss 1.7370445728302002 train acc 0.7694749894215885\n",
      "epoch 3 batch id 186801 / 225000 loss 0.01373253483325243 train acc 0.7694779471201975\n",
      "epoch 3 batch id 186901 / 225000 loss 0.012199020013213158 train acc 0.7694768888341956\n",
      "epoch 3 batch id 187001 / 225000 loss 1.7793262004852295 train acc 0.7694905374837567\n",
      "epoch 3 batch id 187101 / 225000 loss 0.04448963329195976 train acc 0.7694908097765378\n",
      "epoch 3 batch id 187201 / 225000 loss 0.22059442102909088 train acc 0.7694803980747966\n",
      "epoch 3 batch id 187301 / 225000 loss 0.9431743025779724 train acc 0.769471332240618\n",
      "epoch 3 batch id 187401 / 225000 loss 3.077665328979492 train acc 0.7694742824211184\n",
      "epoch 3 batch id 187501 / 225000 loss 2.0120623111724854 train acc 0.7694852294121098\n",
      "epoch 3 batch id 187601 / 225000 loss 0.27010712027549744 train acc 0.769492166886104\n",
      "epoch 3 batch id 187701 / 225000 loss 0.0019311552168801427 train acc 0.7695044245901727\n",
      "epoch 3 batch id 187801 / 225000 loss 3.6301560401916504 train acc 0.7695140068476739\n",
      "epoch 3 batch id 187901 / 225000 loss 0.0009368187165819108 train acc 0.7695142654908702\n",
      "epoch 3 batch id 188001 / 225000 loss 0.11933130025863647 train acc 0.7695264918803624\n",
      "epoch 3 batch id 188101 / 225000 loss 2.86130952835083 train acc 0.7695387052700411\n",
      "epoch 3 batch id 188201 / 225000 loss 0.0049383267760276794 train acc 0.7695336369094744\n",
      "epoch 3 batch id 188301 / 225000 loss 2.693699836730957 train acc 0.7695458335324825\n",
      "epoch 3 batch id 188401 / 225000 loss 0.039839260280132294 train acc 0.7695527093805234\n",
      "epoch 3 batch id 188501 / 225000 loss 1.7215490341186523 train acc 0.769554272921629\n",
      "epoch 3 batch id 188601 / 225000 loss 0.29480841755867004 train acc 0.7695770435999809\n",
      "epoch 3 batch id 188701 / 225000 loss 1.780521273612976 train acc 0.7695931659079708\n",
      "epoch 3 batch id 188801 / 225000 loss 1.018934726715088 train acc 0.7696145677194507\n",
      "epoch 3 batch id 188901 / 225000 loss 0.005657580681145191 train acc 0.7695869794230841\n",
      "epoch 3 batch id 189001 / 225000 loss 0.09896797686815262 train acc 0.7695964571616023\n",
      "epoch 3 batch id 189101 / 225000 loss 3.069505214691162 train acc 0.7696191453244562\n",
      "epoch 3 batch id 189201 / 225000 loss 0.09251092374324799 train acc 0.7696193466207896\n",
      "epoch 3 batch id 189301 / 225000 loss 0.006268934812396765 train acc 0.76962747159286\n",
      "epoch 3 batch id 189401 / 225000 loss 4.061625003814697 train acc 0.7696316281329032\n",
      "epoch 3 batch id 189501 / 225000 loss 0.3456636369228363 train acc 0.7696489728286394\n",
      "epoch 3 batch id 189601 / 225000 loss 2.7497241497039795 train acc 0.769651795085469\n",
      "epoch 3 batch id 189701 / 225000 loss 2.14814829826355 train acc 0.7696519786400704\n",
      "epoch 3 batch id 189801 / 225000 loss 1.2494802474975586 train acc 0.76962977012766\n",
      "epoch 3 batch id 189901 / 225000 loss 3.089534044265747 train acc 0.7696194332836583\n",
      "epoch 3 batch id 190001 / 225000 loss 1.831217646598816 train acc 0.7696235809285215\n",
      "epoch 3 batch id 190101 / 225000 loss 0.0004913076991215348 train acc 0.7696250940289635\n",
      "epoch 3 batch id 190201 / 225000 loss 0.17396314442157745 train acc 0.7696318631342632\n",
      "epoch 3 batch id 190301 / 225000 loss 1.0496470928192139 train acc 0.769643879958592\n",
      "epoch 3 batch id 190401 / 225000 loss 1.3826037645339966 train acc 0.7696466930320744\n",
      "epoch 3 batch id 190501 / 225000 loss 0.5086695551872253 train acc 0.7696639387719749\n",
      "epoch 3 batch id 190601 / 225000 loss 1.3315483331680298 train acc 0.7696575568858506\n",
      "epoch 3 batch id 190701 / 225000 loss 0.825252890586853 train acc 0.7696787117005155\n",
      "epoch 3 batch id 190801 / 225000 loss 0.011157223954796791 train acc 0.7696775698240576\n",
      "epoch 3 batch id 190901 / 225000 loss 0.46781685948371887 train acc 0.7696764291439018\n",
      "epoch 3 batch id 191001 / 225000 loss 0.006437836680561304 train acc 0.7696844519138644\n",
      "epoch 3 batch id 191101 / 225000 loss 2.621368885040283 train acc 0.7697016237486983\n",
      "epoch 3 batch id 191201 / 225000 loss 0.8756574392318726 train acc 0.7697043948514913\n",
      "epoch 3 batch id 191301 / 225000 loss 0.7078395485877991 train acc 0.769717617785584\n",
      "epoch 3 batch id 191401 / 225000 loss 1.4566025733947754 train acc 0.7697242961113056\n",
      "epoch 3 batch id 191501 / 225000 loss 1.1512516736984253 train acc 0.7697283565098877\n",
      "epoch 3 batch id 191601 / 225000 loss 1.7525362968444824 train acc 0.7697363270546604\n",
      "epoch 3 batch id 191701 / 225000 loss 1.2474360466003418 train acc 0.7697429851696131\n",
      "epoch 3 batch id 191801 / 225000 loss 2.2929296493530273 train acc 0.7697509397761221\n",
      "epoch 3 batch id 191901 / 225000 loss 0.0037339571863412857 train acc 0.7697601888473744\n",
      "epoch 3 batch id 192001 / 225000 loss 0.6338616013526917 train acc 0.769772032437331\n",
      "epoch 3 batch id 192101 / 225000 loss 1.2106133699417114 train acc 0.7697799595004711\n",
      "epoch 3 batch id 192201 / 225000 loss 0.0036659943871200085 train acc 0.7697852768716084\n",
      "epoch 3 batch id 192301 / 225000 loss 0.016167420893907547 train acc 0.769797088938695\n",
      "epoch 3 batch id 192401 / 225000 loss 0.015387587249279022 train acc 0.7698036912490059\n",
      "epoch 3 batch id 192501 / 225000 loss 1.3904712200164795 train acc 0.769797299754287\n",
      "epoch 3 batch id 192601 / 225000 loss 2.446094512939453 train acc 0.7698000010384162\n",
      "epoch 3 batch id 192701 / 225000 loss 0.0023337029851973057 train acc 0.7698169703322765\n",
      "epoch 3 batch id 192801 / 225000 loss 6.093733310699463 train acc 0.7698235486330465\n",
      "epoch 3 batch id 192901 / 225000 loss 2.4523468017578125 train acc 0.7698378961228817\n",
      "epoch 3 batch id 193001 / 225000 loss 0.40917864441871643 train acc 0.7698392754441686\n",
      "epoch 3 batch id 193101 / 225000 loss 2.0176920890808105 train acc 0.7698419479961264\n",
      "epoch 3 batch id 193201 / 225000 loss 0.9152587056159973 train acc 0.7698472057598046\n",
      "epoch 3 batch id 193301 / 225000 loss 0.002955094911158085 train acc 0.7698615113217211\n",
      "epoch 3 batch id 193401 / 225000 loss 1.2529127597808838 train acc 0.7698680461838356\n",
      "epoch 3 batch id 193501 / 225000 loss 0.0034931572154164314 train acc 0.7698564865297853\n",
      "epoch 3 batch id 193601 / 225000 loss 0.5661541819572449 train acc 0.769856560658261\n",
      "epoch 3 batch id 193701 / 225000 loss 0.11789240688085556 train acc 0.7698566347101977\n",
      "epoch 3 batch id 193801 / 225000 loss 2.2745845317840576 train acc 0.7698786383971187\n",
      "epoch 3 batch id 193901 / 225000 loss 2.1222009658813477 train acc 0.7698877262107983\n",
      "epoch 3 batch id 194001 / 225000 loss 0.297509104013443 train acc 0.769886495430436\n",
      "epoch 3 batch id 194101 / 225000 loss 0.1130305752158165 train acc 0.7699045857568998\n",
      "epoch 3 batch id 194201 / 225000 loss 0.9932068586349487 train acc 0.76991364617072\n",
      "epoch 3 batch id 194301 / 225000 loss 3.9345579147338867 train acc 0.7699124039505716\n",
      "epoch 3 batch id 194401 / 225000 loss 2.1101012229919434 train acc 0.7699085910051903\n",
      "epoch 3 batch id 194501 / 225000 loss 5.055129051208496 train acc 0.769907352661426\n",
      "epoch 3 batch id 194601 / 225000 loss 1.350744605064392 train acc 0.7699241011094496\n",
      "epoch 3 batch id 194701 / 225000 loss 1.3637667894363403 train acc 0.7699305601922949\n",
      "epoch 3 batch id 194801 / 225000 loss 0.0006841712747700512 train acc 0.7699305958388304\n",
      "epoch 3 batch id 194901 / 225000 loss 0.403563529253006 train acc 0.7699498719862905\n",
      "epoch 3 batch id 195001 / 225000 loss 0.001137139624916017 train acc 0.7699447695140025\n",
      "epoch 3 batch id 195101 / 225000 loss 0.0027548805810511112 train acc 0.7699512047606112\n",
      "epoch 3 batch id 195201 / 225000 loss 0.0015826254384592175 train acc 0.7699627563383384\n",
      "epoch 3 batch id 195301 / 225000 loss 0.014462821185588837 train acc 0.7699755761619245\n",
      "epoch 3 batch id 195401 / 225000 loss 1.0843650102615356 train acc 0.7699883828639567\n",
      "epoch 3 batch id 195501 / 225000 loss 0.05283612012863159 train acc 0.7700203579521332\n",
      "epoch 3 batch id 195601 / 225000 loss 2.194740056991577 train acc 0.7700267381046109\n",
      "epoch 3 batch id 195701 / 225000 loss 2.419409990310669 train acc 0.7700369441137245\n",
      "epoch 3 batch id 195801 / 225000 loss 0.31664538383483887 train acc 0.7700356484389763\n",
      "epoch 3 batch id 195901 / 225000 loss 0.6422966718673706 train acc 0.7700534964089004\n",
      "epoch 3 batch id 196001 / 225000 loss 0.4133700728416443 train acc 0.7700547446186499\n",
      "epoch 3 batch id 196101 / 225000 loss 2.6428794860839844 train acc 0.7700585412619008\n",
      "epoch 3 batch id 196201 / 225000 loss 0.2990388572216034 train acc 0.7700712534594625\n",
      "epoch 3 batch id 196301 / 225000 loss 0.010928361676633358 train acc 0.7700724907157885\n",
      "epoch 3 batch id 196401 / 225000 loss 0.006289979908615351 train acc 0.770077545430013\n",
      "epoch 3 batch id 196501 / 225000 loss 2.1296920776367188 train acc 0.7700813227413601\n",
      "epoch 3 batch id 196601 / 225000 loss 0.0648283064365387 train acc 0.7700749233218549\n",
      "epoch 3 batch id 196701 / 225000 loss 0.006854941602796316 train acc 0.7700723433027793\n",
      "epoch 3 batch id 196801 / 225000 loss 0.13777640461921692 train acc 0.7700811987743965\n",
      "epoch 3 batch id 196901 / 225000 loss 1.1546610593795776 train acc 0.7700925845983515\n",
      "epoch 3 batch id 197001 / 225000 loss 0.3686405420303345 train acc 0.7700785782813285\n",
      "epoch 3 batch id 197101 / 225000 loss 0.03400567173957825 train acc 0.7700823435700478\n",
      "epoch 3 batch id 197201 / 225000 loss 1.4981964826583862 train acc 0.7700823018138854\n",
      "epoch 3 batch id 197301 / 225000 loss 2.284032106399536 train acc 0.7700847942990658\n",
      "epoch 3 batch id 197401 / 225000 loss 0.4601356089115143 train acc 0.7701088140384293\n",
      "epoch 3 batch id 197501 / 225000 loss 2.3198845386505127 train acc 0.7701150880248707\n",
      "epoch 3 batch id 197601 / 225000 loss 0.0011498325038701296 train acc 0.770117560133805\n",
      "epoch 3 batch id 197701 / 225000 loss 0.006730764172971249 train acc 0.7701187652060435\n",
      "epoch 3 batch id 197801 / 225000 loss 2.4589991569519043 train acc 0.7701300802321526\n",
      "epoch 3 batch id 197901 / 225000 loss 0.0016800375888124108 train acc 0.7701274879864175\n",
      "epoch 3 batch id 198001 / 225000 loss 0.0006877784035168588 train acc 0.7701034338210413\n",
      "epoch 3 batch id 198101 / 225000 loss 2.2764296531677246 train acc 0.7701071675559437\n",
      "epoch 3 batch id 198201 / 225000 loss 2.691401958465576 train acc 0.7700982840651661\n",
      "epoch 3 batch id 198301 / 225000 loss 1.453821063041687 train acc 0.7700831059853455\n",
      "epoch 3 batch id 198401 / 225000 loss 0.010521209798753262 train acc 0.7700906245432231\n",
      "epoch 3 batch id 198501 / 225000 loss 1.5473629236221313 train acc 0.7701006544047637\n",
      "epoch 3 batch id 198601 / 225000 loss 0.48068761825561523 train acc 0.7701043801390728\n",
      "epoch 3 batch id 198701 / 225000 loss 0.004470870830118656 train acc 0.7701093602951168\n",
      "epoch 3 batch id 198801 / 225000 loss 2.3235490322113037 train acc 0.7701168505188606\n",
      "epoch 3 batch id 198901 / 225000 loss 1.105189323425293 train acc 0.770134388464613\n",
      "epoch 3 batch id 199001 / 225000 loss 1.1767836809158325 train acc 0.7701230144572138\n",
      "epoch 3 batch id 199101 / 225000 loss 1.197629451751709 train acc 0.7701154188075399\n",
      "epoch 3 batch id 199201 / 225000 loss 1.874367117881775 train acc 0.7701103408115421\n",
      "epoch 3 batch id 199301 / 225000 loss 0.31339600682258606 train acc 0.7701178117520735\n",
      "epoch 3 batch id 199401 / 225000 loss 2.028472661972046 train acc 0.7701315439742027\n",
      "epoch 3 batch id 199501 / 225000 loss 2.46480131149292 train acc 0.7701189467721966\n",
      "epoch 3 batch id 199601 / 225000 loss 1.0669286251068115 train acc 0.770116382182454\n",
      "epoch 3 batch id 199701 / 225000 loss 1.2673155069351196 train acc 0.7701063089318532\n",
      "epoch 3 batch id 199801 / 225000 loss 0.006175857502967119 train acc 0.7701100094594121\n",
      "epoch 3 batch id 199901 / 225000 loss 3.1934847831726074 train acc 0.7701137062846108\n",
      "epoch 3 batch id 200001 / 225000 loss 1.0660213232040405 train acc 0.7701386493067535\n",
      "epoch 3 batch id 200101 / 225000 loss 2.00431227684021 train acc 0.7701360812789542\n",
      "epoch 3 batch id 200201 / 225000 loss 0.011930054053664207 train acc 0.7701609882068521\n",
      "epoch 3 batch id 200301 / 225000 loss 1.6047052145004272 train acc 0.7701733890494805\n",
      "epoch 3 batch id 200401 / 225000 loss 3.0291638374328613 train acc 0.77019825250373\n",
      "epoch 3 batch id 200501 / 225000 loss 0.6377061605453491 train acc 0.7701994005017432\n",
      "epoch 3 batch id 200601 / 225000 loss 2.977029323577881 train acc 0.7702167486702459\n",
      "epoch 3 batch id 200701 / 225000 loss 0.10069669038057327 train acc 0.7702353251852257\n",
      "epoch 3 batch id 200801 / 225000 loss 0.016991764307022095 train acc 0.7702426780743123\n",
      "epoch 3 batch id 200901 / 225000 loss 0.8560485243797302 train acc 0.7702438016734611\n",
      "epoch 3 batch id 201001 / 225000 loss 1.4077939987182617 train acc 0.7702586056785787\n",
      "epoch 3 batch id 201101 / 225000 loss 2.926922082901001 train acc 0.7702584770836545\n",
      "epoch 3 batch id 201201 / 225000 loss 0.0052246712148189545 train acc 0.7702608336936695\n",
      "epoch 3 batch id 201301 / 225000 loss 1.5711215734481812 train acc 0.7702768490966264\n",
      "epoch 3 batch id 201401 / 225000 loss 0.06740772724151611 train acc 0.7702729877210143\n",
      "epoch 3 batch id 201501 / 225000 loss 0.004755194298923016 train acc 0.7702666488007504\n",
      "epoch 3 batch id 201601 / 225000 loss 2.242426872253418 train acc 0.7702727169012058\n",
      "epoch 3 batch id 201701 / 225000 loss 1.9087245464324951 train acc 0.7702911735687974\n",
      "epoch 3 batch id 201801 / 225000 loss 2.8962161540985107 train acc 0.7703046565676087\n",
      "epoch 3 batch id 201901 / 225000 loss 0.005719441920518875 train acc 0.7703230791328424\n",
      "epoch 3 batch id 202001 / 225000 loss 1.7043637037277222 train acc 0.7703093053994782\n",
      "epoch 3 batch id 202101 / 225000 loss 0.001132894423790276 train acc 0.7703301814439315\n",
      "epoch 3 batch id 202201 / 225000 loss 0.05233461782336235 train acc 0.7703399092981736\n",
      "epoch 3 batch id 202301 / 225000 loss 1.3008900880813599 train acc 0.7703372697119638\n",
      "epoch 3 batch id 202401 / 225000 loss 0.004512001760303974 train acc 0.7703618065128137\n",
      "epoch 3 batch id 202501 / 225000 loss 0.010184956714510918 train acc 0.7703752080236641\n",
      "epoch 3 batch id 202601 / 225000 loss 2.439424514770508 train acc 0.7703787246854655\n",
      "epoch 3 batch id 202701 / 225000 loss 3.357699394226074 train acc 0.7703736044716109\n",
      "epoch 3 batch id 202801 / 225000 loss 0.6679931879043579 train acc 0.77039067854695\n",
      "epoch 3 batch id 202901 / 225000 loss 0.6274212598800659 train acc 0.7703966466404798\n",
      "epoch 3 batch id 203001 / 225000 loss 1.8604391813278198 train acc 0.7704001458120896\n",
      "epoch 3 batch id 203101 / 225000 loss 0.029706213623285294 train acc 0.7703999487939498\n",
      "epoch 3 batch id 203201 / 225000 loss 3.883716106414795 train acc 0.7704046732053484\n",
      "epoch 3 batch id 203301 / 225000 loss 0.012591419741511345 train acc 0.7704044741540867\n",
      "epoch 3 batch id 203401 / 225000 loss 0.6834667325019836 train acc 0.7704153371910659\n",
      "epoch 3 batch id 203501 / 225000 loss 0.00438705924898386 train acc 0.7704347890182358\n",
      "epoch 3 batch id 203601 / 225000 loss 0.004796371329575777 train acc 0.7704517659539982\n",
      "epoch 3 batch id 203701 / 225000 loss 1.9491267204284668 train acc 0.7704355894178232\n",
      "epoch 3 batch id 203801 / 225000 loss 0.007697715889662504 train acc 0.7704537759873602\n",
      "epoch 3 batch id 203901 / 225000 loss 1.2533328533172607 train acc 0.770462136036606\n",
      "epoch 3 batch id 204001 / 225000 loss 0.005448380019515753 train acc 0.7704582330478772\n",
      "epoch 3 batch id 204101 / 225000 loss 1.4472745656967163 train acc 0.7704616831862656\n",
      "epoch 3 batch id 204201 / 225000 loss 0.5143951177597046 train acc 0.7704700270811602\n",
      "epoch 3 batch id 204301 / 225000 loss 1.0733695030212402 train acc 0.7704722443845111\n",
      "epoch 3 batch id 204401 / 225000 loss 0.019439512863755226 train acc 0.7704707902603216\n",
      "epoch 3 batch id 204501 / 225000 loss 1.1568628549575806 train acc 0.7704852299010763\n",
      "epoch 3 batch id 204601 / 225000 loss 2.444624900817871 train acc 0.7704837708515598\n",
      "epoch 3 batch id 204701 / 225000 loss 3.3778674602508545 train acc 0.7705006326300311\n",
      "epoch 3 batch id 204801 / 225000 loss 0.02362079732120037 train acc 0.7704942846958756\n",
      "epoch 3 batch id 204901 / 225000 loss 0.7283835411071777 train acc 0.7704952635663076\n",
      "epoch 3 batch id 205001 / 225000 loss 0.032186415046453476 train acc 0.7705194121004287\n",
      "epoch 3 batch id 205101 / 225000 loss 0.08251181244850159 train acc 0.7705410992632898\n",
      "epoch 3 batch id 205201 / 225000 loss 3.6835150718688965 train acc 0.7705335256650796\n",
      "epoch 3 batch id 205301 / 225000 loss 1.3296204805374146 train acc 0.7705149999269365\n",
      "epoch 3 batch id 205401 / 225000 loss 0.1440543234348297 train acc 0.7705208348547475\n",
      "epoch 3 batch id 205501 / 225000 loss 0.014643260277807713 train acc 0.7705132821738093\n",
      "epoch 3 batch id 205601 / 225000 loss 0.13667523860931396 train acc 0.7705191122611271\n",
      "epoch 3 batch id 205701 / 225000 loss 0.001212708535604179 train acc 0.7705346595300947\n",
      "epoch 3 batch id 205801 / 225000 loss 0.8776194453239441 train acc 0.770517393015583\n",
      "epoch 3 batch id 205901 / 225000 loss 0.19123142957687378 train acc 0.7705110708544397\n",
      "epoch 3 batch id 206001 / 225000 loss 0.0037292237393558025 train acc 0.7705229586264144\n",
      "epoch 3 batch id 206101 / 225000 loss 0.003718576394021511 train acc 0.7705275568774533\n",
      "epoch 3 batch id 206201 / 225000 loss 1.0105433464050293 train acc 0.7705345754870248\n",
      "epoch 3 batch id 206301 / 225000 loss 0.20852813124656677 train acc 0.7705306808982991\n",
      "epoch 3 batch id 206401 / 225000 loss 0.48729774355888367 train acc 0.7705328462555898\n",
      "epoch 3 batch id 206501 / 225000 loss 2.061202049255371 train acc 0.7705362201635827\n",
      "epoch 3 batch id 206601 / 225000 loss 0.017519114539027214 train acc 0.7705553216102535\n",
      "epoch 3 batch id 206701 / 225000 loss 1.4892019033432007 train acc 0.7705453771389592\n",
      "epoch 3 batch id 206801 / 225000 loss 0.006667011417448521 train acc 0.7705390689600147\n",
      "epoch 3 batch id 206901 / 225000 loss 0.004776775371283293 train acc 0.7705472665671022\n",
      "epoch 3 batch id 207001 / 225000 loss 0.0015368727035820484 train acc 0.7705409635702243\n",
      "epoch 3 batch id 207101 / 225000 loss 0.0016707436880096793 train acc 0.77054311664357\n",
      "epoch 3 batch id 207201 / 225000 loss 0.1367415189743042 train acc 0.77054888731232\n",
      "epoch 3 batch id 207301 / 225000 loss 0.015627149492502213 train acc 0.7705691241238586\n",
      "epoch 3 batch id 207401 / 225000 loss 0.6277832388877869 train acc 0.7705604119555837\n",
      "epoch 3 batch id 207501 / 225000 loss 0.023029861971735954 train acc 0.7705589370653635\n",
      "epoch 3 batch id 207601 / 225000 loss 0.7631881237030029 train acc 0.7705598720622733\n",
      "epoch 3 batch id 207701 / 225000 loss 0.002123187994584441 train acc 0.7705620098121819\n",
      "epoch 3 batch id 207801 / 225000 loss 1.3971885442733765 train acc 0.770553317837739\n",
      "epoch 3 batch id 207901 / 225000 loss 3.0469117164611816 train acc 0.7705470392157806\n",
      "epoch 3 batch id 208001 / 225000 loss 2.4187369346618652 train acc 0.7705624011423022\n",
      "epoch 3 batch id 208101 / 225000 loss 0.12348361313343048 train acc 0.7705477148115578\n",
      "epoch 3 batch id 208201 / 225000 loss 2.9015722274780273 train acc 0.7705426486904482\n",
      "epoch 3 batch id 208301 / 225000 loss 1.0909514427185059 train acc 0.7705387876198386\n",
      "epoch 3 batch id 208401 / 225000 loss 0.09436850249767303 train acc 0.7705481259686854\n",
      "epoch 3 batch id 208501 / 225000 loss 2.042309045791626 train acc 0.7705526592198598\n",
      "epoch 3 batch id 208601 / 225000 loss 2.522609233856201 train acc 0.7705547912042607\n",
      "epoch 3 batch id 208701 / 225000 loss 0.9129770994186401 train acc 0.770559316917504\n",
      "epoch 3 batch id 208801 / 225000 loss 0.0023445605766028166 train acc 0.7705734167939808\n",
      "epoch 3 batch id 208901 / 225000 loss 0.24111786484718323 train acc 0.7705695520844802\n",
      "epoch 3 batch id 209001 / 225000 loss 1.0281593799591064 train acc 0.7705860259041822\n",
      "epoch 3 batch id 209101 / 225000 loss 2.8749749660491943 train acc 0.7705988971836577\n",
      "epoch 3 batch id 209201 / 225000 loss 1.6082617044448853 train acc 0.770603390997175\n",
      "epoch 3 batch id 209301 / 225000 loss 0.5536946058273315 train acc 0.7706007138045208\n",
      "epoch 3 batch id 209401 / 225000 loss 2.8204426765441895 train acc 0.7705956514056762\n",
      "epoch 3 batch id 209501 / 225000 loss 0.47823581099510193 train acc 0.770619233321082\n",
      "epoch 3 batch id 209601 / 225000 loss 1.0610876083374023 train acc 0.7706237088563509\n",
      "epoch 3 batch id 209701 / 225000 loss 2.8803083896636963 train acc 0.7706246036022718\n",
      "epoch 3 batch id 209801 / 225000 loss 1.1934565305709839 train acc 0.7706493296028141\n",
      "epoch 3 batch id 209901 / 225000 loss 0.7002054452896118 train acc 0.7706537844031234\n",
      "epoch 3 batch id 210001 / 225000 loss 0.06185251846909523 train acc 0.7706618063723506\n",
      "epoch 3 batch id 210101 / 225000 loss 0.10136165469884872 train acc 0.7706840995521201\n",
      "epoch 3 batch id 210201 / 225000 loss 2.313333749771118 train acc 0.7706909101288767\n",
      "epoch 3 batch id 210301 / 225000 loss 1.5950576066970825 train acc 0.7707036580900709\n",
      "epoch 3 batch id 210401 / 225000 loss 0.0826616883277893 train acc 0.7707033236534047\n",
      "epoch 3 batch id 210501 / 225000 loss 2.5102314949035645 train acc 0.7707113030341899\n",
      "epoch 3 batch id 210601 / 225000 loss 0.7202645540237427 train acc 0.7707133394428326\n",
      "epoch 3 batch id 210701 / 225000 loss 0.14420393109321594 train acc 0.77071656043398\n",
      "epoch 3 batch id 210801 / 225000 loss 0.32217472791671753 train acc 0.770724522179686\n",
      "epoch 3 batch id 210901 / 225000 loss 0.017615124583244324 train acc 0.7707431448878858\n",
      "epoch 3 batch id 211001 / 225000 loss 0.25206345319747925 train acc 0.7707487168307259\n",
      "epoch 3 batch id 211101 / 225000 loss 0.005274439230561256 train acc 0.7707566520291235\n",
      "epoch 3 batch id 211201 / 225000 loss 0.008173385635018349 train acc 0.7707515589414823\n",
      "epoch 3 batch id 211301 / 225000 loss 2.3864147663116455 train acc 0.7707476538208528\n",
      "epoch 3 batch id 211401 / 225000 loss 0.7334452867507935 train acc 0.770763856367756\n",
      "epoch 3 batch id 211501 / 225000 loss 0.0025741099379956722 train acc 0.7707587670980279\n",
      "epoch 3 batch id 211601 / 225000 loss 1.1586921215057373 train acc 0.7707749490786906\n",
      "epoch 3 batch id 211701 / 225000 loss 0.4597673714160919 train acc 0.7707769448420178\n",
      "epoch 3 batch id 211801 / 225000 loss 0.0024701273068785667 train acc 0.7707576923621702\n",
      "epoch 3 batch id 211901 / 225000 loss 0.001954025588929653 train acc 0.7707455368308785\n",
      "epoch 3 batch id 212001 / 225000 loss 0.0017850772710517049 train acc 0.7707652322394706\n",
      "epoch 3 batch id 212101 / 225000 loss 0.004370904061943293 train acc 0.7707731222389334\n",
      "epoch 3 batch id 212201 / 225000 loss 3.018697738647461 train acc 0.7707715797757786\n",
      "epoch 3 batch id 212301 / 225000 loss 1.3315670490264893 train acc 0.7707947678060867\n",
      "epoch 3 batch id 212401 / 225000 loss 2.4891552925109863 train acc 0.7707885085286792\n",
      "epoch 3 batch id 212501 / 225000 loss 2.2737841606140137 train acc 0.7707951962578999\n",
      "epoch 3 batch id 212601 / 225000 loss 0.029863450676202774 train acc 0.7707995258724089\n",
      "epoch 3 batch id 212701 / 225000 loss 0.9683184027671814 train acc 0.7708062021335114\n",
      "epoch 3 batch id 212801 / 225000 loss 0.004494193010032177 train acc 0.7708246201850555\n",
      "epoch 3 batch id 212901 / 225000 loss 0.19331094622612 train acc 0.7708230586047036\n",
      "epoch 3 batch id 213001 / 225000 loss 0.7640160322189331 train acc 0.7708203247872075\n",
      "epoch 3 batch id 213101 / 225000 loss 1.2678349018096924 train acc 0.7708164203828232\n",
      "epoch 3 batch id 213201 / 225000 loss 0.3050650358200073 train acc 0.7708195552553694\n",
      "epoch 3 batch id 213301 / 225000 loss 0.7873795628547668 train acc 0.7708308915570016\n",
      "epoch 3 batch id 213401 / 225000 loss 0.95989590883255 train acc 0.7708469032478761\n",
      "epoch 3 batch id 213501 / 225000 loss 2.2601723670959473 train acc 0.770850019437848\n",
      "epoch 3 batch id 213601 / 225000 loss 1.0055259466171265 train acc 0.7708437694580081\n",
      "epoch 3 batch id 213701 / 225000 loss 2.772874116897583 train acc 0.7708503937744793\n",
      "epoch 3 batch id 213801 / 225000 loss 1.5982747077941895 train acc 0.7708476574010411\n",
      "epoch 3 batch id 213901 / 225000 loss 1.0611850023269653 train acc 0.7708531049410708\n",
      "epoch 3 batch id 214001 / 225000 loss 0.7840160131454468 train acc 0.7708503698580847\n",
      "epoch 3 batch id 214101 / 225000 loss 0.6527436375617981 train acc 0.7708674877744616\n",
      "epoch 3 batch id 214201 / 225000 loss 0.3868291974067688 train acc 0.770865915658657\n",
      "epoch 3 batch id 214301 / 225000 loss 2.2192397117614746 train acc 0.7708690113438574\n",
      "epoch 3 batch id 214401 / 225000 loss 1.1011762619018555 train acc 0.7708709381019678\n",
      "epoch 3 batch id 214501 / 225000 loss 0.5136336088180542 train acc 0.7708716975678435\n",
      "epoch 3 batch id 214601 / 225000 loss 1.0282117128372192 train acc 0.7708666315627607\n",
      "epoch 3 batch id 214701 / 225000 loss 0.08360424637794495 train acc 0.7708557482266035\n",
      "epoch 3 batch id 214801 / 225000 loss 0.0025681082624942064 train acc 0.770878627194473\n",
      "epoch 3 batch id 214901 / 225000 loss 0.019811507314443588 train acc 0.7708851983006129\n",
      "epoch 3 batch id 215001 / 225000 loss 0.9132839441299438 train acc 0.7708894377235455\n",
      "epoch 3 batch id 215101 / 225000 loss 0.003002805868163705 train acc 0.7708971599388195\n",
      "epoch 3 batch id 215201 / 225000 loss 0.24360977113246918 train acc 0.7709106835005414\n",
      "epoch 3 batch id 215301 / 225000 loss 2.0605838298797607 train acc 0.7709032935285949\n",
      "epoch 3 batch id 215401 / 225000 loss 2.024843215942383 train acc 0.7709086773041908\n",
      "epoch 3 batch id 215501 / 225000 loss 0.9704302549362183 train acc 0.7708954946844794\n",
      "epoch 3 batch id 215601 / 225000 loss 1.1949131488800049 train acc 0.7708858029415449\n",
      "epoch 3 batch id 215701 / 225000 loss 0.004422521684318781 train acc 0.7708946643733687\n",
      "epoch 3 batch id 215801 / 225000 loss 3.689523220062256 train acc 0.7708988836937735\n",
      "epoch 3 batch id 215901 / 225000 loss 0.7651767730712891 train acc 0.7708949935387053\n",
      "epoch 3 batch id 216001 / 225000 loss 1.3600122928619385 train acc 0.7708841625733214\n",
      "epoch 3 batch id 216101 / 225000 loss 0.004835283383727074 train acc 0.7708825965636439\n",
      "epoch 3 batch id 216201 / 225000 loss 0.9826686978340149 train acc 0.770869468688859\n",
      "epoch 3 batch id 216301 / 225000 loss 0.9618306159973145 train acc 0.7708760014979126\n",
      "epoch 3 batch id 216401 / 225000 loss 1.0141994953155518 train acc 0.7708779072185433\n",
      "epoch 3 batch id 216501 / 225000 loss 0.841140866279602 train acc 0.7708936679276308\n",
      "epoch 3 batch id 216601 / 225000 loss 2.178586006164551 train acc 0.7708932553404647\n",
      "epoch 3 batch id 216701 / 225000 loss 0.005554452538490295 train acc 0.7708963041241157\n",
      "epoch 3 batch id 216801 / 225000 loss 1.8482394218444824 train acc 0.7708970438328236\n",
      "epoch 3 batch id 216901 / 225000 loss 2.5111217498779297 train acc 0.7709127666539113\n",
      "epoch 3 batch id 217001 / 225000 loss 2.5831785202026367 train acc 0.7709134980944788\n",
      "epoch 3 batch id 217101 / 225000 loss 1.6231961250305176 train acc 0.7709130773234577\n",
      "epoch 3 batch id 217201 / 225000 loss 2.415062427520752 train acc 0.7709034488791489\n",
      "epoch 3 batch id 217301 / 225000 loss 0.03430592641234398 train acc 0.7708903778629643\n",
      "epoch 3 batch id 217401 / 225000 loss 1.109081745147705 train acc 0.7709049176406733\n",
      "epoch 3 batch id 217501 / 225000 loss 1.1257853507995605 train acc 0.7709045015884984\n",
      "epoch 3 batch id 217601 / 225000 loss 0.10284614562988281 train acc 0.7709109792693968\n",
      "epoch 3 batch id 217701 / 225000 loss 1.8684446811676025 train acc 0.7709117091791035\n",
      "epoch 3 batch id 217801 / 225000 loss 0.9361015558242798 train acc 0.7708952208667545\n",
      "epoch 3 batch id 217901 / 225000 loss 2.038682222366333 train acc 0.7708913680983566\n",
      "epoch 3 batch id 218001 / 225000 loss 2.6884267330169678 train acc 0.770886372080862\n",
      "epoch 3 batch id 218101 / 225000 loss 0.015132533386349678 train acc 0.770887111934379\n",
      "epoch 3 batch id 218201 / 225000 loss 0.21345965564250946 train acc 0.7708901425749652\n",
      "epoch 3 batch id 218301 / 225000 loss 1.0905097723007202 train acc 0.7708943156467446\n",
      "epoch 3 batch id 218401 / 225000 loss 0.07109957933425903 train acc 0.7708939061634333\n",
      "epoch 3 batch id 218501 / 225000 loss 1.930254340171814 train acc 0.7708923528954101\n",
      "epoch 3 batch id 218601 / 225000 loss 0.31422722339630127 train acc 0.7709045246819548\n",
      "epoch 3 batch id 218701 / 225000 loss 0.9122270941734314 train acc 0.7709235440167169\n",
      "epoch 3 batch id 218801 / 225000 loss 0.6284859776496887 train acc 0.7709242645143304\n",
      "epoch 3 batch id 218901 / 225000 loss 2.364877939224243 train acc 0.7709364050415485\n",
      "epoch 3 batch id 219001 / 225000 loss 0.0011648123618215322 train acc 0.7709485344815777\n",
      "epoch 3 batch id 219101 / 225000 loss 0.000756304245442152 train acc 0.7709686400335918\n",
      "epoch 3 batch id 219201 / 225000 loss 1.7220687866210938 train acc 0.7709761816780033\n",
      "epoch 3 batch id 219301 / 225000 loss 0.00047042820369824767 train acc 0.7709586367595223\n",
      "epoch 3 batch id 219401 / 225000 loss 2.902981996536255 train acc 0.7709502235632472\n",
      "epoch 3 batch id 219501 / 225000 loss 2.2332165241241455 train acc 0.7709566243433971\n",
      "epoch 3 batch id 219601 / 225000 loss 0.008478052914142609 train acc 0.7709539118674323\n",
      "epoch 3 batch id 219701 / 225000 loss 3.0001087188720703 train acc 0.7709455123099122\n",
      "epoch 3 batch id 219801 / 225000 loss 0.6390635967254639 train acc 0.7709666925992148\n",
      "epoch 3 batch id 219901 / 225000 loss 0.2385702133178711 train acc 0.7709787586231986\n",
      "epoch 3 batch id 220001 / 225000 loss 3.490163803100586 train acc 0.7709851318857641\n",
      "epoch 3 batch id 220101 / 225000 loss 0.013698744587600231 train acc 0.7709914993571133\n",
      "epoch 3 batch id 220201 / 225000 loss 0.029517915099859238 train acc 0.7709933197396923\n",
      "epoch 3 batch id 220301 / 225000 loss 0.8236153721809387 train acc 0.7709917340366136\n",
      "epoch 3 batch id 220401 / 225000 loss 0.0015949815278872848 train acc 0.7710162385833095\n",
      "epoch 3 batch id 220501 / 225000 loss 1.358095645904541 train acc 0.7710271155232856\n",
      "epoch 3 batch id 220601 / 225000 loss 1.9430614709854126 train acc 0.7710198503179949\n",
      "epoch 3 batch id 220701 / 225000 loss 1.0043503046035767 train acc 0.7710205209763435\n",
      "epoch 3 batch id 220801 / 225000 loss 2.252192974090576 train acc 0.7710302489572058\n",
      "epoch 3 batch id 220901 / 225000 loss 2.3871188163757324 train acc 0.7710263873862047\n",
      "epoch 3 batch id 221001 / 225000 loss 0.8271711468696594 train acc 0.7710270541762254\n",
      "epoch 3 batch id 221101 / 225000 loss 0.9932814240455627 train acc 0.7710435502326991\n",
      "epoch 3 batch id 221201 / 225000 loss 1.2500568628311157 train acc 0.7710430784670955\n",
      "epoch 3 batch id 221301 / 225000 loss 0.6368272304534912 train acc 0.7710493852264563\n",
      "epoch 3 batch id 221401 / 225000 loss 0.00326264719478786 train acc 0.7710556862886798\n",
      "epoch 3 batch id 221501 / 225000 loss 3.2970871925354004 train acc 0.7710676249768624\n",
      "epoch 3 batch id 221601 / 225000 loss 0.001908138394355774 train acc 0.7710693995063199\n",
      "epoch 3 batch id 221701 / 225000 loss 1.324428915977478 train acc 0.7710745553696194\n",
      "epoch 3 batch id 221801 / 225000 loss 0.005521318409591913 train acc 0.7710718166284192\n",
      "epoch 3 batch id 221901 / 225000 loss 1.898801565170288 train acc 0.7710837265266943\n",
      "epoch 3 batch id 222001 / 225000 loss 0.005148264113813639 train acc 0.7710899950901122\n",
      "epoch 3 batch id 222101 / 225000 loss 2.009500741958618 train acc 0.7710861274825417\n",
      "epoch 3 batch id 222201 / 225000 loss 3.443331718444824 train acc 0.7710980148604192\n",
      "epoch 3 batch id 222301 / 225000 loss 0.9506003260612488 train acc 0.7711177637527497\n",
      "epoch 3 batch id 222401 / 225000 loss 0.0023663246538490057 train acc 0.7711082683980738\n",
      "epoch 3 batch id 222501 / 225000 loss 1.1526190042495728 train acc 0.7711111410735233\n",
      "epoch 3 batch id 222601 / 225000 loss 1.9332468509674072 train acc 0.7711117649965633\n",
      "epoch 3 batch id 222701 / 225000 loss 0.18976353108882904 train acc 0.7711258593360605\n",
      "epoch 3 batch id 222801 / 225000 loss 0.832486629486084 train acc 0.7711309644032118\n",
      "epoch 3 batch id 222901 / 225000 loss 0.9301902651786804 train acc 0.7711315785931872\n",
      "epoch 3 batch id 223001 / 225000 loss 3.225975275039673 train acc 0.7711176183066444\n",
      "epoch 3 batch id 223101 / 225000 loss 3.7258353233337402 train acc 0.7711193584968243\n",
      "epoch 3 batch id 223201 / 225000 loss 0.003702162764966488 train acc 0.7711132566610365\n",
      "epoch 3 batch id 223301 / 225000 loss 1.7519073486328125 train acc 0.7711217146362981\n",
      "epoch 3 batch id 223401 / 225000 loss 0.00441253837198019 train acc 0.7711335222313239\n",
      "epoch 3 batch id 223501 / 225000 loss 1.4363878965377808 train acc 0.7711363707544933\n",
      "epoch 3 batch id 223601 / 225000 loss 2.3257224559783936 train acc 0.7711448070446912\n",
      "epoch 3 batch id 223701 / 225000 loss 0.002535542706027627 train acc 0.7711420601606609\n",
      "epoch 3 batch id 223801 / 225000 loss 0.0011389722349122167 train acc 0.7711571887525078\n",
      "epoch 3 batch id 223901 / 225000 loss 0.020711608231067657 train acc 0.7711633713114279\n",
      "epoch 3 batch id 224001 / 225000 loss 1.1864867210388184 train acc 0.7711650840844461\n",
      "epoch 3 batch id 224101 / 225000 loss 2.0557303428649902 train acc 0.771179066581586\n",
      "epoch 3 batch id 224201 / 225000 loss 1.1722840070724487 train acc 0.7711896913929911\n",
      "epoch 3 batch id 224301 / 225000 loss 3.061180830001831 train acc 0.7711947338620871\n",
      "epoch 3 batch id 224401 / 225000 loss 0.64647376537323 train acc 0.7711919732978018\n",
      "epoch 3 batch id 224501 / 225000 loss 0.012224473990499973 train acc 0.7711992374198778\n",
      "epoch 3 batch id 224601 / 225000 loss 0.7144837975502014 train acc 0.7712064950734858\n",
      "epoch 3 batch id 224701 / 225000 loss 1.166116714477539 train acc 0.7712181966257382\n",
      "epoch 3 batch id 224801 / 225000 loss 0.9744383692741394 train acc 0.771215430536341\n",
      "epoch 3 batch id 224901 / 225000 loss 2.187485933303833 train acc 0.7712059973054811\n",
      "epoch 3 train acc 0.7711944444444444\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1745bc6965e14391bbedbcd130bbc1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 test acc 0.78018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5d016f40f24ffb925dc90de6f77feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 / 225000 loss 2.621037483215332 train acc 0.5\n",
      "epoch 4 batch id 101 / 225000 loss 1.3906028270721436 train acc 0.7920792079207921\n",
      "epoch 4 batch id 201 / 225000 loss 2.331331253051758 train acc 0.7873134328358209\n",
      "epoch 4 batch id 301 / 225000 loss 0.039606865495443344 train acc 0.7990033222591362\n",
      "epoch 4 batch id 401 / 225000 loss 0.33229386806488037 train acc 0.7899002493765586\n",
      "epoch 4 batch id 501 / 225000 loss 1.0660619735717773 train acc 0.7879241516966068\n",
      "epoch 4 batch id 601 / 225000 loss 2.383063554763794 train acc 0.7874376039933444\n",
      "epoch 4 batch id 701 / 225000 loss 2.0021278858184814 train acc 0.7842368045649073\n",
      "epoch 4 batch id 801 / 225000 loss 1.9823715686798096 train acc 0.7874531835205992\n",
      "epoch 4 batch id 901 / 225000 loss 0.06876713782548904 train acc 0.7830188679245284\n",
      "epoch 4 batch id 1001 / 225000 loss 1.2961605787277222 train acc 0.7867132867132867\n",
      "epoch 4 batch id 1101 / 225000 loss 0.004297594539821148 train acc 0.7865576748410535\n",
      "epoch 4 batch id 1201 / 225000 loss 0.005784790031611919 train acc 0.7862198168193172\n",
      "epoch 4 batch id 1301 / 225000 loss 1.2922353744506836 train acc 0.787086856264412\n",
      "epoch 4 batch id 1401 / 225000 loss 0.01661107689142227 train acc 0.7890792291220556\n",
      "epoch 4 batch id 1501 / 225000 loss 3.2980706691741943 train acc 0.7884743504330446\n",
      "epoch 4 batch id 1601 / 225000 loss 0.00938389915972948 train acc 0.7896627108057465\n",
      "epoch 4 batch id 1701 / 225000 loss 0.0024871788918972015 train acc 0.7896825396825397\n",
      "epoch 4 batch id 1801 / 225000 loss 1.1817599534988403 train acc 0.7897001665741255\n",
      "epoch 4 batch id 1901 / 225000 loss 1.5812263488769531 train acc 0.7885323513940031\n",
      "epoch 4 batch id 2001 / 225000 loss 0.0004528897115960717 train acc 0.7901049475262368\n",
      "epoch 4 batch id 2101 / 225000 loss 2.8646647930145264 train acc 0.7906949071870538\n",
      "epoch 4 batch id 2201 / 225000 loss 0.0012519657611846924 train acc 0.7911176737846434\n",
      "epoch 4 batch id 2301 / 225000 loss 1.4946975708007812 train acc 0.7919382877009996\n",
      "epoch 4 batch id 2401 / 225000 loss 1.990842580795288 train acc 0.7923781757601\n",
      "epoch 4 batch id 2501 / 225000 loss 0.001377232139930129 train acc 0.7925829668132747\n",
      "epoch 4 batch id 2601 / 225000 loss 1.5523526668548584 train acc 0.7920991926182238\n",
      "epoch 4 batch id 2701 / 225000 loss 1.622223973274231 train acc 0.7913735653461681\n",
      "epoch 4 batch id 2801 / 225000 loss 2.170811653137207 train acc 0.7902534808996787\n",
      "epoch 4 batch id 2901 / 225000 loss 0.009383691474795341 train acc 0.7896415029300241\n",
      "epoch 4 batch id 3001 / 225000 loss 0.7260805368423462 train acc 0.7903198933688771\n",
      "epoch 4 batch id 3101 / 225000 loss 1.2051974534988403 train acc 0.7900677200902935\n",
      "epoch 4 batch id 3201 / 225000 loss 0.0010010669939219952 train acc 0.7895970009372071\n",
      "epoch 4 batch id 3301 / 225000 loss 0.33082929253578186 train acc 0.7898364132081187\n",
      "epoch 4 batch id 3401 / 225000 loss 0.0025547367986291647 train acc 0.7885915907086151\n",
      "epoch 4 batch id 3501 / 225000 loss 1.1839975118637085 train acc 0.7874892887746359\n",
      "epoch 4 batch id 3601 / 225000 loss 0.008095836266875267 train acc 0.7874201610663705\n",
      "epoch 4 batch id 3701 / 225000 loss 2.3581647872924805 train acc 0.7870170224263713\n",
      "epoch 4 batch id 3801 / 225000 loss 0.02325369417667389 train acc 0.7876874506708761\n",
      "epoch 4 batch id 3901 / 225000 loss 2.8222568035125732 train acc 0.7864650089720584\n",
      "epoch 4 batch id 4001 / 225000 loss 0.5801699757575989 train acc 0.7854286428392901\n",
      "epoch 4 batch id 4101 / 225000 loss 2.1000003814697266 train acc 0.7848695440136552\n",
      "epoch 4 batch id 4201 / 225000 loss 0.014856986701488495 train acc 0.7843370626041418\n",
      "epoch 4 batch id 4301 / 225000 loss 0.04224686697125435 train acc 0.7847593582887701\n",
      "epoch 4 batch id 4401 / 225000 loss 0.0061687566339969635 train acc 0.7840263576459896\n",
      "epoch 4 batch id 4501 / 225000 loss 0.002945731161162257 train acc 0.7843812486114197\n",
      "epoch 4 batch id 4601 / 225000 loss 0.24716581404209137 train acc 0.7841773527494023\n",
      "epoch 4 batch id 4701 / 225000 loss 0.019329283386468887 train acc 0.7837162305892363\n",
      "epoch 4 batch id 4801 / 225000 loss 1.9601668119430542 train acc 0.7834826077900438\n",
      "epoch 4 batch id 4901 / 225000 loss 0.013051368296146393 train acc 0.7835645786574168\n",
      "epoch 4 batch id 5001 / 225000 loss 1.5920766592025757 train acc 0.7831933613277344\n",
      "epoch 4 batch id 5101 / 225000 loss 1.3580163717269897 train acc 0.7837188786512449\n",
      "epoch 4 batch id 5201 / 225000 loss 0.009655994363129139 train acc 0.7835993078254182\n",
      "epoch 4 batch id 5301 / 225000 loss 0.0030249147675931454 train acc 0.7829183172986229\n",
      "epoch 4 batch id 5401 / 225000 loss 2.1988024711608887 train acc 0.7828179966672838\n",
      "epoch 4 batch id 5501 / 225000 loss 0.040419988334178925 train acc 0.7834030176331576\n",
      "epoch 4 batch id 5601 / 225000 loss 1.1756974458694458 train acc 0.7831637207641493\n",
      "epoch 4 batch id 5701 / 225000 loss 0.6390142440795898 train acc 0.7825820031573408\n",
      "epoch 4 batch id 5801 / 225000 loss 1.9519752264022827 train acc 0.782752973625237\n",
      "epoch 4 batch id 5901 / 225000 loss 1.115034580230713 train acc 0.7821979325538044\n",
      "epoch 4 batch id 6001 / 225000 loss 0.6023053526878357 train acc 0.7827445425762373\n",
      "epoch 4 batch id 6101 / 225000 loss 1.8403387069702148 train acc 0.7831093263399442\n",
      "epoch 4 batch id 6201 / 225000 loss 1.8571668863296509 train acc 0.7832607643928399\n",
      "epoch 4 batch id 6301 / 225000 loss 1.6686928272247314 train acc 0.7832883669258848\n",
      "epoch 4 batch id 6401 / 225000 loss 1.7198923826217651 train acc 0.7828854866427121\n",
      "epoch 4 batch id 6501 / 225000 loss 0.41597211360931396 train acc 0.7826488232579604\n",
      "epoch 4 batch id 6601 / 225000 loss 0.00799966137856245 train acc 0.7823057112558703\n",
      "epoch 4 batch id 6701 / 225000 loss 0.009798646904528141 train acc 0.7816743769586629\n",
      "epoch 4 batch id 6801 / 225000 loss 2.1662328243255615 train acc 0.781318923687693\n",
      "epoch 4 batch id 6901 / 225000 loss 3.7302989959716797 train acc 0.7817707578611796\n",
      "epoch 4 batch id 7001 / 225000 loss 1.0465751886367798 train acc 0.7817454649335809\n",
      "epoch 4 batch id 7101 / 225000 loss 1.3552074432373047 train acc 0.7814392339107168\n",
      "epoch 4 batch id 7201 / 225000 loss 0.007834887132048607 train acc 0.7814886821274823\n",
      "epoch 4 batch id 7301 / 225000 loss 0.002398530952632427 train acc 0.7816052595534858\n",
      "epoch 4 batch id 7401 / 225000 loss 0.6995331645011902 train acc 0.7810093230644507\n",
      "epoch 4 batch id 7501 / 225000 loss 1.3889015913009644 train acc 0.7804959338754832\n",
      "epoch 4 batch id 7601 / 225000 loss 0.15933212637901306 train acc 0.7800947243783712\n",
      "epoch 4 batch id 7701 / 225000 loss 1.0133068561553955 train acc 0.780093494351383\n",
      "epoch 4 batch id 7801 / 225000 loss 0.021787235513329506 train acc 0.77986796564543\n",
      "epoch 4 batch id 7901 / 225000 loss 1.7680928707122803 train acc 0.7798696367548411\n",
      "epoch 4 batch id 8001 / 225000 loss 0.6798462867736816 train acc 0.7796837895263092\n",
      "epoch 4 batch id 8101 / 225000 loss 2.0466415882110596 train acc 0.7795333909393902\n",
      "epoch 4 batch id 8201 / 225000 loss 0.002267533680424094 train acc 0.7796610169491526\n",
      "epoch 4 batch id 8301 / 225000 loss 0.2590346038341522 train acc 0.7793940489097699\n",
      "epoch 4 batch id 8401 / 225000 loss 1.3598594665527344 train acc 0.7796095702892513\n",
      "epoch 4 batch id 8501 / 225000 loss 0.23353566229343414 train acc 0.7799376543936007\n",
      "epoch 4 batch id 8601 / 225000 loss 1.8761475086212158 train acc 0.7800255784211139\n",
      "epoch 4 batch id 8701 / 225000 loss 2.3979742527008057 train acc 0.7796804964946558\n",
      "epoch 4 batch id 8801 / 225000 loss 0.5352564454078674 train acc 0.7799965912964436\n",
      "epoch 4 batch id 8901 / 225000 loss 0.0009526344365440309 train acc 0.780417930569599\n",
      "epoch 4 batch id 9001 / 225000 loss 0.19222453236579895 train acc 0.7804410621042106\n",
      "epoch 4 batch id 9101 / 225000 loss 0.2618508040904999 train acc 0.7801889902208549\n",
      "epoch 4 batch id 9201 / 225000 loss 0.6264523267745972 train acc 0.780404303880013\n",
      "epoch 4 batch id 9301 / 225000 loss 0.008522681891918182 train acc 0.7803730781636383\n",
      "epoch 4 batch id 9401 / 225000 loss 0.008509822189807892 train acc 0.7806084459100096\n",
      "epoch 4 batch id 9501 / 225000 loss 3.4748733043670654 train acc 0.7809441111461951\n",
      "epoch 4 batch id 9601 / 225000 loss 0.0017226398922502995 train acc 0.7812207061764399\n",
      "epoch 4 batch id 9701 / 225000 loss 3.215668201446533 train acc 0.781491598804247\n",
      "epoch 4 batch id 9801 / 225000 loss 0.00317222997546196 train acc 0.7815784103662892\n",
      "epoch 4 batch id 9901 / 225000 loss 0.1974387764930725 train acc 0.7815119684880315\n",
      "epoch 4 batch id 10001 / 225000 loss 1.5469176769256592 train acc 0.7817718228177182\n",
      "epoch 4 batch id 10101 / 225000 loss 3.9318740367889404 train acc 0.7815810315810315\n",
      "epoch 4 batch id 10201 / 225000 loss 0.1413334161043167 train acc 0.7815410253896676\n",
      "epoch 4 batch id 10301 / 225000 loss 0.009567759931087494 train acc 0.7815260654305407\n",
      "epoch 4 batch id 10401 / 225000 loss 0.06505346298217773 train acc 0.7817277184886069\n",
      "epoch 4 batch id 10501 / 225000 loss 2.7801218032836914 train acc 0.7819017236453671\n",
      "epoch 4 batch id 10601 / 225000 loss 0.16563737392425537 train acc 0.7816951231015942\n",
      "epoch 4 batch id 10701 / 225000 loss 2.266669273376465 train acc 0.7817727315204187\n",
      "epoch 4 batch id 10801 / 225000 loss 0.19526304304599762 train acc 0.7817100268493657\n",
      "epoch 4 batch id 10901 / 225000 loss 1.8121546506881714 train acc 0.7815108705623337\n",
      "epoch 4 batch id 11001 / 225000 loss 1.481021523475647 train acc 0.7815653122443414\n",
      "epoch 4 batch id 11101 / 225000 loss 5.312662124633789 train acc 0.7812809656787677\n",
      "epoch 4 batch id 11201 / 225000 loss 1.3201382160186768 train acc 0.781202571199\n",
      "epoch 4 batch id 11301 / 225000 loss 2.381270170211792 train acc 0.7813025395982657\n",
      "epoch 4 batch id 11401 / 225000 loss 0.00197344901971519 train acc 0.7816200333304096\n",
      "epoch 4 batch id 11501 / 225000 loss 0.002824394963681698 train acc 0.7815624728284497\n",
      "epoch 4 batch id 11601 / 225000 loss 3.4638638496398926 train acc 0.7815705542625636\n",
      "epoch 4 batch id 11701 / 225000 loss 0.002150243381038308 train acc 0.7818348859071874\n",
      "epoch 4 batch id 11801 / 225000 loss 0.0023865371476858854 train acc 0.7816710448267096\n",
      "epoch 4 batch id 11901 / 225000 loss 0.8766544461250305 train acc 0.7816359969750442\n",
      "epoch 4 batch id 12001 / 225000 loss 0.6947792172431946 train acc 0.7816848595950338\n",
      "epoch 4 batch id 12101 / 225000 loss 1.9210327863693237 train acc 0.7816089579373605\n",
      "epoch 4 batch id 12201 / 225000 loss 1.035075068473816 train acc 0.7820055733136628\n",
      "epoch 4 batch id 12301 / 225000 loss 0.0030407803133130074 train acc 0.7820908869197626\n",
      "epoch 4 batch id 12401 / 225000 loss 1.9376623630523682 train acc 0.7821143456172889\n",
      "epoch 4 batch id 12501 / 225000 loss 3.490090847015381 train acc 0.7822374210063195\n",
      "epoch 4 batch id 12601 / 225000 loss 1.9746289253234863 train acc 0.7821601460201572\n",
      "epoch 4 batch id 12701 / 225000 loss 2.168607234954834 train acc 0.782103771356586\n",
      "epoch 4 batch id 12801 / 225000 loss 0.020592186599969864 train acc 0.7822045152722443\n",
      "epoch 4 batch id 12901 / 225000 loss 0.18975141644477844 train acc 0.78240058910162\n",
      "epoch 4 batch id 13001 / 225000 loss 0.4994738698005676 train acc 0.7825167294823475\n",
      "epoch 4 batch id 13101 / 225000 loss 1.2222429513931274 train acc 0.7826120143500496\n",
      "epoch 4 batch id 13201 / 225000 loss 0.0028525437228381634 train acc 0.7825922278615256\n",
      "epoch 4 batch id 13301 / 225000 loss 2.167294979095459 train acc 0.7828358770017292\n",
      "epoch 4 batch id 13401 / 225000 loss 1.542980432510376 train acc 0.7830199238862772\n",
      "epoch 4 batch id 13501 / 225000 loss 0.7630878686904907 train acc 0.7831271757647582\n",
      "epoch 4 batch id 13601 / 225000 loss 1.7597543001174927 train acc 0.7829019925005515\n",
      "epoch 4 batch id 13701 / 225000 loss 0.0009364272700622678 train acc 0.782917305306182\n",
      "epoch 4 batch id 13801 / 225000 loss 0.1612028330564499 train acc 0.7829867400912978\n",
      "epoch 4 batch id 13901 / 225000 loss 0.8064948320388794 train acc 0.782929285662902\n",
      "epoch 4 batch id 14001 / 225000 loss 0.013911246322095394 train acc 0.7827833726162416\n",
      "epoch 4 batch id 14101 / 225000 loss 1.8576823472976685 train acc 0.7827104460676548\n",
      "epoch 4 batch id 14201 / 225000 loss 2.664937973022461 train acc 0.7830082388564186\n",
      "epoch 4 batch id 14301 / 225000 loss 3.1693012714385986 train acc 0.7829872036920495\n",
      "epoch 4 batch id 14401 / 225000 loss 0.00934581272304058 train acc 0.7828449413235192\n",
      "epoch 4 batch id 14501 / 225000 loss 0.006950457580387592 train acc 0.7828770429625543\n",
      "epoch 4 batch id 14601 / 225000 loss 2.403252601623535 train acc 0.7827032395041436\n",
      "epoch 4 batch id 14701 / 225000 loss 3.2356579303741455 train acc 0.7825488062036596\n",
      "epoch 4 batch id 14801 / 225000 loss 0.18223655223846436 train acc 0.7826498209580434\n",
      "epoch 4 batch id 14901 / 225000 loss 0.0032182459253817797 train acc 0.7825145963358164\n",
      "epoch 4 batch id 15001 / 225000 loss 1.3345577716827393 train acc 0.7824311712552496\n",
      "epoch 4 batch id 15101 / 225000 loss 2.0661144256591797 train acc 0.7827296205549301\n",
      "epoch 4 batch id 15201 / 225000 loss 1.9650694131851196 train acc 0.7826294322741925\n",
      "epoch 4 batch id 15301 / 225000 loss 1.4442108869552612 train acc 0.7827592967779884\n",
      "epoch 4 batch id 15401 / 225000 loss 1.3070577383041382 train acc 0.78282254399065\n",
      "epoch 4 batch id 15501 / 225000 loss 1.1843409538269043 train acc 0.7826753112702406\n",
      "epoch 4 batch id 15601 / 225000 loss 2.428210735321045 train acc 0.7827703352349208\n",
      "epoch 4 batch id 15701 / 225000 loss 0.003936002496629953 train acc 0.7828482262276288\n",
      "epoch 4 batch id 15801 / 225000 loss 0.016537904739379883 train acc 0.7828460224036453\n",
      "epoch 4 batch id 15901 / 225000 loss 0.9337080121040344 train acc 0.78300106911515\n",
      "epoch 4 batch id 16001 / 225000 loss 2.6848459243774414 train acc 0.783169801887382\n",
      "epoch 4 batch id 16101 / 225000 loss 2.622532844543457 train acc 0.7830258990124837\n",
      "epoch 4 batch id 16201 / 225000 loss 0.9760069847106934 train acc 0.7832386889698166\n",
      "epoch 4 batch id 16301 / 225000 loss 1.4215247631072998 train acc 0.7833415127906264\n",
      "epoch 4 batch id 16401 / 225000 loss 0.0011069833999499679 train acc 0.7831534662520578\n",
      "epoch 4 batch id 16501 / 225000 loss 2.2303109169006348 train acc 0.7830737531058723\n",
      "epoch 4 batch id 16601 / 225000 loss 0.0024735182523727417 train acc 0.783281127642913\n",
      "epoch 4 batch id 16701 / 225000 loss 0.002709378954023123 train acc 0.7832914196754686\n",
      "epoch 4 batch id 16801 / 225000 loss 1.3711823225021362 train acc 0.7831230283911672\n",
      "epoch 4 batch id 16901 / 225000 loss 0.0037946519441902637 train acc 0.7832376782438909\n",
      "epoch 4 batch id 17001 / 225000 loss 2.652377128601074 train acc 0.7831892241632845\n",
      "epoch 4 batch id 17101 / 225000 loss 0.018221616744995117 train acc 0.7830828606514239\n",
      "epoch 4 batch id 17201 / 225000 loss 2.1343300342559814 train acc 0.7830940061624324\n",
      "epoch 4 batch id 17301 / 225000 loss 0.08672203868627548 train acc 0.7830761227674701\n",
      "epoch 4 batch id 17401 / 225000 loss 1.1703556776046753 train acc 0.7833314177346129\n",
      "epoch 4 batch id 17501 / 225000 loss 0.9064021110534668 train acc 0.7833123821495914\n",
      "epoch 4 batch id 17601 / 225000 loss 0.2401110678911209 train acc 0.7831941366967786\n",
      "epoch 4 batch id 17701 / 225000 loss 0.0012149063404649496 train acc 0.783317326704706\n",
      "epoch 4 batch id 17801 / 225000 loss 0.3736454248428345 train acc 0.7831582495365429\n",
      "epoch 4 batch id 17901 / 225000 loss 0.017393622547388077 train acc 0.7832662979721803\n",
      "epoch 4 batch id 18001 / 225000 loss 0.001748000388033688 train acc 0.7832342647630687\n",
      "epoch 4 batch id 18101 / 225000 loss 3.771078109741211 train acc 0.7833545108005082\n",
      "epoch 4 batch id 18201 / 225000 loss 0.0318545363843441 train acc 0.7832674028899511\n",
      "epoch 4 batch id 18301 / 225000 loss 0.7485910058021545 train acc 0.7832358887492487\n",
      "epoch 4 batch id 18401 / 225000 loss 0.0018982277251780033 train acc 0.7831231998260965\n",
      "epoch 4 batch id 18501 / 225000 loss 0.41652536392211914 train acc 0.7832819847575807\n",
      "epoch 4 batch id 18601 / 225000 loss 0.0015031981747597456 train acc 0.7833449814526101\n",
      "epoch 4 batch id 18701 / 225000 loss 0.006279677618294954 train acc 0.7833939361531469\n",
      "epoch 4 batch id 18801 / 225000 loss 0.0019243520218878984 train acc 0.7832296154459869\n",
      "epoch 4 batch id 18901 / 225000 loss 0.003510418813675642 train acc 0.7830802603036876\n",
      "epoch 4 batch id 19001 / 225000 loss 1.3658719062805176 train acc 0.7832482500921004\n",
      "epoch 4 batch id 19101 / 225000 loss 4.296643257141113 train acc 0.7832443327574472\n",
      "epoch 4 batch id 19201 / 225000 loss 0.006019150838255882 train acc 0.7832795166918389\n",
      "epoch 4 batch id 19301 / 225000 loss 0.1490713208913803 train acc 0.7833661468317704\n",
      "epoch 4 batch id 19401 / 225000 loss 0.009788693860173225 train acc 0.7834518839235091\n",
      "epoch 4 batch id 19501 / 225000 loss 0.7831929922103882 train acc 0.7834341828624173\n",
      "epoch 4 batch id 19601 / 225000 loss 0.003968951292335987 train acc 0.783595224733432\n",
      "epoch 4 batch id 19701 / 225000 loss 1.5624828338623047 train acc 0.783500837520938\n",
      "epoch 4 batch id 19801 / 225000 loss 0.9442956447601318 train acc 0.7836346649159134\n",
      "epoch 4 batch id 19901 / 225000 loss 2.175077438354492 train acc 0.7835912768202603\n",
      "epoch 4 batch id 20001 / 225000 loss 1.21565842628479 train acc 0.7834983250837458\n",
      "epoch 4 batch id 20101 / 225000 loss 0.0029796164017170668 train acc 0.7835804188846326\n",
      "epoch 4 batch id 20201 / 225000 loss 0.0066232020035386086 train acc 0.7834884411662789\n",
      "epoch 4 batch id 20301 / 225000 loss 0.0015834979712963104 train acc 0.783692921530959\n",
      "epoch 4 batch id 20401 / 225000 loss 1.4487473964691162 train acc 0.7837360913680702\n",
      "epoch 4 batch id 20501 / 225000 loss 2.5508861541748047 train acc 0.7836812838398127\n",
      "epoch 4 batch id 20601 / 225000 loss 0.9442324042320251 train acc 0.7837240910635406\n",
      "epoch 4 batch id 20701 / 225000 loss 1.0029476881027222 train acc 0.7836940244432636\n",
      "epoch 4 batch id 20801 / 225000 loss 1.0707937479019165 train acc 0.7837003028700543\n",
      "epoch 4 batch id 20901 / 225000 loss 1.1499748229980469 train acc 0.7838141715707383\n",
      "epoch 4 batch id 21001 / 225000 loss 0.0019334915559738874 train acc 0.7836888719584781\n",
      "epoch 4 batch id 21101 / 225000 loss 0.853356659412384 train acc 0.7837187811004218\n",
      "epoch 4 batch id 21201 / 225000 loss 0.6204667687416077 train acc 0.7837248243007405\n",
      "epoch 4 batch id 21301 / 225000 loss 2.111912727355957 train acc 0.7838716492183465\n",
      "epoch 4 batch id 21401 / 225000 loss 0.021422386169433594 train acc 0.7839119667305267\n",
      "epoch 4 batch id 21501 / 225000 loss 0.009449606761336327 train acc 0.7838588902841729\n",
      "epoch 4 batch id 21601 / 225000 loss 4.317543983459473 train acc 0.7839451877227906\n",
      "epoch 4 batch id 21701 / 225000 loss 1.105790615081787 train acc 0.7840882908621722\n",
      "epoch 4 batch id 21801 / 225000 loss 0.012988622300326824 train acc 0.7839777991835237\n",
      "epoch 4 batch id 21901 / 225000 loss 0.6727685928344727 train acc 0.7840737865850874\n",
      "epoch 4 batch id 22001 / 225000 loss 2.8200411796569824 train acc 0.7843166219717286\n",
      "epoch 4 batch id 22101 / 225000 loss 0.005361876916140318 train acc 0.7842065969865617\n",
      "epoch 4 batch id 22201 / 225000 loss 0.06887774914503098 train acc 0.7842777352371515\n",
      "epoch 4 batch id 22301 / 225000 loss 1.5302544832229614 train acc 0.7842249226492085\n",
      "epoch 4 batch id 22401 / 225000 loss 1.9756332635879517 train acc 0.7842507030936119\n",
      "epoch 4 batch id 22501 / 225000 loss 0.11516599357128143 train acc 0.7843318074752234\n",
      "epoch 4 batch id 22601 / 225000 loss 1.569882869720459 train acc 0.7844564399805318\n",
      "epoch 4 batch id 22701 / 225000 loss 0.42749568819999695 train acc 0.7844257962204308\n",
      "epoch 4 batch id 22801 / 225000 loss 0.809596061706543 train acc 0.7844392789789921\n",
      "epoch 4 batch id 22901 / 225000 loss 0.7248356938362122 train acc 0.7843325618968604\n",
      "epoch 4 batch id 23001 / 225000 loss 1.005879521369934 train acc 0.7844006782313813\n",
      "epoch 4 batch id 23101 / 225000 loss 1.0499303340911865 train acc 0.7844140946279382\n",
      "epoch 4 batch id 23201 / 225000 loss 2.9008712768554688 train acc 0.7843842937804405\n",
      "epoch 4 batch id 23301 / 225000 loss 0.6175975799560547 train acc 0.7842796446504442\n",
      "epoch 4 batch id 23401 / 225000 loss 0.18613842129707336 train acc 0.7841865732233665\n",
      "epoch 4 batch id 23501 / 225000 loss 0.002906770445406437 train acc 0.7840411046338454\n",
      "epoch 4 batch id 23601 / 225000 loss 4.105133533477783 train acc 0.7839286470912249\n",
      "epoch 4 batch id 23701 / 225000 loss 1.1550753116607666 train acc 0.7839120712206236\n",
      "epoch 4 batch id 23801 / 225000 loss 1.5322377681732178 train acc 0.7839796647199697\n",
      "epoch 4 batch id 23901 / 225000 loss 0.003490244038403034 train acc 0.7839420944730346\n",
      "epoch 4 batch id 24001 / 225000 loss 1.121688961982727 train acc 0.7838110912045332\n",
      "epoch 4 batch id 24101 / 225000 loss 0.643389105796814 train acc 0.7836396830007054\n",
      "epoch 4 batch id 24201 / 225000 loss 0.6800816655158997 train acc 0.7836762943680013\n",
      "epoch 4 batch id 24301 / 225000 loss 1.8828476667404175 train acc 0.783661166207152\n",
      "epoch 4 batch id 24401 / 225000 loss 0.6681602001190186 train acc 0.7836871439695094\n",
      "epoch 4 batch id 24501 / 225000 loss 1.9103329181671143 train acc 0.7835496510346517\n",
      "epoch 4 batch id 24601 / 225000 loss 1.8370593786239624 train acc 0.7833726271289785\n",
      "epoch 4 batch id 24701 / 225000 loss 0.0025093904696404934 train acc 0.7834196996073034\n",
      "epoch 4 batch id 24801 / 225000 loss 0.00219100434333086 train acc 0.7834361517680739\n",
      "epoch 4 batch id 24901 / 225000 loss 2.12520170211792 train acc 0.7835227500903578\n",
      "epoch 4 batch id 25001 / 225000 loss 2.0490784645080566 train acc 0.7836986520539179\n",
      "epoch 4 batch id 25101 / 225000 loss 0.0019971311558037996 train acc 0.783634118162623\n",
      "epoch 4 batch id 25201 / 225000 loss 0.031104369089007378 train acc 0.7835502559422245\n",
      "epoch 4 batch id 25301 / 225000 loss 0.006480414420366287 train acc 0.7834670566380776\n",
      "epoch 4 batch id 25401 / 225000 loss 2.8871867656707764 train acc 0.7835813550647612\n",
      "epoch 4 batch id 25501 / 225000 loss 1.3989659547805786 train acc 0.7837535782910474\n",
      "epoch 4 batch id 25601 / 225000 loss 2.5011332035064697 train acc 0.7838853951017538\n",
      "epoch 4 batch id 25701 / 225000 loss 0.003760403022170067 train acc 0.783860550173145\n",
      "epoch 4 batch id 25801 / 225000 loss 0.003484252607449889 train acc 0.7838843455680012\n",
      "epoch 4 batch id 25901 / 225000 loss 0.0027591849211603403 train acc 0.7838500443998301\n",
      "epoch 4 batch id 26001 / 225000 loss 0.005076928995549679 train acc 0.783825622091458\n",
      "epoch 4 batch id 26101 / 225000 loss 2.732119083404541 train acc 0.783705605149228\n",
      "epoch 4 batch id 26201 / 225000 loss 0.91152024269104 train acc 0.7837487118812259\n",
      "epoch 4 batch id 26301 / 225000 loss 0.014877969399094582 train acc 0.783762974791833\n",
      "epoch 4 batch id 26401 / 225000 loss 0.031716641038656235 train acc 0.7837676603158972\n",
      "epoch 4 batch id 26501 / 225000 loss 4.061262130737305 train acc 0.7836591072035017\n",
      "epoch 4 batch id 26601 / 225000 loss 0.47849658131599426 train acc 0.7836735461072892\n",
      "epoch 4 batch id 26701 / 225000 loss 0.003028260311111808 train acc 0.7837253286393768\n",
      "epoch 4 batch id 26801 / 225000 loss 0.0016404340276494622 train acc 0.7836554606171412\n",
      "epoch 4 batch id 26901 / 225000 loss 0.0010908611584454775 train acc 0.783632578714546\n",
      "epoch 4 batch id 27001 / 225000 loss 1.6433110237121582 train acc 0.7834709825562016\n",
      "epoch 4 batch id 27101 / 225000 loss 1.7882606983184814 train acc 0.783448950223239\n",
      "epoch 4 batch id 27201 / 225000 loss 0.010941388085484505 train acc 0.7835833241424948\n",
      "epoch 4 batch id 27301 / 225000 loss 0.014272808097302914 train acc 0.7837441851946815\n",
      "epoch 4 batch id 27401 / 225000 loss 1.0100809335708618 train acc 0.7837578920477355\n",
      "epoch 4 batch id 27501 / 225000 loss 2.5736520290374756 train acc 0.7838169521108324\n",
      "epoch 4 batch id 27601 / 225000 loss 1.6947956085205078 train acc 0.783848411289446\n",
      "epoch 4 batch id 27701 / 225000 loss 1.0063673257827759 train acc 0.7839428179488105\n",
      "epoch 4 batch id 27801 / 225000 loss 2.719005823135376 train acc 0.7839915830365815\n",
      "epoch 4 batch id 27901 / 225000 loss 0.5639697909355164 train acc 0.783968316547794\n",
      "epoch 4 batch id 28001 / 225000 loss 3.077481269836426 train acc 0.7839095032320275\n",
      "epoch 4 batch id 28101 / 225000 loss 0.9809950590133667 train acc 0.7837710401765062\n",
      "epoch 4 batch id 28201 / 225000 loss 0.11266778409481049 train acc 0.7838019928371335\n",
      "epoch 4 batch id 28301 / 225000 loss 3.984841823577881 train acc 0.7837885587081729\n",
      "epoch 4 batch id 28401 / 225000 loss 0.007416971027851105 train acc 0.7837664166754692\n",
      "epoch 4 batch id 28501 / 225000 loss 0.8927329778671265 train acc 0.7836654854215641\n",
      "epoch 4 batch id 28601 / 225000 loss 0.05795377120375633 train acc 0.7836177056746267\n",
      "epoch 4 batch id 28701 / 225000 loss 0.5024374723434448 train acc 0.7836834953485942\n",
      "epoch 4 batch id 28801 / 225000 loss 1.6992772817611694 train acc 0.7836359848616368\n",
      "epoch 4 batch id 28901 / 225000 loss 0.9724708795547485 train acc 0.7838137088682052\n",
      "epoch 4 batch id 29001 / 225000 loss 0.0019226992735639215 train acc 0.7840160684114341\n",
      "epoch 4 batch id 29101 / 225000 loss 0.6664338707923889 train acc 0.7840022679633002\n",
      "epoch 4 batch id 29201 / 225000 loss 1.887882947921753 train acc 0.7839628779836307\n",
      "epoch 4 batch id 29301 / 225000 loss 0.00477997213602066 train acc 0.783906692604348\n",
      "epoch 4 batch id 29401 / 225000 loss 0.019345764070749283 train acc 0.7839104112105031\n",
      "epoch 4 batch id 29501 / 225000 loss 2.841853618621826 train acc 0.7839734246296736\n",
      "epoch 4 batch id 29601 / 225000 loss 2.5466620922088623 train acc 0.7839937839937839\n",
      "epoch 4 batch id 29701 / 225000 loss 1.1604814529418945 train acc 0.784064509612471\n",
      "epoch 4 batch id 29801 / 225000 loss 0.006154102273285389 train acc 0.784000536894735\n",
      "epoch 4 batch id 29901 / 225000 loss 0.007180350832641125 train acc 0.7839955185445303\n",
      "epoch 4 batch id 30001 / 225000 loss 2.1914472579956055 train acc 0.7839405353154895\n",
      "epoch 4 batch id 30101 / 225000 loss 0.1753949224948883 train acc 0.7839523603866981\n",
      "epoch 4 batch id 30201 / 225000 loss 1.5912458896636963 train acc 0.7839972186351445\n",
      "epoch 4 batch id 30301 / 225000 loss 0.000663071870803833 train acc 0.7838107653212765\n",
      "epoch 4 batch id 30401 / 225000 loss 1.4876914024353027 train acc 0.783896911285813\n",
      "epoch 4 batch id 30501 / 225000 loss 3.2274563312530518 train acc 0.7837939739680666\n",
      "epoch 4 batch id 30601 / 225000 loss 1.7942478656768799 train acc 0.783765236430182\n",
      "epoch 4 batch id 30701 / 225000 loss 1.0665589570999146 train acc 0.7838262597309534\n",
      "epoch 4 batch id 30801 / 225000 loss 0.5939083099365234 train acc 0.7838381870718483\n",
      "epoch 4 batch id 30901 / 225000 loss 0.3698400557041168 train acc 0.7838500372156241\n",
      "epoch 4 batch id 31001 / 225000 loss 1.2359671592712402 train acc 0.7839263249572594\n",
      "epoch 4 batch id 31101 / 225000 loss 0.18293847143650055 train acc 0.7839378155043246\n",
      "epoch 4 batch id 31201 / 225000 loss 0.9489102363586426 train acc 0.7839492323963976\n",
      "epoch 4 batch id 31301 / 225000 loss 0.004857300315052271 train acc 0.783864732756142\n",
      "epoch 4 batch id 31401 / 225000 loss 2.8017332553863525 train acc 0.7838205789624534\n",
      "epoch 4 batch id 31501 / 225000 loss 1.7044768333435059 train acc 0.7838719405733151\n",
      "epoch 4 batch id 31601 / 225000 loss 0.024919427931308746 train acc 0.7838834214107149\n",
      "epoch 4 batch id 31701 / 225000 loss 1.4141100645065308 train acc 0.7837607646446484\n",
      "epoch 4 batch id 31801 / 225000 loss 0.34872308373451233 train acc 0.7838747209207257\n",
      "epoch 4 batch id 31901 / 225000 loss 2.285397529602051 train acc 0.7838547380959845\n",
      "epoch 4 batch id 32001 / 225000 loss 1.3548320531845093 train acc 0.7837567576013249\n",
      "epoch 4 batch id 32101 / 225000 loss 2.6431095600128174 train acc 0.7837372667518145\n",
      "epoch 4 batch id 32201 / 225000 loss 0.14932575821876526 train acc 0.7836557870873575\n",
      "epoch 4 batch id 32301 / 225000 loss 1.511462926864624 train acc 0.7836754280053249\n",
      "epoch 4 batch id 32401 / 225000 loss 0.08617130666971207 train acc 0.7837026634980402\n",
      "epoch 4 batch id 32501 / 225000 loss 0.07016539573669434 train acc 0.7837758838189595\n",
      "epoch 4 batch id 32601 / 225000 loss 0.007796064950525761 train acc 0.7837949756142449\n",
      "epoch 4 batch id 32701 / 225000 loss 0.00234871543943882 train acc 0.7838521757744411\n",
      "epoch 4 batch id 32801 / 225000 loss 0.018828775733709335 train acc 0.7837337276302552\n",
      "epoch 4 batch id 32901 / 225000 loss 0.01254023052752018 train acc 0.7836767879395763\n",
      "epoch 4 batch id 33001 / 225000 loss 1.478774070739746 train acc 0.7837186751916608\n",
      "epoch 4 batch id 33101 / 225000 loss 2.6156668663024902 train acc 0.7836923355789855\n",
      "epoch 4 batch id 33201 / 225000 loss 0.06303869932889938 train acc 0.7837188638896418\n",
      "epoch 4 batch id 33301 / 225000 loss 0.00544312410056591 train acc 0.783812798414462\n",
      "epoch 4 batch id 33401 / 225000 loss 1.065753698348999 train acc 0.7837714439687434\n",
      "epoch 4 batch id 33501 / 225000 loss 0.6254026889801025 train acc 0.783812423509746\n",
      "epoch 4 batch id 33601 / 225000 loss 1.2516050338745117 train acc 0.7839201214249576\n",
      "epoch 4 batch id 33701 / 225000 loss 0.7968937754631042 train acc 0.783982671137355\n",
      "epoch 4 batch id 33801 / 225000 loss 2.246572494506836 train acc 0.7839782846661342\n",
      "epoch 4 batch id 33901 / 225000 loss 0.04827137291431427 train acc 0.7839075543494293\n",
      "epoch 4 batch id 34001 / 225000 loss 0.8119485974311829 train acc 0.7839107673303727\n",
      "epoch 4 batch id 34101 / 225000 loss 3.1341450214385986 train acc 0.7838773056508607\n",
      "epoch 4 batch id 34201 / 225000 loss 1.744631290435791 train acc 0.783719774275606\n",
      "epoch 4 batch id 34301 / 225000 loss 2.1316425800323486 train acc 0.7837599486895426\n",
      "epoch 4 batch id 34401 / 225000 loss 0.013235555961728096 train acc 0.783792622307491\n",
      "epoch 4 batch id 34501 / 225000 loss 0.8388010859489441 train acc 0.7837381525173184\n",
      "epoch 4 batch id 34601 / 225000 loss 1.6502918004989624 train acc 0.7837634750440738\n",
      "epoch 4 batch id 34701 / 225000 loss 0.006382754538208246 train acc 0.7837526296072159\n",
      "epoch 4 batch id 34801 / 225000 loss 1.3890156745910645 train acc 0.7837274790954283\n",
      "epoch 4 batch id 34901 / 225000 loss 0.0460406169295311 train acc 0.7837955932494771\n",
      "epoch 4 batch id 35001 / 225000 loss 0.005103739444166422 train acc 0.7838347475786406\n",
      "epoch 4 batch id 35101 / 225000 loss 0.05351180583238602 train acc 0.7838879234209851\n",
      "epoch 4 batch id 35201 / 225000 loss 0.5092042088508606 train acc 0.7840118178460839\n",
      "epoch 4 batch id 35301 / 225000 loss 0.0019718005787581205 train acc 0.7841137644825925\n",
      "epoch 4 batch id 35401 / 225000 loss 0.9554675221443176 train acc 0.7841233298494393\n",
      "epoch 4 batch id 35501 / 225000 loss 0.0873522162437439 train acc 0.7841962198247937\n",
      "epoch 4 batch id 35601 / 225000 loss 2.0133893489837646 train acc 0.7841914552961995\n",
      "epoch 4 batch id 35701 / 225000 loss 3.4556021690368652 train acc 0.7841657096439876\n",
      "epoch 4 batch id 35801 / 225000 loss 1.517587423324585 train acc 0.7841540739085501\n",
      "epoch 4 batch id 35901 / 225000 loss 0.009000888094305992 train acc 0.7841494665886745\n",
      "epoch 4 batch id 36001 / 225000 loss 2.3426616191864014 train acc 0.7841101636065665\n",
      "epoch 4 batch id 36101 / 225000 loss 1.372743844985962 train acc 0.7840780033794078\n",
      "epoch 4 batch id 36201 / 225000 loss 2.619243860244751 train acc 0.7840391149415762\n",
      "epoch 4 batch id 36301 / 225000 loss 0.0003332120832055807 train acc 0.7840417619349329\n",
      "epoch 4 batch id 36401 / 225000 loss 0.4988612234592438 train acc 0.7840031867256394\n",
      "epoch 4 batch id 36501 / 225000 loss 0.9865208268165588 train acc 0.7840675597928823\n",
      "epoch 4 batch id 36601 / 225000 loss 0.63027423620224 train acc 0.7840359553017677\n",
      "epoch 4 batch id 36701 / 225000 loss 1.3244401216506958 train acc 0.7840726410724503\n",
      "epoch 4 batch id 36801 / 225000 loss 0.223478764295578 train acc 0.7840547811200782\n",
      "epoch 4 batch id 36901 / 225000 loss 0.10199357569217682 train acc 0.7840505677352917\n",
      "epoch 4 batch id 37001 / 225000 loss 0.0019494825974106789 train acc 0.7842017783303153\n",
      "epoch 4 batch id 37101 / 225000 loss 0.43613478541374207 train acc 0.784156761273281\n",
      "epoch 4 batch id 37201 / 225000 loss 0.8007282018661499 train acc 0.7841254267358404\n",
      "epoch 4 batch id 37301 / 225000 loss 1.0812638998031616 train acc 0.7840607490415806\n",
      "epoch 4 batch id 37401 / 225000 loss 0.9799258708953857 train acc 0.7840498917141253\n",
      "epoch 4 batch id 37501 / 225000 loss 0.35606518387794495 train acc 0.7840457587797659\n",
      "epoch 4 batch id 37601 / 225000 loss 0.0011596117401495576 train acc 0.7840416478285152\n",
      "epoch 4 batch id 37701 / 225000 loss 0.020732495933771133 train acc 0.784037558685446\n",
      "epoch 4 batch id 37801 / 225000 loss 2.9149646759033203 train acc 0.7840004232692257\n",
      "epoch 4 batch id 37901 / 225000 loss 0.3012675642967224 train acc 0.783963483813092\n",
      "epoch 4 batch id 38001 / 225000 loss 0.12737126648426056 train acc 0.7839530538670035\n",
      "epoch 4 batch id 38101 / 225000 loss 1.66318941116333 train acc 0.7839492401774232\n",
      "epoch 4 batch id 38201 / 225000 loss 2.2505016326904297 train acc 0.7839716237794823\n",
      "epoch 4 batch id 38301 / 225000 loss 1.6892104148864746 train acc 0.7839873632542231\n",
      "epoch 4 batch id 38401 / 225000 loss 0.0051634409464895725 train acc 0.7840225514960548\n",
      "epoch 4 batch id 38501 / 225000 loss 1.069486379623413 train acc 0.7840250902573959\n",
      "epoch 4 batch id 38601 / 225000 loss 0.017911292612552643 train acc 0.7840859045102458\n",
      "epoch 4 batch id 38701 / 225000 loss 0.517159104347229 train acc 0.7839849099506473\n",
      "epoch 4 batch id 38801 / 225000 loss 0.9431506395339966 train acc 0.7839488672972346\n",
      "epoch 4 batch id 38901 / 225000 loss 0.28272831439971924 train acc 0.7839837022184519\n",
      "epoch 4 batch id 39001 / 225000 loss 0.0020782281644642353 train acc 0.7839798979513346\n",
      "epoch 4 batch id 39101 / 225000 loss 0.9725261330604553 train acc 0.7839697194445154\n",
      "epoch 4 batch id 39201 / 225000 loss 0.8449474573135376 train acc 0.784042498915844\n",
      "epoch 4 batch id 39301 / 225000 loss 1.9844757318496704 train acc 0.784044935243378\n",
      "epoch 4 batch id 39401 / 225000 loss 1.5603543519973755 train acc 0.7841679145199361\n",
      "epoch 4 batch id 39501 / 225000 loss 0.018114358186721802 train acc 0.7842143236880079\n",
      "epoch 4 batch id 39601 / 225000 loss 1.122862458229065 train acc 0.7841973687533144\n",
      "epoch 4 batch id 39701 / 225000 loss 1.8077378273010254 train acc 0.7842182816553739\n",
      "epoch 4 batch id 39801 / 225000 loss 1.996652364730835 train acc 0.7842830582146177\n",
      "epoch 4 batch id 39901 / 225000 loss 1.6464958190917969 train acc 0.784284855016165\n",
      "epoch 4 batch id 40001 / 225000 loss 2.767307758331299 train acc 0.7843053923651909\n",
      "epoch 4 batch id 40101 / 225000 loss 1.8758877515792847 train acc 0.7842447819256377\n",
      "epoch 4 batch id 40201 / 225000 loss 0.7236559987068176 train acc 0.7842031292753912\n",
      "epoch 4 batch id 40301 / 225000 loss 3.5942740440368652 train acc 0.7841802932929703\n",
      "epoch 4 batch id 40401 / 225000 loss 3.010251760482788 train acc 0.7841451944258806\n",
      "epoch 4 batch id 40501 / 225000 loss 1.7284884452819824 train acc 0.7841287869435323\n",
      "epoch 4 batch id 40601 / 225000 loss 1.2143259048461914 train acc 0.7840755153813945\n",
      "epoch 4 batch id 40701 / 225000 loss 0.8392992615699768 train acc 0.7840286479447679\n",
      "epoch 4 batch id 40801 / 225000 loss 1.4587185382843018 train acc 0.7838962280336266\n",
      "epoch 4 batch id 40901 / 225000 loss 1.7843453884124756 train acc 0.7838622527566563\n",
      "epoch 4 batch id 41001 / 225000 loss 2.8669722080230713 train acc 0.7838345406209605\n",
      "epoch 4 batch id 41101 / 225000 loss 2.9050614833831787 train acc 0.7838069633342254\n",
      "epoch 4 batch id 41201 / 225000 loss 1.1223289966583252 train acc 0.7839190796339894\n",
      "epoch 4 batch id 41301 / 225000 loss 3.274374008178711 train acc 0.784030653010823\n",
      "epoch 4 batch id 41401 / 225000 loss 0.008615032769739628 train acc 0.7840390328736021\n",
      "epoch 4 batch id 41501 / 225000 loss 0.001860744203440845 train acc 0.7840774921086239\n",
      "epoch 4 batch id 41601 / 225000 loss 0.0018774685449898243 train acc 0.7840015865003245\n",
      "epoch 4 batch id 41701 / 225000 loss 0.009921303950250149 train acc 0.7839500251792523\n",
      "epoch 4 batch id 41801 / 225000 loss 0.0072228447534143925 train acc 0.7840362670749503\n",
      "epoch 4 batch id 41901 / 225000 loss 0.004568497650325298 train acc 0.7840206677644925\n",
      "epoch 4 batch id 42001 / 225000 loss 0.8499099016189575 train acc 0.7839694292993024\n",
      "epoch 4 batch id 42101 / 225000 loss 2.4769322872161865 train acc 0.7839956295574927\n",
      "epoch 4 batch id 42201 / 225000 loss 3.0151448249816895 train acc 0.7839387692234782\n",
      "epoch 4 batch id 42301 / 225000 loss 2.3294217586517334 train acc 0.7839235479066688\n",
      "epoch 4 batch id 42401 / 225000 loss 0.008982772938907146 train acc 0.7838376453385534\n",
      "epoch 4 batch id 42501 / 225000 loss 0.001120419823564589 train acc 0.7838874379426366\n",
      "epoch 4 batch id 42601 / 225000 loss 0.008508258499205112 train acc 0.7839017863430436\n",
      "epoch 4 batch id 42701 / 225000 loss 4.16361141204834 train acc 0.7839336315308775\n",
      "epoch 4 batch id 42801 / 225000 loss 0.0024959323927760124 train acc 0.7839945328380178\n",
      "epoch 4 batch id 42901 / 225000 loss 1.6819206476211548 train acc 0.7839910491596932\n",
      "epoch 4 batch id 43001 / 225000 loss 0.005499320104718208 train acc 0.7840340922304132\n",
      "epoch 4 batch id 43101 / 225000 loss 1.0083656311035156 train acc 0.784163940511821\n",
      "epoch 4 batch id 43201 / 225000 loss 0.01933080330491066 train acc 0.7841716626929932\n",
      "epoch 4 batch id 43301 / 225000 loss 3.2729742527008057 train acc 0.7840927461259555\n",
      "epoch 4 batch id 43401 / 225000 loss 0.0046419925056397915 train acc 0.784071795580747\n",
      "epoch 4 batch id 43501 / 225000 loss 0.13318507373332977 train acc 0.7840164593917381\n",
      "epoch 4 batch id 43601 / 225000 loss 0.6515750288963318 train acc 0.7840932547418638\n",
      "epoch 4 batch id 43701 / 225000 loss 0.6641486883163452 train acc 0.784089608933434\n",
      "epoch 4 batch id 43801 / 225000 loss 2.7903330326080322 train acc 0.7840060729207096\n",
      "epoch 4 batch id 43901 / 225000 loss 2.5218987464904785 train acc 0.7840026423088312\n",
      "epoch 4 batch id 44001 / 225000 loss 0.003797928337007761 train acc 0.7840446808027091\n",
      "epoch 4 batch id 44101 / 225000 loss 0.32573944330215454 train acc 0.7840071653703997\n",
      "epoch 4 batch id 44201 / 225000 loss 0.0006172035355120897 train acc 0.7840094115517748\n",
      "epoch 4 batch id 44301 / 225000 loss 0.00973671767860651 train acc 0.7840342204464911\n",
      "epoch 4 batch id 44401 / 225000 loss 4.756866455078125 train acc 0.7840026125537713\n",
      "epoch 4 batch id 44501 / 225000 loss 2.977832794189453 train acc 0.7840104716747939\n",
      "epoch 4 batch id 44601 / 225000 loss 2.682046890258789 train acc 0.7839958745319612\n",
      "epoch 4 batch id 44701 / 225000 loss 1.4088990688323975 train acc 0.7840093062795016\n",
      "epoch 4 batch id 44801 / 225000 loss 1.5613312721252441 train acc 0.7840226780652217\n",
      "epoch 4 batch id 44901 / 225000 loss 1.0090370178222656 train acc 0.7840526937039264\n",
      "epoch 4 batch id 45001 / 225000 loss 0.007210761308670044 train acc 0.7841159085353658\n",
      "epoch 4 batch id 45101 / 225000 loss 0.001231655478477478 train acc 0.7842121017272344\n",
      "epoch 4 batch id 45201 / 225000 loss 0.0012581262271851301 train acc 0.7842083139753545\n",
      "epoch 4 batch id 45301 / 225000 loss 0.3030136525630951 train acc 0.7841879870201541\n",
      "epoch 4 batch id 45401 / 225000 loss 0.8048084378242493 train acc 0.7841952820422458\n",
      "epoch 4 batch id 45501 / 225000 loss 0.003010412212461233 train acc 0.7841970506142723\n",
      "epoch 4 batch id 45601 / 225000 loss 2.82905912399292 train acc 0.7841165763908686\n",
      "epoch 4 batch id 45701 / 225000 loss 2.7975950241088867 train acc 0.7840583357038139\n",
      "epoch 4 batch id 45801 / 225000 loss 2.5899152755737305 train acc 0.7840058077334556\n",
      "epoch 4 batch id 45901 / 225000 loss 1.098914384841919 train acc 0.7840569922223917\n",
      "epoch 4 batch id 46001 / 225000 loss 1.679064393043518 train acc 0.7840807808525901\n",
      "epoch 4 batch id 46101 / 225000 loss 1.804044246673584 train acc 0.7840556603978222\n",
      "epoch 4 batch id 46201 / 225000 loss 0.005861727986484766 train acc 0.784149693729573\n",
      "epoch 4 batch id 46301 / 225000 loss 0.6499253511428833 train acc 0.7841839269130256\n",
      "epoch 4 batch id 46401 / 225000 loss 1.3339781761169434 train acc 0.784121031874313\n",
      "epoch 4 batch id 46501 / 225000 loss 0.0021959631703794003 train acc 0.7841444270015698\n",
      "epoch 4 batch id 46601 / 225000 loss 2.071957588195801 train acc 0.7841838157979443\n",
      "epoch 4 batch id 46701 / 225000 loss 0.9786561131477356 train acc 0.7840999122074473\n",
      "epoch 4 batch id 46801 / 225000 loss 0.32452309131622314 train acc 0.7840911518984637\n",
      "epoch 4 batch id 46901 / 225000 loss 1.4201068878173828 train acc 0.7840451163088207\n",
      "epoch 4 batch id 47001 / 225000 loss 1.717969536781311 train acc 0.7840684240760835\n",
      "epoch 4 batch id 47101 / 225000 loss 5.935232162475586 train acc 0.7840438631876181\n",
      "epoch 4 batch id 47201 / 225000 loss 0.006401194725185633 train acc 0.7840882608419313\n",
      "epoch 4 batch id 47301 / 225000 loss 0.43672052025794983 train acc 0.7841906090780322\n",
      "epoch 4 batch id 47401 / 225000 loss 1.8247102499008179 train acc 0.7841343009641146\n",
      "epoch 4 batch id 47501 / 225000 loss 0.02066796086728573 train acc 0.7841887539209701\n",
      "epoch 4 batch id 47601 / 225000 loss 0.07859418541193008 train acc 0.7842114661456692\n",
      "epoch 4 batch id 47701 / 225000 loss 0.04929161071777344 train acc 0.7841711913796356\n",
      "epoch 4 batch id 47801 / 225000 loss 0.0024070858489722013 train acc 0.784152005188176\n",
      "epoch 4 batch id 47901 / 225000 loss 1.1449369192123413 train acc 0.7841433372998476\n",
      "epoch 4 batch id 48001 / 225000 loss 0.9448735117912292 train acc 0.7841763713255974\n",
      "epoch 4 batch id 48101 / 225000 loss 0.0011681633768603206 train acc 0.7840793330699986\n",
      "epoch 4 batch id 48201 / 225000 loss 1.3040711879730225 train acc 0.7841227360428207\n",
      "epoch 4 batch id 48301 / 225000 loss 2.0631303787231445 train acc 0.7840779694002195\n",
      "epoch 4 batch id 48401 / 225000 loss 0.0076160551980137825 train acc 0.7840592136526104\n",
      "epoch 4 batch id 48501 / 225000 loss 0.002921373350545764 train acc 0.7840456897795922\n",
      "epoch 4 batch id 48601 / 225000 loss 3.696857213973999 train acc 0.7841299561737413\n",
      "epoch 4 batch id 48701 / 225000 loss 1.055614948272705 train acc 0.7841420094043243\n",
      "epoch 4 batch id 48801 / 225000 loss 2.75321888923645 train acc 0.784143767545747\n",
      "epoch 4 batch id 48901 / 225000 loss 0.018670829012989998 train acc 0.7841608556062248\n",
      "epoch 4 batch id 49001 / 225000 loss 0.002333332784473896 train acc 0.7841268545539887\n",
      "epoch 4 batch id 49101 / 225000 loss 1.7229806184768677 train acc 0.7841744567320421\n",
      "epoch 4 batch id 49201 / 225000 loss 1.2584478855133057 train acc 0.7841253226560436\n",
      "epoch 4 batch id 49301 / 225000 loss 0.03974912315607071 train acc 0.7841778057240218\n",
      "epoch 4 batch id 49401 / 225000 loss 1.5882651805877686 train acc 0.7841946519301228\n",
      "epoch 4 batch id 49501 / 225000 loss 2.8807315826416016 train acc 0.7841760772509646\n",
      "epoch 4 batch id 49601 / 225000 loss 0.9461628794670105 train acc 0.7842029394568658\n",
      "epoch 4 batch id 49701 / 225000 loss 2.4962806701660156 train acc 0.7842347236474115\n",
      "epoch 4 batch id 49801 / 225000 loss 0.0024182633496820927 train acc 0.7842412802955764\n",
      "epoch 4 batch id 49901 / 225000 loss 1.493628978729248 train acc 0.7841626420312218\n",
      "epoch 4 batch id 50001 / 225000 loss 0.6527346968650818 train acc 0.7841693166136677\n",
      "epoch 4 batch id 50101 / 225000 loss 0.003895870642736554 train acc 0.7841659847108841\n",
      "epoch 4 batch id 50201 / 225000 loss 1.294899582862854 train acc 0.7841377661799566\n",
      "epoch 4 batch id 50301 / 225000 loss 1.1300511360168457 train acc 0.7841345102483052\n",
      "epoch 4 batch id 50401 / 225000 loss 0.8995642066001892 train acc 0.7841064661415448\n",
      "epoch 4 batch id 50501 / 225000 loss 1.9687646627426147 train acc 0.7840884338923981\n",
      "epoch 4 batch id 50601 / 225000 loss 1.8418524265289307 train acc 0.7841248196675955\n",
      "epoch 4 batch id 50701 / 225000 loss 0.6922448873519897 train acc 0.7841659927812075\n",
      "epoch 4 batch id 50801 / 225000 loss 0.005571925081312656 train acc 0.7841577921694455\n",
      "epoch 4 batch id 50901 / 225000 loss 0.18444083631038666 train acc 0.7841987387281193\n",
      "epoch 4 batch id 51001 / 225000 loss 0.005929672624915838 train acc 0.7842689359032176\n",
      "epoch 4 batch id 51101 / 225000 loss 0.0015542396577075124 train acc 0.7842654742568639\n",
      "epoch 4 batch id 51201 / 225000 loss 3.7075998783111572 train acc 0.784340149606453\n",
      "epoch 4 batch id 51301 / 225000 loss 2.0100741386413574 train acc 0.7843658018362215\n",
      "epoch 4 batch id 51401 / 225000 loss 0.002128060208633542 train acc 0.7843573082235754\n",
      "epoch 4 batch id 51501 / 225000 loss 0.5816315412521362 train acc 0.7844168074406322\n",
      "epoch 4 batch id 51601 / 225000 loss 1.0331082344055176 train acc 0.7843694889633922\n",
      "epoch 4 batch id 51701 / 225000 loss 0.06680791079998016 train acc 0.7843223535328137\n",
      "epoch 4 batch id 51801 / 225000 loss 1.7437411546707153 train acc 0.7843236617053725\n",
      "epoch 4 batch id 51901 / 225000 loss 0.003911914769560099 train acc 0.7844357526829926\n",
      "epoch 4 batch id 52001 / 225000 loss 0.7748017907142639 train acc 0.7844368377531201\n",
      "epoch 4 batch id 52101 / 225000 loss 0.0034640789963304996 train acc 0.7844954991266962\n",
      "epoch 4 batch id 52201 / 225000 loss 0.002051529474556446 train acc 0.7845060439455183\n",
      "epoch 4 batch id 52301 / 225000 loss 0.7755299806594849 train acc 0.784559568650695\n",
      "epoch 4 batch id 52401 / 225000 loss 1.4158726930618286 train acc 0.784531783744585\n",
      "epoch 4 batch id 52501 / 225000 loss 0.04261337220668793 train acc 0.7845326755680844\n",
      "epoch 4 batch id 52601 / 225000 loss 0.0027154104318469763 train acc 0.7845240584779757\n",
      "epoch 4 batch id 52701 / 225000 loss 0.03755807876586914 train acc 0.7845059866036698\n",
      "epoch 4 batch id 52801 / 225000 loss 0.006127904634922743 train acc 0.7845495350466847\n",
      "epoch 4 batch id 52901 / 225000 loss 0.010210142470896244 train acc 0.7845740156140716\n",
      "epoch 4 batch id 53001 / 225000 loss 2.401343822479248 train acc 0.7845370842059584\n",
      "epoch 4 batch id 53101 / 225000 loss 1.2866376638412476 train acc 0.7845803280540856\n",
      "epoch 4 batch id 53201 / 225000 loss 1.5004358291625977 train acc 0.7845905152158794\n",
      "epoch 4 batch id 53301 / 225000 loss 4.596102714538574 train acc 0.7845396896868727\n",
      "epoch 4 batch id 53401 / 225000 loss 0.7335466742515564 train acc 0.7844750098312766\n",
      "epoch 4 batch id 53501 / 225000 loss 0.15085482597351074 train acc 0.7845554288704883\n",
      "epoch 4 batch id 53601 / 225000 loss 1.2127844095230103 train acc 0.7845609223708513\n",
      "epoch 4 batch id 53701 / 225000 loss 0.030118362978100777 train acc 0.784608294072736\n",
      "epoch 4 batch id 53801 / 225000 loss 0.018746886402368546 train acc 0.7846833701975799\n",
      "epoch 4 batch id 53901 / 225000 loss 0.005308923311531544 train acc 0.7846978720246378\n",
      "epoch 4 batch id 54001 / 225000 loss 1.2903897762298584 train acc 0.7847678746689876\n",
      "epoch 4 batch id 54101 / 225000 loss 0.8624081611633301 train acc 0.7848145135949428\n",
      "epoch 4 batch id 54201 / 225000 loss 1.2935082912445068 train acc 0.7848609804247154\n",
      "epoch 4 batch id 54301 / 225000 loss 0.22420132160186768 train acc 0.7848428205742067\n",
      "epoch 4 batch id 54401 / 225000 loss 0.0032800056505948305 train acc 0.7848063454715906\n",
      "epoch 4 batch id 54501 / 225000 loss 3.245745897293091 train acc 0.7848067007944808\n",
      "epoch 4 batch id 54601 / 225000 loss 3.0577361583709717 train acc 0.7848391055108881\n",
      "epoch 4 batch id 54701 / 225000 loss 0.8695530295372009 train acc 0.784752563938502\n",
      "epoch 4 batch id 54801 / 225000 loss 0.7035664916038513 train acc 0.7846891480082481\n",
      "epoch 4 batch id 54901 / 225000 loss 2.651289463043213 train acc 0.7847079288173258\n",
      "epoch 4 batch id 55001 / 225000 loss 0.0020924771670252085 train acc 0.7846948237304776\n",
      "epoch 4 batch id 55101 / 225000 loss 2.166402578353882 train acc 0.7847316745612603\n",
      "epoch 4 batch id 55201 / 225000 loss 2.6399497985839844 train acc 0.784754805166573\n",
      "epoch 4 batch id 55301 / 225000 loss 0.8561041355133057 train acc 0.7847190828375618\n",
      "epoch 4 batch id 55401 / 225000 loss 1.3072786331176758 train acc 0.7846970271294742\n",
      "epoch 4 batch id 55501 / 225000 loss 1.4285101890563965 train acc 0.7847471216734834\n",
      "epoch 4 batch id 55601 / 225000 loss 1.1651121377944946 train acc 0.7847700580924803\n",
      "epoch 4 batch id 55701 / 225000 loss 1.4622060060501099 train acc 0.7848018886554999\n",
      "epoch 4 batch id 55801 / 225000 loss 0.17117957770824432 train acc 0.7848156843067329\n",
      "epoch 4 batch id 55901 / 225000 loss 1.0904344320297241 train acc 0.7848249584086152\n",
      "epoch 4 batch id 56001 / 225000 loss 3.2391347885131836 train acc 0.7847940215353297\n",
      "epoch 4 batch id 56101 / 225000 loss 0.32466793060302734 train acc 0.7847943886918237\n",
      "epoch 4 batch id 56201 / 225000 loss 0.0016638559754937887 train acc 0.7848125478194338\n",
      "epoch 4 batch id 56301 / 225000 loss 0.0005513114738278091 train acc 0.7848217616028135\n",
      "epoch 4 batch id 56401 / 225000 loss 2.193164587020874 train acc 0.7848619705324373\n",
      "epoch 4 batch id 56501 / 225000 loss 0.20996320247650146 train acc 0.7848799136298472\n",
      "epoch 4 batch id 56601 / 225000 loss 0.11296724528074265 train acc 0.7848536244942669\n",
      "epoch 4 batch id 56701 / 225000 loss 1.458475947380066 train acc 0.7848186099010599\n",
      "epoch 4 batch id 56801 / 225000 loss 2.787571907043457 train acc 0.7848013239203535\n",
      "epoch 4 batch id 56901 / 225000 loss 0.8106383085250854 train acc 0.7848192474648952\n",
      "epoch 4 batch id 57001 / 225000 loss 0.002005439717322588 train acc 0.7848678093366783\n",
      "epoch 4 batch id 57101 / 225000 loss 1.8188221454620361 train acc 0.7848373933906586\n",
      "epoch 4 batch id 57201 / 225000 loss 0.016443848609924316 train acc 0.7848070837922414\n",
      "epoch 4 batch id 57301 / 225000 loss 2.500518560409546 train acc 0.784794331687056\n",
      "epoch 4 batch id 57401 / 225000 loss 0.0219082310795784 train acc 0.7847816240135189\n",
      "epoch 4 batch id 57501 / 225000 loss 2.8349502086639404 train acc 0.7847950470426601\n",
      "epoch 4 batch id 57601 / 225000 loss 0.02215925231575966 train acc 0.7847780420478812\n",
      "epoch 4 batch id 57701 / 225000 loss 1.2955962419509888 train acc 0.7848087554808408\n",
      "epoch 4 batch id 57801 / 225000 loss 1.7592897415161133 train acc 0.7847831352398748\n",
      "epoch 4 batch id 57901 / 225000 loss 1.7228655815124512 train acc 0.7848094160722613\n",
      "epoch 4 batch id 58001 / 225000 loss 0.9826937317848206 train acc 0.7848356062826503\n",
      "epoch 4 batch id 58101 / 225000 loss 0.09622073918581009 train acc 0.7848444949312404\n",
      "epoch 4 batch id 58201 / 225000 loss 0.008495919406414032 train acc 0.784814693905603\n",
      "epoch 4 batch id 58301 / 225000 loss 4.197691440582275 train acc 0.7848107236582563\n",
      "epoch 4 batch id 58401 / 225000 loss 2.2758209705352783 train acc 0.7847511172753892\n",
      "epoch 4 batch id 58501 / 225000 loss 0.0005275692092254758 train acc 0.7848070973145759\n",
      "epoch 4 batch id 58601 / 225000 loss 0.0019331825897097588 train acc 0.7848202249108377\n",
      "epoch 4 batch id 58701 / 225000 loss 0.9778781533241272 train acc 0.7847353537418442\n",
      "epoch 4 batch id 58801 / 225000 loss 0.5537083148956299 train acc 0.784740055441234\n",
      "epoch 4 batch id 58901 / 225000 loss 1.4305894374847412 train acc 0.7847702076365427\n",
      "epoch 4 batch id 59001 / 225000 loss 1.636474847793579 train acc 0.7847155132963848\n",
      "epoch 4 batch id 59101 / 225000 loss 0.25427696108818054 train acc 0.7847286847938275\n",
      "epoch 4 batch id 59201 / 225000 loss 3.476398229598999 train acc 0.7847882637117616\n",
      "epoch 4 batch id 59301 / 225000 loss 1.4196171760559082 train acc 0.7847548945211716\n",
      "epoch 4 batch id 59401 / 225000 loss 0.3824273645877838 train acc 0.7847468897830003\n",
      "epoch 4 batch id 59501 / 225000 loss 1.8589235544204712 train acc 0.7847725248315154\n",
      "epoch 4 batch id 59601 / 225000 loss 1.161368727684021 train acc 0.7848442140232547\n",
      "epoch 4 batch id 59701 / 225000 loss 0.3888230323791504 train acc 0.7849072879851259\n",
      "epoch 4 batch id 59801 / 225000 loss 3.466470241546631 train acc 0.7848196518452869\n",
      "epoch 4 batch id 59901 / 225000 loss 3.1355783939361572 train acc 0.7848533413465552\n",
      "epoch 4 batch id 60001 / 225000 loss 1.0246621370315552 train acc 0.7848285861902302\n",
      "epoch 4 batch id 60101 / 225000 loss 0.008066867478191853 train acc 0.7847664764313406\n",
      "epoch 4 batch id 60201 / 225000 loss 0.0015121623873710632 train acc 0.7847211840334878\n",
      "epoch 4 batch id 60301 / 225000 loss 0.0007559809600934386 train acc 0.7847382298801014\n",
      "epoch 4 batch id 60401 / 225000 loss 2.1716573238372803 train acc 0.7847179682455588\n",
      "epoch 4 batch id 60501 / 225000 loss 0.6948580145835876 train acc 0.7847101700798333\n",
      "epoch 4 batch id 60601 / 225000 loss 0.0024899402633309364 train acc 0.784690021616805\n",
      "epoch 4 batch id 60701 / 225000 loss 0.03163362666964531 train acc 0.7847028879260638\n",
      "epoch 4 batch id 60801 / 225000 loss 0.002374982461333275 train acc 0.7847239354615878\n",
      "epoch 4 batch id 60901 / 225000 loss 0.4159078598022461 train acc 0.7847900691285857\n",
      "epoch 4 batch id 61001 / 225000 loss 3.4136159420013428 train acc 0.784827297913149\n",
      "epoch 4 batch id 61101 / 225000 loss 1.673970341682434 train acc 0.7848398553215168\n",
      "epoch 4 batch id 61201 / 225000 loss 0.006189036648720503 train acc 0.7848482867926995\n",
      "epoch 4 batch id 61301 / 225000 loss 3.636381149291992 train acc 0.7848607689923492\n",
      "epoch 4 batch id 61401 / 225000 loss 0.0019743945449590683 train acc 0.7848447093695542\n",
      "epoch 4 batch id 61501 / 225000 loss 1.0961217880249023 train acc 0.7848693517178582\n",
      "epoch 4 batch id 61601 / 225000 loss 0.40094617009162903 train acc 0.7848695638057823\n",
      "epoch 4 batch id 61701 / 225000 loss 2.727720022201538 train acc 0.7848333090225442\n",
      "epoch 4 batch id 61801 / 225000 loss 1.1333266496658325 train acc 0.784882121648517\n",
      "epoch 4 batch id 61901 / 225000 loss 2.48144793510437 train acc 0.7849307765625757\n",
      "epoch 4 batch id 62001 / 225000 loss 3.287199020385742 train acc 0.7849228238254222\n",
      "epoch 4 batch id 62101 / 225000 loss 1.3535643815994263 train acc 0.7849471023010901\n",
      "epoch 4 batch id 62201 / 225000 loss 0.0010926863178610802 train acc 0.785023552676002\n",
      "epoch 4 batch id 62301 / 225000 loss 1.0262227058410645 train acc 0.7850275276480313\n",
      "epoch 4 batch id 62401 / 225000 loss 2.222468376159668 train acc 0.7850595343023349\n",
      "epoch 4 batch id 62501 / 225000 loss 1.3461921215057373 train acc 0.785015439752964\n",
      "epoch 4 batch id 62601 / 225000 loss 1.3420778512954712 train acc 0.7850433699142186\n",
      "epoch 4 batch id 62701 / 225000 loss 0.3395579159259796 train acc 0.7850831725171847\n",
      "epoch 4 batch id 62801 / 225000 loss 1.031182050704956 train acc 0.7850671167656565\n",
      "epoch 4 batch id 62901 / 225000 loss 0.46099668741226196 train acc 0.7850709845630435\n",
      "epoch 4 batch id 63001 / 225000 loss 0.007056545931845903 train acc 0.7850589673179791\n",
      "epoch 4 batch id 63101 / 225000 loss 0.23268267512321472 train acc 0.7851183024040823\n",
      "epoch 4 batch id 63201 / 225000 loss 0.858649492263794 train acc 0.7851022926852423\n",
      "epoch 4 batch id 63301 / 225000 loss 1.202430248260498 train acc 0.7851179286267199\n",
      "epoch 4 batch id 63401 / 225000 loss 2.4538302421569824 train acc 0.7851216857778268\n",
      "epoch 4 batch id 63501 / 225000 loss 2.1087191104888916 train acc 0.785133304987323\n",
      "epoch 4 batch id 63601 / 225000 loss 0.13144551217556 train acc 0.7851920567286678\n",
      "epoch 4 batch id 63701 / 225000 loss 1.6393187046051025 train acc 0.785191755231472\n",
      "epoch 4 batch id 63801 / 225000 loss 0.0019360671285539865 train acc 0.785183617811633\n",
      "epoch 4 batch id 63901 / 225000 loss 0.00606825016438961 train acc 0.7852107165772053\n",
      "epoch 4 batch id 64001 / 225000 loss 0.9619193077087402 train acc 0.7851947625818346\n",
      "epoch 4 batch id 64101 / 225000 loss 0.014325283467769623 train acc 0.7851983588399557\n",
      "epoch 4 batch id 64201 / 225000 loss 2.791722297668457 train acc 0.785213625955982\n",
      "epoch 4 batch id 64301 / 225000 loss 0.6927204728126526 train acc 0.7852443974432746\n",
      "epoch 4 batch id 64401 / 225000 loss 1.5565176010131836 train acc 0.7852983649322216\n",
      "epoch 4 batch id 64501 / 225000 loss 2.6482279300689697 train acc 0.7851893769088851\n",
      "epoch 4 batch id 64601 / 225000 loss 1.2101664543151855 train acc 0.785150384668968\n",
      "epoch 4 batch id 64701 / 225000 loss 1.5028811693191528 train acc 0.7851501522387598\n",
      "epoch 4 batch id 64801 / 225000 loss 2.264906167984009 train acc 0.7851614944213824\n",
      "epoch 4 batch id 64901 / 225000 loss 0.0021122379694133997 train acc 0.7851265774025054\n",
      "epoch 4 batch id 65001 / 225000 loss 0.5645681023597717 train acc 0.7851033061029831\n",
      "epoch 4 batch id 65101 / 225000 loss 2.517474889755249 train acc 0.7851185081642371\n",
      "epoch 4 batch id 65201 / 225000 loss 1.414050579071045 train acc 0.7851144921090167\n",
      "epoch 4 batch id 65301 / 225000 loss 1.5948971509933472 train acc 0.7850913462274697\n",
      "epoch 4 batch id 65401 / 225000 loss 0.01509744394570589 train acc 0.785106496842556\n",
      "epoch 4 batch id 65501 / 225000 loss 2.0397090911865234 train acc 0.7851101509900612\n",
      "epoch 4 batch id 65601 / 225000 loss 1.7885959148406982 train acc 0.7850566302342952\n",
      "epoch 4 batch id 65701 / 225000 loss 1.1581026315689087 train acc 0.7850793747431546\n",
      "epoch 4 batch id 65801 / 225000 loss 0.033776283264160156 train acc 0.7850488594398262\n",
      "epoch 4 batch id 65901 / 225000 loss 0.01905929483473301 train acc 0.7850374045917361\n",
      "epoch 4 batch id 66001 / 225000 loss 0.004894654732197523 train acc 0.785025984454781\n",
      "epoch 4 batch id 66101 / 225000 loss 1.8648059368133545 train acc 0.785075112328104\n",
      "epoch 4 batch id 66201 / 225000 loss 0.0018531177192926407 train acc 0.7851240917810909\n",
      "epoch 4 batch id 66301 / 225000 loss 0.0013757288688793778 train acc 0.7850861977949051\n",
      "epoch 4 batch id 66401 / 225000 loss 0.004544158466160297 train acc 0.7851011279950603\n",
      "epoch 4 batch id 66501 / 225000 loss 1.2782323360443115 train acc 0.7851423286867867\n",
      "epoch 4 batch id 66601 / 225000 loss 1.9444140195846558 train acc 0.7851383612858666\n",
      "epoch 4 batch id 66701 / 225000 loss 0.002468329155817628 train acc 0.7851756345482077\n",
      "epoch 4 batch id 66801 / 225000 loss 2.873605728149414 train acc 0.7852015688387899\n",
      "epoch 4 batch id 66901 / 225000 loss 0.009214915335178375 train acc 0.7852050044095006\n",
      "epoch 4 batch id 67001 / 225000 loss 2.552055597305298 train acc 0.7851972358621513\n",
      "epoch 4 batch id 67101 / 225000 loss 0.0134719368070364 train acc 0.7851894904695906\n",
      "epoch 4 batch id 67201 / 225000 loss 0.8698663115501404 train acc 0.7852152497730689\n",
      "epoch 4 batch id 67301 / 225000 loss 1.1169002056121826 train acc 0.7851889273562057\n",
      "epoch 4 batch id 67401 / 225000 loss 1.6222631931304932 train acc 0.7851812287651518\n",
      "epoch 4 batch id 67501 / 225000 loss 3.347309112548828 train acc 0.7850920727100339\n",
      "epoch 4 batch id 67601 / 225000 loss 0.0007609969470649958 train acc 0.7850993328501058\n",
      "epoch 4 batch id 67701 / 225000 loss 1.0348048210144043 train acc 0.7851102642501588\n",
      "epoch 4 batch id 67801 / 225000 loss 0.03757256641983986 train acc 0.7851395997109187\n",
      "epoch 4 batch id 67901 / 225000 loss 0.0037959767505526543 train acc 0.7851209849634025\n",
      "epoch 4 batch id 68001 / 225000 loss 3.2711915969848633 train acc 0.785054631549536\n",
      "epoch 4 batch id 68101 / 225000 loss 0.007207421585917473 train acc 0.785072906418408\n",
      "epoch 4 batch id 68201 / 225000 loss 4.2892608642578125 train acc 0.78504714007126\n",
      "epoch 4 batch id 68301 / 225000 loss 0.18965886533260345 train acc 0.7850800134697882\n",
      "epoch 4 batch id 68401 / 225000 loss 0.014167893677949905 train acc 0.785021417815529\n",
      "epoch 4 batch id 68501 / 225000 loss 0.007113239727914333 train acc 0.7850177369673436\n",
      "epoch 4 batch id 68601 / 225000 loss 0.00676617119461298 train acc 0.7850249996355738\n",
      "epoch 4 batch id 68701 / 225000 loss 0.013220145367085934 train acc 0.785024963246532\n",
      "epoch 4 batch id 68801 / 225000 loss 0.8324716687202454 train acc 0.7850539963081932\n",
      "epoch 4 batch id 68901 / 225000 loss 1.732024073600769 train acc 0.7850829450951365\n",
      "epoch 4 batch id 69001 / 225000 loss 0.560031533241272 train acc 0.7851226793814582\n",
      "epoch 4 batch id 69101 / 225000 loss 0.19231492280960083 train acc 0.7850827050259764\n",
      "epoch 4 batch id 69201 / 225000 loss 1.6753026247024536 train acc 0.785057296859872\n",
      "epoch 4 batch id 69301 / 225000 loss 0.001387153286486864 train acc 0.7850968961486847\n",
      "epoch 4 batch id 69401 / 225000 loss 0.0004731928347609937 train acc 0.785154392588003\n",
      "epoch 4 batch id 69501 / 225000 loss 1.0793806314468384 train acc 0.785164961655228\n",
      "epoch 4 batch id 69601 / 225000 loss 0.0016413603443652391 train acc 0.7852006436689128\n",
      "epoch 4 batch id 69701 / 225000 loss 0.14875763654708862 train acc 0.7852182895510825\n",
      "epoch 4 batch id 69801 / 225000 loss 1.6080259084701538 train acc 0.7852036503775017\n",
      "epoch 4 batch id 69901 / 225000 loss 0.6183286309242249 train acc 0.7851962060628603\n",
      "epoch 4 batch id 70001 / 225000 loss 0.0010519997449591756 train acc 0.785181640262282\n",
      "epoch 4 batch id 70101 / 225000 loss 1.5379517078399658 train acc 0.7852277428282051\n",
      "epoch 4 batch id 70201 / 225000 loss 2.818150520324707 train acc 0.7852808364553211\n",
      "epoch 4 batch id 70301 / 225000 loss 0.660233199596405 train acc 0.7852804369781369\n",
      "epoch 4 batch id 70401 / 225000 loss 1.691720962524414 train acc 0.785244527776594\n",
      "epoch 4 batch id 70501 / 225000 loss 1.5369057655334473 train acc 0.7852725493255415\n",
      "epoch 4 batch id 70601 / 225000 loss 2.3833022117614746 train acc 0.785265081231144\n",
      "epoch 4 batch id 70701 / 225000 loss 2.9893457889556885 train acc 0.7852823863877456\n",
      "epoch 4 batch id 70801 / 225000 loss 1.990838646888733 train acc 0.7852713944718295\n",
      "epoch 4 batch id 70901 / 225000 loss 1.2947893142700195 train acc 0.7852956939958534\n",
      "epoch 4 batch id 71001 / 225000 loss 1.242655634880066 train acc 0.7853516147659892\n",
      "epoch 4 batch id 71101 / 225000 loss 0.021207017824053764 train acc 0.7853757331120519\n",
      "epoch 4 batch id 71201 / 225000 loss 2.390064001083374 train acc 0.7854454291372313\n",
      "epoch 4 batch id 71301 / 225000 loss 0.013921523466706276 train acc 0.7854728545181695\n",
      "epoch 4 batch id 71401 / 225000 loss 2.234090805053711 train acc 0.7854756936177364\n",
      "epoch 4 batch id 71501 / 225000 loss 0.011875566095113754 train acc 0.7855449574131831\n",
      "epoch 4 batch id 71601 / 225000 loss 0.0009511029347777367 train acc 0.7856489434505105\n",
      "epoch 4 batch id 71701 / 225000 loss 2.818920850753784 train acc 0.7856689585919304\n",
      "epoch 4 batch id 71801 / 225000 loss 1.2367619276046753 train acc 0.7856958816729572\n",
      "epoch 4 batch id 71901 / 225000 loss 1.669615626335144 train acc 0.7857227298646751\n",
      "epoch 4 batch id 72001 / 225000 loss 1.5107941627502441 train acc 0.7857842252190942\n",
      "epoch 4 batch id 72101 / 225000 loss 1.215744137763977 train acc 0.7857553986768561\n",
      "epoch 4 batch id 72201 / 225000 loss 0.37209829688072205 train acc 0.7858166784393568\n",
      "epoch 4 batch id 72301 / 225000 loss 1.0939885377883911 train acc 0.7858397532537585\n",
      "epoch 4 batch id 72401 / 225000 loss 0.09846056252717972 train acc 0.785855858344498\n",
      "epoch 4 batch id 72501 / 225000 loss 2.024430513381958 train acc 0.7858477814099116\n",
      "epoch 4 batch id 72601 / 225000 loss 0.0037816462572664022 train acc 0.7858087354168676\n",
      "epoch 4 batch id 72701 / 225000 loss 2.1762595176696777 train acc 0.7857491643856344\n",
      "epoch 4 batch id 72801 / 225000 loss 1.544859766960144 train acc 0.7857824755154462\n",
      "epoch 4 batch id 72901 / 225000 loss 0.9601190090179443 train acc 0.7858156952579526\n",
      "epoch 4 batch id 73001 / 225000 loss 0.8684918880462646 train acc 0.7858008794400076\n",
      "epoch 4 batch id 73101 / 225000 loss 0.74370938539505 train acc 0.7858032037865419\n",
      "epoch 4 batch id 73201 / 225000 loss 0.22150211036205292 train acc 0.7857952760208193\n",
      "epoch 4 batch id 73301 / 225000 loss 0.2992895245552063 train acc 0.7858180652378549\n",
      "epoch 4 batch id 73401 / 225000 loss 1.3712131977081299 train acc 0.7858033269301509\n",
      "epoch 4 batch id 73501 / 225000 loss 0.02185269258916378 train acc 0.7858566550114965\n",
      "epoch 4 batch id 73601 / 225000 loss 0.8536673784255981 train acc 0.7858249208570536\n",
      "epoch 4 batch id 73701 / 225000 loss 1.7146117687225342 train acc 0.785813625323944\n",
      "epoch 4 batch id 73801 / 225000 loss 0.650109052658081 train acc 0.7857888104497229\n",
      "epoch 4 batch id 73901 / 225000 loss 0.03424042463302612 train acc 0.785784360157508\n",
      "epoch 4 batch id 74001 / 225000 loss 2.4759058952331543 train acc 0.7857697868947717\n",
      "epoch 4 batch id 74101 / 225000 loss 0.04281622916460037 train acc 0.7857518791919137\n",
      "epoch 4 batch id 74201 / 225000 loss 4.388154029846191 train acc 0.7857138043961671\n",
      "epoch 4 batch id 74301 / 225000 loss 1.0790175199508667 train acc 0.7857363965491716\n",
      "epoch 4 batch id 74401 / 225000 loss 2.447023630142212 train acc 0.7857152457628258\n",
      "epoch 4 batch id 74501 / 225000 loss 0.026467008516192436 train acc 0.78568072911773\n",
      "epoch 4 batch id 74601 / 225000 loss 1.3671313524246216 train acc 0.7856798166244421\n",
      "epoch 4 batch id 74701 / 225000 loss 0.027662839740514755 train acc 0.7857324533808115\n",
      "epoch 4 batch id 74801 / 225000 loss 0.3400159478187561 train acc 0.7857515273859975\n",
      "epoch 4 batch id 74901 / 225000 loss 0.8289774060249329 train acc 0.7857438485467484\n",
      "epoch 4 batch id 75001 / 225000 loss 0.0018776038195937872 train acc 0.7857461900507994\n",
      "epoch 4 batch id 75101 / 225000 loss 2.101365327835083 train acc 0.7858084446279011\n",
      "epoch 4 batch id 75201 / 225000 loss 1.3808897733688354 train acc 0.7858007207350967\n",
      "epoch 4 batch id 75301 / 225000 loss 2.7424206733703613 train acc 0.7857697772937943\n",
      "epoch 4 batch id 75401 / 225000 loss 0.005266440566629171 train acc 0.7858151748650548\n",
      "epoch 4 batch id 75501 / 225000 loss 0.5645158290863037 train acc 0.7858273400352314\n",
      "epoch 4 batch id 75601 / 225000 loss 4.379755973815918 train acc 0.7858560071956721\n",
      "epoch 4 batch id 75701 / 225000 loss 1.278014898300171 train acc 0.7858251542251754\n",
      "epoch 4 batch id 75801 / 225000 loss 1.1503369808197021 train acc 0.7858075750979538\n",
      "epoch 4 batch id 75901 / 225000 loss 1.1647189855575562 train acc 0.7858559175768435\n",
      "epoch 4 batch id 76001 / 225000 loss 0.038559868931770325 train acc 0.7858843962579439\n",
      "epoch 4 batch id 76101 / 225000 loss 0.8426640629768372 train acc 0.7859128000946111\n",
      "epoch 4 batch id 76201 / 225000 loss 0.12304052710533142 train acc 0.7859411293815042\n",
      "epoch 4 batch id 76301 / 225000 loss 0.0018041457515209913 train acc 0.7859726609087693\n",
      "epoch 4 batch id 76401 / 225000 loss 0.15601949393749237 train acc 0.7859844766429759\n",
      "epoch 4 batch id 76501 / 225000 loss 0.002865534508600831 train acc 0.786019137004745\n",
      "epoch 4 batch id 76601 / 225000 loss 0.003090130863711238 train acc 0.7860504432057023\n",
      "epoch 4 batch id 76701 / 225000 loss 0.9632622003555298 train acc 0.7860262578062868\n",
      "epoch 4 batch id 76801 / 225000 loss 1.9213788509368896 train acc 0.7860574732099842\n",
      "epoch 4 batch id 76901 / 225000 loss 3.1460888385772705 train acc 0.7860300906360126\n",
      "epoch 4 batch id 77001 / 225000 loss 0.6558774709701538 train acc 0.7860514798509111\n",
      "epoch 4 batch id 77101 / 225000 loss 0.0041021425276994705 train acc 0.7860598435817953\n",
      "epoch 4 batch id 77201 / 225000 loss 1.6137505769729614 train acc 0.7860876154453957\n",
      "epoch 4 batch id 77301 / 225000 loss 0.0007033968577161431 train acc 0.7861185495659824\n",
      "epoch 4 batch id 77401 / 225000 loss 1.4436275959014893 train acc 0.7861590935517629\n",
      "epoch 4 batch id 77501 / 225000 loss 0.015032218769192696 train acc 0.7861575979664779\n",
      "epoch 4 batch id 77601 / 225000 loss 2.4991705417633057 train acc 0.7861496630198065\n",
      "epoch 4 batch id 77701 / 225000 loss 0.0028229253366589546 train acc 0.7861771405773413\n",
      "epoch 4 batch id 77801 / 225000 loss 0.014192954637110233 train acc 0.7862238274572306\n",
      "epoch 4 batch id 77901 / 225000 loss 0.014280634000897408 train acc 0.7862736036764612\n",
      "epoch 4 batch id 78001 / 225000 loss 0.5805961489677429 train acc 0.7862623556108255\n",
      "epoch 4 batch id 78101 / 225000 loss 0.06004253029823303 train acc 0.7862959501158756\n",
      "epoch 4 batch id 78201 / 225000 loss 0.0006803880678489804 train acc 0.7862942929118554\n",
      "epoch 4 batch id 78301 / 225000 loss 0.0017375376773998141 train acc 0.7863054111697169\n",
      "epoch 4 batch id 78401 / 225000 loss 0.012349625118076801 train acc 0.7863005573908496\n",
      "epoch 4 batch id 78501 / 225000 loss 0.0024389945901930332 train acc 0.7862957159781404\n",
      "epoch 4 batch id 78601 / 225000 loss 2.704030990600586 train acc 0.786278164399944\n",
      "epoch 4 batch id 78701 / 225000 loss 1.5199952125549316 train acc 0.7862733637437898\n",
      "epoch 4 batch id 78801 / 225000 loss 1.75571608543396 train acc 0.7862749203690309\n",
      "epoch 4 batch id 78901 / 225000 loss 1.2819406986236572 train acc 0.7862796415761524\n",
      "epoch 4 batch id 79001 / 225000 loss 1.2966843843460083 train acc 0.7863254895507652\n",
      "epoch 4 batch id 79101 / 225000 loss 0.9447398781776428 train acc 0.7863269743745338\n",
      "epoch 4 batch id 79201 / 225000 loss 0.0008095588418655097 train acc 0.7863126728197877\n",
      "epoch 4 batch id 79301 / 225000 loss 1.9528714418411255 train acc 0.7863078649701769\n",
      "epoch 4 batch id 79401 / 225000 loss 0.2905886173248291 train acc 0.786315663530686\n",
      "epoch 4 batch id 79501 / 225000 loss 1.784189224243164 train acc 0.786329731701488\n",
      "epoch 4 batch id 79601 / 225000 loss 2.650346279144287 train acc 0.7863688898380674\n",
      "epoch 4 batch id 79701 / 225000 loss 0.044972989708185196 train acc 0.7864236333295692\n",
      "epoch 4 batch id 79801 / 225000 loss 2.8880503177642822 train acc 0.7864563100713023\n",
      "epoch 4 batch id 79901 / 225000 loss 0.012285174801945686 train acc 0.7864075543485063\n",
      "epoch 4 batch id 80001 / 225000 loss 1.007739543914795 train acc 0.7864401694978813\n",
      "epoch 4 batch id 80101 / 225000 loss 0.6730108857154846 train acc 0.786444613675235\n",
      "epoch 4 batch id 80201 / 225000 loss 0.8431270122528076 train acc 0.7864739841149113\n",
      "epoch 4 batch id 80301 / 225000 loss 1.8265016078948975 train acc 0.7865188478350207\n",
      "epoch 4 batch id 80401 / 225000 loss 0.9534680843353271 train acc 0.7865200681583563\n",
      "epoch 4 batch id 80501 / 225000 loss 0.0005913213826715946 train acc 0.7865150743469025\n",
      "epoch 4 batch id 80601 / 225000 loss 2.724868059158325 train acc 0.7865380082132976\n",
      "epoch 4 batch id 80701 / 225000 loss 3.6328506469726562 train acc 0.7865268088375609\n",
      "epoch 4 batch id 80801 / 225000 loss 2.04443359375 train acc 0.7865280132671625\n",
      "epoch 4 batch id 80901 / 225000 loss 0.9160065650939941 train acc 0.7865910186524271\n",
      "epoch 4 batch id 81001 / 225000 loss 0.016604823991656303 train acc 0.7865674497845706\n",
      "epoch 4 batch id 81101 / 225000 loss 1.2881717681884766 train acc 0.7865439390389761\n",
      "epoch 4 batch id 81201 / 225000 loss 3.1452558040618896 train acc 0.7865235649807268\n",
      "epoch 4 batch id 81301 / 225000 loss 0.3485032916069031 train acc 0.7865555159223134\n",
      "epoch 4 batch id 81401 / 225000 loss 2.150033950805664 train acc 0.786538248915861\n",
      "epoch 4 batch id 81501 / 225000 loss 1.1658995151519775 train acc 0.7865118219408351\n",
      "epoch 4 batch id 81601 / 225000 loss 0.11258500814437866 train acc 0.7865528608718031\n",
      "epoch 4 batch id 81701 / 225000 loss 0.8017323613166809 train acc 0.7865754397131002\n",
      "epoch 4 batch id 81801 / 225000 loss 1.578728437423706 train acc 0.7866040757447953\n",
      "epoch 4 batch id 81901 / 225000 loss 1.0893391370773315 train acc 0.7865899073271388\n",
      "epoch 4 batch id 82001 / 225000 loss 1.7549080848693848 train acc 0.7865879684394093\n",
      "epoch 4 batch id 82101 / 225000 loss 0.3345393240451813 train acc 0.78657689918515\n",
      "epoch 4 batch id 82201 / 225000 loss 1.6132584810256958 train acc 0.7865780221651805\n",
      "epoch 4 batch id 82301 / 225000 loss 0.0326525941491127 train acc 0.7865973681972273\n",
      "epoch 4 batch id 82401 / 225000 loss 0.09515732526779175 train acc 0.7866318369922695\n",
      "epoch 4 batch id 82501 / 225000 loss 0.9611443281173706 train acc 0.7866450103635108\n",
      "epoch 4 batch id 82601 / 225000 loss 0.9933282136917114 train acc 0.786624859263205\n",
      "epoch 4 batch id 82701 / 225000 loss 1.300424337387085 train acc 0.7866108027714296\n",
      "epoch 4 batch id 82801 / 225000 loss 1.707502841949463 train acc 0.7866118766681561\n",
      "epoch 4 batch id 82901 / 225000 loss 1.6598676443099976 train acc 0.7865948541030868\n",
      "epoch 4 batch id 83001 / 225000 loss 1.0623117685317993 train acc 0.7865748605438488\n",
      "epoch 4 batch id 83101 / 225000 loss 1.5927720069885254 train acc 0.7865819905897643\n",
      "epoch 4 batch id 83201 / 225000 loss 1.3245251178741455 train acc 0.7865860987247749\n",
      "epoch 4 batch id 83301 / 225000 loss 0.6684951782226562 train acc 0.7866682272721816\n",
      "epoch 4 batch id 83401 / 225000 loss 1.8017157316207886 train acc 0.7866842124195154\n",
      "epoch 4 batch id 83501 / 225000 loss 0.0037391420919448137 train acc 0.7866492616854888\n",
      "epoch 4 batch id 83601 / 225000 loss 0.8736404180526733 train acc 0.7866622408822861\n",
      "epoch 4 batch id 83701 / 225000 loss 0.6701822280883789 train acc 0.7866512944887157\n",
      "epoch 4 batch id 83801 / 225000 loss 1.4007750749588013 train acc 0.786691089605136\n",
      "epoch 4 batch id 83901 / 225000 loss 0.0030451391357928514 train acc 0.7867158913481365\n",
      "epoch 4 batch id 84001 / 225000 loss 1.9544157981872559 train acc 0.7867257532648421\n",
      "epoch 4 batch id 84101 / 225000 loss 0.45426300168037415 train acc 0.7866820846363302\n",
      "epoch 4 batch id 84201 / 225000 loss 1.3687853813171387 train acc 0.7866830560207123\n",
      "epoch 4 batch id 84301 / 225000 loss 0.8447468876838684 train acc 0.7867166463031281\n",
      "epoch 4 batch id 84401 / 225000 loss 0.008933980949223042 train acc 0.7867234985367472\n",
      "epoch 4 batch id 84501 / 225000 loss 2.743077278137207 train acc 0.7867717541804239\n",
      "epoch 4 batch id 84601 / 225000 loss 0.04175913333892822 train acc 0.7867844351721611\n",
      "epoch 4 batch id 84701 / 225000 loss 0.001433675759471953 train acc 0.7868325049291035\n",
      "epoch 4 batch id 84801 / 225000 loss 0.0028831232339143753 train acc 0.7868303439817926\n",
      "epoch 4 batch id 84901 / 225000 loss 2.2857654094696045 train acc 0.7868075758824984\n",
      "epoch 4 batch id 85001 / 225000 loss 1.0650418996810913 train acc 0.7868172139151304\n",
      "epoch 4 batch id 85101 / 225000 loss 2.8127870559692383 train acc 0.7868238916111444\n",
      "epoch 4 batch id 85201 / 225000 loss 0.00199295487254858 train acc 0.7868393563455828\n",
      "epoch 4 batch id 85301 / 225000 loss 1.262371301651001 train acc 0.786845992426818\n",
      "epoch 4 batch id 85401 / 225000 loss 0.00172730244230479 train acc 0.7868496856008712\n",
      "epoch 4 batch id 85501 / 225000 loss 1.753821849822998 train acc 0.7868445983087917\n",
      "epoch 4 batch id 85601 / 225000 loss 0.038085661828517914 train acc 0.7868307613228818\n",
      "epoch 4 batch id 85701 / 225000 loss 2.3836681842803955 train acc 0.7868607134105786\n",
      "epoch 4 batch id 85801 / 225000 loss 0.8192586898803711 train acc 0.7868556310532512\n",
      "epoch 4 batch id 85901 / 225000 loss 0.9683848023414612 train acc 0.7868913051070419\n",
      "epoch 4 batch id 86001 / 225000 loss 0.0033878704998642206 train acc 0.7868600365112034\n",
      "epoch 4 batch id 86101 / 225000 loss 0.004046221729367971 train acc 0.786898526149522\n",
      "epoch 4 batch id 86201 / 225000 loss 4.494248390197754 train acc 0.7869369264857716\n",
      "epoch 4 batch id 86301 / 225000 loss 1.2993974685668945 train acc 0.7869781346681962\n",
      "epoch 4 batch id 86401 / 225000 loss 0.0005378240603022277 train acc 0.7870134604923554\n",
      "epoch 4 batch id 86501 / 225000 loss 0.4066329300403595 train acc 0.7870198032392689\n",
      "epoch 4 batch id 86601 / 225000 loss 0.9609062075614929 train acc 0.7870232445352825\n",
      "epoch 4 batch id 86701 / 225000 loss 0.0038524146657437086 train acc 0.7870382117853312\n",
      "epoch 4 batch id 86801 / 225000 loss 1.6934635639190674 train acc 0.787035863642124\n",
      "epoch 4 batch id 86901 / 225000 loss 1.0501693487167358 train acc 0.7870766734560016\n",
      "epoch 4 batch id 87001 / 225000 loss 0.00649636797606945 train acc 0.7870886541534006\n",
      "epoch 4 batch id 87101 / 225000 loss 1.4520068168640137 train acc 0.7871063478031252\n",
      "epoch 4 batch id 87201 / 225000 loss 0.8103311657905579 train acc 0.7871211339319503\n",
      "epoch 4 batch id 87301 / 225000 loss 0.9304072260856628 train acc 0.7870986586637038\n",
      "epoch 4 batch id 87401 / 225000 loss 0.0032349529210478067 train acc 0.787147744304985\n",
      "epoch 4 batch id 87501 / 225000 loss 0.0022818981669843197 train acc 0.7871567182089347\n",
      "epoch 4 batch id 87601 / 225000 loss 1.8561123609542847 train acc 0.7871399869864499\n",
      "epoch 4 batch id 87701 / 225000 loss 1.6199047565460205 train acc 0.7871375468922818\n",
      "epoch 4 batch id 87801 / 225000 loss 3.3118138313293457 train acc 0.7871180282684708\n",
      "epoch 4 batch id 87901 / 225000 loss 0.9407704472541809 train acc 0.787135527468402\n",
      "epoch 4 batch id 88001 / 225000 loss 0.8436319828033447 train acc 0.7871217372529857\n",
      "epoch 4 batch id 88101 / 225000 loss 0.00445579132065177 train acc 0.7871108159952781\n",
      "epoch 4 batch id 88201 / 225000 loss 0.0014302462805062532 train acc 0.7871055883720139\n",
      "epoch 4 batch id 88301 / 225000 loss 0.9831671714782715 train acc 0.7871060350392408\n",
      "epoch 4 batch id 88401 / 225000 loss 0.0019623232074081898 train acc 0.7870866845397676\n",
      "epoch 4 batch id 88501 / 225000 loss 0.00825472455471754 train acc 0.7871210494796669\n",
      "epoch 4 batch id 88601 / 225000 loss 0.0038197259418666363 train acc 0.7871130122684845\n",
      "epoch 4 batch id 88701 / 225000 loss 2.041998863220215 train acc 0.787110630094362\n",
      "epoch 4 batch id 88801 / 225000 loss 1.0990875959396362 train acc 0.787099807434601\n",
      "epoch 4 batch id 88901 / 225000 loss 1.4246618747711182 train acc 0.7871171302909978\n",
      "epoch 4 batch id 89001 / 225000 loss 0.799245297908783 train acc 0.7871119425624431\n",
      "epoch 4 batch id 89101 / 225000 loss 1.0466246604919434 train acc 0.787112378087788\n",
      "epoch 4 batch id 89201 / 225000 loss 0.0007788240909576416 train acc 0.7871212206141187\n",
      "epoch 4 batch id 89301 / 225000 loss 0.2854591906070709 train acc 0.7871272438158587\n",
      "epoch 4 batch id 89401 / 225000 loss 0.7403204441070557 train acc 0.787169606603953\n",
      "epoch 4 batch id 89501 / 225000 loss 0.08174490928649902 train acc 0.7871699757544608\n",
      "epoch 4 batch id 89601 / 225000 loss 1.8113833665847778 train acc 0.7871675539335499\n",
      "epoch 4 batch id 89701 / 225000 loss 0.06201046705245972 train acc 0.7871344801061304\n",
      "epoch 4 batch id 89801 / 225000 loss 1.2144495248794556 train acc 0.7871794300731618\n",
      "epoch 4 batch id 89901 / 225000 loss 3.91011118888855 train acc 0.7871797866542085\n",
      "epoch 4 batch id 90001 / 225000 loss 0.6437264680862427 train acc 0.7871856979366896\n",
      "epoch 4 batch id 90101 / 225000 loss 0.5778651833534241 train acc 0.7872110187456299\n",
      "epoch 4 batch id 90201 / 225000 loss 0.002761078765615821 train acc 0.787233511823594\n",
      "epoch 4 batch id 90301 / 225000 loss 1.251155138015747 train acc 0.7873002513814908\n",
      "epoch 4 batch id 90401 / 225000 loss 0.15763217210769653 train acc 0.787303237796042\n",
      "epoch 4 batch id 90501 / 225000 loss 2.264064311981201 train acc 0.787358703218749\n",
      "epoch 4 batch id 90601 / 225000 loss 1.0513932704925537 train acc 0.7873478217679717\n",
      "epoch 4 batch id 90701 / 225000 loss 0.23779596388339996 train acc 0.7873507458572673\n",
      "epoch 4 batch id 90801 / 225000 loss 0.6083175539970398 train acc 0.787372936421405\n",
      "epoch 4 batch id 90901 / 225000 loss 2.8636786937713623 train acc 0.7873703259590104\n",
      "epoch 4 batch id 91001 / 225000 loss 0.6657660007476807 train acc 0.7873814573466226\n",
      "epoch 4 batch id 91101 / 225000 loss 2.180954933166504 train acc 0.7873980527107276\n",
      "epoch 4 batch id 91201 / 225000 loss 0.004343423992395401 train acc 0.7874146116818894\n",
      "epoch 4 batch id 91301 / 225000 loss 1.1274892091751099 train acc 0.7874557781404365\n",
      "epoch 4 batch id 91401 / 225000 loss 1.5887757539749146 train acc 0.7874312097241825\n",
      "epoch 4 batch id 91501 / 225000 loss 1.2343599796295166 train acc 0.7874066950087977\n",
      "epoch 4 batch id 91601 / 225000 loss 1.2916215658187866 train acc 0.7873876922741018\n",
      "epoch 4 batch id 91701 / 225000 loss 0.23092058300971985 train acc 0.7873796359908835\n",
      "epoch 4 batch id 91801 / 225000 loss 0.13005807995796204 train acc 0.7874396793063256\n",
      "epoch 4 batch id 91901 / 225000 loss 0.8875373005867004 train acc 0.7874506262173425\n",
      "epoch 4 batch id 92001 / 225000 loss 0.19663774967193604 train acc 0.7874398104368431\n",
      "epoch 4 batch id 92101 / 225000 loss 0.9945111274719238 train acc 0.7874317325544782\n",
      "epoch 4 batch id 92201 / 225000 loss 0.0021489609498530626 train acc 0.7874751900738604\n",
      "epoch 4 batch id 92301 / 225000 loss 0.001202356768772006 train acc 0.7874833425423343\n",
      "epoch 4 batch id 92401 / 225000 loss 1.8136050701141357 train acc 0.7874671269791452\n",
      "epoch 4 batch id 92501 / 225000 loss 0.004984670784324408 train acc 0.7875022972724619\n",
      "epoch 4 batch id 92601 / 225000 loss 0.012527260929346085 train acc 0.7874779969978726\n",
      "epoch 4 batch id 92701 / 225000 loss 2.0598084926605225 train acc 0.7874564459930313\n",
      "epoch 4 batch id 92801 / 225000 loss 3.0499138832092285 train acc 0.7874484111162595\n",
      "epoch 4 batch id 92901 / 225000 loss 1.6845614910125732 train acc 0.7874215562803414\n",
      "epoch 4 batch id 93001 / 225000 loss 2.110166072845459 train acc 0.7873920710529995\n",
      "epoch 4 batch id 93101 / 225000 loss 0.0024391296319663525 train acc 0.787405613258719\n",
      "epoch 4 batch id 93201 / 225000 loss 0.011944296769797802 train acc 0.7874244911535284\n",
      "epoch 4 batch id 93301 / 225000 loss 1.0395532846450806 train acc 0.7874379695823196\n",
      "epoch 4 batch id 93401 / 225000 loss 2.7295374870300293 train acc 0.7874514191496879\n",
      "epoch 4 batch id 93501 / 225000 loss 0.002161966636776924 train acc 0.7874247334253109\n",
      "epoch 4 batch id 93601 / 225000 loss 0.7902551293373108 train acc 0.7874274847490945\n",
      "epoch 4 batch id 93701 / 225000 loss 1.0901596546173096 train acc 0.7874222260167981\n",
      "epoch 4 batch id 93801 / 225000 loss 1.715848445892334 train acc 0.7874196437138197\n",
      "epoch 4 batch id 93901 / 225000 loss 0.08230697363615036 train acc 0.7874649897232191\n",
      "epoch 4 batch id 94001 / 225000 loss 0.006795856170356274 train acc 0.7874623674216231\n",
      "epoch 4 batch id 94101 / 225000 loss 1.6190240383148193 train acc 0.7874331834943306\n",
      "epoch 4 batch id 94201 / 225000 loss 0.12122137099504471 train acc 0.7874438700226112\n",
      "epoch 4 batch id 94301 / 225000 loss 1.830712080001831 train acc 0.7874386273740469\n",
      "epoch 4 batch id 94401 / 225000 loss 0.8175498247146606 train acc 0.787459878602981\n",
      "epoch 4 batch id 94501 / 225000 loss 0.0019273930229246616 train acc 0.7874757939069428\n",
      "epoch 4 batch id 94601 / 225000 loss 1.1851142644882202 train acc 0.7874996035982706\n",
      "epoch 4 batch id 94701 / 225000 loss 0.002132537541911006 train acc 0.7875550416574271\n",
      "epoch 4 batch id 94801 / 225000 loss 0.0386231355369091 train acc 0.7876314595837597\n",
      "epoch 4 batch id 94901 / 225000 loss 0.009862499311566353 train acc 0.7876655672753712\n",
      "epoch 4 batch id 95001 / 225000 loss 1.4672126770019531 train acc 0.7876469721371354\n",
      "epoch 4 batch id 95101 / 225000 loss 0.031829606741666794 train acc 0.7876284161049831\n",
      "epoch 4 batch id 95201 / 225000 loss 1.0042378902435303 train acc 0.7876440373525488\n",
      "epoch 4 batch id 95301 / 225000 loss 0.960307776927948 train acc 0.7876438862131562\n",
      "epoch 4 batch id 95401 / 225000 loss 0.004960227757692337 train acc 0.7876411148730097\n",
      "epoch 4 batch id 95501 / 225000 loss 0.002099116798490286 train acc 0.7876462026575638\n",
      "epoch 4 batch id 95601 / 225000 loss 1.1905286312103271 train acc 0.7876512797983285\n",
      "epoch 4 batch id 95701 / 225000 loss 1.3692396879196167 train acc 0.787661570934473\n",
      "epoch 4 batch id 95801 / 225000 loss 0.945618748664856 train acc 0.7876744501623156\n",
      "epoch 4 batch id 95901 / 225000 loss 1.7549464702606201 train acc 0.7876664476908478\n",
      "epoch 4 batch id 96001 / 225000 loss 3.3961639404296875 train acc 0.7876402329142405\n",
      "epoch 4 batch id 96101 / 225000 loss 1.0687856674194336 train acc 0.7876348841323191\n",
      "epoch 4 batch id 96201 / 225000 loss 1.2017464637756348 train acc 0.7876477375495057\n",
      "epoch 4 batch id 96301 / 225000 loss 1.860901951789856 train acc 0.7876475841372363\n",
      "epoch 4 batch id 96401 / 225000 loss 3.5352282524108887 train acc 0.7876370577068703\n",
      "epoch 4 batch id 96501 / 225000 loss 0.7379524111747742 train acc 0.7876498689132755\n",
      "epoch 4 batch id 96601 / 225000 loss 0.0009256949997507036 train acc 0.7876704174905022\n",
      "epoch 4 batch id 96701 / 225000 loss 3.331967830657959 train acc 0.7876754118364857\n",
      "epoch 4 batch id 96801 / 225000 loss 0.0011633224785327911 train acc 0.7876700653918864\n",
      "epoch 4 batch id 96901 / 225000 loss 2.7096304893493652 train acc 0.7876802096985583\n",
      "epoch 4 batch id 97001 / 225000 loss 1.309617280960083 train acc 0.7876826012102968\n",
      "epoch 4 batch id 97101 / 225000 loss 0.0015633186558261514 train acc 0.7876849877962122\n",
      "epoch 4 batch id 97201 / 225000 loss 0.0017603269079700112 train acc 0.7876976574315079\n",
      "epoch 4 batch id 97301 / 225000 loss 0.39819273352622986 train acc 0.7876820382113237\n",
      "epoch 4 batch id 97401 / 225000 loss 1.5849354267120361 train acc 0.7876895514419769\n",
      "epoch 4 batch id 97501 / 225000 loss 0.0032543072011321783 train acc 0.7877303822524897\n",
      "epoch 4 batch id 97601 / 225000 loss 2.7605669498443604 train acc 0.7876968473683671\n",
      "epoch 4 batch id 97701 / 225000 loss 0.0032381615601480007 train acc 0.7877119988536453\n",
      "epoch 4 batch id 97801 / 225000 loss 0.015857094898819923 train acc 0.7877194507213627\n",
      "epoch 4 batch id 97901 / 225000 loss 0.0015222568763419986 train acc 0.787752423366462\n",
      "epoch 4 batch id 98001 / 225000 loss 0.0008113976800814271 train acc 0.7877674717604922\n",
      "epoch 4 batch id 98101 / 225000 loss 1.364395260810852 train acc 0.7878003282331475\n",
      "epoch 4 batch id 98201 / 225000 loss 0.9690133333206177 train acc 0.7878254803922567\n",
      "epoch 4 batch id 98301 / 225000 loss 0.003587198443710804 train acc 0.7878226060772525\n",
      "epoch 4 batch id 98401 / 225000 loss 0.002306915121152997 train acc 0.7878629282222742\n",
      "epoch 4 batch id 98501 / 225000 loss 0.04050897806882858 train acc 0.7878930163145552\n",
      "epoch 4 batch id 98601 / 225000 loss 0.9745415449142456 train acc 0.7879179724343567\n",
      "epoch 4 batch id 98701 / 225000 loss 0.2429048717021942 train acc 0.787912483156199\n",
      "epoch 4 batch id 98801 / 225000 loss 1.6503429412841797 train acc 0.7879323083774455\n",
      "epoch 4 batch id 98901 / 225000 loss 1.2904542684555054 train acc 0.787952093507649\n",
      "epoch 4 batch id 99001 / 225000 loss 4.062036991119385 train acc 0.7879415359440813\n",
      "epoch 4 batch id 99101 / 225000 loss 1.096663236618042 train acc 0.7879259543294215\n",
      "epoch 4 batch id 99201 / 225000 loss 0.8063048124313354 train acc 0.7878952833136763\n",
      "epoch 4 batch id 99301 / 225000 loss 0.0026731835678219795 train acc 0.7878772620618121\n",
      "epoch 4 batch id 99401 / 225000 loss 0.7986124753952026 train acc 0.787874367461092\n",
      "epoch 4 batch id 99501 / 225000 loss 2.666564464569092 train acc 0.7878790162912935\n",
      "epoch 4 batch id 99601 / 225000 loss 0.0012143554631620646 train acc 0.7879363661007419\n",
      "epoch 4 batch id 99701 / 225000 loss 0.36227497458457947 train acc 0.7879183759440728\n",
      "epoch 4 batch id 99801 / 225000 loss 0.003069673664867878 train acc 0.7879354916283404\n",
      "epoch 4 batch id 99901 / 225000 loss 0.2775373160839081 train acc 0.7879450656149588\n",
      "epoch 4 batch id 100001 / 225000 loss 0.005679296795278788 train acc 0.7879896201037989\n",
      "epoch 4 batch id 100101 / 225000 loss 1.0889548063278198 train acc 0.7879716486348788\n",
      "epoch 4 batch id 100201 / 225000 loss 1.2860932350158691 train acc 0.7879711779323559\n",
      "epoch 4 batch id 100301 / 225000 loss 0.003176304744556546 train acc 0.7879756931635776\n",
      "epoch 4 batch id 100401 / 225000 loss 1.2181847095489502 train acc 0.7879801994004044\n",
      "epoch 4 batch id 100501 / 225000 loss 0.0035462831147015095 train acc 0.7879871842071223\n",
      "epoch 4 batch id 100601 / 225000 loss 0.40127187967300415 train acc 0.7879618492857924\n",
      "epoch 4 batch id 100701 / 225000 loss 2.9591615200042725 train acc 0.7879564254575426\n",
      "epoch 4 batch id 100801 / 225000 loss 0.2372460514307022 train acc 0.7879609329272527\n",
      "epoch 4 batch id 100901 / 225000 loss 0.05415383726358414 train acc 0.7879654314625226\n",
      "epoch 4 batch id 101001 / 225000 loss 0.083947092294693 train acc 0.7879748715359254\n",
      "epoch 4 batch id 101101 / 225000 loss 0.705422043800354 train acc 0.787976874610538\n",
      "epoch 4 batch id 101201 / 225000 loss 0.004391036927700043 train acc 0.7879986363771109\n",
      "epoch 4 batch id 101301 / 225000 loss 1.2648215293884277 train acc 0.7879932083592462\n",
      "epoch 4 batch id 101401 / 225000 loss 0.2900180220603943 train acc 0.787980394670664\n",
      "epoch 4 batch id 101501 / 225000 loss 0.0012312469771131873 train acc 0.7880316450084236\n",
      "epoch 4 batch id 101601 / 225000 loss 0.8099843263626099 train acc 0.7880434247694412\n",
      "epoch 4 batch id 101701 / 225000 loss 2.9331936836242676 train acc 0.7880478068062261\n",
      "epoch 4 batch id 101801 / 225000 loss 0.001692810794338584 train acc 0.7880841052641919\n",
      "epoch 4 batch id 101901 / 225000 loss 2.63549542427063 train acc 0.7881080656715832\n",
      "epoch 4 batch id 102001 / 225000 loss 0.002625376218929887 train acc 0.7881148224037019\n",
      "epoch 4 batch id 102101 / 225000 loss 0.5235965847969055 train acc 0.7880995288978561\n",
      "epoch 4 batch id 102201 / 225000 loss 2.877990245819092 train acc 0.7881062807604622\n",
      "epoch 4 batch id 102301 / 225000 loss 0.7731647491455078 train acc 0.7881496759562467\n",
      "epoch 4 batch id 102401 / 225000 loss 0.4920032322406769 train acc 0.7881758967197586\n",
      "epoch 4 batch id 102501 / 225000 loss 0.9915662407875061 train acc 0.788199627320709\n",
      "epoch 4 batch id 102601 / 225000 loss 3.512739658355713 train acc 0.7882038186762312\n",
      "epoch 4 batch id 102701 / 225000 loss 0.21004797518253326 train acc 0.7881812251097847\n",
      "epoch 4 batch id 102801 / 225000 loss 2.2235641479492188 train acc 0.7881708349140573\n",
      "epoch 4 batch id 102901 / 225000 loss 1.8531392812728882 train acc 0.7881604649128774\n",
      "epoch 4 batch id 103001 / 225000 loss 0.008148003369569778 train acc 0.7881840953000456\n",
      "epoch 4 batch id 103101 / 225000 loss 0.1451769322156906 train acc 0.7881785821670013\n",
      "epoch 4 batch id 103201 / 225000 loss 0.8974459171295166 train acc 0.7881343204038721\n",
      "epoch 4 batch id 103301 / 225000 loss 5.147892951965332 train acc 0.7881385465774775\n",
      "epoch 4 batch id 103401 / 225000 loss 0.003546783234924078 train acc 0.7881379290335684\n",
      "epoch 4 batch id 103501 / 225000 loss 0.0013279718114063144 train acc 0.7881373126829693\n",
      "epoch 4 batch id 103601 / 225000 loss 1.1050831079483032 train acc 0.7881463499387071\n",
      "epoch 4 batch id 103701 / 225000 loss 1.8736780881881714 train acc 0.7881650128735499\n",
      "epoch 4 batch id 103801 / 225000 loss 4.6756792068481445 train acc 0.7881788229400487\n",
      "epoch 4 batch id 103901 / 225000 loss 0.0007166812429204583 train acc 0.7881926064234223\n",
      "epoch 4 batch id 104001 / 225000 loss 1.8552874326705933 train acc 0.7881630945856289\n",
      "epoch 4 batch id 104101 / 225000 loss 1.6985455751419067 train acc 0.7881936772941662\n",
      "epoch 4 batch id 104201 / 225000 loss 0.2914714813232422 train acc 0.7882218020940298\n",
      "epoch 4 batch id 104301 / 225000 loss 2.2851991653442383 train acc 0.7881923471491165\n",
      "epoch 4 batch id 104401 / 225000 loss 2.212155342102051 train acc 0.7881749216961523\n",
      "epoch 4 batch id 104501 / 225000 loss 0.5831510424613953 train acc 0.7881838451306686\n",
      "epoch 4 batch id 104601 / 225000 loss 0.8015596866607666 train acc 0.788223821951989\n",
      "epoch 4 batch id 104701 / 225000 loss 3.8759400844573975 train acc 0.7882398448916438\n",
      "epoch 4 batch id 104801 / 225000 loss 0.0032910953741520643 train acc 0.7882367534660929\n",
      "epoch 4 batch id 104901 / 225000 loss 3.4976282119750977 train acc 0.7882670327260941\n",
      "epoch 4 batch id 105001 / 225000 loss 0.6628719568252563 train acc 0.7882853496633365\n",
      "epoch 4 batch id 105101 / 225000 loss 0.7569805979728699 train acc 0.7882560584580547\n",
      "epoch 4 batch id 105201 / 225000 loss 0.015131083317101002 train acc 0.7882814802140664\n",
      "epoch 4 batch id 105301 / 225000 loss 0.004330742172896862 train acc 0.7882902346606395\n",
      "epoch 4 batch id 105401 / 225000 loss 2.7252135276794434 train acc 0.7882942287075075\n",
      "epoch 4 batch id 105501 / 225000 loss 0.005432885140180588 train acc 0.7883076937659359\n",
      "epoch 4 batch id 105601 / 225000 loss 1.1400631666183472 train acc 0.7883045615098342\n",
      "epoch 4 batch id 105701 / 225000 loss 0.2271050661802292 train acc 0.7883274519635576\n",
      "epoch 4 batch id 105801 / 225000 loss 0.003310231026262045 train acc 0.7883148552471149\n",
      "epoch 4 batch id 105901 / 225000 loss 1.4084396362304688 train acc 0.7883494962276089\n",
      "epoch 4 batch id 106001 / 225000 loss 0.2980805039405823 train acc 0.7883416194186847\n",
      "epoch 4 batch id 106101 / 225000 loss 0.44857221841812134 train acc 0.7883573199121592\n",
      "epoch 4 batch id 106201 / 225000 loss 1.2272531986236572 train acc 0.7883400344629523\n",
      "epoch 4 batch id 106301 / 225000 loss 1.0588078498840332 train acc 0.7883533550954366\n",
      "epoch 4 batch id 106401 / 225000 loss 0.7501512765884399 train acc 0.7883314066597118\n",
      "epoch 4 batch id 106501 / 225000 loss 0.154054194688797 train acc 0.7883400155867081\n",
      "epoch 4 batch id 106601 / 225000 loss 0.7684438228607178 train acc 0.7883532987495427\n",
      "epoch 4 batch id 106701 / 225000 loss 0.001578085357323289 train acc 0.7883735860020056\n",
      "epoch 4 batch id 106801 / 225000 loss 0.0019390954403206706 train acc 0.7884102208780817\n",
      "epoch 4 batch id 106901 / 225000 loss 0.001025685458444059 train acc 0.7884467872143385\n",
      "epoch 4 batch id 107001 / 225000 loss 0.7713810801506042 train acc 0.7884645937888431\n",
      "epoch 4 batch id 107101 / 225000 loss 3.536038875579834 train acc 0.7884893698471537\n",
      "epoch 4 batch id 107201 / 225000 loss 0.010615803301334381 train acc 0.7884814507327357\n",
      "epoch 4 batch id 107301 / 225000 loss 1.9086071252822876 train acc 0.788485195850924\n",
      "epoch 4 batch id 107401 / 225000 loss 0.21748781204223633 train acc 0.788479623094757\n",
      "epoch 4 batch id 107501 / 225000 loss 0.05939443036913872 train acc 0.7884926651845099\n",
      "epoch 4 batch id 107601 / 225000 loss 1.2159751653671265 train acc 0.7885010362357228\n",
      "epoch 4 batch id 107701 / 225000 loss 0.18421603739261627 train acc 0.7885024280183099\n",
      "epoch 4 batch id 107801 / 225000 loss 0.21268366277217865 train acc 0.7885107744826115\n",
      "epoch 4 batch id 107901 / 225000 loss 0.6110875010490417 train acc 0.7885538595564453\n",
      "epoch 4 batch id 108001 / 225000 loss 0.9689671397209167 train acc 0.788592235257081\n",
      "epoch 4 batch id 108101 / 225000 loss 0.02089412696659565 train acc 0.7885889122209785\n",
      "epoch 4 batch id 108201 / 225000 loss 1.4708715677261353 train acc 0.7886040794447371\n",
      "epoch 4 batch id 108301 / 225000 loss 0.020464101806282997 train acc 0.7886122935152954\n",
      "epoch 4 batch id 108401 / 225000 loss 0.005614887457340956 train acc 0.7886181861790943\n",
      "epoch 4 batch id 108501 / 225000 loss 0.02938721887767315 train acc 0.7886332844858572\n",
      "epoch 4 batch id 108601 / 225000 loss 2.8928043842315674 train acc 0.7886207309324961\n",
      "epoch 4 batch id 108701 / 225000 loss 0.0732281506061554 train acc 0.7886013008159999\n",
      "epoch 4 batch id 108801 / 225000 loss 0.0687604770064354 train acc 0.7886117774652807\n",
      "epoch 4 batch id 108901 / 225000 loss 0.004966785665601492 train acc 0.7886176435478095\n",
      "epoch 4 batch id 109001 / 225000 loss 2.326543092727661 train acc 0.7886395537655618\n",
      "epoch 4 batch id 109101 / 225000 loss 0.3124859631061554 train acc 0.7886522579994684\n",
      "epoch 4 batch id 109201 / 225000 loss 0.013741472736001015 train acc 0.7886580708967866\n",
      "epoch 4 batch id 109301 / 225000 loss 0.7296054363250732 train acc 0.7886844585136458\n",
      "epoch 4 batch id 109401 / 225000 loss 0.004590118303894997 train acc 0.7886925165217868\n",
      "epoch 4 batch id 109501 / 225000 loss 0.9649521708488464 train acc 0.7886937105597209\n",
      "epoch 4 batch id 109601 / 225000 loss 3.0389740467071533 train acc 0.7886949024187736\n",
      "epoch 4 batch id 109701 / 225000 loss 0.5544460415840149 train acc 0.7887029288702929\n",
      "epoch 4 batch id 109801 / 225000 loss 0.8488273024559021 train acc 0.7887018333166365\n",
      "epoch 4 batch id 109901 / 225000 loss 0.004552255850285292 train acc 0.788743960473517\n",
      "epoch 4 batch id 110001 / 225000 loss 0.6700797080993652 train acc 0.7887291933709694\n",
      "epoch 4 batch id 110101 / 225000 loss 3.4406964778900146 train acc 0.7886917466689676\n",
      "epoch 4 batch id 110201 / 225000 loss 0.0025954782031476498 train acc 0.7886793223291985\n",
      "epoch 4 batch id 110301 / 225000 loss 1.388305902481079 train acc 0.7886691870427285\n",
      "epoch 4 batch id 110401 / 225000 loss 0.010029722936451435 train acc 0.7886635990616027\n",
      "epoch 4 batch id 110501 / 225000 loss 0.7613052725791931 train acc 0.7886783830010589\n",
      "epoch 4 batch id 110601 / 225000 loss 3.1176109313964844 train acc 0.7886863590745111\n",
      "epoch 4 batch id 110701 / 225000 loss 1.5558382272720337 train acc 0.7886943207378434\n",
      "epoch 4 batch id 110801 / 225000 loss 6.512851715087891 train acc 0.7887180621113528\n",
      "epoch 4 batch id 110901 / 225000 loss 0.6362211108207703 train acc 0.7887079467272613\n",
      "epoch 4 batch id 111001 / 225000 loss 0.004813737701624632 train acc 0.7887203718885415\n",
      "epoch 4 batch id 111101 / 225000 loss 3.295032501220703 train acc 0.7887215236586529\n",
      "epoch 4 batch id 111201 / 225000 loss 0.013255852274596691 train acc 0.7887451551694679\n",
      "epoch 4 batch id 111301 / 225000 loss 0.005234743934124708 train acc 0.7887372979577901\n",
      "epoch 4 batch id 111401 / 225000 loss 0.6209317445755005 train acc 0.7887586287376236\n",
      "epoch 4 batch id 111501 / 225000 loss 0.05035432055592537 train acc 0.7887888897857418\n",
      "epoch 4 batch id 111601 / 225000 loss 1.233279824256897 train acc 0.7887854947536312\n",
      "epoch 4 batch id 111701 / 225000 loss 0.14875571429729462 train acc 0.7887843439181386\n",
      "epoch 4 batch id 111801 / 225000 loss 2.583617687225342 train acc 0.7888010840690155\n",
      "epoch 4 batch id 111901 / 225000 loss 0.3310132324695587 train acc 0.7887798143001403\n",
      "epoch 4 batch id 112001 / 225000 loss 0.00315635884180665 train acc 0.788767511004366\n",
      "epoch 4 batch id 112101 / 225000 loss 1.6868780851364136 train acc 0.7887574597907244\n",
      "epoch 4 batch id 112201 / 225000 loss 4.371945858001709 train acc 0.7887496546376592\n",
      "epoch 4 batch id 112301 / 225000 loss 0.007845129817724228 train acc 0.788761898825478\n",
      "epoch 4 batch id 112401 / 225000 loss 1.3526253700256348 train acc 0.7887563277906781\n",
      "epoch 4 batch id 112501 / 225000 loss 0.002259758533909917 train acc 0.7887818774944223\n",
      "epoch 4 batch id 112601 / 225000 loss 0.002689352724701166 train acc 0.788802941359313\n",
      "epoch 4 batch id 112701 / 225000 loss 0.10937071591615677 train acc 0.7888017852547892\n",
      "epoch 4 batch id 112801 / 225000 loss 0.8838571310043335 train acc 0.7887895497380343\n",
      "epoch 4 batch id 112901 / 225000 loss 0.09252238273620605 train acc 0.7888326941302557\n",
      "epoch 4 batch id 113001 / 225000 loss 0.0009880426805466413 train acc 0.7888116034371377\n",
      "epoch 4 batch id 113101 / 225000 loss 1.4372442960739136 train acc 0.7888281270722628\n",
      "epoch 4 batch id 113201 / 225000 loss 0.23451901972293854 train acc 0.7888490384360562\n",
      "epoch 4 batch id 113301 / 225000 loss 3.183502674102783 train acc 0.7888522607920495\n",
      "epoch 4 batch id 113401 / 225000 loss 2.2021477222442627 train acc 0.7888687048615092\n",
      "epoch 4 batch id 113501 / 225000 loss 0.002999153221026063 train acc 0.7888961330737174\n",
      "epoch 4 batch id 113601 / 225000 loss 0.0018851811764761806 train acc 0.7889081082032728\n",
      "epoch 4 batch id 113701 / 225000 loss 0.006160533055663109 train acc 0.7888848822789597\n",
      "epoch 4 batch id 113801 / 225000 loss 0.0007447980460710824 train acc 0.7889056335181589\n",
      "epoch 4 batch id 113901 / 225000 loss 0.0045514837838709354 train acc 0.7888956198804224\n",
      "epoch 4 batch id 114001 / 225000 loss 0.08129877597093582 train acc 0.7889250971482706\n",
      "epoch 4 batch id 114101 / 225000 loss 2.943138837814331 train acc 0.7889019377568995\n",
      "epoch 4 batch id 114201 / 225000 loss 2.015596866607666 train acc 0.788891953660651\n",
      "epoch 4 batch id 114301 / 225000 loss 2.551023244857788 train acc 0.7888929230715391\n",
      "epoch 4 batch id 114401 / 225000 loss 0.003678391221910715 train acc 0.7889244849258311\n",
      "epoch 4 batch id 114501 / 225000 loss 0.008620805107057095 train acc 0.7889276076191475\n",
      "epoch 4 batch id 114601 / 225000 loss 1.8358042240142822 train acc 0.7889350878264587\n",
      "epoch 4 batch id 114701 / 225000 loss 0.3362460434436798 train acc 0.7889294775110941\n",
      "epoch 4 batch id 114801 / 225000 loss 0.00672597112134099 train acc 0.78893041001385\n",
      "epoch 4 batch id 114901 / 225000 loss 0.9776304960250854 train acc 0.7889248135351302\n",
      "epoch 4 batch id 115001 / 225000 loss 1.4081568717956543 train acc 0.7889322701541726\n",
      "epoch 4 batch id 115101 / 225000 loss 0.029197387397289276 train acc 0.7889788099147705\n",
      "epoch 4 batch id 115201 / 225000 loss 0.0014378358609974384 train acc 0.7889753561167003\n",
      "epoch 4 batch id 115301 / 225000 loss 0.0007337908027693629 train acc 0.7889784130233042\n",
      "epoch 4 batch id 115401 / 225000 loss 0.0053617507219314575 train acc 0.7889749655548912\n",
      "epoch 4 batch id 115501 / 225000 loss 0.006590276025235653 train acc 0.7889758530229175\n",
      "epoch 4 batch id 115601 / 225000 loss 2.8641984462738037 train acc 0.7889594380671447\n",
      "epoch 4 batch id 115701 / 225000 loss 0.012664620764553547 train acc 0.7889841055824928\n",
      "epoch 4 batch id 115801 / 225000 loss 0.738911509513855 train acc 0.7890087304945553\n",
      "epoch 4 batch id 115901 / 225000 loss 0.0025006933137774467 train acc 0.7890311559002943\n",
      "epoch 4 batch id 116001 / 225000 loss 1.8703689575195312 train acc 0.7890621632572133\n",
      "epoch 4 batch id 116101 / 225000 loss 0.0026693195104599 train acc 0.7890694309265208\n",
      "epoch 4 batch id 116201 / 225000 loss 0.002347217872738838 train acc 0.7890659288646397\n",
      "epoch 4 batch id 116301 / 225000 loss 0.009206952527165413 train acc 0.7890731807981015\n",
      "epoch 4 batch id 116401 / 225000 loss 1.1254347562789917 train acc 0.7890589427925877\n",
      "epoch 4 batch id 116501 / 225000 loss 0.0028469874523580074 train acc 0.789061896464408\n",
      "epoch 4 batch id 116601 / 225000 loss 0.015557662583887577 train acc 0.7890562688141611\n",
      "epoch 4 batch id 116701 / 225000 loss 1.0071548223495483 train acc 0.7890806419825023\n",
      "epoch 4 batch id 116801 / 225000 loss 2.442892551422119 train acc 0.7890814290973536\n",
      "epoch 4 batch id 116901 / 225000 loss 1.0608429908752441 train acc 0.7890800763038811\n",
      "epoch 4 batch id 117001 / 225000 loss 0.016804682090878487 train acc 0.7890744523551081\n",
      "epoch 4 batch id 117101 / 225000 loss 1.4230612516403198 train acc 0.7890773776483548\n",
      "epoch 4 batch id 117201 / 225000 loss 1.1911590099334717 train acc 0.7891208266141074\n",
      "epoch 4 batch id 117301 / 225000 loss 0.01881309412419796 train acc 0.7891151823087612\n",
      "epoch 4 batch id 117401 / 225000 loss 1.8400592803955078 train acc 0.7891201948876074\n",
      "epoch 4 batch id 117501 / 225000 loss 0.0010999646037817001 train acc 0.7891400924247454\n",
      "epoch 4 batch id 117601 / 225000 loss 0.0044104233384132385 train acc 0.7891599561228221\n",
      "epoch 4 batch id 117701 / 225000 loss 3.060729503631592 train acc 0.7891946542510259\n",
      "epoch 4 batch id 117801 / 225000 loss 3.575303316116333 train acc 0.789227171246424\n",
      "epoch 4 batch id 117901 / 225000 loss 1.256937861442566 train acc 0.7892235858898567\n",
      "epoch 4 batch id 118001 / 225000 loss 0.2355218082666397 train acc 0.7892263624884535\n",
      "epoch 4 batch id 118101 / 225000 loss 0.8878220319747925 train acc 0.789250302707005\n",
      "epoch 4 batch id 118201 / 225000 loss 0.006040921434760094 train acc 0.7892488219219803\n",
      "epoch 4 batch id 118301 / 225000 loss 0.537792444229126 train acc 0.7892156448381671\n",
      "epoch 4 batch id 118401 / 225000 loss 0.0011064070276916027 train acc 0.7892226417006614\n",
      "epoch 4 batch id 118501 / 225000 loss 0.10662996023893356 train acc 0.789238065501557\n",
      "epoch 4 batch id 118601 / 225000 loss 2.4920973777770996 train acc 0.7892640028330284\n",
      "epoch 4 batch id 118701 / 225000 loss 0.0012992825359106064 train acc 0.7892414554216055\n",
      "epoch 4 batch id 118801 / 225000 loss 1.6187570095062256 train acc 0.7892399895623774\n",
      "epoch 4 batch id 118901 / 225000 loss 0.42579084634780884 train acc 0.7892469365270267\n",
      "epoch 4 batch id 119001 / 225000 loss 0.341796338558197 train acc 0.7892559726388854\n",
      "epoch 4 batch id 119101 / 225000 loss 0.07453683763742447 train acc 0.7892461020478417\n",
      "epoch 4 batch id 119201 / 225000 loss 0.9205721020698547 train acc 0.7892320534223706\n",
      "epoch 4 batch id 119301 / 225000 loss 1.3955790996551514 train acc 0.7892515569861107\n",
      "epoch 4 batch id 119401 / 225000 loss 1.0437040328979492 train acc 0.7892731216656477\n",
      "epoch 4 batch id 119501 / 225000 loss 2.2756476402282715 train acc 0.7892695458615409\n",
      "epoch 4 batch id 119601 / 225000 loss 1.926558494567871 train acc 0.7892806080216721\n",
      "epoch 4 batch id 119701 / 225000 loss 0.0014397980412468314 train acc 0.7892979173106324\n",
      "epoch 4 batch id 119801 / 225000 loss 0.004603871610015631 train acc 0.7893068505271241\n",
      "epoch 4 batch id 119901 / 225000 loss 0.0014156956458464265 train acc 0.7893074286286186\n",
      "epoch 4 batch id 120001 / 225000 loss 0.002946461783722043 train acc 0.7893142557145357\n",
      "epoch 4 batch id 120101 / 225000 loss 0.01667914353311062 train acc 0.7892898477115095\n",
      "epoch 4 batch id 120201 / 225000 loss 0.36125996708869934 train acc 0.7893091571617541\n",
      "epoch 4 batch id 120301 / 225000 loss 0.6710909605026245 train acc 0.7893305126308177\n",
      "epoch 4 batch id 120401 / 225000 loss 1.4493809938430786 train acc 0.7893663673889751\n",
      "epoch 4 batch id 120501 / 225000 loss 1.116842269897461 train acc 0.7893751919071211\n",
      "epoch 4 batch id 120601 / 225000 loss 1.9496705532073975 train acc 0.7893591263754032\n",
      "epoch 4 batch id 120701 / 225000 loss 2.8754723072052 train acc 0.7893555148673168\n",
      "epoch 4 batch id 120801 / 225000 loss 2.662010669708252 train acc 0.789391230205048\n",
      "epoch 4 batch id 120901 / 225000 loss 0.19121676683425903 train acc 0.7893979371551931\n",
      "epoch 4 batch id 121001 / 225000 loss 0.00818836409598589 train acc 0.78939843472368\n",
      "epoch 4 batch id 121101 / 225000 loss 2.0999021530151367 train acc 0.7894030602554892\n",
      "epoch 4 batch id 121201 / 225000 loss 1.509052038192749 train acc 0.7894221169792328\n",
      "epoch 4 batch id 121301 / 225000 loss 1.9338136911392212 train acc 0.7894287763497415\n",
      "epoch 4 batch id 121401 / 225000 loss 0.0010267987381666899 train acc 0.7894354247493842\n",
      "epoch 4 batch id 121501 / 225000 loss 2.1646933555603027 train acc 0.7894050254730414\n",
      "epoch 4 batch id 121601 / 225000 loss 0.0013314347015693784 train acc 0.7894260737987352\n",
      "epoch 4 batch id 121701 / 225000 loss 0.864652156829834 train acc 0.7894470875342027\n",
      "epoch 4 batch id 121801 / 225000 loss 0.0008460565004497766 train acc 0.7894680667646407\n",
      "epoch 4 batch id 121901 / 225000 loss 1.3818690776824951 train acc 0.7894602997514376\n",
      "epoch 4 batch id 122001 / 225000 loss 0.1410209834575653 train acc 0.7894545946344702\n",
      "epoch 4 batch id 122101 / 225000 loss 0.6476011872291565 train acc 0.7894857535974317\n",
      "epoch 4 batch id 122201 / 225000 loss 1.847122073173523 train acc 0.7894616247002889\n",
      "epoch 4 batch id 122301 / 225000 loss 0.27336734533309937 train acc 0.7894743297274757\n",
      "epoch 4 batch id 122401 / 225000 loss 1.08420729637146 train acc 0.7894972263298502\n",
      "epoch 4 batch id 122501 / 225000 loss 0.002644553780555725 train acc 0.7895323303483237\n",
      "epoch 4 batch id 122601 / 225000 loss 1.4645251035690308 train acc 0.7895388292102022\n",
      "epoch 4 batch id 122701 / 225000 loss 1.4420826435089111 train acc 0.7895412425326607\n",
      "epoch 4 batch id 122801 / 225000 loss 0.002534934552386403 train acc 0.7895375444825368\n",
      "epoch 4 batch id 122901 / 225000 loss 2.2620668411254883 train acc 0.7895399549230682\n",
      "epoch 4 batch id 123001 / 225000 loss 0.6109998226165771 train acc 0.7895098413834034\n",
      "epoch 4 batch id 123101 / 225000 loss 0.0020776318851858377 train acc 0.7895285172338161\n",
      "epoch 4 batch id 123201 / 225000 loss 0.45315083861351013 train acc 0.7895248415191435\n",
      "epoch 4 batch id 123301 / 225000 loss 1.6331803798675537 train acc 0.7895576678210233\n",
      "epoch 4 batch id 123401 / 225000 loss 0.4705260396003723 train acc 0.7895438448634938\n",
      "epoch 4 batch id 123501 / 225000 loss 0.0028981028590351343 train acc 0.789546238491996\n",
      "epoch 4 batch id 123601 / 225000 loss 0.33114609122276306 train acc 0.7895344697858432\n",
      "epoch 4 batch id 123701 / 225000 loss 3.1195526123046875 train acc 0.7895308041163774\n",
      "epoch 4 batch id 123801 / 225000 loss 0.0011570827336981893 train acc 0.7895231056291953\n",
      "epoch 4 batch id 123901 / 225000 loss 0.0051918174140155315 train acc 0.789519455048789\n",
      "epoch 4 batch id 124001 / 225000 loss 0.0013354949187487364 train acc 0.7895279070330078\n",
      "epoch 4 batch id 124101 / 225000 loss 0.0009260022197850049 train acc 0.7895504468134825\n",
      "epoch 4 batch id 124201 / 225000 loss 2.6086602210998535 train acc 0.7895487959034146\n",
      "epoch 4 batch id 124301 / 225000 loss 0.002972383052110672 train acc 0.7895491588965495\n",
      "epoch 4 batch id 124401 / 225000 loss 0.005684191826730967 train acc 0.7895555501965418\n",
      "epoch 4 batch id 124501 / 225000 loss 0.0021129155065864325 train acc 0.7895759873414672\n",
      "epoch 4 batch id 124601 / 225000 loss 0.006374850869178772 train acc 0.7896084301089077\n",
      "epoch 4 batch id 124701 / 225000 loss 1.4882417917251587 train acc 0.789628792070633\n",
      "epoch 4 batch id 124801 / 225000 loss 0.20338839292526245 train acc 0.7896431118340398\n",
      "epoch 4 batch id 124901 / 225000 loss 1.0515234470367432 train acc 0.7896534054971538\n",
      "epoch 4 batch id 125001 / 225000 loss 1.8752485513687134 train acc 0.7896396828825369\n",
      "epoch 4 batch id 125101 / 225000 loss 0.005845868028700352 train acc 0.7896659499124707\n",
      "epoch 4 batch id 125201 / 225000 loss 0.625152051448822 train acc 0.7896881814043019\n",
      "epoch 4 batch id 125301 / 225000 loss 1.7258824110031128 train acc 0.7897063870200557\n",
      "epoch 4 batch id 125401 / 225000 loss 0.000522664631716907 train acc 0.7897285508090047\n",
      "epoch 4 batch id 125501 / 225000 loss 0.049689944833517075 train acc 0.7897427112134565\n",
      "epoch 4 batch id 125601 / 225000 loss 0.9932589530944824 train acc 0.7897707820797605\n",
      "epoch 4 batch id 125701 / 225000 loss 0.0020795916207134724 train acc 0.789776930971114\n",
      "epoch 4 batch id 125801 / 225000 loss 1.2279144525527954 train acc 0.7897930064148934\n",
      "epoch 4 batch id 125901 / 225000 loss 2.3050765991210938 train acc 0.7898070706348639\n",
      "epoch 4 batch id 126001 / 225000 loss 0.7195186018943787 train acc 0.7898191284196158\n",
      "epoch 4 batch id 126101 / 225000 loss 0.08624322712421417 train acc 0.7897974639376373\n",
      "epoch 4 batch id 126201 / 225000 loss 3.274796485900879 train acc 0.7897698908883448\n",
      "epoch 4 batch id 126301 / 225000 loss 1.0460994243621826 train acc 0.789797784657287\n",
      "epoch 4 batch id 126401 / 225000 loss 4.831380844116211 train acc 0.7897860776417908\n",
      "epoch 4 batch id 126501 / 225000 loss 1.1140514612197876 train acc 0.7897664840594145\n",
      "epoch 4 batch id 126601 / 225000 loss 3.256700277328491 train acc 0.7897469214303204\n",
      "epoch 4 batch id 126701 / 225000 loss 2.3135738372802734 train acc 0.789788557312097\n",
      "epoch 4 batch id 126801 / 225000 loss 0.4916040599346161 train acc 0.7898182979629498\n",
      "epoch 4 batch id 126901 / 225000 loss 0.0735059455037117 train acc 0.7898322314244962\n",
      "epoch 4 batch id 127001 / 225000 loss 0.00319260498508811 train acc 0.7898363005015708\n",
      "epoch 4 batch id 127101 / 225000 loss 1.6306959390640259 train acc 0.78984233011542\n",
      "epoch 4 batch id 127201 / 225000 loss 2.2142131328582764 train acc 0.7898169039551576\n",
      "epoch 4 batch id 127301 / 225000 loss 2.3984386920928955 train acc 0.7898327585800583\n",
      "epoch 4 batch id 127401 / 225000 loss 0.22856822609901428 train acc 0.7898525129316096\n",
      "epoch 4 batch id 127501 / 225000 loss 2.2846901416778564 train acc 0.7898487070689642\n",
      "epoch 4 batch id 127601 / 225000 loss 0.937500536441803 train acc 0.7898253148486297\n",
      "epoch 4 batch id 127701 / 225000 loss 0.0010770277585834265 train acc 0.7898469863196059\n",
      "epoch 4 batch id 127801 / 225000 loss 0.19289445877075195 train acc 0.7898431937152292\n",
      "epoch 4 batch id 127901 / 225000 loss 0.8538550138473511 train acc 0.7898198606734896\n",
      "epoch 4 batch id 128001 / 225000 loss 1.4602187871932983 train acc 0.7898453918328763\n",
      "epoch 4 batch id 128101 / 225000 loss 0.9657572507858276 train acc 0.7898279482595765\n",
      "epoch 4 batch id 128201 / 225000 loss 0.004225997254252434 train acc 0.7898105318991272\n",
      "epoch 4 batch id 128301 / 225000 loss 1.4983488321304321 train acc 0.7898048339451758\n",
      "epoch 4 batch id 128401 / 225000 loss 1.0459506511688232 train acc 0.7898205621451546\n",
      "epoch 4 batch id 128501 / 225000 loss 1.7188349962234497 train acc 0.7898304293351802\n",
      "epoch 4 batch id 128601 / 225000 loss 2.3982627391815186 train acc 0.7898305611931478\n",
      "epoch 4 batch id 128701 / 225000 loss 2.018597364425659 train acc 0.789844290254155\n",
      "epoch 4 batch id 128801 / 225000 loss 0.008871577680110931 train acc 0.7898444111458762\n",
      "epoch 4 batch id 128901 / 225000 loss 1.91006600856781 train acc 0.7898639265793128\n",
      "epoch 4 batch id 129001 / 225000 loss 1.2352598905563354 train acc 0.7898582181533477\n",
      "epoch 4 batch id 129101 / 225000 loss 1.9373315572738647 train acc 0.7898544550390779\n",
      "epoch 4 batch id 129201 / 225000 loss 0.0014571278588846326 train acc 0.7898739173845404\n",
      "epoch 4 batch id 129301 / 225000 loss 0.9403278827667236 train acc 0.7898875492068893\n",
      "epoch 4 batch id 129401 / 225000 loss 0.3347391188144684 train acc 0.7898741122557013\n",
      "epoch 4 batch id 129501 / 225000 loss 0.7086676955223083 train acc 0.7898761399525872\n",
      "epoch 4 batch id 129601 / 225000 loss 4.703564167022705 train acc 0.789880093517797\n",
      "epoch 4 batch id 129701 / 225000 loss 0.3898707926273346 train acc 0.7899033160885421\n",
      "epoch 4 batch id 129801 / 225000 loss 0.002728536259382963 train acc 0.7899245768522585\n",
      "epoch 4 batch id 129901 / 225000 loss 0.008791727013885975 train acc 0.7899265594568171\n",
      "epoch 4 batch id 130001 / 225000 loss 1.7923130989074707 train acc 0.7899612310674533\n",
      "epoch 4 batch id 130101 / 225000 loss 0.01635681465268135 train acc 0.7899766335385585\n",
      "epoch 4 batch id 130201 / 225000 loss 0.002358031226322055 train acc 0.7899977726745571\n",
      "epoch 4 batch id 130301 / 225000 loss 1.0556870698928833 train acc 0.7899728321348263\n",
      "epoch 4 batch id 130401 / 225000 loss 0.004426388535648584 train acc 0.789970935805707\n",
      "epoch 4 batch id 130501 / 225000 loss 2.193812131881714 train acc 0.7899901150182758\n",
      "epoch 4 batch id 130601 / 225000 loss 0.003398919478058815 train acc 0.7899996937236315\n",
      "epoch 4 batch id 130701 / 225000 loss 0.14433689415454865 train acc 0.7900035194834011\n",
      "epoch 4 batch id 130801 / 225000 loss 1.0980496406555176 train acc 0.7900016054923128\n",
      "epoch 4 batch id 130901 / 225000 loss 1.1658313274383545 train acc 0.7900054239463411\n",
      "epoch 4 batch id 131001 / 225000 loss 0.004649435169994831 train acc 0.790011144953092\n",
      "epoch 4 batch id 131101 / 225000 loss 1.6439311504364014 train acc 0.7900149503054896\n",
      "epoch 4 batch id 131201 / 225000 loss 2.2055702209472656 train acc 0.7900282772234968\n",
      "epoch 4 batch id 131301 / 225000 loss 0.015308571048080921 train acc 0.7900225436211453\n",
      "epoch 4 batch id 131401 / 225000 loss 1.4179847240447998 train acc 0.7900453573412684\n",
      "epoch 4 batch id 131501 / 225000 loss 0.021687500178813934 train acc 0.7900605318590733\n",
      "epoch 4 batch id 131601 / 225000 loss 0.0013976892223581672 train acc 0.7900661849074095\n",
      "epoch 4 batch id 131701 / 225000 loss 0.012065987102687359 train acc 0.7900984047197819\n",
      "epoch 4 batch id 131801 / 225000 loss 0.0065226322039961815 train acc 0.7900907428623455\n",
      "epoch 4 batch id 131901 / 225000 loss 0.603050172328949 train acc 0.7900925694270703\n",
      "epoch 4 batch id 132001 / 225000 loss 4.614757537841797 train acc 0.7900849235990637\n",
      "epoch 4 batch id 132101 / 225000 loss 0.0062480587512254715 train acc 0.7900867518035443\n",
      "epoch 4 batch id 132201 / 225000 loss 0.002901255153119564 train acc 0.7901037057208342\n",
      "epoch 4 batch id 132301 / 225000 loss 0.3668608069419861 train acc 0.7900847310299998\n",
      "epoch 4 batch id 132401 / 225000 loss 0.010873015969991684 train acc 0.7901016608635887\n",
      "epoch 4 batch id 132501 / 225000 loss 0.03897199407219887 train acc 0.7901261122557566\n",
      "epoch 4 batch id 132601 / 225000 loss 0.7260835766792297 train acc 0.7901373292810763\n",
      "epoch 4 batch id 132701 / 225000 loss 2.431725025177002 train acc 0.7901033149712512\n",
      "epoch 4 batch id 132801 / 225000 loss 0.004574494436383247 train acc 0.7900862945309147\n",
      "epoch 4 batch id 132901 / 225000 loss 1.4826990365982056 train acc 0.7900862295994763\n",
      "epoch 4 batch id 133001 / 225000 loss 0.2499445080757141 train acc 0.7900955631912542\n",
      "epoch 4 batch id 133101 / 225000 loss 0.6457340717315674 train acc 0.7900691955732865\n",
      "epoch 4 batch id 133201 / 225000 loss 1.1478387117385864 train acc 0.7900653898994753\n",
      "epoch 4 batch id 133301 / 225000 loss 1.213323950767517 train acc 0.7900278317491992\n",
      "epoch 4 batch id 133401 / 225000 loss 0.01843341626226902 train acc 0.7900371811305762\n",
      "epoch 4 batch id 133501 / 225000 loss 0.9919891953468323 train acc 0.7900296626991559\n",
      "epoch 4 batch id 133601 / 225000 loss 0.020238064229488373 train acc 0.7900427392010538\n",
      "epoch 4 batch id 133701 / 225000 loss 0.06253968179225922 train acc 0.7900520564543272\n",
      "epoch 4 batch id 133801 / 225000 loss 0.9025615453720093 train acc 0.7900707020126905\n",
      "epoch 4 batch id 133901 / 225000 loss 0.45096439123153687 train acc 0.7900855856192261\n",
      "epoch 4 batch id 134001 / 225000 loss 0.5824381113052368 train acc 0.7900761934612428\n",
      "epoch 4 batch id 134101 / 225000 loss 0.12823186814785004 train acc 0.7901264718383905\n",
      "epoch 4 batch id 134201 / 225000 loss 3.0997116565704346 train acc 0.7901356919844115\n",
      "epoch 4 batch id 134301 / 225000 loss 1.6595627069473267 train acc 0.7901430369096284\n",
      "epoch 4 batch id 134401 / 225000 loss 0.014605231583118439 train acc 0.790155951220601\n",
      "epoch 4 batch id 134501 / 225000 loss 4.13330602645874 train acc 0.7901614114393202\n",
      "epoch 4 batch id 134601 / 225000 loss 1.1669191122055054 train acc 0.7901575768382108\n",
      "epoch 4 batch id 134701 / 225000 loss 0.01300618052482605 train acc 0.7901574598555319\n",
      "epoch 4 batch id 134801 / 225000 loss 0.002004049252718687 train acc 0.7901406517755803\n",
      "epoch 4 batch id 134901 / 225000 loss 1.3235512971878052 train acc 0.7901498135669862\n",
      "epoch 4 batch id 135001 / 225000 loss 1.571977138519287 train acc 0.7901700728142754\n",
      "epoch 4 batch id 135101 / 225000 loss 1.1358860731124878 train acc 0.7901940030051591\n",
      "epoch 4 batch id 135201 / 225000 loss 2.504495620727539 train acc 0.7902308414878588\n",
      "epoch 4 batch id 135301 / 225000 loss 0.006557881366461515 train acc 0.7902694732485348\n",
      "epoch 4 batch id 135401 / 225000 loss 0.14933162927627563 train acc 0.7902766596997068\n",
      "epoch 4 batch id 135501 / 225000 loss 0.009473016485571861 train acc 0.790285680548483\n",
      "epoch 4 batch id 135601 / 225000 loss 0.02117825299501419 train acc 0.7902928444480498\n",
      "epoch 4 batch id 135701 / 225000 loss 0.0027778022922575474 train acc 0.790281574933125\n",
      "epoch 4 batch id 135801 / 225000 loss 0.0005534743540920317 train acc 0.7902574355122569\n",
      "epoch 4 batch id 135901 / 225000 loss 0.0067851347848773 train acc 0.7902627648067343\n",
      "epoch 4 batch id 136001 / 225000 loss 2.5737388134002686 train acc 0.7902662480422938\n",
      "epoch 4 batch id 136101 / 225000 loss 3.7184648513793945 train acc 0.7902587049323664\n",
      "epoch 4 batch id 136201 / 225000 loss 1.8344974517822266 train acc 0.7902475018538777\n",
      "epoch 4 batch id 136301 / 225000 loss 0.9596990346908569 train acc 0.7902619936757618\n",
      "epoch 4 batch id 136401 / 225000 loss 0.004499415867030621 train acc 0.790270965755383\n",
      "epoch 4 batch id 136501 / 225000 loss 0.0012023254530504346 train acc 0.7902817561776104\n",
      "epoch 4 batch id 136601 / 225000 loss 0.9202238321304321 train acc 0.790298021244354\n",
      "epoch 4 batch id 136701 / 225000 loss 0.016187483444809914 train acc 0.7903288929854208\n",
      "epoch 4 batch id 136801 / 225000 loss 0.0056772795505821705 train acc 0.7903359624564148\n",
      "epoch 4 batch id 136901 / 225000 loss 0.8696965575218201 train acc 0.7903046727197025\n",
      "epoch 4 batch id 137001 / 225000 loss 0.3019092381000519 train acc 0.7903190487660674\n",
      "epoch 4 batch id 137101 / 225000 loss 0.01653733290731907 train acc 0.7903078752160816\n",
      "epoch 4 batch id 137201 / 225000 loss 0.9676708579063416 train acc 0.7902948958097973\n",
      "epoch 4 batch id 137301 / 225000 loss 0.0013116613263264298 train acc 0.7902873977611233\n",
      "epoch 4 batch id 137401 / 225000 loss 1.4400160312652588 train acc 0.7902908275776741\n",
      "epoch 4 batch id 137501 / 225000 loss 1.670735478401184 train acc 0.7902778888880808\n",
      "epoch 4 batch id 137601 / 225000 loss 0.01703917607665062 train acc 0.7902904048662437\n",
      "epoch 4 batch id 137701 / 225000 loss 2.9534194469451904 train acc 0.7902593299976035\n",
      "epoch 4 batch id 137801 / 225000 loss 0.1478222757577896 train acc 0.7902482565438568\n",
      "epoch 4 batch id 137901 / 225000 loss 0.9990982413291931 train acc 0.7902480765186619\n",
      "epoch 4 batch id 138001 / 225000 loss 1.4506334066390991 train acc 0.7902515199165223\n",
      "epoch 4 batch id 138101 / 225000 loss 0.0007047417457215488 train acc 0.7902549583276008\n",
      "epoch 4 batch id 138201 / 225000 loss 1.8903363943099976 train acc 0.7902547738438941\n",
      "epoch 4 batch id 138301 / 225000 loss 2.152120351791382 train acc 0.790254589626973\n",
      "epoch 4 batch id 138401 / 225000 loss 2.333589553833008 train acc 0.7902525993309297\n",
      "epoch 4 batch id 138501 / 225000 loss 1.0611801147460938 train acc 0.7902325614977509\n",
      "epoch 4 batch id 138601 / 225000 loss 0.0026593978982418776 train acc 0.790241412399622\n",
      "epoch 4 batch id 138701 / 225000 loss 0.9069045186042786 train acc 0.7902268188405275\n",
      "epoch 4 batch id 138801 / 225000 loss 0.0016284503508359194 train acc 0.790230257707077\n",
      "epoch 4 batch id 138901 / 225000 loss 0.003429361619055271 train acc 0.7902444906804127\n",
      "epoch 4 batch id 139001 / 225000 loss 0.0027396264486014843 train acc 0.7902515089819497\n",
      "epoch 4 batch id 139101 / 225000 loss 0.002640010556206107 train acc 0.7902369501297618\n",
      "epoch 4 batch id 139201 / 225000 loss 1.6929795742034912 train acc 0.7902529435851754\n",
      "epoch 4 batch id 139301 / 225000 loss 0.7861166596412659 train acc 0.7902401992806943\n",
      "epoch 4 batch id 139401 / 225000 loss 3.4991588592529297 train acc 0.7902507872970782\n",
      "epoch 4 batch id 139501 / 225000 loss 4.389677047729492 train acc 0.7902380628095856\n",
      "epoch 4 batch id 139601 / 225000 loss 0.0018053790554404259 train acc 0.7902414739149433\n",
      "epoch 4 batch id 139701 / 225000 loss 2.5575239658355713 train acc 0.7902305638470734\n",
      "epoch 4 batch id 139801 / 225000 loss 0.011123168282210827 train acc 0.7902393402050056\n",
      "epoch 4 batch id 139901 / 225000 loss 0.005041228141635656 train acc 0.790240956104674\n",
      "epoch 4 batch id 140001 / 225000 loss 2.54400372505188 train acc 0.7902282840836851\n",
      "epoch 4 batch id 140101 / 225000 loss 3.3092570304870605 train acc 0.7902531031184645\n",
      "epoch 4 batch id 140201 / 225000 loss 0.4801722764968872 train acc 0.790265404669011\n",
      "epoch 4 batch id 140301 / 225000 loss 0.060637298971414566 train acc 0.7902759068003792\n",
      "epoch 4 batch id 140401 / 225000 loss 2.339634656906128 train acc 0.7902507816895891\n",
      "epoch 4 batch id 140501 / 225000 loss 2.5018742084503174 train acc 0.7902470445050214\n",
      "epoch 4 batch id 140601 / 225000 loss 1.687417984008789 train acc 0.7902362003115199\n",
      "epoch 4 batch id 140701 / 225000 loss 1.0550464391708374 train acc 0.7902644615176865\n",
      "epoch 4 batch id 140801 / 225000 loss 0.0028835581615567207 train acc 0.7902589470245239\n",
      "epoch 4 batch id 140901 / 225000 loss 0.039024729281663895 train acc 0.7902658604268246\n",
      "epoch 4 batch id 141001 / 225000 loss 0.008532047271728516 train acc 0.7902763100970915\n",
      "epoch 4 batch id 141101 / 225000 loss 0.00855481717735529 train acc 0.7902991474192246\n",
      "epoch 4 batch id 141201 / 225000 loss 0.91749507188797 train acc 0.7902953945085375\n",
      "epoch 4 batch id 141301 / 225000 loss 1.553195834159851 train acc 0.7902898776371009\n",
      "epoch 4 batch id 141401 / 225000 loss 0.8384717702865601 train acc 0.7902896726331496\n",
      "epoch 4 batch id 141501 / 225000 loss 0.008815979585051537 train acc 0.790317736270415\n",
      "epoch 4 batch id 141601 / 225000 loss 1.1648495197296143 train acc 0.7903439947457999\n",
      "epoch 4 batch id 141701 / 225000 loss 2.605102777481079 train acc 0.7903278734800743\n",
      "epoch 4 batch id 141801 / 225000 loss 3.6088547706604004 train acc 0.7903276422592225\n",
      "epoch 4 batch id 141901 / 225000 loss 0.05602976679801941 train acc 0.790343267489306\n",
      "epoch 4 batch id 142001 / 225000 loss 1.9342519044876099 train acc 0.7903307018964655\n",
      "epoch 4 batch id 142101 / 225000 loss 0.6614298224449158 train acc 0.7903410250455661\n",
      "epoch 4 batch id 142201 / 225000 loss 1.0411708354949951 train acc 0.7903232044781682\n",
      "epoch 4 batch id 142301 / 225000 loss 0.003397155087441206 train acc 0.7903352752264566\n",
      "epoch 4 batch id 142401 / 225000 loss 0.6716310381889343 train acc 0.7903332841763752\n",
      "epoch 4 batch id 142501 / 225000 loss 0.008856565691530704 train acc 0.7903207696788093\n",
      "epoch 4 batch id 142601 / 225000 loss 0.07665224373340607 train acc 0.7903328167404156\n",
      "epoch 4 batch id 142701 / 225000 loss 1.4656360149383545 train acc 0.790344846917681\n",
      "epoch 4 batch id 142801 / 225000 loss 0.4431784152984619 train acc 0.7903743671262806\n",
      "epoch 4 batch id 142901 / 225000 loss 2.99177622795105 train acc 0.7903811030013785\n",
      "epoch 4 batch id 143001 / 225000 loss 0.5296462178230286 train acc 0.7903860812162152\n",
      "epoch 4 batch id 143101 / 225000 loss 1.5927501916885376 train acc 0.7903858114199063\n",
      "epoch 4 batch id 143201 / 225000 loss 3.9762868881225586 train acc 0.7904152205641022\n",
      "epoch 4 batch id 143301 / 225000 loss 0.04361647367477417 train acc 0.7904009741732437\n",
      "epoch 4 batch id 143401 / 225000 loss 1.8303987979888916 train acc 0.790397207829792\n",
      "epoch 4 batch id 143501 / 225000 loss 3.1332030296325684 train acc 0.7903969310318395\n",
      "epoch 4 batch id 143601 / 225000 loss 0.010986221954226494 train acc 0.7904053592941553\n",
      "epoch 4 batch id 143701 / 225000 loss 1.9960920810699463 train acc 0.7904050772089268\n",
      "epoch 4 batch id 143801 / 225000 loss 0.0011620940640568733 train acc 0.7904134880842275\n",
      "epoch 4 batch id 143901 / 225000 loss 2.5763111114501953 train acc 0.7903715054099694\n",
      "epoch 4 batch id 144001 / 225000 loss 1.32315993309021 train acc 0.7903972889077159\n",
      "epoch 4 batch id 144101 / 225000 loss 1.8119562864303589 train acc 0.7904056876773929\n",
      "epoch 4 batch id 144201 / 225000 loss 0.001973190810531378 train acc 0.7904314117100436\n",
      "epoch 4 batch id 144301 / 225000 loss 0.08200521767139435 train acc 0.7904328452332278\n",
      "epoch 4 batch id 144401 / 225000 loss 1.0480663776397705 train acc 0.790439470640785\n",
      "epoch 4 batch id 144501 / 225000 loss 2.439042568206787 train acc 0.7904530072456246\n",
      "epoch 4 batch id 144601 / 225000 loss 2.478470802307129 train acc 0.7904475072786495\n",
      "epoch 4 batch id 144701 / 225000 loss 1.4034900665283203 train acc 0.7904558365180614\n",
      "epoch 4 batch id 144801 / 225000 loss 0.21343867480754852 train acc 0.7904762398049737\n",
      "epoch 4 batch id 144901 / 225000 loss 1.4320240020751953 train acc 0.7904741858234242\n",
      "epoch 4 batch id 145001 / 225000 loss 0.8730875849723816 train acc 0.7904738588009738\n",
      "epoch 4 batch id 145101 / 225000 loss 0.001248854212462902 train acc 0.7904924845452478\n",
      "epoch 4 batch id 145201 / 225000 loss 1.3531386852264404 train acc 0.7904921453708996\n",
      "epoch 4 batch id 145301 / 225000 loss 1.1216410398483276 train acc 0.7905038506273184\n",
      "epoch 4 batch id 145401 / 225000 loss 1.3360697031021118 train acc 0.7905155397830826\n",
      "epoch 4 batch id 145501 / 225000 loss 1.5825152397155762 train acc 0.7905117490601439\n",
      "epoch 4 batch id 145601 / 225000 loss 1.3305928707122803 train acc 0.7905113975865551\n",
      "epoch 4 batch id 145701 / 225000 loss 1.6244946718215942 train acc 0.7905076149099869\n",
      "epoch 4 batch id 145801 / 225000 loss 0.2508207857608795 train acc 0.7905175547492815\n",
      "epoch 4 batch id 145901 / 225000 loss 3.293546438217163 train acc 0.7905120595472273\n",
      "epoch 4 batch id 146001 / 225000 loss 0.014219501055777073 train acc 0.7905048595557564\n",
      "epoch 4 batch id 146101 / 225000 loss 1.9042527675628662 train acc 0.7904839802602309\n",
      "epoch 4 batch id 146201 / 225000 loss 1.3295048475265503 train acc 0.7904785192987736\n",
      "epoch 4 batch id 146301 / 225000 loss 0.07589973509311676 train acc 0.7904833186376033\n",
      "epoch 4 batch id 146401 / 225000 loss 0.5298129320144653 train acc 0.790491526697222\n",
      "epoch 4 batch id 146501 / 225000 loss 0.9359092712402344 train acc 0.7905014300243685\n",
      "epoch 4 batch id 146601 / 225000 loss 0.014770901761949062 train acc 0.7904823295884749\n",
      "epoch 4 batch id 146701 / 225000 loss 0.023726047948002815 train acc 0.7904717759251811\n",
      "epoch 4 batch id 146801 / 225000 loss 0.3835861086845398 train acc 0.7904952963535671\n",
      "epoch 4 batch id 146901 / 225000 loss 3.7162764072418213 train acc 0.7905017664958033\n",
      "epoch 4 batch id 147001 / 225000 loss 0.8360850214958191 train acc 0.790504826497779\n",
      "epoch 4 batch id 147101 / 225000 loss 0.6572917103767395 train acc 0.7905095818519249\n",
      "epoch 4 batch id 147201 / 225000 loss 2.6941683292388916 train acc 0.7905109340289808\n",
      "epoch 4 batch id 147301 / 225000 loss 1.1816619634628296 train acc 0.7905173759852275\n",
      "epoch 4 batch id 147401 / 225000 loss 0.007543459534645081 train acc 0.7905238092007517\n",
      "epoch 4 batch id 147501 / 225000 loss 2.2220354080200195 train acc 0.7905268438858042\n",
      "epoch 4 batch id 147601 / 225000 loss 1.1133579015731812 train acc 0.7905468120134688\n",
      "epoch 4 batch id 147701 / 225000 loss 0.8724082708358765 train acc 0.7905667531025518\n",
      "epoch 4 batch id 147801 / 225000 loss 0.8680453300476074 train acc 0.7905731354997598\n",
      "epoch 4 batch id 147901 / 225000 loss 2.990339756011963 train acc 0.7905811995862096\n",
      "epoch 4 batch id 148001 / 225000 loss 2.7633914947509766 train acc 0.7905824960642158\n",
      "epoch 4 batch id 148101 / 225000 loss 2.345637321472168 train acc 0.7905905429402907\n",
      "epoch 4 batch id 148201 / 225000 loss 0.6719948053359985 train acc 0.7905935182623599\n",
      "epoch 4 batch id 148301 / 225000 loss 1.4762964248657227 train acc 0.7906032326147497\n",
      "epoch 4 batch id 148401 / 225000 loss 2.7382237911224365 train acc 0.7906146184998754\n",
      "epoch 4 batch id 148501 / 225000 loss 0.9992499947547913 train acc 0.7906091541471101\n",
      "epoch 4 batch id 148601 / 225000 loss 1.0081720352172852 train acc 0.7906087442211022\n",
      "epoch 4 batch id 148701 / 225000 loss 2.340535879135132 train acc 0.7906167409768596\n",
      "epoch 4 batch id 148801 / 225000 loss 7.203680992126465 train acc 0.7905877648671716\n",
      "epoch 4 batch id 148901 / 225000 loss 1.5715187788009644 train acc 0.790582333228118\n",
      "epoch 4 batch id 149001 / 225000 loss 1.880748987197876 train acc 0.7905634861510996\n",
      "epoch 4 batch id 149101 / 225000 loss 1.4565171003341675 train acc 0.7905564013655173\n",
      "epoch 4 batch id 149201 / 225000 loss 0.00034148310078307986 train acc 0.790549326076903\n",
      "epoch 4 batch id 149301 / 225000 loss 0.00608471967279911 train acc 0.7905790985994735\n",
      "epoch 4 batch id 149401 / 225000 loss 1.902627944946289 train acc 0.7905803843347768\n",
      "epoch 4 batch id 149501 / 225000 loss 0.04833318293094635 train acc 0.7905900294981304\n",
      "epoch 4 batch id 149601 / 225000 loss 0.9010066390037537 train acc 0.7905996617669668\n",
      "epoch 4 batch id 149701 / 225000 loss 1.4116051197052002 train acc 0.7906309911089439\n",
      "epoch 4 batch id 149801 / 225000 loss 0.005154475569725037 train acc 0.790640583173677\n",
      "epoch 4 batch id 149901 / 225000 loss 0.0006190998246893287 train acc 0.7906318169992195\n",
      "epoch 4 batch id 150001 / 225000 loss 1.0676270723342896 train acc 0.7906497290018066\n",
      "epoch 4 batch id 150101 / 225000 loss 3.0068564414978027 train acc 0.7906676171377939\n",
      "epoch 4 batch id 150201 / 225000 loss 0.9927236437797546 train acc 0.7906621793463425\n",
      "epoch 4 batch id 150301 / 225000 loss 0.002678422024473548 train acc 0.7906683920931996\n",
      "epoch 4 batch id 150401 / 225000 loss 0.045807335525751114 train acc 0.7906446765646505\n",
      "epoch 4 batch id 150501 / 225000 loss 0.00764508405700326 train acc 0.790639264855383\n",
      "epoch 4 batch id 150601 / 225000 loss 0.012546149082481861 train acc 0.7906488004727724\n",
      "epoch 4 batch id 150701 / 225000 loss 1.7775284051895142 train acc 0.7906334397250184\n",
      "epoch 4 batch id 150801 / 225000 loss 0.005867005325853825 train acc 0.7906595446979795\n",
      "epoch 4 batch id 150901 / 225000 loss 0.01151199173182249 train acc 0.7906806449261436\n",
      "epoch 4 batch id 151001 / 225000 loss 0.0025901491753757 train acc 0.7906934391162972\n",
      "epoch 4 batch id 151101 / 225000 loss 0.010627135634422302 train acc 0.7907128344617177\n",
      "epoch 4 batch id 151201 / 225000 loss 0.12484639137983322 train acc 0.7907388178649613\n",
      "epoch 4 batch id 151301 / 225000 loss 1.968316912651062 train acc 0.7907366772195822\n",
      "epoch 4 batch id 151401 / 225000 loss 1.4418330192565918 train acc 0.7907262831817491\n",
      "epoch 4 batch id 151501 / 225000 loss 3.1532845497131348 train acc 0.7907291040983228\n",
      "epoch 4 batch id 151601 / 225000 loss 0.008798082359135151 train acc 0.7907137815713616\n",
      "epoch 4 batch id 151701 / 225000 loss 0.9008359909057617 train acc 0.7907133110526628\n",
      "epoch 4 batch id 151801 / 225000 loss 1.6756256818771362 train acc 0.7906864908663316\n",
      "epoch 4 batch id 151901 / 225000 loss 2.479128360748291 train acc 0.7906712266542024\n",
      "epoch 4 batch id 152001 / 225000 loss 0.9473182559013367 train acc 0.7906822981427754\n",
      "epoch 4 batch id 152101 / 225000 loss 0.8115556836128235 train acc 0.7906637694689713\n",
      "epoch 4 batch id 152201 / 225000 loss 1.9291712045669556 train acc 0.7906584056609353\n",
      "epoch 4 batch id 152301 / 225000 loss 1.3910599946975708 train acc 0.7906317095751177\n",
      "epoch 4 batch id 152401 / 225000 loss 0.013579281978309155 train acc 0.790647699162079\n",
      "epoch 4 batch id 152501 / 225000 loss 1.755069375038147 train acc 0.7906538317781523\n",
      "epoch 4 batch id 152601 / 225000 loss 0.002370767993852496 train acc 0.7906353824680048\n",
      "epoch 4 batch id 152701 / 225000 loss 1.0231674909591675 train acc 0.7906578869817487\n",
      "epoch 4 batch id 152801 / 225000 loss 0.8965739011764526 train acc 0.790672181464781\n",
      "epoch 4 batch id 152901 / 225000 loss 1.6327919960021973 train acc 0.7906815521154211\n",
      "epoch 4 batch id 153001 / 225000 loss 1.1997579336166382 train acc 0.7906958124456703\n",
      "epoch 4 batch id 153101 / 225000 loss 0.3944377899169922 train acc 0.7906937250573151\n",
      "epoch 4 batch id 153201 / 225000 loss 2.259814500808716 train acc 0.7906753219626503\n",
      "epoch 4 batch id 153301 / 225000 loss 1.5977985858917236 train acc 0.7906748814423911\n",
      "epoch 4 batch id 153401 / 225000 loss 0.05996629595756531 train acc 0.7906809603587982\n",
      "epoch 4 batch id 153501 / 225000 loss 0.9193254709243774 train acc 0.7906854027009595\n",
      "epoch 4 batch id 153601 / 225000 loss 0.3592413365840912 train acc 0.7906833288845776\n",
      "epoch 4 batch id 153701 / 225000 loss 0.005623888690024614 train acc 0.7907040292515989\n",
      "epoch 4 batch id 153801 / 225000 loss 0.009296271950006485 train acc 0.790716575314855\n",
      "epoch 4 batch id 153901 / 225000 loss 0.136930450797081 train acc 0.7907096120233137\n",
      "epoch 4 batch id 154001 / 225000 loss 0.1591004580259323 train acc 0.7907107746053597\n",
      "epoch 4 batch id 154101 / 225000 loss 0.01712956465780735 train acc 0.7907184249291049\n",
      "epoch 4 batch id 154201 / 225000 loss 2.5374691486358643 train acc 0.7907455204570658\n",
      "epoch 4 batch id 154301 / 225000 loss 0.006906962022185326 train acc 0.7907661000252753\n",
      "epoch 4 batch id 154401 / 225000 loss 1.4991295337677002 train acc 0.7907510314052371\n",
      "epoch 4 batch id 154501 / 225000 loss 0.48150402307510376 train acc 0.7907602539789387\n",
      "epoch 4 batch id 154601 / 225000 loss 2.4932126998901367 train acc 0.790769464621833\n",
      "epoch 4 batch id 154701 / 225000 loss 0.009180248714983463 train acc 0.790749574986587\n",
      "epoch 4 batch id 154801 / 225000 loss 0.002999682677909732 train acc 0.7907539356980898\n",
      "epoch 4 batch id 154901 / 225000 loss 0.17779044806957245 train acc 0.7907550629111497\n",
      "epoch 4 batch id 155001 / 225000 loss 1.2527402639389038 train acc 0.7907658660266708\n",
      "epoch 4 batch id 155101 / 225000 loss 0.8819960951805115 train acc 0.7907702078000787\n",
      "epoch 4 batch id 155201 / 225000 loss 0.0015179188922047615 train acc 0.7907906521220869\n",
      "epoch 4 batch id 155301 / 225000 loss 1.6318176984786987 train acc 0.7907804843497466\n",
      "epoch 4 batch id 155401 / 225000 loss 0.006796788889914751 train acc 0.7907864170758232\n",
      "epoch 4 batch id 155501 / 225000 loss 0.3090378940105438 train acc 0.7907875190513244\n",
      "epoch 4 batch id 155601 / 225000 loss 0.8017111420631409 train acc 0.7907902262838927\n",
      "epoch 4 batch id 155701 / 225000 loss 2.1176822185516357 train acc 0.7907881131142381\n",
      "epoch 4 batch id 155801 / 225000 loss 2.7745919227600098 train acc 0.7907924211012767\n",
      "epoch 4 batch id 155901 / 225000 loss 2.1223952770233154 train acc 0.790807948634069\n",
      "epoch 4 batch id 156001 / 225000 loss 0.8144881129264832 train acc 0.7908058281677681\n",
      "epoch 4 batch id 156101 / 225000 loss 0.008636862970888615 train acc 0.7907764844555768\n",
      "epoch 4 batch id 156201 / 225000 loss 1.5069864988327026 train acc 0.7907935928707243\n",
      "epoch 4 batch id 156301 / 225000 loss 0.038460999727249146 train acc 0.7908090799163153\n",
      "epoch 4 batch id 156401 / 225000 loss 0.003152896650135517 train acc 0.790822948702374\n",
      "epoch 4 batch id 156501 / 225000 loss 0.6397085189819336 train acc 0.7908048510872135\n",
      "epoch 4 batch id 156601 / 225000 loss 0.08943487703800201 train acc 0.7908091263785033\n",
      "epoch 4 batch id 156701 / 225000 loss 0.002421186538413167 train acc 0.7908229685834807\n",
      "epoch 4 batch id 156801 / 225000 loss 0.8373951315879822 train acc 0.7908336043775231\n",
      "epoch 4 batch id 156901 / 225000 loss 1.8339825868606567 train acc 0.7908203261929497\n",
      "epoch 4 batch id 157001 / 225000 loss 1.1456828117370605 train acc 0.790808657269699\n",
      "epoch 4 batch id 157101 / 225000 loss 0.0036777621135115623 train acc 0.7908160991973316\n",
      "epoch 4 batch id 157201 / 225000 loss 0.0021596967708319426 train acc 0.7908505671083518\n",
      "epoch 4 batch id 157301 / 225000 loss 0.009418071247637272 train acc 0.790848437072873\n",
      "epoch 4 batch id 157401 / 225000 loss 0.0018013266380876303 train acc 0.7908621927433752\n",
      "epoch 4 batch id 157501 / 225000 loss 1.745997428894043 train acc 0.7908664071974146\n",
      "epoch 4 batch id 157601 / 225000 loss 0.24124036729335785 train acc 0.7908499946066332\n",
      "epoch 4 batch id 157701 / 225000 loss 3.2807769775390625 train acc 0.7908256764383231\n",
      "epoch 4 batch id 157801 / 225000 loss 0.008853946812450886 train acc 0.7908409959379218\n",
      "epoch 4 batch id 157901 / 225000 loss 2.886037826538086 train acc 0.7908531294925302\n",
      "epoch 4 batch id 158001 / 225000 loss 1.3909025192260742 train acc 0.7908684122252391\n",
      "epoch 4 batch id 158101 / 225000 loss 0.34073275327682495 train acc 0.7908820943574044\n",
      "epoch 4 batch id 158201 / 225000 loss 1.442505121231079 train acc 0.7908752157066011\n",
      "epoch 4 batch id 158301 / 225000 loss 1.252846121788025 train acc 0.7908872969848579\n",
      "epoch 4 batch id 158401 / 225000 loss 0.0038918929640203714 train acc 0.7908946281904786\n",
      "epoch 4 batch id 158501 / 225000 loss 1.8878620862960815 train acc 0.7909098365309998\n",
      "epoch 4 batch id 158601 / 225000 loss 0.14767487347126007 train acc 0.7908950763236046\n",
      "epoch 4 batch id 158701 / 225000 loss 1.9403177499771118 train acc 0.7908992381900555\n",
      "epoch 4 batch id 158801 / 225000 loss 0.01799466274678707 train acc 0.7909112663018495\n",
      "epoch 4 batch id 158901 / 225000 loss 0.003716131439432502 train acc 0.7909091195146664\n",
      "epoch 4 batch id 159001 / 225000 loss 0.0018333508633077145 train acc 0.7908943968905856\n",
      "epoch 4 batch id 159101 / 225000 loss 0.003442842746153474 train acc 0.7908812641026769\n",
      "epoch 4 batch id 159201 / 225000 loss 2.0010111331939697 train acc 0.7908979843091438\n",
      "epoch 4 batch id 159301 / 225000 loss 0.004614478908479214 train acc 0.7909115448113948\n",
      "epoch 4 batch id 159401 / 225000 loss 1.3303364515304565 train acc 0.7909282250425028\n",
      "epoch 4 batch id 159501 / 225000 loss 0.0031059279572218657 train acc 0.7909229409220004\n",
      "epoch 4 batch id 159601 / 225000 loss 1.4315253496170044 train acc 0.7909035657671318\n",
      "epoch 4 batch id 159701 / 225000 loss 1.0979481935501099 train acc 0.7909264813620454\n",
      "epoch 4 batch id 159801 / 225000 loss 1.5043339729309082 train acc 0.7909212082527644\n",
      "epoch 4 batch id 159901 / 225000 loss 0.0009076135465875268 train acc 0.7909268860107191\n",
      "epoch 4 batch id 160001 / 225000 loss 0.9945762753486633 train acc 0.7909497440640996\n",
      "epoch 4 batch id 160101 / 225000 loss 1.290286660194397 train acc 0.7909585199342914\n",
      "epoch 4 batch id 160201 / 225000 loss 0.8590457439422607 train acc 0.7909719664671256\n",
      "epoch 4 batch id 160301 / 225000 loss 0.023955337703227997 train acc 0.7909666814305588\n",
      "epoch 4 batch id 160401 / 225000 loss 3.13281512260437 train acc 0.7909769889215155\n",
      "epoch 4 batch id 160501 / 225000 loss 1.8272812366485596 train acc 0.7909685920959995\n",
      "epoch 4 batch id 160601 / 225000 loss 0.2110515832901001 train acc 0.7909913387836938\n",
      "epoch 4 batch id 160701 / 225000 loss 0.0011518497485667467 train acc 0.7910062787412648\n",
      "epoch 4 batch id 160801 / 225000 loss 0.0017780582420527935 train acc 0.791010317100018\n",
      "epoch 4 batch id 160901 / 225000 loss 0.0012172694550827146 train acc 0.7910283341930753\n",
      "epoch 4 batch id 161001 / 225000 loss 0.029549892991781235 train acc 0.7910494344755623\n",
      "epoch 4 batch id 161101 / 225000 loss 0.30533432960510254 train acc 0.7910363684893328\n",
      "epoch 4 batch id 161201 / 225000 loss 0.1964334100484848 train acc 0.7910543358912165\n",
      "epoch 4 batch id 161301 / 225000 loss 1.4254732131958008 train acc 0.7910676313228064\n",
      "epoch 4 batch id 161401 / 225000 loss 0.9562262892723083 train acc 0.7910700677195308\n",
      "epoch 4 batch id 161501 / 225000 loss 1.1607906818389893 train acc 0.7910957207695308\n",
      "epoch 4 batch id 161601 / 225000 loss 0.07946456968784332 train acc 0.7911012308092152\n",
      "epoch 4 batch id 161701 / 225000 loss 3.1703732013702393 train acc 0.7910912733996698\n",
      "epoch 4 batch id 161801 / 225000 loss 0.9426282644271851 train acc 0.7910859636219801\n",
      "epoch 4 batch id 161901 / 225000 loss 1.0157665014266968 train acc 0.7910883811712096\n",
      "epoch 4 batch id 162001 / 225000 loss 1.651404857635498 train acc 0.7911093141400362\n",
      "epoch 4 batch id 162101 / 225000 loss 4.130734920501709 train acc 0.7910947495697127\n",
      "epoch 4 batch id 162201 / 225000 loss 0.5907144546508789 train acc 0.7910925333382655\n",
      "epoch 4 batch id 162301 / 225000 loss 0.007501293905079365 train acc 0.7911103443601702\n",
      "epoch 4 batch id 162401 / 225000 loss 0.10505861788988113 train acc 0.7911158182523507\n",
      "epoch 4 batch id 162501 / 225000 loss 0.003077711444348097 train acc 0.7911151315991901\n",
      "epoch 4 batch id 162601 / 225000 loss 0.0010970107978209853 train acc 0.7911344333675685\n",
      "epoch 4 batch id 162701 / 225000 loss 0.01886223629117012 train acc 0.791133736117172\n",
      "epoch 4 batch id 162801 / 225000 loss 1.5929467678070068 train acc 0.7911100054667969\n",
      "epoch 4 batch id 162901 / 225000 loss 2.5029985904693604 train acc 0.7911400175566755\n",
      "epoch 4 batch id 163001 / 225000 loss 0.8218468427658081 train acc 0.7911331832320048\n",
      "epoch 4 batch id 163101 / 225000 loss 1.1352769136428833 train acc 0.7911309556655078\n",
      "epoch 4 batch id 163201 / 225000 loss 0.006537577603012323 train acc 0.7911195397087027\n",
      "epoch 4 batch id 163301 / 225000 loss 0.0015295445919036865 train acc 0.7911448797006755\n",
      "epoch 4 batch id 163401 / 225000 loss 0.0036898734979331493 train acc 0.7911319392170183\n",
      "epoch 4 batch id 163501 / 225000 loss 0.2026047706604004 train acc 0.791137363074232\n",
      "epoch 4 batch id 163601 / 225000 loss 1.3816014528274536 train acc 0.7911366678687783\n",
      "epoch 4 batch id 163701 / 225000 loss 1.5573673248291016 train acc 0.7911283376399656\n",
      "epoch 4 batch id 163801 / 225000 loss 0.3161550760269165 train acc 0.7911169650978932\n",
      "epoch 4 batch id 163901 / 225000 loss 0.46318334341049194 train acc 0.79113611265337\n",
      "epoch 4 batch id 164001 / 225000 loss 0.7869907021522522 train acc 0.7911567612392607\n",
      "epoch 4 batch id 164101 / 225000 loss 0.016446206718683243 train acc 0.7911682439473251\n",
      "epoch 4 batch id 164201 / 225000 loss 0.00691304262727499 train acc 0.791185802766122\n",
      "epoch 4 batch id 164301 / 225000 loss 0.0157672930508852 train acc 0.7911896458329529\n",
      "epoch 4 batch id 164401 / 225000 loss 0.000827202049549669 train acc 0.7911858808644716\n",
      "epoch 4 batch id 164501 / 225000 loss 0.009260028600692749 train acc 0.7912079561826372\n",
      "epoch 4 batch id 164601 / 225000 loss 1.2847836017608643 train acc 0.7912224105564365\n",
      "epoch 4 batch id 164701 / 225000 loss 0.004092499613761902 train acc 0.7912049714330818\n",
      "epoch 4 batch id 164801 / 225000 loss 0.5946032404899597 train acc 0.7912178930953089\n",
      "epoch 4 batch id 164901 / 225000 loss 0.005630179774016142 train acc 0.7912232187797527\n",
      "epoch 4 batch id 165001 / 225000 loss 0.8595165014266968 train acc 0.7912345985781905\n",
      "epoch 4 batch id 165101 / 225000 loss 0.0052208248525857925 train acc 0.7912323365697361\n",
      "epoch 4 batch id 165201 / 225000 loss 0.759383499622345 train acc 0.7912331039158359\n",
      "epoch 4 batch id 165301 / 225000 loss 1.2257165908813477 train acc 0.7912308455484238\n",
      "epoch 4 batch id 165401 / 225000 loss 0.5440717935562134 train acc 0.7912301013899553\n",
      "epoch 4 batch id 165501 / 225000 loss 1.9656261205673218 train acc 0.7912323792605482\n",
      "epoch 4 batch id 165601 / 225000 loss 0.8711453676223755 train acc 0.7912482412545818\n",
      "epoch 4 batch id 165701 / 225000 loss 0.005621972028166056 train acc 0.7912731365531892\n",
      "epoch 4 batch id 165801 / 225000 loss 2.3368828296661377 train acc 0.7912829235046833\n",
      "epoch 4 batch id 165901 / 225000 loss 2.4308922290802 train acc 0.7912896848120264\n",
      "epoch 4 batch id 166001 / 225000 loss 0.011563981883227825 train acc 0.7913175221836013\n",
      "epoch 4 batch id 166101 / 225000 loss 1.1877036094665527 train acc 0.7913242545198403\n",
      "epoch 4 batch id 166201 / 225000 loss 1.0619151592254639 train acc 0.7913249619436706\n",
      "epoch 4 batch id 166301 / 225000 loss 1.385768175125122 train acc 0.7913422047973253\n",
      "epoch 4 batch id 166401 / 225000 loss 0.002476111985743046 train acc 0.7913413981887129\n",
      "epoch 4 batch id 166501 / 225000 loss 1.7556426525115967 train acc 0.7913571089663125\n",
      "epoch 4 batch id 166601 / 225000 loss 0.9441261291503906 train acc 0.7913728008835481\n",
      "epoch 4 batch id 166701 / 225000 loss 0.007378948386758566 train acc 0.7913779761369159\n",
      "epoch 4 batch id 166801 / 225000 loss 3.7885308265686035 train acc 0.7913801476010336\n",
      "epoch 4 batch id 166901 / 225000 loss 2.8321914672851562 train acc 0.7913718312053253\n",
      "epoch 4 batch id 167001 / 225000 loss 0.11825993657112122 train acc 0.7913799917365765\n",
      "epoch 4 batch id 167101 / 225000 loss 0.8604960441589355 train acc 0.7914060957145679\n",
      "epoch 4 batch id 167201 / 225000 loss 0.5272940397262573 train acc 0.7914172164042081\n",
      "epoch 4 batch id 167301 / 225000 loss 0.667206346988678 train acc 0.7914088977352197\n",
      "epoch 4 batch id 167401 / 225000 loss 0.9720202088356018 train acc 0.7914050692648192\n",
      "epoch 4 batch id 167501 / 225000 loss 2.0670878887176514 train acc 0.7914057229509077\n",
      "epoch 4 batch id 167601 / 225000 loss 0.010513696819543839 train acc 0.7914078674948241\n",
      "epoch 4 batch id 167701 / 225000 loss 1.9299827814102173 train acc 0.7914129909779906\n",
      "epoch 4 batch id 167801 / 225000 loss 0.2803444266319275 train acc 0.7914315170946538\n",
      "epoch 4 batch id 167901 / 225000 loss 1.6516962051391602 train acc 0.7914321534713908\n",
      "epoch 4 batch id 168001 / 225000 loss 0.003168730065226555 train acc 0.7914432056952042\n",
      "epoch 4 batch id 168101 / 225000 loss 0.3570674657821655 train acc 0.7914512703672197\n",
      "epoch 4 batch id 168201 / 225000 loss 0.039109278470277786 train acc 0.7914548664990101\n",
      "epoch 4 batch id 168301 / 225000 loss 0.905605673789978 train acc 0.7914510311881688\n",
      "epoch 4 batch id 168401 / 225000 loss 1.4321746826171875 train acc 0.7914531386393192\n",
      "epoch 4 batch id 168501 / 225000 loss 0.038905225694179535 train acc 0.7914626619426591\n",
      "epoch 4 batch id 168601 / 225000 loss 1.0110564231872559 train acc 0.7914425181345306\n",
      "epoch 4 batch id 168701 / 225000 loss 1.0363709926605225 train acc 0.791431289678188\n",
      "epoch 4 batch id 168801 / 225000 loss 1.6104333400726318 train acc 0.7914482141693473\n",
      "epoch 4 batch id 168901 / 225000 loss 0.35285672545433044 train acc 0.7914799201899337\n",
      "epoch 4 batch id 169001 / 225000 loss 0.7462503910064697 train acc 0.791489399471009\n",
      "epoch 4 batch id 169101 / 225000 loss 3.820817470550537 train acc 0.7914855618831349\n",
      "epoch 4 batch id 169201 / 225000 loss 0.3290135860443115 train acc 0.7914832063640286\n",
      "epoch 4 batch id 169301 / 225000 loss 0.001984846079722047 train acc 0.7915059568460907\n",
      "epoch 4 batch id 169401 / 225000 loss 4.185334205627441 train acc 0.7914873583981205\n",
      "epoch 4 batch id 169501 / 225000 loss 0.722180962562561 train acc 0.791482056153061\n",
      "epoch 4 batch id 169601 / 225000 loss 1.0273933410644531 train acc 0.7914944487355617\n",
      "epoch 4 batch id 169701 / 225000 loss 0.019946523010730743 train acc 0.7915068267128655\n",
      "epoch 4 batch id 169801 / 225000 loss 3.0190060138702393 train acc 0.791526551669307\n",
      "epoch 4 batch id 169901 / 225000 loss 1.712200403213501 train acc 0.7915315389550385\n",
      "epoch 4 batch id 170001 / 225000 loss 5.395504951477051 train acc 0.7915232851571461\n",
      "epoch 4 batch id 170101 / 225000 loss 3.623802900314331 train acc 0.791529738214355\n",
      "epoch 4 batch id 170201 / 225000 loss 2.136462688446045 train acc 0.7915332459856288\n",
      "epoch 4 batch id 170301 / 225000 loss 1.7269468307495117 train acc 0.7915484935496562\n",
      "epoch 4 batch id 170401 / 225000 loss 0.0024742973037064075 train acc 0.791560788962506\n",
      "epoch 4 batch id 170501 / 225000 loss 0.3336668908596039 train acc 0.7915701374185489\n",
      "epoch 4 batch id 170601 / 225000 loss 0.014749974943697453 train acc 0.7915560283937374\n",
      "epoch 4 batch id 170701 / 225000 loss 2.174207925796509 train acc 0.7915595104891008\n",
      "epoch 4 batch id 170801 / 225000 loss 0.006151089444756508 train acc 0.7915439605154536\n",
      "epoch 4 batch id 170901 / 225000 loss 0.0012057970743626356 train acc 0.7915576854436194\n",
      "epoch 4 batch id 171001 / 225000 loss 0.0024455231614410877 train acc 0.7915684703598225\n",
      "epoch 4 batch id 171101 / 225000 loss 0.7812367677688599 train acc 0.7915763204189339\n",
      "epoch 4 batch id 171201 / 225000 loss 2.8468518257141113 train acc 0.7915958434822227\n",
      "epoch 4 batch id 171301 / 225000 loss 1.1912108659744263 train acc 0.7916153437516419\n",
      "epoch 4 batch id 171401 / 225000 loss 0.9962438344955444 train acc 0.7916071084766133\n",
      "epoch 4 batch id 171501 / 225000 loss 0.0326400026679039 train acc 0.7916163754147206\n",
      "epoch 4 batch id 171601 / 225000 loss 4.6724042892456055 train acc 0.79160814913666\n",
      "epoch 4 batch id 171701 / 225000 loss 2.075839042663574 train acc 0.7916246847717835\n",
      "epoch 4 batch id 171801 / 225000 loss 2.928847074508667 train acc 0.7916208287495416\n",
      "epoch 4 batch id 171901 / 225000 loss 0.21148823201656342 train acc 0.7916489723736336\n",
      "epoch 4 batch id 172001 / 225000 loss 0.0036087341140955687 train acc 0.791664001953477\n",
      "epoch 4 batch id 172101 / 225000 loss 3.4237749576568604 train acc 0.7916659403489811\n",
      "epoch 4 batch id 172201 / 225000 loss 0.04497019946575165 train acc 0.7916780390357779\n",
      "epoch 4 batch id 172301 / 225000 loss 1.9808887243270874 train acc 0.7916654575423242\n",
      "epoch 4 batch id 172401 / 225000 loss 0.28184762597084045 train acc 0.7916630413976717\n",
      "epoch 4 batch id 172501 / 225000 loss 0.058104258030653 train acc 0.7916794685248202\n",
      "epoch 4 batch id 172601 / 225000 loss 2.731886386871338 train acc 0.7916857376260856\n",
      "epoch 4 batch id 172701 / 225000 loss 1.023738980293274 train acc 0.791697789821715\n",
      "epoch 4 batch id 172801 / 225000 loss 0.002461110707372427 train acc 0.7916779995486137\n",
      "epoch 4 batch id 172901 / 225000 loss 1.318176507949829 train acc 0.7916799208795785\n",
      "epoch 4 batch id 173001 / 225000 loss 1.8383210897445679 train acc 0.7916818399893643\n",
      "epoch 4 batch id 173101 / 225000 loss 0.007943449541926384 train acc 0.7916750914206158\n",
      "epoch 4 batch id 173201 / 225000 loss 0.0036976253613829613 train acc 0.7916914451995081\n",
      "epoch 4 batch id 173301 / 225000 loss 0.0012799373362213373 train acc 0.7917135504122884\n",
      "epoch 4 batch id 173401 / 225000 loss 1.1261377334594727 train acc 0.7916967030178603\n",
      "epoch 4 batch id 173501 / 225000 loss 1.2139804363250732 train acc 0.7916856386994887\n",
      "epoch 4 batch id 173601 / 225000 loss 1.50221586227417 train acc 0.7916889879666592\n",
      "epoch 4 batch id 173701 / 225000 loss 0.2181990146636963 train acc 0.791680819338979\n",
      "epoch 4 batch id 173801 / 225000 loss 1.3944023847579956 train acc 0.7916482068572678\n",
      "epoch 4 batch id 173901 / 225000 loss 0.002998288720846176 train acc 0.7916472590726907\n",
      "epoch 4 batch id 174001 / 225000 loss 0.32170742750167847 train acc 0.7916420020574595\n",
      "epoch 4 batch id 174101 / 225000 loss 0.9994855523109436 train acc 0.791636751081269\n",
      "epoch 4 batch id 174201 / 225000 loss 1.7199443578720093 train acc 0.7916501627430382\n",
      "epoch 4 batch id 174301 / 225000 loss 0.5318852663040161 train acc 0.791683639221806\n",
      "epoch 4 batch id 174401 / 225000 loss 2.000148057937622 train acc 0.7916855407939175\n",
      "epoch 4 batch id 174501 / 225000 loss 0.17172853648662567 train acc 0.7916874401865892\n",
      "epoch 4 batch id 174601 / 225000 loss 1.8453269004821777 train acc 0.7916721553713896\n",
      "epoch 4 batch id 174701 / 225000 loss 1.0502938032150269 train acc 0.7916940944814282\n",
      "epoch 4 batch id 174801 / 225000 loss 0.7344794273376465 train acc 0.7916945555231377\n",
      "epoch 4 batch id 174901 / 225000 loss 2.259990692138672 train acc 0.7917021629378905\n",
      "epoch 4 batch id 175001 / 225000 loss 0.9015489220619202 train acc 0.7916997617156474\n",
      "epoch 4 batch id 175101 / 225000 loss 0.9487558007240295 train acc 0.7916987909834895\n",
      "epoch 4 batch id 175201 / 225000 loss 0.653406023979187 train acc 0.7916963944269725\n",
      "epoch 4 batch id 175301 / 225000 loss 0.6580461859703064 train acc 0.791701131197198\n",
      "epoch 4 batch id 175401 / 225000 loss 0.007480266038328409 train acc 0.7917001613445761\n",
      "epoch 4 batch id 175501 / 225000 loss 1.671870231628418 train acc 0.7917034660771164\n",
      "epoch 4 batch id 175601 / 225000 loss 0.9619006514549255 train acc 0.7917010723173559\n",
      "epoch 4 batch id 175701 / 225000 loss 1.9268312454223633 train acc 0.7916915669233527\n",
      "epoch 4 batch id 175801 / 225000 loss 0.041765712201595306 train acc 0.791713357716964\n",
      "epoch 4 batch id 175901 / 225000 loss 0.0005729881813749671 train acc 0.7917308599723708\n",
      "epoch 4 batch id 176001 / 225000 loss 0.7642998695373535 train acc 0.7917355583206913\n",
      "epoch 4 batch id 176101 / 225000 loss 0.0038036706391721964 train acc 0.7917530280918337\n",
      "epoch 4 batch id 176201 / 225000 loss 1.540703296661377 train acc 0.7917548708577137\n",
      "epoch 4 batch id 176301 / 225000 loss 0.8371300101280212 train acc 0.7917638016800812\n",
      "epoch 4 batch id 176401 / 225000 loss 1.9432733058929443 train acc 0.791755715670546\n",
      "epoch 4 batch id 176501 / 225000 loss 0.8773251175880432 train acc 0.7917618030492745\n",
      "epoch 4 batch id 176601 / 225000 loss 1.765634298324585 train acc 0.7917650522930221\n",
      "epoch 4 batch id 176701 / 225000 loss 0.16388025879859924 train acc 0.7917583941234062\n",
      "epoch 4 batch id 176801 / 225000 loss 0.004157756920903921 train acc 0.7917715397537344\n",
      "epoch 4 batch id 176901 / 225000 loss 2.9925498962402344 train acc 0.7917549929056364\n",
      "epoch 4 batch id 177001 / 225000 loss 3.638511896133423 train acc 0.7917525889684239\n",
      "epoch 4 batch id 177101 / 225000 loss 2.340245485305786 train acc 0.7917417180027216\n",
      "epoch 4 batch id 177201 / 225000 loss 0.0005018501542508602 train acc 0.791726626824905\n",
      "epoch 4 batch id 177301 / 225000 loss 1.0920547246932983 train acc 0.7917355232062989\n",
      "epoch 4 batch id 177401 / 225000 loss 0.7286128997802734 train acc 0.791741591084605\n",
      "epoch 4 batch id 177501 / 225000 loss 1.2626934051513672 train acc 0.7917307508126715\n",
      "epoch 4 batch id 177601 / 225000 loss 0.39991626143455505 train acc 0.7917283686465729\n",
      "epoch 4 batch id 177701 / 225000 loss 0.0043474421836435795 train acc 0.7917358371646755\n",
      "epoch 4 batch id 177801 / 225000 loss 0.7893053293228149 train acc 0.7917573579451184\n",
      "epoch 4 batch id 177901 / 225000 loss 0.00022401823662221432 train acc 0.7917521542880591\n",
      "epoch 4 batch id 178001 / 225000 loss 2.141465425491333 train acc 0.7917581923697058\n",
      "epoch 4 batch id 178101 / 225000 loss 0.0032352814450860023 train acc 0.7917572051813297\n",
      "epoch 4 batch id 178201 / 225000 loss 0.15884172916412354 train acc 0.7917604278314937\n",
      "epoch 4 batch id 178301 / 225000 loss 2.8959460258483887 train acc 0.7917832765940741\n",
      "epoch 4 batch id 178401 / 225000 loss 1.0722591876983643 train acc 0.7918046984041569\n",
      "epoch 4 batch id 178501 / 225000 loss 0.003863680874928832 train acc 0.7918190934504569\n",
      "epoch 4 batch id 178601 / 225000 loss 0.012118049897253513 train acc 0.7918236739995856\n",
      "epoch 4 batch id 178701 / 225000 loss 0.00637719826772809 train acc 0.7918408402862883\n",
      "epoch 4 batch id 178801 / 225000 loss 2.250012159347534 train acc 0.7918579873714353\n",
      "epoch 4 batch id 178901 / 225000 loss 1.711347222328186 train acc 0.7918779101290658\n",
      "epoch 4 batch id 179001 / 225000 loss 0.00842165295034647 train acc 0.7918740677426384\n",
      "epoch 4 batch id 179101 / 225000 loss 0.7851659059524536 train acc 0.791860458623905\n",
      "epoch 4 batch id 179201 / 225000 loss 2.285344362258911 train acc 0.791860815508842\n",
      "epoch 4 batch id 179301 / 225000 loss 0.00030753659666515887 train acc 0.7918402574441861\n",
      "epoch 4 batch id 179401 / 225000 loss 1.716636061668396 train acc 0.7918350510866717\n",
      "epoch 4 batch id 179501 / 225000 loss 0.0048460825346410275 train acc 0.7918214940306739\n",
      "epoch 4 batch id 179601 / 225000 loss 1.0363540649414062 train acc 0.7918163039181296\n",
      "epoch 4 batch id 179701 / 225000 loss 2.5245964527130127 train acc 0.7918236403804096\n",
      "epoch 4 batch id 179801 / 225000 loss 2.0316550731658936 train acc 0.7918379208124537\n",
      "epoch 4 batch id 179901 / 225000 loss 0.009299922734498978 train acc 0.7918563543282139\n",
      "epoch 4 batch id 180001 / 225000 loss 2.6766574382781982 train acc 0.7918553230259832\n",
      "epoch 4 batch id 180101 / 225000 loss 1.3215599060058594 train acc 0.7918765026290804\n",
      "epoch 4 batch id 180201 / 225000 loss 0.023780496791005135 train acc 0.7918796233095265\n",
      "epoch 4 batch id 180301 / 225000 loss 1.7456390857696533 train acc 0.7919021525116333\n",
      "epoch 4 batch id 180401 / 225000 loss 2.0426230430603027 train acc 0.7918816968863809\n",
      "epoch 4 batch id 180501 / 225000 loss 0.0032571733463555574 train acc 0.7918681890959053\n",
      "epoch 4 batch id 180601 / 225000 loss 0.010509093292057514 train acc 0.7918934557394477\n",
      "epoch 4 batch id 180701 / 225000 loss 0.00776259321719408 train acc 0.7918813398929724\n",
      "epoch 4 batch id 180801 / 225000 loss 2.204525947570801 train acc 0.7918941266917772\n",
      "epoch 4 batch id 180901 / 225000 loss 0.30779752135276794 train acc 0.7919248649813987\n",
      "epoch 4 batch id 181001 / 225000 loss 1.5485950708389282 train acc 0.7919168954867652\n",
      "epoch 4 batch id 181101 / 225000 loss 0.27036115527153015 train acc 0.7919199783546198\n",
      "epoch 4 batch id 181201 / 225000 loss 0.24488013982772827 train acc 0.7919313359197797\n",
      "epoch 4 batch id 181301 / 225000 loss 1.1833550930023193 train acc 0.79193992311129\n",
      "epoch 4 batch id 181401 / 225000 loss 1.1875680685043335 train acc 0.7919636606192909\n",
      "epoch 4 batch id 181501 / 225000 loss 0.40409576892852783 train acc 0.7919708431358505\n",
      "epoch 4 batch id 181601 / 225000 loss 1.8927958011627197 train acc 0.7919587447205687\n",
      "epoch 4 batch id 181701 / 225000 loss 1.085263967514038 train acc 0.7919672979235117\n",
      "epoch 4 batch id 181801 / 225000 loss 0.005801316350698471 train acc 0.7919620904175445\n",
      "epoch 4 batch id 181901 / 225000 loss 1.9288822412490845 train acc 0.7919527655153078\n",
      "epoch 4 batch id 182001 / 225000 loss 0.9176352024078369 train acc 0.7919668023802067\n",
      "epoch 4 batch id 182101 / 225000 loss 1.3458703756332397 train acc 0.7919712137769699\n",
      "epoch 4 batch id 182201 / 225000 loss 0.8844262957572937 train acc 0.791979736664453\n",
      "epoch 4 batch id 182301 / 225000 loss 0.0006871851510368288 train acc 0.7919786506930845\n",
      "epoch 4 batch id 182401 / 225000 loss 0.06850363314151764 train acc 0.7919830483385508\n",
      "epoch 4 batch id 182501 / 225000 loss 0.1735742688179016 train acc 0.7919956602977518\n",
      "epoch 4 batch id 182601 / 225000 loss 1.5873738527297974 train acc 0.7920027820220042\n",
      "epoch 4 batch id 182701 / 225000 loss 3.6093034744262695 train acc 0.7919962123907368\n",
      "epoch 4 batch id 182801 / 225000 loss 3.3001444339752197 train acc 0.7920046936285906\n",
      "epoch 4 batch id 182901 / 225000 loss 0.0628804937005043 train acc 0.7920049644343115\n",
      "epoch 4 batch id 183001 / 225000 loss 0.8377174139022827 train acc 0.791990207703783\n",
      "epoch 4 batch id 183101 / 225000 loss 0.0027757775969803333 train acc 0.7920014090583886\n",
      "epoch 4 batch id 183201 / 225000 loss 0.7581546902656555 train acc 0.7920139628058799\n",
      "epoch 4 batch id 183301 / 225000 loss 2.00445556640625 train acc 0.7920183195945467\n",
      "epoch 4 batch id 183401 / 225000 loss 1.989199161529541 train acc 0.7920076771664276\n",
      "epoch 4 batch id 183501 / 225000 loss 0.0036007026210427284 train acc 0.7920270189263274\n",
      "epoch 4 batch id 183601 / 225000 loss 2.080209732055664 train acc 0.7920340847816733\n",
      "epoch 4 batch id 183701 / 225000 loss 0.8130837082862854 train acc 0.7920452256656196\n",
      "epoch 4 batch id 183801 / 225000 loss 0.01757068745791912 train acc 0.7920658755937128\n",
      "epoch 4 batch id 183901 / 225000 loss 0.0006767974700778723 train acc 0.7920742682204012\n",
      "epoch 4 batch id 184001 / 225000 loss 0.9476628303527832 train acc 0.7920812930364509\n",
      "epoch 4 batch id 184101 / 225000 loss 0.005436955485492945 train acc 0.7920896681712756\n",
      "epoch 4 batch id 184201 / 225000 loss 0.02594250626862049 train acc 0.7920912481474042\n",
      "epoch 4 batch id 184301 / 225000 loss 1.2215313911437988 train acc 0.7920765486893723\n",
      "epoch 4 batch id 184401 / 225000 loss 1.753374457359314 train acc 0.7920591536922251\n",
      "epoch 4 batch id 184501 / 225000 loss 1.743168592453003 train acc 0.792063457650636\n",
      "epoch 4 batch id 184601 / 225000 loss 0.01810246706008911 train acc 0.7920691112182491\n",
      "epoch 4 batch id 184701 / 225000 loss 0.0013615640345960855 train acc 0.7920639303522992\n",
      "epoch 4 batch id 184801 / 225000 loss 0.23986594378948212 train acc 0.7920831056109003\n",
      "epoch 4 batch id 184901 / 225000 loss 0.8821094632148743 train acc 0.7920954997539223\n",
      "epoch 4 batch id 185001 / 225000 loss 0.00197879271581769 train acc 0.7920984210896157\n",
      "epoch 4 batch id 185101 / 225000 loss 2.802363872528076 train acc 0.7921188972506902\n",
      "epoch 4 batch id 185201 / 225000 loss 0.07930408418178558 train acc 0.7921272023369205\n",
      "epoch 4 batch id 185301 / 225000 loss 2.5717825889587402 train acc 0.7921408950842144\n",
      "epoch 4 batch id 185401 / 225000 loss 0.5646982192993164 train acc 0.7921356950609759\n",
      "epoch 4 batch id 185501 / 225000 loss 0.6531076431274414 train acc 0.7921183713295347\n",
      "epoch 4 batch id 185601 / 225000 loss 0.5381534695625305 train acc 0.792148210408349\n",
      "epoch 4 batch id 185701 / 225000 loss 0.0013337243581190705 train acc 0.7921430148464467\n",
      "epoch 4 batch id 185801 / 225000 loss 3.308856248855591 train acc 0.7921364793515643\n",
      "epoch 4 batch id 185901 / 225000 loss 3.161529541015625 train acc 0.7921299508878381\n",
      "epoch 4 batch id 186001 / 225000 loss 1.0087193250656128 train acc 0.7921516550986285\n",
      "epoch 4 batch id 186101 / 225000 loss 2.0821032524108887 train acc 0.792162589131708\n",
      "epoch 4 batch id 186201 / 225000 loss 0.0037086824886500835 train acc 0.7921829098662199\n",
      "epoch 4 batch id 186301 / 225000 loss 0.6679990887641907 train acc 0.7921911315559229\n",
      "epoch 4 batch id 186401 / 225000 loss 1.5054889917373657 train acc 0.7922006856186394\n",
      "epoch 4 batch id 186501 / 225000 loss 1.5673738718032837 train acc 0.7922182722880843\n",
      "epoch 4 batch id 186601 / 225000 loss 1.3526232242584229 train acc 0.792211724481648\n",
      "epoch 4 batch id 186701 / 225000 loss 1.0552476644515991 train acc 0.792223930241402\n",
      "epoch 4 batch id 186801 / 225000 loss 0.003155273152515292 train acc 0.7922227397069609\n",
      "epoch 4 batch id 186901 / 225000 loss 0.009217928163707256 train acc 0.792217537626872\n",
      "epoch 4 batch id 187001 / 225000 loss 1.0083588361740112 train acc 0.7922270469141877\n",
      "epoch 4 batch id 187101 / 225000 loss 0.1152195855975151 train acc 0.792227192799611\n",
      "epoch 4 batch id 187201 / 225000 loss 0.09504413604736328 train acc 0.7922260030662229\n",
      "epoch 4 batch id 187301 / 225000 loss 1.8834106922149658 train acc 0.7922154713535966\n",
      "epoch 4 batch id 187401 / 225000 loss 1.9382219314575195 train acc 0.7922076189561422\n",
      "epoch 4 batch id 187501 / 225000 loss 1.9227399826049805 train acc 0.792217108175423\n",
      "epoch 4 batch id 187601 / 225000 loss 0.3268273174762726 train acc 0.7922159263543371\n",
      "epoch 4 batch id 187701 / 225000 loss 0.0007025065715424716 train acc 0.7922333924699388\n",
      "epoch 4 batch id 187801 / 225000 loss 3.9879698753356934 train acc 0.7922428528069606\n",
      "epoch 4 batch id 187901 / 225000 loss 0.06875894218683243 train acc 0.7922350067322685\n",
      "epoch 4 batch id 188001 / 225000 loss 0.025870079174637794 train acc 0.7922351476853846\n",
      "epoch 4 batch id 188101 / 225000 loss 2.918285608291626 train acc 0.7922552245867911\n",
      "epoch 4 batch id 188201 / 225000 loss 0.0013021157355979085 train acc 0.7922473844453536\n",
      "epoch 4 batch id 188301 / 225000 loss 3.510852813720703 train acc 0.7922528292467911\n",
      "epoch 4 batch id 188401 / 225000 loss 0.028975097462534904 train acc 0.7922595952250784\n",
      "epoch 4 batch id 188501 / 225000 loss 2.1294260025024414 train acc 0.792275637795025\n",
      "epoch 4 batch id 188601 / 225000 loss 0.1480366438627243 train acc 0.7922929889024979\n",
      "epoch 4 batch id 188701 / 225000 loss 0.8105314373970032 train acc 0.7923116464671623\n",
      "epoch 4 batch id 188801 / 225000 loss 0.8176306486129761 train acc 0.7923289601220332\n",
      "epoch 4 batch id 188901 / 225000 loss 0.004514605272561312 train acc 0.7923078755538615\n",
      "epoch 4 batch id 189001 / 225000 loss 0.8508811593055725 train acc 0.7923119454394422\n",
      "epoch 4 batch id 189101 / 225000 loss 2.406146764755249 train acc 0.7923384857827299\n",
      "epoch 4 batch id 189201 / 225000 loss 1.6827890872955322 train acc 0.792334607110956\n",
      "epoch 4 batch id 189301 / 225000 loss 0.0066084228456020355 train acc 0.7923492216100285\n",
      "epoch 4 batch id 189401 / 225000 loss 3.568516492843628 train acc 0.7923400615625049\n",
      "epoch 4 batch id 189501 / 225000 loss 0.2804344892501831 train acc 0.792354657759062\n",
      "epoch 4 batch id 189601 / 225000 loss 1.9401350021362305 train acc 0.7923520972990649\n",
      "epoch 4 batch id 189701 / 225000 loss 1.6573834419250488 train acc 0.7923548109920349\n",
      "epoch 4 batch id 189801 / 225000 loss 1.7868986129760742 train acc 0.7923403986280367\n",
      "epoch 4 batch id 189901 / 225000 loss 3.1171185970306396 train acc 0.7923273179182837\n",
      "epoch 4 batch id 190001 / 225000 loss 2.167415142059326 train acc 0.7923313561507571\n",
      "epoch 4 batch id 190101 / 225000 loss 0.0013540770160034299 train acc 0.7923327599539193\n",
      "epoch 4 batch id 190201 / 225000 loss 0.24644729495048523 train acc 0.7923354766799333\n",
      "epoch 4 batch id 190301 / 225000 loss 1.281270980834961 train acc 0.7923408179673255\n",
      "epoch 4 batch id 190401 / 225000 loss 1.6255207061767578 train acc 0.7923566577906629\n",
      "epoch 4 batch id 190501 / 225000 loss 0.008229359053075314 train acc 0.7923619823517987\n",
      "epoch 4 batch id 190601 / 225000 loss 0.8444371819496155 train acc 0.7923528732797834\n",
      "epoch 4 batch id 190701 / 225000 loss 0.36024209856987 train acc 0.792372614721475\n",
      "epoch 4 batch id 190801 / 225000 loss 0.0022484094370156527 train acc 0.7923766122819063\n",
      "epoch 4 batch id 190901 / 225000 loss 0.098482146859169 train acc 0.7923688194404429\n",
      "epoch 4 batch id 191001 / 225000 loss 0.0020694416016340256 train acc 0.7923819770577117\n",
      "epoch 4 batch id 191101 / 225000 loss 1.0563578605651855 train acc 0.7924016619483938\n",
      "epoch 4 batch id 191201 / 225000 loss 0.532237708568573 train acc 0.7924056359537869\n",
      "epoch 4 batch id 191301 / 225000 loss 0.2074713408946991 train acc 0.7924200605328775\n",
      "epoch 4 batch id 191401 / 225000 loss 1.1132770776748657 train acc 0.7924344700393415\n",
      "epoch 4 batch id 191501 / 225000 loss 1.2594709396362305 train acc 0.792435809734675\n",
      "epoch 4 batch id 191601 / 225000 loss 0.6965275406837463 train acc 0.7924358432367263\n",
      "epoch 4 batch id 191701 / 225000 loss 0.8141666650772095 train acc 0.7924476137318011\n",
      "epoch 4 batch id 191801 / 225000 loss 0.7238863110542297 train acc 0.7924541582160677\n",
      "epoch 4 batch id 191901 / 225000 loss 0.00618360098451376 train acc 0.7924580903695134\n",
      "epoch 4 batch id 192001 / 225000 loss 0.31205248832702637 train acc 0.7924711329628491\n",
      "epoch 4 batch id 192101 / 225000 loss 1.1929627656936646 train acc 0.7924685451923728\n",
      "epoch 4 batch id 192201 / 225000 loss 0.006847768556326628 train acc 0.7924711630012331\n",
      "epoch 4 batch id 192301 / 225000 loss 0.06241191178560257 train acc 0.7924763781779606\n",
      "epoch 4 batch id 192401 / 225000 loss 0.0047140102833509445 train acc 0.7924880847812641\n",
      "epoch 4 batch id 192501 / 225000 loss 1.3494876623153687 train acc 0.7924777014145381\n",
      "epoch 4 batch id 192601 / 225000 loss 2.098240613937378 train acc 0.7924790110124039\n",
      "epoch 4 batch id 192701 / 225000 loss 0.006108094938099384 train acc 0.7924881033310673\n",
      "epoch 4 batch id 192801 / 225000 loss 5.84166145324707 train acc 0.792491999522824\n",
      "epoch 4 batch id 192901 / 225000 loss 1.4077762365341187 train acc 0.792501075681308\n",
      "epoch 4 batch id 193001 / 225000 loss 0.5516242980957031 train acc 0.7925010751239631\n",
      "epoch 4 batch id 193101 / 225000 loss 1.1839375495910645 train acc 0.7925036638857386\n",
      "epoch 4 batch id 193201 / 225000 loss 0.7917230725288391 train acc 0.7925036619893272\n",
      "epoch 4 batch id 193301 / 225000 loss 0.0007723896997049451 train acc 0.7925088333738574\n",
      "epoch 4 batch id 193401 / 225000 loss 1.146228551864624 train acc 0.792516584712592\n",
      "epoch 4 batch id 193501 / 225000 loss 0.027378439903259277 train acc 0.7925088242438023\n",
      "epoch 4 batch id 193601 / 225000 loss 0.2861291170120239 train acc 0.7925088196858487\n",
      "epoch 4 batch id 193701 / 225000 loss 0.006434914655983448 train acc 0.792513977728561\n",
      "epoch 4 batch id 193801 / 225000 loss 0.9999596476554871 train acc 0.7925255803633624\n",
      "epoch 4 batch id 193901 / 225000 loss 2.201770305633545 train acc 0.7925229885353866\n",
      "epoch 4 batch id 194001 / 225000 loss 0.07589156180620193 train acc 0.7925165334199308\n",
      "epoch 4 batch id 194101 / 225000 loss 0.1921432912349701 train acc 0.7925178128912267\n",
      "epoch 4 batch id 194201 / 225000 loss 0.671402096748352 train acc 0.7925319643050242\n",
      "epoch 4 batch id 194301 / 225000 loss 3.6074211597442627 train acc 0.7925293745271512\n",
      "epoch 4 batch id 194401 / 225000 loss 3.028550148010254 train acc 0.7925203574055689\n",
      "epoch 4 batch id 194501 / 225000 loss 5.652487277984619 train acc 0.7925113495560434\n",
      "epoch 4 batch id 194601 / 225000 loss 1.0614372491836548 train acc 0.7925254752031079\n",
      "epoch 4 batch id 194701 / 225000 loss 1.2949509620666504 train acc 0.7925254621188387\n",
      "epoch 4 batch id 194801 / 225000 loss 0.0003216313198208809 train acc 0.792529299130908\n",
      "epoch 4 batch id 194901 / 225000 loss 0.6761545538902283 train acc 0.792542111123083\n",
      "epoch 4 batch id 195001 / 225000 loss 0.0005505785229615867 train acc 0.7925318331700864\n",
      "epoch 4 batch id 195101 / 225000 loss 0.00424994807690382 train acc 0.7925395051793687\n",
      "epoch 4 batch id 195201 / 225000 loss 0.004481644835323095 train acc 0.792540765672307\n",
      "epoch 4 batch id 195301 / 225000 loss 0.02243567816913128 train acc 0.7925509854020205\n",
      "epoch 4 batch id 195401 / 225000 loss 1.2991384267807007 train acc 0.7925599152512014\n",
      "epoch 4 batch id 195501 / 225000 loss 0.5117880702018738 train acc 0.7925867386867587\n",
      "epoch 4 batch id 195601 / 225000 loss 2.0003387928009033 train acc 0.7925905286782787\n",
      "epoch 4 batch id 195701 / 225000 loss 2.049762487411499 train acc 0.7926032570094175\n",
      "epoch 4 batch id 195801 / 225000 loss 0.16222377121448517 train acc 0.7925968202409589\n",
      "epoch 4 batch id 195901 / 225000 loss 0.40083280205726624 train acc 0.7926133608302153\n",
      "epoch 4 batch id 196001 / 225000 loss 0.5930359363555908 train acc 0.7926196805118341\n",
      "epoch 4 batch id 196101 / 225000 loss 2.659308671951294 train acc 0.7926259937481196\n",
      "epoch 4 batch id 196201 / 225000 loss 0.26824867725372314 train acc 0.7926373973629084\n",
      "epoch 4 batch id 196301 / 225000 loss 0.007254172582179308 train acc 0.7926436951416447\n",
      "epoch 4 batch id 196401 / 225000 loss 0.004252226557582617 train acc 0.7926512594131394\n",
      "epoch 4 batch id 196501 / 225000 loss 2.301841974258423 train acc 0.7926702663090773\n",
      "epoch 4 batch id 196601 / 225000 loss 0.19404247403144836 train acc 0.7926701797040707\n",
      "epoch 4 batch id 196701 / 225000 loss 0.002196652116253972 train acc 0.792671364151682\n",
      "epoch 4 batch id 196801 / 225000 loss 0.13147586584091187 train acc 0.7926750880330893\n",
      "epoch 4 batch id 196901 / 225000 loss 0.5144438147544861 train acc 0.7926800778055977\n",
      "epoch 4 batch id 197001 / 225000 loss 0.47456586360931396 train acc 0.7926698341632784\n",
      "epoch 4 batch id 197101 / 225000 loss 0.007061691954731941 train acc 0.7926748215381961\n",
      "epoch 4 batch id 197201 / 225000 loss 0.8501979112625122 train acc 0.79268233933905\n",
      "epoch 4 batch id 197301 / 225000 loss 1.9289895296096802 train acc 0.7926733772256603\n",
      "epoch 4 batch id 197401 / 225000 loss 0.9186069965362549 train acc 0.7926986185480317\n",
      "epoch 4 batch id 197501 / 225000 loss 1.7996727228164673 train acc 0.7927048470640655\n",
      "epoch 4 batch id 197601 / 225000 loss 0.00046351453056558967 train acc 0.7927060085728311\n",
      "epoch 4 batch id 197701 / 225000 loss 0.017474491149187088 train acc 0.7927021107632233\n",
      "epoch 4 batch id 197801 / 225000 loss 1.0222758054733276 train acc 0.7927095919636402\n",
      "epoch 4 batch id 197901 / 225000 loss 0.007964929565787315 train acc 0.7927069595403763\n",
      "epoch 4 batch id 198001 / 225000 loss 0.0009030629880726337 train acc 0.7926866530977116\n",
      "epoch 4 batch id 198101 / 225000 loss 1.6379376649856567 train acc 0.7926890828415808\n",
      "epoch 4 batch id 198201 / 225000 loss 2.753267526626587 train acc 0.792681419367208\n",
      "epoch 4 batch id 198301 / 225000 loss 1.187957525253296 train acc 0.7926699814927812\n",
      "epoch 4 batch id 198401 / 225000 loss 0.00687549589201808 train acc 0.7926774562628213\n",
      "epoch 4 batch id 198501 / 225000 loss 1.1670677661895752 train acc 0.7926836640621457\n",
      "epoch 4 batch id 198601 / 225000 loss 0.22924377024173737 train acc 0.7926848303885681\n",
      "epoch 4 batch id 198701 / 225000 loss 0.0017524001887068152 train acc 0.792685995541039\n",
      "epoch 4 batch id 198801 / 225000 loss 1.6514407396316528 train acc 0.7926959622939522\n",
      "epoch 4 batch id 198901 / 225000 loss 0.7416276335716248 train acc 0.792703405211638\n",
      "epoch 4 batch id 199001 / 225000 loss 1.2887964248657227 train acc 0.792684458872066\n",
      "epoch 4 batch id 199101 / 225000 loss 0.670169472694397 train acc 0.7926755767173445\n",
      "epoch 4 batch id 199201 / 225000 loss 1.7831298112869263 train acc 0.7926704685217444\n",
      "epoch 4 batch id 199301 / 225000 loss 0.049298450350761414 train acc 0.792677909292979\n",
      "epoch 4 batch id 199401 / 225000 loss 2.1455483436584473 train acc 0.7926903576210751\n",
      "epoch 4 batch id 199501 / 225000 loss 2.692089080810547 train acc 0.792687755951098\n",
      "epoch 4 batch id 199601 / 225000 loss 1.0570014715194702 train acc 0.7926813993917866\n",
      "epoch 4 batch id 199701 / 225000 loss 1.5986909866333008 train acc 0.7926637823546202\n",
      "epoch 4 batch id 199801 / 225000 loss 0.007708714343607426 train acc 0.7926649516268688\n",
      "epoch 4 batch id 199901 / 225000 loss 2.435030937194824 train acc 0.7926686209673789\n",
      "epoch 4 batch id 200001 / 225000 loss 0.606380820274353 train acc 0.7926847865760671\n",
      "epoch 4 batch id 200101 / 225000 loss 2.1810972690582275 train acc 0.7926734499077965\n",
      "epoch 4 batch id 200201 / 225000 loss 0.013621984049677849 train acc 0.7926908457000714\n",
      "epoch 4 batch id 200301 / 225000 loss 1.2081239223480225 train acc 0.7927007353932332\n",
      "epoch 4 batch id 200401 / 225000 loss 2.094914436340332 train acc 0.7927168527103158\n",
      "epoch 4 batch id 200501 / 225000 loss 0.0071586258709430695 train acc 0.79271674455489\n",
      "epoch 4 batch id 200601 / 225000 loss 2.5907187461853027 train acc 0.792727852802329\n",
      "epoch 4 batch id 200701 / 225000 loss 0.05222790315747261 train acc 0.7927551432230033\n",
      "epoch 4 batch id 200801 / 225000 loss 0.008035551756620407 train acc 0.7927799164346792\n",
      "epoch 4 batch id 200901 / 225000 loss 0.9581888914108276 train acc 0.7927785327101409\n",
      "epoch 4 batch id 201001 / 225000 loss 0.9845332503318787 train acc 0.7927945632111283\n",
      "epoch 4 batch id 201101 / 225000 loss 3.075422763824463 train acc 0.7928006325179885\n",
      "epoch 4 batch id 201201 / 225000 loss 0.004033783450722694 train acc 0.7928017256375466\n",
      "epoch 4 batch id 201301 / 225000 loss 1.6221001148223877 train acc 0.7928090272775595\n",
      "epoch 4 batch id 201401 / 225000 loss 0.0654074177145958 train acc 0.7928001847061336\n",
      "epoch 4 batch id 201501 / 225000 loss 0.004672445356845856 train acc 0.7928000357318326\n",
      "epoch 4 batch id 201601 / 225000 loss 0.8600035309791565 train acc 0.792813527710676\n",
      "epoch 4 batch id 201701 / 225000 loss 1.9858386516571045 train acc 0.7928270063113222\n",
      "epoch 4 batch id 201801 / 225000 loss 2.6705188751220703 train acc 0.7928330384884118\n",
      "epoch 4 batch id 201901 / 225000 loss 0.02083394303917885 train acc 0.7928403029207384\n",
      "epoch 4 batch id 202001 / 225000 loss 0.45252978801727295 train acc 0.7928228078078822\n",
      "epoch 4 batch id 202101 / 225000 loss 0.015430565923452377 train acc 0.7928436771713153\n",
      "epoch 4 batch id 202201 / 225000 loss 0.014189617708325386 train acc 0.7928447435967181\n",
      "epoch 4 batch id 202301 / 225000 loss 1.4693764448165894 train acc 0.7928421016208521\n",
      "epoch 4 batch id 202401 / 225000 loss 0.0019171382300555706 train acc 0.7928629305191179\n",
      "epoch 4 batch id 202501 / 225000 loss 0.004538772627711296 train acc 0.7928701586658832\n",
      "epoch 4 batch id 202601 / 225000 loss 1.7757669687271118 train acc 0.7928588703905707\n",
      "epoch 4 batch id 202701 / 225000 loss 2.5391712188720703 train acc 0.7928525266278903\n",
      "epoch 4 batch id 202801 / 225000 loss 0.7011393308639526 train acc 0.7928696110965923\n",
      "epoch 4 batch id 202901 / 225000 loss 0.18371181190013885 train acc 0.7928829823411417\n",
      "epoch 4 batch id 203001 / 225000 loss 1.9855549335479736 train acc 0.7928864882439003\n",
      "epoch 4 batch id 203101 / 225000 loss 0.012761374935507774 train acc 0.7928936834382894\n",
      "epoch 4 batch id 203201 / 225000 loss 3.2449142932891846 train acc 0.7928971806241111\n",
      "epoch 4 batch id 203301 / 225000 loss 0.004923930391669273 train acc 0.792894525850832\n",
      "epoch 4 batch id 203401 / 225000 loss 0.3168903887271881 train acc 0.792904164679623\n",
      "epoch 4 batch id 203501 / 225000 loss 0.0038789936807006598 train acc 0.7929174795209851\n",
      "epoch 4 batch id 203601 / 225000 loss 0.004457445815205574 train acc 0.7929332370666156\n",
      "epoch 4 batch id 203701 / 225000 loss 1.962371587753296 train acc 0.7929133877595103\n",
      "epoch 4 batch id 203801 / 225000 loss 0.008495664224028587 train acc 0.7929291318492059\n",
      "epoch 4 batch id 203901 / 225000 loss 1.3992576599121094 train acc 0.7929325996439448\n",
      "epoch 4 batch id 204001 / 225000 loss 0.0026683262549340725 train acc 0.7929421914598458\n",
      "epoch 4 batch id 204101 / 225000 loss 1.108504056930542 train acc 0.7929431996903494\n",
      "epoch 4 batch id 204201 / 225000 loss 0.7330554127693176 train acc 0.7929515526368627\n",
      "epoch 4 batch id 204301 / 225000 loss 0.8638869524002075 train acc 0.7929513316136485\n",
      "epoch 4 batch id 204401 / 225000 loss 0.004539444576948881 train acc 0.7929560031506695\n",
      "epoch 4 batch id 204501 / 225000 loss 0.9540991187095642 train acc 0.792974117485978\n",
      "epoch 4 batch id 204601 / 225000 loss 1.6333568096160889 train acc 0.7929738857581341\n",
      "epoch 4 batch id 204701 / 225000 loss 1.5879786014556885 train acc 0.79298586719166\n",
      "epoch 4 batch id 204801 / 225000 loss 0.0012946994975209236 train acc 0.7929722022841685\n",
      "epoch 4 batch id 204901 / 225000 loss 0.5883350968360901 train acc 0.7929780723373727\n",
      "epoch 4 batch id 205001 / 225000 loss 0.0026879599317908287 train acc 0.7929912537012015\n",
      "epoch 4 batch id 205101 / 225000 loss 0.035202208906412125 train acc 0.793012954593103\n",
      "epoch 4 batch id 205201 / 225000 loss 2.150496006011963 train acc 0.793002958075253\n",
      "epoch 4 batch id 205301 / 225000 loss 1.1020653247833252 train acc 0.7929929712958047\n",
      "epoch 4 batch id 205401 / 225000 loss 0.006278157699853182 train acc 0.7930012512110457\n",
      "epoch 4 batch id 205501 / 225000 loss 0.014777285046875477 train acc 0.7929888419034458\n",
      "epoch 4 batch id 205601 / 225000 loss 0.5555544495582581 train acc 0.7929898200884237\n",
      "epoch 4 batch id 205701 / 225000 loss 0.0004988893633708358 train acc 0.7929932280348662\n",
      "epoch 4 batch id 205801 / 225000 loss 1.1388102769851685 train acc 0.7929808407150597\n",
      "epoch 4 batch id 205901 / 225000 loss 0.008836248889565468 train acc 0.7929757504820277\n",
      "epoch 4 batch id 206001 / 225000 loss 0.0009331594919785857 train acc 0.792994936917782\n",
      "epoch 4 batch id 206101 / 225000 loss 0.0030095616821199656 train acc 0.7930031877574587\n",
      "epoch 4 batch id 206201 / 225000 loss 1.320269227027893 train acc 0.7930005189111595\n",
      "epoch 4 batch id 206301 / 225000 loss 1.6210894584655762 train acc 0.7929942171875076\n",
      "epoch 4 batch id 206401 / 225000 loss 0.27182909846305847 train acc 0.7929964002112393\n",
      "epoch 4 batch id 206501 / 225000 loss 1.4742333889007568 train acc 0.7930070556559048\n",
      "epoch 4 batch id 206601 / 225000 loss 0.001985150156542659 train acc 0.793023751095106\n",
      "epoch 4 batch id 206701 / 225000 loss 1.6271933317184448 train acc 0.7930174503268006\n",
      "epoch 4 batch id 206801 / 225000 loss 0.004506257828325033 train acc 0.7930184090018907\n",
      "epoch 4 batch id 206901 / 225000 loss 0.006367821712046862 train acc 0.7930254082870551\n",
      "epoch 4 batch id 207001 / 225000 loss 0.0022016987204551697 train acc 0.7930251544678528\n",
      "epoch 4 batch id 207101 / 225000 loss 0.003403953742235899 train acc 0.7930309365961535\n",
      "epoch 4 batch id 207201 / 225000 loss 0.04760567843914032 train acc 0.7930258541223256\n",
      "epoch 4 batch id 207301 / 225000 loss 0.004048865754157305 train acc 0.7930376602138919\n",
      "epoch 4 batch id 207401 / 225000 loss 0.22814694046974182 train acc 0.793030168610566\n",
      "epoch 4 batch id 207501 / 225000 loss 0.01642322540283203 train acc 0.7930419612435603\n",
      "epoch 4 batch id 207601 / 225000 loss 0.9988154768943787 train acc 0.7930429044176088\n",
      "epoch 4 batch id 207701 / 225000 loss 0.005142329726368189 train acc 0.793048661296768\n",
      "epoch 4 batch id 207801 / 225000 loss 1.0778733491897583 train acc 0.7930508034128806\n",
      "epoch 4 batch id 207901 / 225000 loss 0.05217202007770538 train acc 0.7930493359820299\n",
      "epoch 4 batch id 208001 / 225000 loss 0.5940141677856445 train acc 0.7930550814659545\n",
      "epoch 4 batch id 208101 / 225000 loss 0.4663962125778198 train acc 0.7930391973128433\n",
      "epoch 4 batch id 208201 / 225000 loss 2.2006351947784424 train acc 0.7930353360454561\n",
      "epoch 4 batch id 208301 / 225000 loss 0.018579626455903053 train acc 0.7930338788579988\n",
      "epoch 4 batch id 208401 / 225000 loss 0.26054373383522034 train acc 0.7930360219000868\n",
      "epoch 4 batch id 208501 / 225000 loss 2.5394954681396484 train acc 0.7930393619215256\n",
      "epoch 4 batch id 208601 / 225000 loss 2.894242286682129 train acc 0.7930367064395665\n",
      "epoch 4 batch id 208701 / 225000 loss 0.8458200693130493 train acc 0.7930364492743207\n",
      "epoch 4 batch id 208801 / 225000 loss 0.002746892860159278 train acc 0.7930529547272284\n",
      "epoch 4 batch id 208901 / 225000 loss 0.07020147889852524 train acc 0.7930479030737048\n",
      "epoch 4 batch id 209001 / 225000 loss 0.6382275819778442 train acc 0.7930572102525826\n",
      "epoch 4 batch id 209101 / 225000 loss 2.979116439819336 train acc 0.7930629217459505\n",
      "epoch 4 batch id 209201 / 225000 loss 0.6351559162139893 train acc 0.7930638476871525\n",
      "epoch 4 batch id 209301 / 225000 loss 1.1791737079620361 train acc 0.793054022675477\n",
      "epoch 4 batch id 209401 / 225000 loss 2.7380058765411377 train acc 0.7930454009293174\n",
      "epoch 4 batch id 209501 / 225000 loss 0.016162967309355736 train acc 0.793065426895337\n",
      "epoch 4 batch id 209601 / 225000 loss 1.2255977392196655 train acc 0.7930603861622798\n",
      "epoch 4 batch id 209701 / 225000 loss 3.6466853618621826 train acc 0.7930660797993333\n",
      "epoch 4 batch id 209801 / 225000 loss 1.0116130113601685 train acc 0.7930789176410027\n",
      "epoch 4 batch id 209901 / 225000 loss 0.7653988599777222 train acc 0.7930810239112724\n",
      "epoch 4 batch id 210001 / 225000 loss 0.0009577057207934558 train acc 0.7930878900576664\n",
      "epoch 4 batch id 210101 / 225000 loss 0.01231332030147314 train acc 0.7931137881304706\n",
      "epoch 4 batch id 210201 / 225000 loss 2.596921682357788 train acc 0.7931158748055432\n",
      "epoch 4 batch id 210301 / 225000 loss 1.4800143241882324 train acc 0.7931262809021355\n",
      "epoch 4 batch id 210401 / 225000 loss 0.0499325767159462 train acc 0.7931307360706461\n",
      "epoch 4 batch id 210501 / 225000 loss 1.9580349922180176 train acc 0.7931363746490515\n",
      "epoch 4 batch id 210601 / 225000 loss 0.47402167320251465 train acc 0.7931455691093584\n",
      "epoch 4 batch id 210701 / 225000 loss 0.18350455164909363 train acc 0.7931452627182595\n",
      "epoch 4 batch id 210801 / 225000 loss 0.18093721568584442 train acc 0.7931449566178529\n",
      "epoch 4 batch id 210901 / 225000 loss 0.021536633372306824 train acc 0.7931565047107411\n",
      "epoch 4 batch id 211001 / 225000 loss 0.017127487808465958 train acc 0.7931656722006056\n",
      "epoch 4 batch id 211101 / 225000 loss 0.011824975721538067 train acc 0.7931760152723104\n",
      "epoch 4 batch id 211201 / 225000 loss 0.00892797764390707 train acc 0.7931662255387049\n",
      "epoch 4 batch id 211301 / 225000 loss 1.9867877960205078 train acc 0.7931588113638838\n",
      "epoch 4 batch id 211401 / 225000 loss 0.7340590953826904 train acc 0.793170325589756\n",
      "epoch 4 batch id 211501 / 225000 loss 0.004476781468838453 train acc 0.7931605524323762\n",
      "epoch 4 batch id 211601 / 225000 loss 1.5249062776565552 train acc 0.793169692014688\n",
      "epoch 4 batch id 211701 / 225000 loss 1.3317785263061523 train acc 0.7931681947652586\n",
      "epoch 4 batch id 211801 / 225000 loss 0.0008837390341795981 train acc 0.7931525346905822\n",
      "epoch 4 batch id 211901 / 225000 loss 0.0009060516022145748 train acc 0.7931545863398474\n",
      "epoch 4 batch id 212001 / 225000 loss 0.0021032255608588457 train acc 0.7931660699713681\n",
      "epoch 4 batch id 212101 / 225000 loss 0.0014567211037501693 train acc 0.7931692919882509\n",
      "epoch 4 batch id 212201 / 225000 loss 2.0011439323425293 train acc 0.7931677984552382\n",
      "epoch 4 batch id 212301 / 225000 loss 0.9803993105888367 train acc 0.7931816147827848\n",
      "epoch 4 batch id 212401 / 225000 loss 2.3683440685272217 train acc 0.7931754087786781\n",
      "epoch 4 batch id 212501 / 225000 loss 2.0574841499328613 train acc 0.7931750909407486\n",
      "epoch 4 batch id 212601 / 225000 loss 0.014138277620077133 train acc 0.7931794770485557\n",
      "epoch 4 batch id 212701 / 225000 loss 0.8300957679748535 train acc 0.7931873851086737\n",
      "epoch 4 batch id 212801 / 225000 loss 0.0038805892691016197 train acc 0.7932058589950235\n",
      "epoch 4 batch id 212901 / 225000 loss 0.14244656264781952 train acc 0.7932020046876248\n",
      "epoch 4 batch id 213001 / 225000 loss 0.49518948793411255 train acc 0.7931958065924574\n",
      "epoch 4 batch id 213101 / 225000 loss 1.1383576393127441 train acc 0.79318257539852\n",
      "epoch 4 batch id 213201 / 225000 loss 0.11567290127277374 train acc 0.7931869456522249\n",
      "epoch 4 batch id 213301 / 225000 loss 0.3218928575515747 train acc 0.7931983441240313\n",
      "epoch 4 batch id 213401 / 225000 loss 0.9997294545173645 train acc 0.7932202754438826\n",
      "epoch 4 batch id 213501 / 225000 loss 2.505727529525757 train acc 0.7932175961705097\n",
      "epoch 4 batch id 213601 / 225000 loss 0.00543560367077589 train acc 0.793214919405808\n",
      "epoch 4 batch id 213701 / 225000 loss 2.818721055984497 train acc 0.793218094440363\n",
      "epoch 4 batch id 213801 / 225000 loss 0.7540696263313293 train acc 0.7932095733883378\n",
      "epoch 4 batch id 213901 / 225000 loss 1.0037986040115356 train acc 0.793211579188503\n",
      "epoch 4 batch id 214001 / 225000 loss 0.08887343853712082 train acc 0.7932112466764174\n",
      "epoch 4 batch id 214101 / 225000 loss 0.5770444869995117 train acc 0.7932331002657624\n",
      "epoch 4 batch id 214201 / 225000 loss 0.13492867350578308 train acc 0.7932292566327889\n",
      "epoch 4 batch id 214301 / 225000 loss 0.8553096055984497 train acc 0.7932335826711028\n",
      "epoch 4 batch id 214401 / 225000 loss 0.8797908425331116 train acc 0.7932390707132896\n",
      "epoch 4 batch id 214501 / 225000 loss 0.1592569649219513 train acc 0.7932433881427127\n",
      "epoch 4 batch id 214601 / 225000 loss 0.7385846376419067 train acc 0.7932348870694917\n",
      "epoch 4 batch id 214701 / 225000 loss 0.01012471690773964 train acc 0.7932263939152588\n",
      "epoch 4 batch id 214801 / 225000 loss 0.019676273688673973 train acc 0.793235366688237\n",
      "epoch 4 batch id 214901 / 225000 loss 0.04064914956688881 train acc 0.7932513110688177\n",
      "epoch 4 batch id 215001 / 225000 loss 0.2650027573108673 train acc 0.793253287194013\n",
      "epoch 4 batch id 215101 / 225000 loss 0.0011685846839100122 train acc 0.7932587482159543\n",
      "epoch 4 batch id 215201 / 225000 loss 0.013800367712974548 train acc 0.7932734977997314\n",
      "epoch 4 batch id 215301 / 225000 loss 1.7812868356704712 train acc 0.7932812666917478\n",
      "epoch 4 batch id 215401 / 225000 loss 0.005927783437073231 train acc 0.793294831500318\n",
      "epoch 4 batch id 215501 / 225000 loss 1.3290001153945923 train acc 0.7932875021461617\n",
      "epoch 4 batch id 215601 / 225000 loss 1.0540391206741333 train acc 0.793283658239062\n",
      "epoch 4 batch id 215701 / 225000 loss 0.001524512656033039 train acc 0.7932948850492116\n",
      "epoch 4 batch id 215801 / 225000 loss 4.819416046142578 train acc 0.7932945167075222\n",
      "epoch 4 batch id 215901 / 225000 loss 0.6877443194389343 train acc 0.7932906748926591\n",
      "epoch 4 batch id 216001 / 225000 loss 1.5182859897613525 train acc 0.7932833644288684\n",
      "epoch 4 batch id 216101 / 225000 loss 0.002066820627078414 train acc 0.7932772175973272\n",
      "epoch 4 batch id 216201 / 225000 loss 0.9353134036064148 train acc 0.7932652947951212\n",
      "epoch 4 batch id 216301 / 225000 loss 1.0761561393737793 train acc 0.7932730315624985\n",
      "epoch 4 batch id 216401 / 225000 loss 0.8007831573486328 train acc 0.7932796059167934\n",
      "epoch 4 batch id 216501 / 225000 loss 0.7885974645614624 train acc 0.793291947843197\n",
      "epoch 4 batch id 216601 / 225000 loss 2.4401514530181885 train acc 0.7932927364139593\n",
      "epoch 4 batch id 216701 / 225000 loss 0.007835069671273232 train acc 0.7932969852469531\n",
      "epoch 4 batch id 216801 / 225000 loss 1.8594918251037598 train acc 0.793290851979465\n",
      "epoch 4 batch id 216901 / 225000 loss 2.1003658771514893 train acc 0.7933112341575189\n",
      "epoch 4 batch id 217001 / 225000 loss 1.3758888244628906 train acc 0.7933108603186161\n",
      "epoch 4 batch id 217101 / 225000 loss 1.9691271781921387 train acc 0.7933081837485778\n",
      "epoch 4 batch id 217201 / 225000 loss 1.917015552520752 train acc 0.7932997546051814\n",
      "epoch 4 batch id 217301 / 225000 loss 0.07522127777338028 train acc 0.7932936341756366\n",
      "epoch 4 batch id 217401 / 225000 loss 0.8354184031486511 train acc 0.7933139681970184\n",
      "epoch 4 batch id 217501 / 225000 loss 1.0779386758804321 train acc 0.7933089962804769\n",
      "epoch 4 batch id 217601 / 225000 loss 0.006053141318261623 train acc 0.7933166667432594\n",
      "epoch 4 batch id 217701 / 225000 loss 0.0007048444822430611 train acc 0.7933208850671334\n",
      "epoch 4 batch id 217801 / 225000 loss 1.7990150451660156 train acc 0.7933101776392211\n",
      "epoch 4 batch id 217901 / 225000 loss 1.7830957174301147 train acc 0.793306363899202\n",
      "epoch 4 batch id 218001 / 225000 loss 2.623774528503418 train acc 0.7933048472254715\n",
      "epoch 4 batch id 218101 / 225000 loss 0.008026007562875748 train acc 0.7933159407797304\n",
      "epoch 4 batch id 218201 / 225000 loss 0.3638703525066376 train acc 0.7933144211071443\n",
      "epoch 4 batch id 218301 / 225000 loss 1.0048470497131348 train acc 0.7933197740734124\n",
      "epoch 4 batch id 218401 / 225000 loss 0.2752256691455841 train acc 0.7933228327709122\n",
      "epoch 4 batch id 218501 / 225000 loss 1.860642910003662 train acc 0.7933190237115619\n",
      "epoch 4 batch id 218601 / 225000 loss 0.02589801512658596 train acc 0.7933186490455213\n",
      "epoch 4 batch id 218701 / 225000 loss 1.0549017190933228 train acc 0.7933377076465128\n",
      "epoch 4 batch id 218801 / 225000 loss 0.6414798498153687 train acc 0.7933361821929515\n",
      "epoch 4 batch id 218901 / 225000 loss 1.5495175123214722 train acc 0.793352931233754\n",
      "epoch 4 batch id 219001 / 225000 loss 0.000394202652387321 train acc 0.7933650987895032\n",
      "epoch 4 batch id 219101 / 225000 loss 0.001291606342419982 train acc 0.7933806783173057\n",
      "epoch 4 batch id 219201 / 225000 loss 1.6844786405563354 train acc 0.7933894005958002\n",
      "epoch 4 batch id 219301 / 225000 loss 0.0009930412052199244 train acc 0.7933627753635414\n",
      "epoch 4 batch id 219401 / 225000 loss 1.3248399496078491 train acc 0.7933635215883246\n",
      "epoch 4 batch id 219501 / 225000 loss 3.4057135581970215 train acc 0.7933608502922538\n",
      "epoch 4 batch id 219601 / 225000 loss 0.0030072927474975586 train acc 0.7933615967140405\n",
      "epoch 4 batch id 219701 / 225000 loss 4.830248832702637 train acc 0.7933498254445815\n",
      "epoch 4 batch id 219801 / 225000 loss 0.7566129565238953 train acc 0.7933619501276155\n",
      "epoch 4 batch id 219901 / 225000 loss 0.46146854758262634 train acc 0.7933706531575573\n",
      "epoch 4 batch id 220001 / 225000 loss 3.050218105316162 train acc 0.7933816209926319\n",
      "epoch 4 batch id 220101 / 225000 loss 0.029261866584420204 train acc 0.7933846279662519\n",
      "epoch 4 batch id 220201 / 225000 loss 0.06140794977545738 train acc 0.7933944441669202\n",
      "epoch 4 batch id 220301 / 225000 loss 0.5151144862174988 train acc 0.7933917685348683\n",
      "epoch 4 batch id 220401 / 225000 loss 0.0018825423903763294 train acc 0.7934140498455089\n",
      "epoch 4 batch id 220501 / 225000 loss 1.72588050365448 train acc 0.7934193042208425\n",
      "epoch 4 batch id 220601 / 225000 loss 2.628108501434326 train acc 0.7934132211549358\n",
      "epoch 4 batch id 220701 / 225000 loss 1.0843088626861572 train acc 0.7934014798301775\n",
      "epoch 4 batch id 220801 / 225000 loss 1.3072774410247803 train acc 0.793412393965607\n",
      "epoch 4 batch id 220901 / 225000 loss 1.8340014219284058 train acc 0.7934085857465561\n",
      "epoch 4 batch id 221001 / 225000 loss 0.6565719842910767 train acc 0.7934160931398501\n",
      "epoch 4 batch id 221101 / 225000 loss 1.5592771768569946 train acc 0.7934360314969177\n",
      "epoch 4 batch id 221201 / 225000 loss 1.0145161151885986 train acc 0.7934367385319234\n",
      "epoch 4 batch id 221301 / 225000 loss 0.7804609537124634 train acc 0.793449871442063\n",
      "epoch 4 batch id 221401 / 225000 loss 0.0015152482083067298 train acc 0.7934494424144426\n",
      "epoch 4 batch id 221501 / 225000 loss 3.194870948791504 train acc 0.7934603004049643\n",
      "epoch 4 batch id 221601 / 225000 loss 0.003843925427645445 train acc 0.7934542262895925\n",
      "epoch 4 batch id 221701 / 225000 loss 1.181281566619873 train acc 0.7934628170373611\n",
      "epoch 4 batch id 221801 / 225000 loss 0.003044567769393325 train acc 0.7934668914928247\n",
      "epoch 4 batch id 221901 / 225000 loss 3.5897152423858643 train acc 0.7934653291332622\n",
      "epoch 4 batch id 222001 / 225000 loss 0.006738672032952309 train acc 0.7934727771496525\n",
      "epoch 4 batch id 222101 / 225000 loss 1.8043690919876099 train acc 0.7934678367049225\n",
      "epoch 4 batch id 222201 / 225000 loss 2.2750496864318848 train acc 0.7934741517814952\n",
      "epoch 4 batch id 222301 / 225000 loss 0.564242422580719 train acc 0.7934883333858147\n",
      "epoch 4 batch id 222401 / 225000 loss 0.0013355546398088336 train acc 0.7934822685149797\n",
      "epoch 4 batch id 222501 / 225000 loss 1.4194753170013428 train acc 0.7934807034575125\n",
      "epoch 4 batch id 222601 / 225000 loss 1.7248739004135132 train acc 0.793483632149002\n",
      "epoch 4 batch id 222701 / 225000 loss 0.08650577068328857 train acc 0.7934888033731325\n",
      "epoch 4 batch id 222801 / 225000 loss 0.016740988940000534 train acc 0.7934984582654476\n",
      "epoch 4 batch id 222901 / 225000 loss 0.6474706530570984 train acc 0.793496888753303\n",
      "epoch 4 batch id 223001 / 225000 loss 2.917304754257202 train acc 0.7934863520791386\n",
      "epoch 4 batch id 223101 / 225000 loss 3.4712443351745605 train acc 0.7934870305377385\n",
      "epoch 4 batch id 223201 / 225000 loss 0.001089147524908185 train acc 0.7934865883217369\n",
      "epoch 4 batch id 223301 / 225000 loss 0.7171776294708252 train acc 0.7934962225874492\n",
      "epoch 4 batch id 223401 / 225000 loss 0.0029417031910270452 train acc 0.7935058482280741\n",
      "epoch 4 batch id 223501 / 225000 loss 1.2088420391082764 train acc 0.7935143466919611\n",
      "epoch 4 batch id 223601 / 225000 loss 1.3540810346603394 train acc 0.793523955617372\n",
      "epoch 4 batch id 223701 / 225000 loss 0.0012535166461020708 train acc 0.7935279681360388\n",
      "epoch 4 batch id 223801 / 225000 loss 0.001170382951386273 train acc 0.7935409135794746\n",
      "epoch 4 batch id 223901 / 225000 loss 0.13731160759925842 train acc 0.7935482646348163\n",
      "epoch 4 batch id 224001 / 225000 loss 1.1293745040893555 train acc 0.7935399841964991\n",
      "epoch 4 batch id 224101 / 225000 loss 2.1705806255340576 train acc 0.7935473291060727\n",
      "epoch 4 batch id 224201 / 225000 loss 1.0615644454956055 train acc 0.793559127746977\n",
      "epoch 4 batch id 224301 / 225000 loss 2.5567753314971924 train acc 0.7935619992777563\n",
      "epoch 4 batch id 224401 / 225000 loss 0.5624589323997498 train acc 0.793557069710028\n",
      "epoch 4 batch id 224501 / 225000 loss 0.08607429265975952 train acc 0.793567734664879\n",
      "epoch 4 batch id 224601 / 225000 loss 0.011397168040275574 train acc 0.7935750508679836\n",
      "epoch 4 batch id 224701 / 225000 loss 0.34814754128456116 train acc 0.7935868109176194\n",
      "epoch 4 batch id 224801 / 225000 loss 1.0476312637329102 train acc 0.7935774307053794\n",
      "epoch 4 batch id 224901 / 225000 loss 2.0449044704437256 train acc 0.7935658356343458\n",
      "epoch 4 train acc 0.7935644444444444\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38e8c60d7fa424dba29150c0b3909b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 test acc 0.79426\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03b7ed670454ea8a07faae3fc24d879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 / 225000 loss 1.9072415828704834 train acc 0.5\n",
      "epoch 5 batch id 101 / 225000 loss 1.7172784805297852 train acc 0.8118811881188119\n",
      "epoch 5 batch id 201 / 225000 loss 1.7981948852539062 train acc 0.8121890547263682\n",
      "epoch 5 batch id 301 / 225000 loss 0.4723477065563202 train acc 0.8156146179401993\n",
      "epoch 5 batch id 401 / 225000 loss 0.044587306678295135 train acc 0.807356608478803\n",
      "epoch 5 batch id 501 / 225000 loss 1.070417046546936 train acc 0.8073852295409182\n",
      "epoch 5 batch id 601 / 225000 loss 1.9234647750854492 train acc 0.8049084858569051\n",
      "epoch 5 batch id 701 / 225000 loss 1.8338991403579712 train acc 0.7999286733238231\n",
      "epoch 5 batch id 801 / 225000 loss 1.990224838256836 train acc 0.8043071161048689\n",
      "epoch 5 batch id 901 / 225000 loss 0.05950021743774414 train acc 0.8002219755826859\n",
      "epoch 5 batch id 1001 / 225000 loss 1.0702122449874878 train acc 0.8044455544455544\n",
      "epoch 5 batch id 1101 / 225000 loss 0.0009270061855204403 train acc 0.8054041780199819\n",
      "epoch 5 batch id 1201 / 225000 loss 0.8626514673233032 train acc 0.805578684429642\n",
      "epoch 5 batch id 1301 / 225000 loss 1.6608561277389526 train acc 0.8047655649500385\n",
      "epoch 5 batch id 1401 / 225000 loss 0.008946281857788563 train acc 0.8060314061384726\n",
      "epoch 5 batch id 1501 / 225000 loss 3.5325427055358887 train acc 0.8056295802798135\n",
      "epoch 5 batch id 1601 / 225000 loss 0.006436916068196297 train acc 0.8071517801374141\n",
      "epoch 5 batch id 1701 / 225000 loss 0.0008316285093314946 train acc 0.8077601410934744\n",
      "epoch 5 batch id 1801 / 225000 loss 1.7741644382476807 train acc 0.807329261521377\n",
      "epoch 5 batch id 1901 / 225000 loss 1.4133708477020264 train acc 0.8068122041031036\n",
      "epoch 5 batch id 2001 / 225000 loss 0.0004094079486094415 train acc 0.8085957021489255\n",
      "epoch 5 batch id 2101 / 225000 loss 1.7436978816986084 train acc 0.8092574964302713\n",
      "epoch 5 batch id 2201 / 225000 loss 0.0007910002022981644 train acc 0.8103134938664244\n",
      "epoch 5 batch id 2301 / 225000 loss 1.0628468990325928 train acc 0.8096479791395046\n",
      "epoch 5 batch id 2401 / 225000 loss 1.0778793096542358 train acc 0.809454394002499\n",
      "epoch 5 batch id 2501 / 225000 loss 0.0022754711098968983 train acc 0.8102758896441423\n",
      "epoch 5 batch id 2601 / 225000 loss 0.9168496131896973 train acc 0.8095924644367551\n",
      "epoch 5 batch id 2701 / 225000 loss 1.6735188961029053 train acc 0.8092373195112921\n",
      "epoch 5 batch id 2801 / 225000 loss 0.9250030517578125 train acc 0.8083720099964299\n",
      "epoch 5 batch id 2901 / 225000 loss 0.009759724140167236 train acc 0.8079110651499483\n",
      "epoch 5 batch id 3001 / 225000 loss 0.3772311806678772 train acc 0.8091469510163279\n",
      "epoch 5 batch id 3101 / 225000 loss 1.669348955154419 train acc 0.8088519832312158\n",
      "epoch 5 batch id 3201 / 225000 loss 0.0005482440465129912 train acc 0.8084973445798188\n",
      "epoch 5 batch id 3301 / 225000 loss 0.24592353403568268 train acc 0.8086943350499849\n",
      "epoch 5 batch id 3401 / 225000 loss 0.0020838903728872538 train acc 0.8076301087915319\n",
      "epoch 5 batch id 3501 / 225000 loss 1.6090095043182373 train acc 0.8063410454155956\n",
      "epoch 5 batch id 3601 / 225000 loss 0.011840566992759705 train acc 0.8064426548181061\n",
      "epoch 5 batch id 3701 / 225000 loss 2.5280230045318604 train acc 0.8060659281275331\n",
      "epoch 5 batch id 3801 / 225000 loss 0.2654848098754883 train acc 0.8063667455932649\n",
      "epoch 5 batch id 3901 / 225000 loss 1.9727177619934082 train acc 0.8049218149192515\n",
      "epoch 5 batch id 4001 / 225000 loss 1.0089105367660522 train acc 0.8043614096475881\n",
      "epoch 5 batch id 4101 / 225000 loss 2.476315498352051 train acc 0.804316020482809\n",
      "epoch 5 batch id 4201 / 225000 loss 0.006752107758074999 train acc 0.8039157343489646\n",
      "epoch 5 batch id 4301 / 225000 loss 0.08054354786872864 train acc 0.804231574052546\n",
      "epoch 5 batch id 4401 / 225000 loss 0.008317124098539352 train acc 0.8035105657805044\n",
      "epoch 5 batch id 4501 / 225000 loss 0.0014271630207076669 train acc 0.8042657187291713\n",
      "epoch 5 batch id 4601 / 225000 loss 0.1371823102235794 train acc 0.8043360139100195\n",
      "epoch 5 batch id 4701 / 225000 loss 0.012142733670771122 train acc 0.8037651563497128\n",
      "epoch 5 batch id 4801 / 225000 loss 1.1881989240646362 train acc 0.8035305144761508\n",
      "epoch 5 batch id 4901 / 225000 loss 0.0035913758911192417 train acc 0.8028973678841053\n",
      "epoch 5 batch id 5001 / 225000 loss 1.5982908010482788 train acc 0.8023395320935813\n",
      "epoch 5 batch id 5101 / 225000 loss 1.107562780380249 train acc 0.8025877278964909\n",
      "epoch 5 batch id 5201 / 225000 loss 0.003729814663529396 train acc 0.8026821765045183\n",
      "epoch 5 batch id 5301 / 225000 loss 0.005099771544337273 train acc 0.8023486134691568\n",
      "epoch 5 batch id 5401 / 225000 loss 2.1766209602355957 train acc 0.802397704128865\n",
      "epoch 5 batch id 5501 / 225000 loss 0.03144048899412155 train acc 0.8029449191056172\n",
      "epoch 5 batch id 5601 / 225000 loss 0.7932714819908142 train acc 0.8025352615604356\n",
      "epoch 5 batch id 5701 / 225000 loss 0.7189366817474365 train acc 0.8019207156639186\n",
      "epoch 5 batch id 5801 / 225000 loss 0.012568757869303226 train acc 0.8019737976210998\n",
      "epoch 5 batch id 5901 / 225000 loss 0.16541430354118347 train acc 0.8014319606846297\n",
      "epoch 5 batch id 6001 / 225000 loss 0.796798825263977 train acc 0.8018663556073987\n",
      "epoch 5 batch id 6101 / 225000 loss 0.44650915265083313 train acc 0.8022045566300606\n",
      "epoch 5 batch id 6201 / 225000 loss 1.4618700742721558 train acc 0.8024109014675053\n",
      "epoch 5 batch id 6301 / 225000 loss 1.294434905052185 train acc 0.8022139342961435\n",
      "epoch 5 batch id 6401 / 225000 loss 1.5076491832733154 train acc 0.8018278394000937\n",
      "epoch 5 batch id 6501 / 225000 loss 0.5154273509979248 train acc 0.8016074450084603\n",
      "epoch 5 batch id 6601 / 225000 loss 0.0058636777102947235 train acc 0.8015830934706862\n",
      "epoch 5 batch id 6701 / 225000 loss 0.0013918823096901178 train acc 0.8011490822265334\n",
      "epoch 5 batch id 6801 / 225000 loss 2.2181336879730225 train acc 0.800691074841935\n",
      "epoch 5 batch id 6901 / 225000 loss 1.584165096282959 train acc 0.8009708737864077\n",
      "epoch 5 batch id 7001 / 225000 loss 0.6552440524101257 train acc 0.8010998428795886\n",
      "epoch 5 batch id 7101 / 225000 loss 1.1867480278015137 train acc 0.8009435290804112\n",
      "epoch 5 batch id 7201 / 225000 loss 0.00622083293274045 train acc 0.8012081655325649\n",
      "epoch 5 batch id 7301 / 225000 loss 0.001754507888108492 train acc 0.801397068894672\n",
      "epoch 5 batch id 7401 / 225000 loss 2.4354751110076904 train acc 0.8012430752601\n",
      "epoch 5 batch id 7501 / 225000 loss 1.5781919956207275 train acc 0.8009265431275829\n",
      "epoch 5 batch id 7601 / 225000 loss 0.41397228837013245 train acc 0.800585449282989\n",
      "epoch 5 batch id 7701 / 225000 loss 1.0923656225204468 train acc 0.8005453837164005\n",
      "epoch 5 batch id 7801 / 225000 loss 0.0031925137154757977 train acc 0.8002179207793872\n",
      "epoch 5 batch id 7901 / 225000 loss 1.0133233070373535 train acc 0.8002468042019998\n",
      "epoch 5 batch id 8001 / 225000 loss 0.8115535378456116 train acc 0.7998375203099612\n",
      "epoch 5 batch id 8101 / 225000 loss 1.8717036247253418 train acc 0.7997778052092335\n",
      "epoch 5 batch id 8201 / 225000 loss 0.003587868297472596 train acc 0.799871966833313\n",
      "epoch 5 batch id 8301 / 225000 loss 0.15237359702587128 train acc 0.7997831586555837\n",
      "epoch 5 batch id 8401 / 225000 loss 1.3403749465942383 train acc 0.8000535650517796\n",
      "epoch 5 batch id 8501 / 225000 loss 0.4685255289077759 train acc 0.800288201388072\n",
      "epoch 5 batch id 8601 / 225000 loss 1.6978950500488281 train acc 0.8003720497616557\n",
      "epoch 5 batch id 8701 / 225000 loss 2.1893434524536133 train acc 0.8000229858636938\n",
      "epoch 5 batch id 8801 / 225000 loss 0.41212737560272217 train acc 0.8002215657311669\n",
      "epoch 5 batch id 8901 / 225000 loss 0.0009477513958700001 train acc 0.8005561172901922\n",
      "epoch 5 batch id 9001 / 225000 loss 0.3518832325935364 train acc 0.8006332629707811\n",
      "epoch 5 batch id 9101 / 225000 loss 0.15903717279434204 train acc 0.8002692011866828\n",
      "epoch 5 batch id 9201 / 225000 loss 0.6512015461921692 train acc 0.8004293011629171\n",
      "epoch 5 batch id 9301 / 225000 loss 0.0021032318472862244 train acc 0.8005322008386195\n",
      "epoch 5 batch id 9401 / 225000 loss 0.0014446373097598553 train acc 0.8007126901393469\n",
      "epoch 5 batch id 9501 / 225000 loss 2.0907280445098877 train acc 0.8008104410062099\n",
      "epoch 5 batch id 9601 / 225000 loss 0.0021813625935465097 train acc 0.800958233517342\n",
      "epoch 5 batch id 9701 / 225000 loss 3.293739080429077 train acc 0.8011545201525616\n",
      "epoch 5 batch id 9801 / 225000 loss 0.004626584239304066 train acc 0.8011937557392103\n",
      "epoch 5 batch id 9901 / 225000 loss 0.0032336143776774406 train acc 0.8012069487930512\n",
      "epoch 5 batch id 10001 / 225000 loss 1.8967976570129395 train acc 0.8012948705129487\n",
      "epoch 5 batch id 10101 / 225000 loss 4.0561113357543945 train acc 0.801059301059301\n",
      "epoch 5 batch id 10201 / 225000 loss 0.030092814937233925 train acc 0.8010979315753357\n",
      "epoch 5 batch id 10301 / 225000 loss 0.0032465504482388496 train acc 0.80089311717309\n",
      "epoch 5 batch id 10401 / 225000 loss 0.03214893862605095 train acc 0.8010527833862129\n",
      "epoch 5 batch id 10501 / 225000 loss 2.87255859375 train acc 0.8011617941148462\n",
      "epoch 5 batch id 10601 / 225000 loss 0.021832816302776337 train acc 0.8010093387416282\n",
      "epoch 5 batch id 10701 / 225000 loss 0.9641488194465637 train acc 0.801186804971498\n",
      "epoch 5 batch id 10801 / 225000 loss 0.07049035280942917 train acc 0.8010600870289788\n",
      "epoch 5 batch id 10901 / 225000 loss 0.9410759806632996 train acc 0.8008668929456013\n",
      "epoch 5 batch id 11001 / 225000 loss 1.4603571891784668 train acc 0.8009499136442142\n",
      "epoch 5 batch id 11101 / 225000 loss 5.5828657150268555 train acc 0.800693631204396\n",
      "epoch 5 batch id 11201 / 225000 loss 1.3604090213775635 train acc 0.8006874386215517\n",
      "epoch 5 batch id 11301 / 225000 loss 1.5784533023834229 train acc 0.800681355632245\n",
      "epoch 5 batch id 11401 / 225000 loss 0.003853986505419016 train acc 0.8008069467590562\n",
      "epoch 5 batch id 11501 / 225000 loss 0.00860228668898344 train acc 0.8007999304408312\n",
      "epoch 5 batch id 11601 / 225000 loss 3.2955877780914307 train acc 0.8007930350831824\n",
      "epoch 5 batch id 11701 / 225000 loss 0.00615574000403285 train acc 0.8008930860610204\n",
      "epoch 5 batch id 11801 / 225000 loss 0.0032124852295964956 train acc 0.8007584103042115\n",
      "epoch 5 batch id 11901 / 225000 loss 0.8900961875915527 train acc 0.8006259978153096\n",
      "epoch 5 batch id 12001 / 225000 loss 0.696247398853302 train acc 0.8006207816015332\n",
      "epoch 5 batch id 12101 / 225000 loss 1.5838541984558105 train acc 0.8006982893975705\n",
      "epoch 5 batch id 12201 / 225000 loss 0.9565696120262146 train acc 0.8010204081632653\n",
      "epoch 5 batch id 12301 / 225000 loss 0.0019521752838045359 train acc 0.8011340541419397\n",
      "epoch 5 batch id 12401 / 225000 loss 1.142028570175171 train acc 0.8011450689460528\n",
      "epoch 5 batch id 12501 / 225000 loss 2.5850114822387695 train acc 0.8012159027277818\n",
      "epoch 5 batch id 12601 / 225000 loss 1.2807430028915405 train acc 0.8011268946908976\n",
      "epoch 5 batch id 12701 / 225000 loss 3.2221317291259766 train acc 0.800960554287064\n",
      "epoch 5 batch id 12801 / 225000 loss 0.024123094975948334 train acc 0.8011483477853293\n",
      "epoch 5 batch id 12901 / 225000 loss 0.03321504220366478 train acc 0.8014107433532285\n",
      "epoch 5 batch id 13001 / 225000 loss 0.04865957796573639 train acc 0.8016306437966311\n",
      "epoch 5 batch id 13101 / 225000 loss 0.9937801957130432 train acc 0.8017517746736891\n",
      "epoch 5 batch id 13201 / 225000 loss 0.002345660701394081 train acc 0.80181425649572\n",
      "epoch 5 batch id 13301 / 225000 loss 2.4685938358306885 train acc 0.8020261634463575\n",
      "epoch 5 batch id 13401 / 225000 loss 1.2597136497497559 train acc 0.8020670099246325\n",
      "epoch 5 batch id 13501 / 225000 loss 0.20928306877613068 train acc 0.8022368713428635\n",
      "epoch 5 batch id 13601 / 225000 loss 1.5853534936904907 train acc 0.8020549959561797\n",
      "epoch 5 batch id 13701 / 225000 loss 0.0015182009665295482 train acc 0.8021129844536895\n",
      "epoch 5 batch id 13801 / 225000 loss 0.016036201268434525 train acc 0.8022244764872111\n",
      "epoch 5 batch id 13901 / 225000 loss 0.8153555989265442 train acc 0.8021365369397885\n",
      "epoch 5 batch id 14001 / 225000 loss 0.002805597148835659 train acc 0.8020141418470109\n",
      "epoch 5 batch id 14101 / 225000 loss 0.5858585834503174 train acc 0.8019466704489043\n",
      "epoch 5 batch id 14201 / 225000 loss 1.6815485954284668 train acc 0.802285050348567\n",
      "epoch 5 batch id 14301 / 225000 loss 4.279278755187988 train acc 0.802338997272918\n",
      "epoch 5 batch id 14401 / 225000 loss 0.004403850995004177 train acc 0.8022359558364003\n",
      "epoch 5 batch id 14501 / 225000 loss 0.0012520725140348077 train acc 0.8022894972760499\n",
      "epoch 5 batch id 14601 / 225000 loss 3.407506227493286 train acc 0.8020854735976988\n",
      "epoch 5 batch id 14701 / 225000 loss 2.622774600982666 train acc 0.8019862594381335\n",
      "epoch 5 batch id 14801 / 225000 loss 0.002610347932204604 train acc 0.8020910749273698\n",
      "epoch 5 batch id 14901 / 225000 loss 0.0012878812849521637 train acc 0.8018924904368834\n",
      "epoch 5 batch id 15001 / 225000 loss 1.674849271774292 train acc 0.8017132191187254\n",
      "epoch 5 batch id 15101 / 225000 loss 1.9509028196334839 train acc 0.8019833123634197\n",
      "epoch 5 batch id 15201 / 225000 loss 2.186133623123169 train acc 0.8018880336819946\n",
      "epoch 5 batch id 15301 / 225000 loss 0.48672962188720703 train acc 0.8019573884059865\n",
      "epoch 5 batch id 15401 / 225000 loss 1.2938923835754395 train acc 0.801960911629115\n",
      "epoch 5 batch id 15501 / 225000 loss 1.2063666582107544 train acc 0.8018837494355203\n",
      "epoch 5 batch id 15601 / 225000 loss 2.271026849746704 train acc 0.8019357733478624\n",
      "epoch 5 batch id 15701 / 225000 loss 0.002023276872932911 train acc 0.8020508247882301\n",
      "epoch 5 batch id 15801 / 225000 loss 0.01836271770298481 train acc 0.8021011328396936\n",
      "epoch 5 batch id 15901 / 225000 loss 0.5316141247749329 train acc 0.8022294195333627\n",
      "epoch 5 batch id 16001 / 225000 loss 1.5316903591156006 train acc 0.8024498468845697\n",
      "epoch 5 batch id 16101 / 225000 loss 2.393710136413574 train acc 0.8023880504316502\n",
      "epoch 5 batch id 16201 / 225000 loss 0.035342685878276825 train acc 0.8026973643602247\n",
      "epoch 5 batch id 16301 / 225000 loss 0.7024891972541809 train acc 0.802895527881725\n",
      "epoch 5 batch id 16401 / 225000 loss 0.030479930341243744 train acc 0.8027406865435034\n",
      "epoch 5 batch id 16501 / 225000 loss 1.8487433195114136 train acc 0.8026483243439791\n",
      "epoch 5 batch id 16601 / 225000 loss 0.001936866668984294 train acc 0.8028130835491838\n",
      "epoch 5 batch id 16701 / 225000 loss 0.003109548008069396 train acc 0.802691455601461\n",
      "epoch 5 batch id 16801 / 225000 loss 1.3247451782226562 train acc 0.8024522349860127\n",
      "epoch 5 batch id 16901 / 225000 loss 0.08445066213607788 train acc 0.8024968936749305\n",
      "epoch 5 batch id 17001 / 225000 loss 1.7577354907989502 train acc 0.8024233868595965\n",
      "epoch 5 batch id 17101 / 225000 loss 0.07922075688838959 train acc 0.8023653587509503\n",
      "epoch 5 batch id 17201 / 225000 loss 1.20926833152771 train acc 0.8024678797744317\n",
      "epoch 5 batch id 17301 / 225000 loss 0.0019221840193495154 train acc 0.8024391653661638\n",
      "epoch 5 batch id 17401 / 225000 loss 1.727249264717102 train acc 0.8026550198264467\n",
      "epoch 5 batch id 17501 / 225000 loss 0.38121843338012695 train acc 0.8026541340494829\n",
      "epoch 5 batch id 17601 / 225000 loss 0.017379075288772583 train acc 0.8026390545991705\n",
      "epoch 5 batch id 17701 / 225000 loss 0.0054112146608531475 train acc 0.8028077509745212\n",
      "epoch 5 batch id 17801 / 225000 loss 0.03821045160293579 train acc 0.8026796247401832\n",
      "epoch 5 batch id 17901 / 225000 loss 0.026850922033190727 train acc 0.8026925870063125\n",
      "epoch 5 batch id 18001 / 225000 loss 0.0035329328384250402 train acc 0.8026637409032832\n",
      "epoch 5 batch id 18101 / 225000 loss 3.2177441120147705 train acc 0.8027871388321087\n",
      "epoch 5 batch id 18201 / 225000 loss 0.0036274262238293886 train acc 0.8027031481786715\n",
      "epoch 5 batch id 18301 / 225000 loss 0.791398823261261 train acc 0.8026883776842796\n",
      "epoch 5 batch id 18401 / 225000 loss 0.003289272775873542 train acc 0.8026330090755938\n",
      "epoch 5 batch id 18501 / 225000 loss 0.05133431777358055 train acc 0.8029025458083346\n",
      "epoch 5 batch id 18601 / 225000 loss 0.0008047670125961304 train acc 0.8029138218375356\n",
      "epoch 5 batch id 18701 / 225000 loss 0.001535777817480266 train acc 0.8029517138120956\n",
      "epoch 5 batch id 18801 / 225000 loss 0.0008621962042525411 train acc 0.802763150896229\n",
      "epoch 5 batch id 18901 / 225000 loss 0.0024479972198605537 train acc 0.8026956245701286\n",
      "epoch 5 batch id 19001 / 225000 loss 0.28839242458343506 train acc 0.8028787958528498\n",
      "epoch 5 batch id 19101 / 225000 loss 3.112600326538086 train acc 0.8029553426522171\n",
      "epoch 5 batch id 19201 / 225000 loss 0.0029886080883443356 train acc 0.8030310921306182\n",
      "epoch 5 batch id 19301 / 225000 loss 0.006619827821850777 train acc 0.8030801512874981\n",
      "epoch 5 batch id 19401 / 225000 loss 0.0009993683779612184 train acc 0.803180248440802\n",
      "epoch 5 batch id 19501 / 225000 loss 1.3089150190353394 train acc 0.803010102046049\n",
      "epoch 5 batch id 19601 / 225000 loss 0.0010992928873747587 train acc 0.8032115708382226\n",
      "epoch 5 batch id 19701 / 225000 loss 1.39670729637146 train acc 0.8030429927414852\n",
      "epoch 5 batch id 19801 / 225000 loss 1.433493733406067 train acc 0.8031665067420838\n",
      "epoch 5 batch id 19901 / 225000 loss 1.269149661064148 train acc 0.8031631576302698\n",
      "epoch 5 batch id 20001 / 225000 loss 1.1167997121810913 train acc 0.8028848557572121\n",
      "epoch 5 batch id 20101 / 225000 loss 0.0060572815127670765 train acc 0.8028829411472066\n",
      "epoch 5 batch id 20201 / 225000 loss 0.00328130298294127 train acc 0.8029305479926736\n",
      "epoch 5 batch id 20301 / 225000 loss 0.0016144101973623037 train acc 0.8030762031427023\n",
      "epoch 5 batch id 20401 / 225000 loss 1.0031459331512451 train acc 0.8030611244546836\n",
      "epoch 5 batch id 20501 / 225000 loss 2.5305211544036865 train acc 0.8029974147602555\n",
      "epoch 5 batch id 20601 / 225000 loss 2.096216917037964 train acc 0.8030678122421242\n",
      "epoch 5 batch id 20701 / 225000 loss 1.1932843923568726 train acc 0.8029926090527028\n",
      "epoch 5 batch id 20801 / 225000 loss 1.0127719640731812 train acc 0.8030383154656027\n",
      "epoch 5 batch id 20901 / 225000 loss 1.2275152206420898 train acc 0.803191234869145\n",
      "epoch 5 batch id 21001 / 225000 loss 0.0019831599202007055 train acc 0.8030450930908052\n",
      "epoch 5 batch id 21101 / 225000 loss 0.819111704826355 train acc 0.8030425098336572\n",
      "epoch 5 batch id 21201 / 225000 loss 0.8436464071273804 train acc 0.8031696618084052\n",
      "epoch 5 batch id 21301 / 225000 loss 1.764997124671936 train acc 0.8032721468475659\n",
      "epoch 5 batch id 21401 / 225000 loss 0.020481696352362633 train acc 0.8033619924302603\n",
      "epoch 5 batch id 21501 / 225000 loss 0.0010208016028627753 train acc 0.8033812380819497\n",
      "epoch 5 batch id 21601 / 225000 loss 4.410675048828125 train acc 0.8034118790796723\n",
      "epoch 5 batch id 21701 / 225000 loss 0.7234684824943542 train acc 0.8034422376848993\n",
      "epoch 5 batch id 21801 / 225000 loss 0.0025192603934556246 train acc 0.8033117746892344\n",
      "epoch 5 batch id 21901 / 225000 loss 0.8358177542686462 train acc 0.8034564631751975\n",
      "epoch 5 batch id 22001 / 225000 loss 2.6430718898773193 train acc 0.8036111994909322\n",
      "epoch 5 batch id 22101 / 225000 loss 0.0056886919774115086 train acc 0.803549613139677\n",
      "epoch 5 batch id 22201 / 225000 loss 0.0035382357891649008 train acc 0.8036011891356245\n",
      "epoch 5 batch id 22301 / 225000 loss 1.1850212812423706 train acc 0.8035401999910318\n",
      "epoch 5 batch id 22401 / 225000 loss 1.7781028747558594 train acc 0.8034797553680639\n",
      "epoch 5 batch id 22501 / 225000 loss 0.32363712787628174 train acc 0.8036309497355673\n",
      "epoch 5 batch id 22601 / 225000 loss 1.9813454151153564 train acc 0.8037697447015619\n",
      "epoch 5 batch id 22701 / 225000 loss 0.01209198497235775 train acc 0.8037751640896876\n",
      "epoch 5 batch id 22801 / 225000 loss 1.2098629474639893 train acc 0.8037805359414061\n",
      "epoch 5 batch id 22901 / 225000 loss 0.7724055647850037 train acc 0.8036330291253657\n",
      "epoch 5 batch id 23001 / 225000 loss 1.030737042427063 train acc 0.8037041867744881\n",
      "epoch 5 batch id 23101 / 225000 loss 1.0735529661178589 train acc 0.8036989740703866\n",
      "epoch 5 batch id 23201 / 225000 loss 2.559299945831299 train acc 0.8036938063014525\n",
      "epoch 5 batch id 23301 / 225000 loss 0.1661270409822464 train acc 0.8036564954293807\n",
      "epoch 5 batch id 23401 / 225000 loss 0.3875454068183899 train acc 0.8035447203110978\n",
      "epoch 5 batch id 23501 / 225000 loss 0.0019368334906175733 train acc 0.8034445342751372\n",
      "epoch 5 batch id 23601 / 225000 loss 2.3266592025756836 train acc 0.8034511249523325\n",
      "epoch 5 batch id 23701 / 225000 loss 2.240471124649048 train acc 0.8033732753892241\n",
      "epoch 5 batch id 23801 / 225000 loss 1.4455069303512573 train acc 0.8034431326414857\n",
      "epoch 5 batch id 23901 / 225000 loss 0.0016344133764505386 train acc 0.8033555081377348\n",
      "epoch 5 batch id 24001 / 225000 loss 0.8634824156761169 train acc 0.803237365109787\n",
      "epoch 5 batch id 24101 / 225000 loss 0.5412169694900513 train acc 0.8031720675490643\n",
      "epoch 5 batch id 24201 / 225000 loss 1.23640775680542 train acc 0.8032106111317714\n",
      "epoch 5 batch id 24301 / 225000 loss 1.9840103387832642 train acc 0.8032282622114316\n",
      "epoch 5 batch id 24401 / 225000 loss 0.733328640460968 train acc 0.8032252776525552\n",
      "epoch 5 batch id 24501 / 225000 loss 2.1437604427337646 train acc 0.803079466144239\n",
      "epoch 5 batch id 24601 / 225000 loss 1.5849418640136719 train acc 0.8028941912930369\n",
      "epoch 5 batch id 24701 / 225000 loss 0.0008157666306942701 train acc 0.8029128375369419\n",
      "epoch 5 batch id 24801 / 225000 loss 0.002123408019542694 train acc 0.8029313334139753\n",
      "epoch 5 batch id 24901 / 225000 loss 2.0953376293182373 train acc 0.8030299987952291\n",
      "epoch 5 batch id 25001 / 225000 loss 1.2316707372665405 train acc 0.8031578736850526\n",
      "epoch 5 batch id 25101 / 225000 loss 0.0020730418618768454 train acc 0.8031751723038922\n",
      "epoch 5 batch id 25201 / 225000 loss 0.23176825046539307 train acc 0.8030633705011706\n",
      "epoch 5 batch id 25301 / 225000 loss 0.00735151581466198 train acc 0.8029722145369749\n",
      "epoch 5 batch id 25401 / 225000 loss 2.6069045066833496 train acc 0.8029998818944136\n",
      "epoch 5 batch id 25501 / 225000 loss 1.644658088684082 train acc 0.8031155640955256\n",
      "epoch 5 batch id 25601 / 225000 loss 2.81929349899292 train acc 0.8032303425647436\n",
      "epoch 5 batch id 25701 / 225000 loss 0.06474673748016357 train acc 0.8031885918835843\n",
      "epoch 5 batch id 25801 / 225000 loss 0.010869142599403858 train acc 0.8031859230262393\n",
      "epoch 5 batch id 25901 / 225000 loss 0.02953062392771244 train acc 0.8031736226400525\n",
      "epoch 5 batch id 26001 / 225000 loss 0.0008748981636017561 train acc 0.8031325718241606\n",
      "epoch 5 batch id 26101 / 225000 loss 1.5182645320892334 train acc 0.8030535228535305\n",
      "epoch 5 batch id 26201 / 225000 loss 1.2483742237091064 train acc 0.8031086599748101\n",
      "epoch 5 batch id 26301 / 225000 loss 0.0021705930121243 train acc 0.8031728831603361\n",
      "epoch 5 batch id 26401 / 225000 loss 0.002926009241491556 train acc 0.8031798037953107\n",
      "epoch 5 batch id 26501 / 225000 loss 1.992098331451416 train acc 0.8030923361382589\n",
      "epoch 5 batch id 26601 / 225000 loss 0.18861107528209686 train acc 0.8031183038231645\n",
      "epoch 5 batch id 26701 / 225000 loss 0.0010110595030710101 train acc 0.8031815287816936\n",
      "epoch 5 batch id 26801 / 225000 loss 0.00046796779497526586 train acc 0.8031696578485877\n",
      "epoch 5 batch id 26901 / 225000 loss 0.0010226273443549871 train acc 0.8031950485112077\n",
      "epoch 5 batch id 27001 / 225000 loss 1.2596138715744019 train acc 0.8030350727750825\n",
      "epoch 5 batch id 27101 / 225000 loss 1.967452883720398 train acc 0.8030330984096528\n",
      "epoch 5 batch id 27201 / 225000 loss 0.02026885561645031 train acc 0.8031873828168082\n",
      "epoch 5 batch id 27301 / 225000 loss 0.003287483938038349 train acc 0.8033039082817479\n",
      "epoch 5 batch id 27401 / 225000 loss 0.6567186117172241 train acc 0.8033100981715996\n",
      "epoch 5 batch id 27501 / 225000 loss 2.1692428588867188 train acc 0.8033344242027562\n",
      "epoch 5 batch id 27601 / 225000 loss 1.3756515979766846 train acc 0.8033585739647114\n",
      "epoch 5 batch id 27701 / 225000 loss 0.5632369518280029 train acc 0.8034366990361359\n",
      "epoch 5 batch id 27801 / 225000 loss 4.800242900848389 train acc 0.8033973598072012\n",
      "epoch 5 batch id 27901 / 225000 loss 0.04534311965107918 train acc 0.8033045410558761\n",
      "epoch 5 batch id 28001 / 225000 loss 3.142376184463501 train acc 0.8032123852719546\n",
      "epoch 5 batch id 28101 / 225000 loss 0.8676797747612 train acc 0.8031564712999537\n",
      "epoch 5 batch id 28201 / 225000 loss 0.01786704547703266 train acc 0.8031896032055601\n",
      "epoch 5 batch id 28301 / 225000 loss 3.3173375129699707 train acc 0.8031076640401399\n",
      "epoch 5 batch id 28401 / 225000 loss 0.00488576153293252 train acc 0.8030791169325023\n",
      "epoch 5 batch id 28501 / 225000 loss 1.4867066144943237 train acc 0.8029805971720291\n",
      "epoch 5 batch id 28601 / 225000 loss 0.015867212787270546 train acc 0.8029963987273172\n",
      "epoch 5 batch id 28701 / 225000 loss 0.47717735171318054 train acc 0.8030817741542107\n",
      "epoch 5 batch id 28801 / 225000 loss 2.3161230087280273 train acc 0.8030189923960973\n",
      "epoch 5 batch id 28901 / 225000 loss 1.1240307092666626 train acc 0.8031209992733815\n",
      "epoch 5 batch id 29001 / 225000 loss 0.00397453224286437 train acc 0.8032654046412193\n",
      "epoch 5 batch id 29101 / 225000 loss 0.16289275884628296 train acc 0.8032971375554104\n",
      "epoch 5 batch id 29201 / 225000 loss 1.0692191123962402 train acc 0.8032430396219308\n",
      "epoch 5 batch id 29301 / 225000 loss 0.0030940419528633356 train acc 0.8031551824169824\n",
      "epoch 5 batch id 29401 / 225000 loss 0.003432861529290676 train acc 0.8031444508690181\n",
      "epoch 5 batch id 29501 / 225000 loss 1.9138355255126953 train acc 0.8032270092539235\n",
      "epoch 5 batch id 29601 / 225000 loss 2.3930106163024902 train acc 0.8032161075639337\n",
      "epoch 5 batch id 29701 / 225000 loss 1.2410730123519897 train acc 0.8031968620585166\n",
      "epoch 5 batch id 29801 / 225000 loss 0.0022309536579996347 train acc 0.80316096775276\n",
      "epoch 5 batch id 29901 / 225000 loss 0.004672037437558174 train acc 0.8031169526102806\n",
      "epoch 5 batch id 30001 / 225000 loss 1.416487216949463 train acc 0.8030898970034333\n",
      "epoch 5 batch id 30101 / 225000 loss 0.07897381484508514 train acc 0.8031377695093186\n",
      "epoch 5 batch id 30201 / 225000 loss 1.4076811075210571 train acc 0.8031770471176451\n",
      "epoch 5 batch id 30301 / 225000 loss 0.0006164873484522104 train acc 0.8030180522094981\n",
      "epoch 5 batch id 30401 / 225000 loss 1.1034997701644897 train acc 0.803123252524588\n",
      "epoch 5 batch id 30501 / 225000 loss 2.755857467651367 train acc 0.8030146552572047\n",
      "epoch 5 batch id 30601 / 225000 loss 1.8445249795913696 train acc 0.8029639554262933\n",
      "epoch 5 batch id 30701 / 225000 loss 1.1194519996643066 train acc 0.8029380150483698\n",
      "epoch 5 batch id 30801 / 225000 loss 0.7352882623672485 train acc 0.8029284763481706\n",
      "epoch 5 batch id 30901 / 225000 loss 0.7157516479492188 train acc 0.8029675415035112\n",
      "epoch 5 batch id 31001 / 225000 loss 1.2972776889801025 train acc 0.8030305474016968\n",
      "epoch 5 batch id 31101 / 225000 loss 0.2475621998310089 train acc 0.803020803189608\n",
      "epoch 5 batch id 31201 / 225000 loss 0.7440220713615417 train acc 0.8030271465658152\n",
      "epoch 5 batch id 31301 / 225000 loss 0.0012570605613291264 train acc 0.8030174754800166\n",
      "epoch 5 batch id 31401 / 225000 loss 2.714946746826172 train acc 0.8029999044616414\n",
      "epoch 5 batch id 31501 / 225000 loss 1.8971638679504395 train acc 0.8030062537697216\n",
      "epoch 5 batch id 31601 / 225000 loss 0.036739662289619446 train acc 0.8029888294674219\n",
      "epoch 5 batch id 31701 / 225000 loss 1.5965564250946045 train acc 0.8029241979748273\n",
      "epoch 5 batch id 31801 / 225000 loss 0.5418969988822937 train acc 0.8029857551649319\n",
      "epoch 5 batch id 31901 / 225000 loss 2.366103410720825 train acc 0.8030155794489201\n",
      "epoch 5 batch id 32001 / 225000 loss 1.6563634872436523 train acc 0.8029280334989531\n",
      "epoch 5 batch id 32101 / 225000 loss 1.783327579498291 train acc 0.8029578517803184\n",
      "epoch 5 batch id 32201 / 225000 loss 0.20186306536197662 train acc 0.8028322101798081\n",
      "epoch 5 batch id 32301 / 225000 loss 1.3107576370239258 train acc 0.8028544007925451\n",
      "epoch 5 batch id 32401 / 225000 loss 0.25137293338775635 train acc 0.8028533069966977\n",
      "epoch 5 batch id 32501 / 225000 loss 0.09209676831960678 train acc 0.8029599089258792\n",
      "epoch 5 batch id 32601 / 225000 loss 0.0012365698348730803 train acc 0.8030045090641391\n",
      "epoch 5 batch id 32701 / 225000 loss 0.005115109030157328 train acc 0.8030411914008746\n",
      "epoch 5 batch id 32801 / 225000 loss 0.10134002566337585 train acc 0.8029709460077437\n",
      "epoch 5 batch id 32901 / 225000 loss 0.004251200705766678 train acc 0.8029543174979484\n",
      "epoch 5 batch id 33001 / 225000 loss 0.9124614000320435 train acc 0.8030286961001182\n",
      "epoch 5 batch id 33101 / 225000 loss 1.5246378183364868 train acc 0.8030044409534455\n",
      "epoch 5 batch id 33201 / 225000 loss 0.09377120435237885 train acc 0.803002921598747\n",
      "epoch 5 batch id 33301 / 225000 loss 0.022375870496034622 train acc 0.8031065133179184\n",
      "epoch 5 batch id 33401 / 225000 loss 1.07015061378479 train acc 0.8030672734349271\n",
      "epoch 5 batch id 33501 / 225000 loss 0.6978564858436584 train acc 0.8031476672338139\n",
      "epoch 5 batch id 33601 / 225000 loss 0.951839029788971 train acc 0.8032350227671795\n",
      "epoch 5 batch id 33701 / 225000 loss 0.6313341856002808 train acc 0.8032847689979525\n",
      "epoch 5 batch id 33801 / 225000 loss 2.174619197845459 train acc 0.8032528623413508\n",
      "epoch 5 batch id 33901 / 225000 loss 0.12800684571266174 train acc 0.803191646264122\n",
      "epoch 5 batch id 34001 / 225000 loss 2.380603313446045 train acc 0.8032043175200729\n",
      "epoch 5 batch id 34101 / 225000 loss 3.221388339996338 train acc 0.8031582651535145\n",
      "epoch 5 batch id 34201 / 225000 loss 1.5434412956237793 train acc 0.8030320750855238\n",
      "epoch 5 batch id 34301 / 225000 loss 1.5350927114486694 train acc 0.8030742543949156\n",
      "epoch 5 batch id 34401 / 225000 loss 0.004021256230771542 train acc 0.8031234557134967\n",
      "epoch 5 batch id 34501 / 225000 loss 0.9250950813293457 train acc 0.8030709254804208\n",
      "epoch 5 batch id 34601 / 225000 loss 1.6104545593261719 train acc 0.8031126268026936\n",
      "epoch 5 batch id 34701 / 225000 loss 0.0038958797231316566 train acc 0.8031396789717875\n",
      "epoch 5 batch id 34801 / 225000 loss 1.39488685131073 train acc 0.8031378408666418\n",
      "epoch 5 batch id 34901 / 225000 loss 0.06358605623245239 train acc 0.8032076444801008\n",
      "epoch 5 batch id 35001 / 225000 loss 0.0010648859897628427 train acc 0.8032556212679638\n",
      "epoch 5 batch id 35101 / 225000 loss 0.04024825990200043 train acc 0.8033104469958121\n",
      "epoch 5 batch id 35201 / 225000 loss 1.176984190940857 train acc 0.8034217777904037\n",
      "epoch 5 batch id 35301 / 225000 loss 0.0020603248849511147 train acc 0.8034899861193734\n",
      "epoch 5 batch id 35401 / 225000 loss 0.6343936920166016 train acc 0.8034801276800091\n",
      "epoch 5 batch id 35501 / 225000 loss 1.697256088256836 train acc 0.803568913551731\n",
      "epoch 5 batch id 35601 / 225000 loss 2.1004343032836914 train acc 0.8035659110699138\n",
      "epoch 5 batch id 35701 / 225000 loss 3.362252712249756 train acc 0.8036259488529733\n",
      "epoch 5 batch id 35801 / 225000 loss 1.447854995727539 train acc 0.8036437529677942\n",
      "epoch 5 batch id 35901 / 225000 loss 0.011843729764223099 train acc 0.8036405671151221\n",
      "epoch 5 batch id 36001 / 225000 loss 1.9147731065750122 train acc 0.8035679564456543\n",
      "epoch 5 batch id 36101 / 225000 loss 1.5172927379608154 train acc 0.803578848231351\n",
      "epoch 5 batch id 36201 / 225000 loss 3.0261359214782715 train acc 0.8036242092759869\n",
      "epoch 5 batch id 36301 / 225000 loss 0.00043842155719175935 train acc 0.803600451778188\n",
      "epoch 5 batch id 36401 / 225000 loss 0.5677773356437683 train acc 0.8035424850965632\n",
      "epoch 5 batch id 36501 / 225000 loss 0.9736539125442505 train acc 0.8035670255609435\n",
      "epoch 5 batch id 36601 / 225000 loss 0.7071324586868286 train acc 0.8035436190268025\n",
      "epoch 5 batch id 36701 / 225000 loss 1.1885086297988892 train acc 0.8035067164382442\n",
      "epoch 5 batch id 36801 / 225000 loss 0.06721717864274979 train acc 0.8035243607510666\n",
      "epoch 5 batch id 36901 / 225000 loss 0.013004729524254799 train acc 0.8034944852443023\n",
      "epoch 5 batch id 37001 / 225000 loss 0.0009803061839193106 train acc 0.8036336855760655\n",
      "epoch 5 batch id 37101 / 225000 loss 0.08764214813709259 train acc 0.8035969380879222\n",
      "epoch 5 batch id 37201 / 225000 loss 0.725832462310791 train acc 0.8036074299077982\n",
      "epoch 5 batch id 37301 / 225000 loss 1.0211422443389893 train acc 0.8035575453741186\n",
      "epoch 5 batch id 37401 / 225000 loss 1.439650058746338 train acc 0.8035948236678163\n",
      "epoch 5 batch id 37501 / 225000 loss 0.0106229642406106 train acc 0.803565238260313\n",
      "epoch 5 batch id 37601 / 225000 loss 0.0009153211722150445 train acc 0.8036089465705699\n",
      "epoch 5 batch id 37701 / 225000 loss 0.069662906229496 train acc 0.8035794806503807\n",
      "epoch 5 batch id 37801 / 225000 loss 3.1355204582214355 train acc 0.8035303298854528\n",
      "epoch 5 batch id 37901 / 225000 loss 0.04835077375173569 train acc 0.8034946307485291\n",
      "epoch 5 batch id 38001 / 225000 loss 0.0838276594877243 train acc 0.8035117496907976\n",
      "epoch 5 batch id 38101 / 225000 loss 1.784277081489563 train acc 0.8035025327419227\n",
      "epoch 5 batch id 38201 / 225000 loss 2.032607078552246 train acc 0.8035457186984634\n",
      "epoch 5 batch id 38301 / 225000 loss 0.8219775557518005 train acc 0.8035429884337224\n",
      "epoch 5 batch id 38401 / 225000 loss 0.0008486474398523569 train acc 0.8035793338715138\n",
      "epoch 5 batch id 38501 / 225000 loss 1.0090893507003784 train acc 0.803563543804057\n",
      "epoch 5 batch id 38601 / 225000 loss 0.00634295167401433 train acc 0.8036190772259786\n",
      "epoch 5 batch id 38701 / 225000 loss 0.015466058626770973 train acc 0.8035645073770704\n",
      "epoch 5 batch id 38801 / 225000 loss 0.7345592975616455 train acc 0.8035359913404294\n",
      "epoch 5 batch id 38901 / 225000 loss 1.0757575035095215 train acc 0.8035847407521658\n",
      "epoch 5 batch id 39001 / 225000 loss 0.0017016301862895489 train acc 0.8035947796210353\n",
      "epoch 5 batch id 39101 / 225000 loss 1.6779972314834595 train acc 0.8035983734431345\n",
      "epoch 5 batch id 39201 / 225000 loss 0.9251376390457153 train acc 0.8036912323665213\n",
      "epoch 5 batch id 39301 / 225000 loss 1.9535478353500366 train acc 0.803713645963207\n",
      "epoch 5 batch id 39401 / 225000 loss 1.9668552875518799 train acc 0.8038311210375371\n",
      "epoch 5 batch id 39501 / 225000 loss 0.009066716767847538 train acc 0.803840409103567\n",
      "epoch 5 batch id 39601 / 225000 loss 1.2728017568588257 train acc 0.8038370243175678\n",
      "epoch 5 batch id 39701 / 225000 loss 1.5025357007980347 train acc 0.8038273595123548\n",
      "epoch 5 batch id 39801 / 225000 loss 0.03104901686310768 train acc 0.8039245245094344\n",
      "epoch 5 batch id 39901 / 225000 loss 1.5745457410812378 train acc 0.8039397508834365\n",
      "epoch 5 batch id 40001 / 225000 loss 3.0303187370300293 train acc 0.8039236519087023\n",
      "epoch 5 batch id 40101 / 225000 loss 2.7266476154327393 train acc 0.8038764619336176\n",
      "epoch 5 batch id 40201 / 225000 loss 0.8598446249961853 train acc 0.8038295067286884\n",
      "epoch 5 batch id 40301 / 225000 loss 2.6879935264587402 train acc 0.8038448177464579\n",
      "epoch 5 batch id 40401 / 225000 loss 2.8407397270202637 train acc 0.8038043612781862\n",
      "epoch 5 batch id 40501 / 225000 loss 1.113379716873169 train acc 0.8037764499641984\n",
      "epoch 5 batch id 40601 / 225000 loss 0.8965832591056824 train acc 0.8037856210438167\n",
      "epoch 5 batch id 40701 / 225000 loss 0.8927191495895386 train acc 0.8037824623473625\n",
      "epoch 5 batch id 40801 / 225000 loss 0.4361657500267029 train acc 0.8036383912159015\n",
      "epoch 5 batch id 40901 / 225000 loss 2.1983935832977295 train acc 0.8036172709713699\n",
      "epoch 5 batch id 41001 / 225000 loss 3.086641550064087 train acc 0.8035352796273262\n",
      "epoch 5 batch id 41101 / 225000 loss 3.519179344177246 train acc 0.8034901827206151\n",
      "epoch 5 batch id 41201 / 225000 loss 0.9937341213226318 train acc 0.8036091357005898\n",
      "epoch 5 batch id 41301 / 225000 loss 3.1188793182373047 train acc 0.8037033001622237\n",
      "epoch 5 batch id 41401 / 225000 loss 0.01829507388174534 train acc 0.8037124707132678\n",
      "epoch 5 batch id 41501 / 225000 loss 0.001304947305470705 train acc 0.803781836582251\n",
      "epoch 5 batch id 41601 / 225000 loss 0.0015593231655657291 train acc 0.8037246700800461\n",
      "epoch 5 batch id 41701 / 225000 loss 0.009278379380702972 train acc 0.8036737728112036\n",
      "epoch 5 batch id 41801 / 225000 loss 0.003758474253118038 train acc 0.8036948876821128\n",
      "epoch 5 batch id 41901 / 225000 loss 0.004270177334547043 train acc 0.8036681702107348\n",
      "epoch 5 batch id 42001 / 225000 loss 0.8903437852859497 train acc 0.8036475322016142\n",
      "epoch 5 batch id 42101 / 225000 loss 1.3700315952301025 train acc 0.8036744970428256\n",
      "epoch 5 batch id 42201 / 225000 loss 3.6446008682250977 train acc 0.8036539418497192\n",
      "epoch 5 batch id 42301 / 225000 loss 2.1571171283721924 train acc 0.8036334838419895\n",
      "epoch 5 batch id 42401 / 225000 loss 0.012019922956824303 train acc 0.8035777458078819\n",
      "epoch 5 batch id 42501 / 225000 loss 0.0008069545729085803 train acc 0.8035987388532034\n",
      "epoch 5 batch id 42601 / 225000 loss 0.006872395984828472 train acc 0.8036137649350954\n",
      "epoch 5 batch id 42701 / 225000 loss 3.4987077713012695 train acc 0.8036697032856374\n",
      "epoch 5 batch id 42801 / 225000 loss 0.0017017822246998549 train acc 0.803684493352959\n",
      "epoch 5 batch id 42901 / 225000 loss 0.7466771602630615 train acc 0.8036642502505769\n",
      "epoch 5 batch id 43001 / 225000 loss 0.012720559723675251 train acc 0.803708053301086\n",
      "epoch 5 batch id 43101 / 225000 loss 0.7337658405303955 train acc 0.803786455070648\n",
      "epoch 5 batch id 43201 / 225000 loss 0.005558086559176445 train acc 0.8037776903312424\n",
      "epoch 5 batch id 43301 / 225000 loss 2.8808672428131104 train acc 0.8037170042262304\n",
      "epoch 5 batch id 43401 / 225000 loss 0.003354865126311779 train acc 0.8037026796617589\n",
      "epoch 5 batch id 43501 / 225000 loss 0.11661755293607712 train acc 0.8036711799728742\n",
      "epoch 5 batch id 43601 / 225000 loss 1.1015641689300537 train acc 0.8037143643494415\n",
      "epoch 5 batch id 43701 / 225000 loss 0.35769739747047424 train acc 0.8037115855472415\n",
      "epoch 5 batch id 43801 / 225000 loss 2.6473166942596436 train acc 0.8036517431108878\n",
      "epoch 5 batch id 43901 / 225000 loss 2.6549081802368164 train acc 0.803637730347828\n",
      "epoch 5 batch id 44001 / 225000 loss 0.002423536730930209 train acc 0.8036521897229608\n",
      "epoch 5 batch id 44101 / 225000 loss 1.228253960609436 train acc 0.8036495771070951\n",
      "epoch 5 batch id 44201 / 225000 loss 0.0006160609773360193 train acc 0.8036809121965567\n",
      "epoch 5 batch id 44301 / 225000 loss 0.003680694382637739 train acc 0.8037177490350105\n",
      "epoch 5 batch id 44401 / 225000 loss 4.308053016662598 train acc 0.8036924844035044\n",
      "epoch 5 batch id 44501 / 225000 loss 2.6721205711364746 train acc 0.8036898047234894\n",
      "epoch 5 batch id 44601 / 225000 loss 1.5950827598571777 train acc 0.8037207685926324\n",
      "epoch 5 batch id 44701 / 225000 loss 1.4405382871627808 train acc 0.803712444911747\n",
      "epoch 5 batch id 44801 / 225000 loss 1.3295120000839233 train acc 0.8037432200174103\n",
      "epoch 5 batch id 44901 / 225000 loss 1.0883084535598755 train acc 0.8037627224337988\n",
      "epoch 5 batch id 45001 / 225000 loss 0.0020154633093625307 train acc 0.8038210261994178\n",
      "epoch 5 batch id 45101 / 225000 loss 0.0010743519524112344 train acc 0.8038901576461719\n",
      "epoch 5 batch id 45201 / 225000 loss 0.0009392285137437284 train acc 0.8038704895909382\n",
      "epoch 5 batch id 45301 / 225000 loss 0.0015034048119559884 train acc 0.803834352442551\n",
      "epoch 5 batch id 45401 / 225000 loss 1.115332841873169 train acc 0.8038699588114799\n",
      "epoch 5 batch id 45501 / 225000 loss 0.003563562873750925 train acc 0.8038229929012549\n",
      "epoch 5 batch id 45601 / 225000 loss 1.9030407667160034 train acc 0.8037707506414333\n",
      "epoch 5 batch id 45701 / 225000 loss 2.37365460395813 train acc 0.8036913853088554\n",
      "epoch 5 batch id 45801 / 225000 loss 2.838987112045288 train acc 0.8036778672954739\n",
      "epoch 5 batch id 45901 / 225000 loss 1.244680643081665 train acc 0.8037515522537635\n",
      "epoch 5 batch id 46001 / 225000 loss 1.6293052434921265 train acc 0.8037814395339232\n",
      "epoch 5 batch id 46101 / 225000 loss 1.9749317169189453 train acc 0.8037515455196199\n",
      "epoch 5 batch id 46201 / 225000 loss 0.04007575660943985 train acc 0.8038137702647129\n",
      "epoch 5 batch id 46301 / 225000 loss 0.2912829518318176 train acc 0.803843329517721\n",
      "epoch 5 batch id 46401 / 225000 loss 0.5183947086334229 train acc 0.8037757806943816\n",
      "epoch 5 batch id 46501 / 225000 loss 0.0021556734573096037 train acc 0.803794542052859\n",
      "epoch 5 batch id 46601 / 225000 loss 1.9063841104507446 train acc 0.8038078582004679\n",
      "epoch 5 batch id 46701 / 225000 loss 1.2647221088409424 train acc 0.8037461724588338\n",
      "epoch 5 batch id 46801 / 225000 loss 0.07051386684179306 train acc 0.8037114591568556\n",
      "epoch 5 batch id 46901 / 225000 loss 1.6778846979141235 train acc 0.8036662331293576\n",
      "epoch 5 batch id 47001 / 225000 loss 1.4981741905212402 train acc 0.8036850279781281\n",
      "epoch 5 batch id 47101 / 225000 loss 5.542669773101807 train acc 0.8036665888197703\n",
      "epoch 5 batch id 47201 / 225000 loss 0.002212636871263385 train acc 0.8037223787631618\n",
      "epoch 5 batch id 47301 / 225000 loss 0.45036864280700684 train acc 0.8037937887148263\n",
      "epoch 5 batch id 47401 / 225000 loss 1.72489333152771 train acc 0.8037172211556718\n",
      "epoch 5 batch id 47501 / 225000 loss 0.005163954570889473 train acc 0.803767289109703\n",
      "epoch 5 batch id 47601 / 225000 loss 0.002042102161794901 train acc 0.8037961387365812\n",
      "epoch 5 batch id 47701 / 225000 loss 0.0752682238817215 train acc 0.803735770738559\n",
      "epoch 5 batch id 47801 / 225000 loss 0.002149933250620961 train acc 0.8037122654337775\n",
      "epoch 5 batch id 47901 / 225000 loss 1.3114389181137085 train acc 0.8036836391724599\n",
      "epoch 5 batch id 48001 / 225000 loss 1.0409817695617676 train acc 0.8037280473323473\n",
      "epoch 5 batch id 48101 / 225000 loss 0.0013245439622551203 train acc 0.8036527307124592\n",
      "epoch 5 batch id 48201 / 225000 loss 1.1229995489120483 train acc 0.8036658990477376\n",
      "epoch 5 batch id 48301 / 225000 loss 1.667847990989685 train acc 0.8035754953313596\n",
      "epoch 5 batch id 48401 / 225000 loss 0.009974083863198757 train acc 0.8035319518191772\n",
      "epoch 5 batch id 48501 / 225000 loss 0.005556311458349228 train acc 0.8035143605286489\n",
      "epoch 5 batch id 48601 / 225000 loss 2.4347543716430664 train acc 0.8035842883891278\n",
      "epoch 5 batch id 48701 / 225000 loss 1.5618507862091064 train acc 0.8035666618755262\n",
      "epoch 5 batch id 48801 / 225000 loss 2.018901824951172 train acc 0.803595213212844\n",
      "epoch 5 batch id 48901 / 225000 loss 0.00636869203299284 train acc 0.8036134230383837\n",
      "epoch 5 batch id 49001 / 225000 loss 0.01330435462296009 train acc 0.8035805391726699\n",
      "epoch 5 batch id 49101 / 225000 loss 1.7073637247085571 train acc 0.8036139793486894\n",
      "epoch 5 batch id 49201 / 225000 loss 1.011861801147461 train acc 0.8036269588016504\n",
      "epoch 5 batch id 49301 / 225000 loss 0.0018114270642399788 train acc 0.8036804527291536\n",
      "epoch 5 batch id 49401 / 225000 loss 1.2786779403686523 train acc 0.8037236088338293\n",
      "epoch 5 batch id 49501 / 225000 loss 2.5851917266845703 train acc 0.8037110361406841\n",
      "epoch 5 batch id 49601 / 225000 loss 0.8631699681282043 train acc 0.8037388359105663\n",
      "epoch 5 batch id 49701 / 225000 loss 2.1239888668060303 train acc 0.8037614937325205\n",
      "epoch 5 batch id 49801 / 225000 loss 0.001461695646867156 train acc 0.803753940683922\n",
      "epoch 5 batch id 49901 / 225000 loss 1.0627083778381348 train acc 0.8037013286306888\n",
      "epoch 5 batch id 50001 / 225000 loss 0.6180645823478699 train acc 0.8037239255214895\n",
      "epoch 5 batch id 50101 / 225000 loss 0.019287748262286186 train acc 0.8037264725254984\n",
      "epoch 5 batch id 50201 / 225000 loss 1.382760763168335 train acc 0.8037339893627617\n",
      "epoch 5 batch id 50301 / 225000 loss 0.5273825526237488 train acc 0.8037365062324805\n",
      "epoch 5 batch id 50401 / 225000 loss 0.7211880683898926 train acc 0.8037092518005595\n",
      "epoch 5 batch id 50501 / 225000 loss 2.175053834915161 train acc 0.803696956495911\n",
      "epoch 5 batch id 50601 / 225000 loss 2.0763869285583496 train acc 0.8037785814509595\n",
      "epoch 5 batch id 50701 / 225000 loss 0.27477627992630005 train acc 0.8038302992051439\n",
      "epoch 5 batch id 50801 / 225000 loss 0.004274814389646053 train acc 0.8038572075352848\n",
      "epoch 5 batch id 50901 / 225000 loss 0.3116850256919861 train acc 0.8038840101373254\n",
      "epoch 5 batch id 51001 / 225000 loss 0.007103950250893831 train acc 0.8039254132271916\n",
      "epoch 5 batch id 51101 / 225000 loss 0.0011355978203937411 train acc 0.8038932701904072\n",
      "epoch 5 batch id 51201 / 225000 loss 2.7938177585601807 train acc 0.8039735552039999\n",
      "epoch 5 batch id 51301 / 225000 loss 1.107358455657959 train acc 0.8039755560320462\n",
      "epoch 5 batch id 51401 / 225000 loss 0.0058092596009373665 train acc 0.803972685356316\n",
      "epoch 5 batch id 51501 / 225000 loss 0.034591857343912125 train acc 0.8039892429273218\n",
      "epoch 5 batch id 51601 / 225000 loss 0.7978521585464478 train acc 0.803928218445379\n",
      "epoch 5 batch id 51701 / 225000 loss 0.05226752907037735 train acc 0.8039012785052514\n",
      "epoch 5 batch id 51801 / 225000 loss 1.6344473361968994 train acc 0.8038985733866142\n",
      "epoch 5 batch id 51901 / 225000 loss 0.003256059717386961 train acc 0.8039922159495964\n",
      "epoch 5 batch id 52001 / 225000 loss 0.6260775923728943 train acc 0.8039797311590162\n",
      "epoch 5 batch id 52101 / 225000 loss 0.0028459089808166027 train acc 0.8040056812729123\n",
      "epoch 5 batch id 52201 / 225000 loss 0.0014320171903818846 train acc 0.8040075860615697\n",
      "epoch 5 batch id 52301 / 225000 loss 0.3316766619682312 train acc 0.8040190436129329\n",
      "epoch 5 batch id 52401 / 225000 loss 0.8520237803459167 train acc 0.8039636648155569\n",
      "epoch 5 batch id 52501 / 225000 loss 0.14105990529060364 train acc 0.8039227824231919\n",
      "epoch 5 batch id 52601 / 225000 loss 0.0017815579194575548 train acc 0.8038725499515218\n",
      "epoch 5 batch id 52701 / 225000 loss 0.05013325437903404 train acc 0.8038984079998482\n",
      "epoch 5 batch id 52801 / 225000 loss 0.001781919738277793 train acc 0.8039099638264426\n",
      "epoch 5 batch id 52901 / 225000 loss 0.009407215751707554 train acc 0.8039640082418101\n",
      "epoch 5 batch id 53001 / 225000 loss 2.020587205886841 train acc 0.8039706797984943\n",
      "epoch 5 batch id 53101 / 225000 loss 0.12822340428829193 train acc 0.8040196983107663\n",
      "epoch 5 batch id 53201 / 225000 loss 0.8045340776443481 train acc 0.8039980451495272\n",
      "epoch 5 batch id 53301 / 225000 loss 5.12583065032959 train acc 0.8039248794581715\n",
      "epoch 5 batch id 53401 / 225000 loss 0.9395858645439148 train acc 0.8038707140315724\n",
      "epoch 5 batch id 53501 / 225000 loss 0.48589134216308594 train acc 0.8039335713351152\n",
      "epoch 5 batch id 53601 / 225000 loss 1.2215989828109741 train acc 0.803921568627451\n",
      "epoch 5 batch id 53701 / 225000 loss 0.07124406099319458 train acc 0.8039561646896706\n",
      "epoch 5 batch id 53801 / 225000 loss 0.02693289704620838 train acc 0.8040185126670508\n",
      "epoch 5 batch id 53901 / 225000 loss 0.000841777422465384 train acc 0.8040342479731359\n",
      "epoch 5 batch id 54001 / 225000 loss 1.0214512348175049 train acc 0.8041286272476436\n",
      "epoch 5 batch id 54101 / 225000 loss 0.8150226473808289 train acc 0.8041579638084324\n",
      "epoch 5 batch id 54201 / 225000 loss 1.011674165725708 train acc 0.8041871921182266\n",
      "epoch 5 batch id 54301 / 225000 loss 0.1827884167432785 train acc 0.8041656691405314\n",
      "epoch 5 batch id 54401 / 225000 loss 0.26519688963890076 train acc 0.8041626073050128\n",
      "epoch 5 batch id 54501 / 225000 loss 0.4708711802959442 train acc 0.8041870791361626\n",
      "epoch 5 batch id 54601 / 225000 loss 3.2168164253234863 train acc 0.8042160399992674\n",
      "epoch 5 batch id 54701 / 225000 loss 0.5938462615013123 train acc 0.8041671998683754\n",
      "epoch 5 batch id 54801 / 225000 loss 1.0633779764175415 train acc 0.8040957281801427\n",
      "epoch 5 batch id 54901 / 225000 loss 3.0231308937072754 train acc 0.804079160671026\n",
      "epoch 5 batch id 55001 / 225000 loss 0.0018201380735263228 train acc 0.8040717441501064\n",
      "epoch 5 batch id 55101 / 225000 loss 2.6607937812805176 train acc 0.8041097257763017\n",
      "epoch 5 batch id 55201 / 225000 loss 0.8731863498687744 train acc 0.8041113385627072\n",
      "epoch 5 batch id 55301 / 225000 loss 0.7645580768585205 train acc 0.8040858212328891\n",
      "epoch 5 batch id 55401 / 225000 loss 1.3332709074020386 train acc 0.8040919838992076\n",
      "epoch 5 batch id 55501 / 225000 loss 1.2501354217529297 train acc 0.8041341597448695\n",
      "epoch 5 batch id 55601 / 225000 loss 1.015282154083252 train acc 0.8041357169835075\n",
      "epoch 5 batch id 55701 / 225000 loss 1.3433946371078491 train acc 0.8041597098795353\n",
      "epoch 5 batch id 55801 / 225000 loss 0.011352205649018288 train acc 0.8041791365746134\n",
      "epoch 5 batch id 55901 / 225000 loss 0.9393903613090515 train acc 0.8041671884223895\n",
      "epoch 5 batch id 56001 / 225000 loss 2.220695734024048 train acc 0.8041195692934054\n",
      "epoch 5 batch id 56101 / 225000 loss 0.2068568766117096 train acc 0.8041389636548368\n",
      "epoch 5 batch id 56201 / 225000 loss 0.002212497405707836 train acc 0.8041671856372662\n",
      "epoch 5 batch id 56301 / 225000 loss 0.0004982160753570497 train acc 0.8041953073657662\n",
      "epoch 5 batch id 56401 / 225000 loss 2.602339744567871 train acc 0.8042632222832928\n",
      "epoch 5 batch id 56501 / 225000 loss 0.15490812063217163 train acc 0.8042866497938089\n",
      "epoch 5 batch id 56601 / 225000 loss 0.3475823402404785 train acc 0.8042702425752195\n",
      "epoch 5 batch id 56701 / 225000 loss 0.5431219339370728 train acc 0.8042406659494542\n",
      "epoch 5 batch id 56801 / 225000 loss 3.429975986480713 train acc 0.8042420027816412\n",
      "epoch 5 batch id 56901 / 225000 loss 1.0103800296783447 train acc 0.8042169733396601\n",
      "epoch 5 batch id 57001 / 225000 loss 0.0017805672250688076 train acc 0.8042446623743443\n",
      "epoch 5 batch id 57101 / 225000 loss 1.9130898714065552 train acc 0.8042240941489641\n",
      "epoch 5 batch id 57201 / 225000 loss 0.0016598532674834132 train acc 0.8041904861803115\n",
      "epoch 5 batch id 57301 / 225000 loss 4.3592095375061035 train acc 0.8041657213661193\n",
      "epoch 5 batch id 57401 / 225000 loss 0.005654374603182077 train acc 0.8041192662148743\n",
      "epoch 5 batch id 57501 / 225000 loss 1.555088758468628 train acc 0.8040903636458496\n",
      "epoch 5 batch id 57601 / 225000 loss 0.005611392203718424 train acc 0.8040442006215169\n",
      "epoch 5 batch id 57701 / 225000 loss 1.4509462118148804 train acc 0.8040501897714077\n",
      "epoch 5 batch id 57801 / 225000 loss 1.5944621562957764 train acc 0.8040215567204719\n",
      "epoch 5 batch id 57901 / 225000 loss 1.6012063026428223 train acc 0.8040318820054921\n",
      "epoch 5 batch id 58001 / 225000 loss 1.058241844177246 train acc 0.8040378614161825\n",
      "epoch 5 batch id 58101 / 225000 loss 0.053195882588624954 train acc 0.8040223059844065\n",
      "epoch 5 batch id 58201 / 225000 loss 0.050940465182065964 train acc 0.8040282813010086\n",
      "epoch 5 batch id 58301 / 225000 loss 4.063482284545898 train acc 0.804034236119449\n",
      "epoch 5 batch id 58401 / 225000 loss 2.253455638885498 train acc 0.8039631170699132\n",
      "epoch 5 batch id 58501 / 225000 loss 0.0006709847366437316 train acc 0.8039948035076323\n",
      "epoch 5 batch id 58601 / 225000 loss 0.0036936886608600616 train acc 0.8039922526919336\n",
      "epoch 5 batch id 58701 / 225000 loss 0.7809470891952515 train acc 0.8039130508849934\n",
      "epoch 5 batch id 58801 / 225000 loss 0.0027313409373164177 train acc 0.8039191510348463\n",
      "epoch 5 batch id 58901 / 225000 loss 0.371462881565094 train acc 0.8039634301624761\n",
      "epoch 5 batch id 59001 / 225000 loss 1.5657737255096436 train acc 0.8039312893001813\n",
      "epoch 5 batch id 59101 / 225000 loss 0.13535016775131226 train acc 0.8039753980474104\n",
      "epoch 5 batch id 59201 / 225000 loss 3.1027512550354004 train acc 0.8040235806827587\n",
      "epoch 5 batch id 59301 / 225000 loss 1.560902714729309 train acc 0.8039704220839446\n",
      "epoch 5 batch id 59401 / 225000 loss 0.9589293003082275 train acc 0.8039258598340095\n",
      "epoch 5 batch id 59501 / 225000 loss 1.8272145986557007 train acc 0.8039570763516579\n",
      "epoch 5 batch id 59601 / 225000 loss 0.9883058667182922 train acc 0.8040007717991309\n",
      "epoch 5 batch id 59701 / 225000 loss 0.010502437129616737 train acc 0.8040526959347415\n",
      "epoch 5 batch id 59801 / 225000 loss 3.3363893032073975 train acc 0.8039999331114864\n",
      "epoch 5 batch id 59901 / 225000 loss 2.9565603733062744 train acc 0.8040308175155674\n",
      "epoch 5 batch id 60001 / 225000 loss 0.9897034168243408 train acc 0.8040365993900102\n",
      "epoch 5 batch id 60101 / 225000 loss 0.0027475603856146336 train acc 0.8039508494035041\n",
      "epoch 5 batch id 60201 / 225000 loss 0.0007034101290628314 train acc 0.8039110646002559\n",
      "epoch 5 batch id 60301 / 225000 loss 0.0006082223262637854 train acc 0.803900432828643\n",
      "epoch 5 batch id 60401 / 225000 loss 2.027254343032837 train acc 0.8038898362609891\n",
      "epoch 5 batch id 60501 / 225000 loss 0.14172296226024628 train acc 0.8038834068858366\n",
      "epoch 5 batch id 60601 / 225000 loss 0.0026418808847665787 train acc 0.8038439959736638\n",
      "epoch 5 batch id 60701 / 225000 loss 0.01771320030093193 train acc 0.8038664931384986\n",
      "epoch 5 batch id 60801 / 225000 loss 0.003386558499187231 train acc 0.8039012516241509\n",
      "epoch 5 batch id 60901 / 225000 loss 0.06284555047750473 train acc 0.8039646311226417\n",
      "epoch 5 batch id 61001 / 225000 loss 3.374258518218994 train acc 0.803982721594728\n",
      "epoch 5 batch id 61101 / 225000 loss 1.7016160488128662 train acc 0.8039925696797107\n",
      "epoch 5 batch id 61201 / 225000 loss 0.001360467984341085 train acc 0.8039983006813615\n",
      "epoch 5 batch id 61301 / 225000 loss 3.987658977508545 train acc 0.8040203259326928\n",
      "epoch 5 batch id 61401 / 225000 loss 0.0017859175568446517 train acc 0.8039812055178255\n",
      "epoch 5 batch id 61501 / 225000 loss 0.9867157340049744 train acc 0.8040031869400498\n",
      "epoch 5 batch id 61601 / 225000 loss 0.3963600695133209 train acc 0.8040169802438272\n",
      "epoch 5 batch id 61701 / 225000 loss 2.301987409591675 train acc 0.8039861590573897\n",
      "epoch 5 batch id 61801 / 225000 loss 0.8537683486938477 train acc 0.8040484781799647\n",
      "epoch 5 batch id 61901 / 225000 loss 1.8164563179016113 train acc 0.8040944411237299\n",
      "epoch 5 batch id 62001 / 225000 loss 3.2183523178100586 train acc 0.8040838050999177\n",
      "epoch 5 batch id 62101 / 225000 loss 1.2891508340835571 train acc 0.8041094346306823\n",
      "epoch 5 batch id 62201 / 225000 loss 0.0007590356981381774 train acc 0.8041791932605585\n",
      "epoch 5 batch id 62301 / 225000 loss 0.9746223092079163 train acc 0.8041925490762588\n",
      "epoch 5 batch id 62401 / 225000 loss 1.651379108428955 train acc 0.8042619509302735\n",
      "epoch 5 batch id 62501 / 225000 loss 1.2469396591186523 train acc 0.8042391321738852\n",
      "epoch 5 batch id 62601 / 225000 loss 1.2720109224319458 train acc 0.8042363540518522\n",
      "epoch 5 batch id 62701 / 225000 loss 0.22962093353271484 train acc 0.8043053539815952\n",
      "epoch 5 batch id 62801 / 225000 loss 0.8773033022880554 train acc 0.8043184025732074\n",
      "epoch 5 batch id 62901 / 225000 loss 0.3881125748157501 train acc 0.8043393586747428\n",
      "epoch 5 batch id 63001 / 225000 loss 0.043249234557151794 train acc 0.8043205663402169\n",
      "epoch 5 batch id 63101 / 225000 loss 0.007804516702890396 train acc 0.804396919224735\n",
      "epoch 5 batch id 63201 / 225000 loss 0.890880286693573 train acc 0.8044057847185963\n",
      "epoch 5 batch id 63301 / 225000 loss 0.8129376769065857 train acc 0.804410672817175\n",
      "epoch 5 batch id 63401 / 225000 loss 2.421175956726074 train acc 0.8043958297187741\n",
      "epoch 5 batch id 63501 / 225000 loss 1.8007034063339233 train acc 0.8044046550448024\n",
      "epoch 5 batch id 63601 / 225000 loss 0.2847725450992584 train acc 0.8044645524441439\n",
      "epoch 5 batch id 63701 / 225000 loss 1.5095999240875244 train acc 0.8044732421783017\n",
      "epoch 5 batch id 63801 / 225000 loss 0.0029666454065591097 train acc 0.8044701493706995\n",
      "epoch 5 batch id 63901 / 225000 loss 0.00395912304520607 train acc 0.8045257507707234\n",
      "epoch 5 batch id 64001 / 225000 loss 0.6845789551734924 train acc 0.8045030546397712\n",
      "epoch 5 batch id 64101 / 225000 loss 0.008603975176811218 train acc 0.8044843294176378\n",
      "epoch 5 batch id 64201 / 225000 loss 2.996196746826172 train acc 0.8045046027320447\n",
      "epoch 5 batch id 64301 / 225000 loss 0.5422266125679016 train acc 0.8045403648465809\n",
      "epoch 5 batch id 64401 / 225000 loss 1.5927845239639282 train acc 0.8045798978276735\n",
      "epoch 5 batch id 64501 / 225000 loss 2.374321699142456 train acc 0.8044836514162571\n",
      "epoch 5 batch id 64601 / 225000 loss 1.0205632448196411 train acc 0.8043915728858686\n",
      "epoch 5 batch id 64701 / 225000 loss 0.6582862138748169 train acc 0.8043731936137\n",
      "epoch 5 batch id 64801 / 225000 loss 2.6979293823242188 train acc 0.8043895927531982\n",
      "epoch 5 batch id 64901 / 225000 loss 0.003181810025125742 train acc 0.804371273169905\n",
      "epoch 5 batch id 65001 / 225000 loss 0.606871485710144 train acc 0.8043376255749911\n",
      "epoch 5 batch id 65101 / 225000 loss 2.35628342628479 train acc 0.8043386430315971\n",
      "epoch 5 batch id 65201 / 225000 loss 1.3884153366088867 train acc 0.8043511602582782\n",
      "epoch 5 batch id 65301 / 225000 loss 1.3099156618118286 train acc 0.8043138696191483\n",
      "epoch 5 batch id 65401 / 225000 loss 0.033097684383392334 train acc 0.8043302090182107\n",
      "epoch 5 batch id 65501 / 225000 loss 2.2522833347320557 train acc 0.8043541319979848\n",
      "epoch 5 batch id 65601 / 225000 loss 1.9450733661651611 train acc 0.8043284401152422\n",
      "epoch 5 batch id 65701 / 225000 loss 1.0957664251327515 train acc 0.8043294622608483\n",
      "epoch 5 batch id 65801 / 225000 loss 0.02938702516257763 train acc 0.8043000866248233\n",
      "epoch 5 batch id 65901 / 225000 loss 0.0024252785369753838 train acc 0.8042973551235945\n",
      "epoch 5 batch id 66001 / 225000 loss 0.0041086990386247635 train acc 0.8042832684353267\n",
      "epoch 5 batch id 66101 / 225000 loss 1.9818847179412842 train acc 0.8043183915523214\n",
      "epoch 5 batch id 66201 / 225000 loss 0.0012604417279362679 train acc 0.8043571849367834\n",
      "epoch 5 batch id 66301 / 225000 loss 0.00139450968708843 train acc 0.8043204476553898\n",
      "epoch 5 batch id 66401 / 225000 loss 0.00179752754047513 train acc 0.8043365310763392\n",
      "epoch 5 batch id 66501 / 225000 loss 1.1472917795181274 train acc 0.8043525661268252\n",
      "epoch 5 batch id 66601 / 225000 loss 0.8707740306854248 train acc 0.8043535382351616\n",
      "epoch 5 batch id 66701 / 225000 loss 0.0032093620393425226 train acc 0.8043957361958591\n",
      "epoch 5 batch id 66801 / 225000 loss 1.400151252746582 train acc 0.8043891558509603\n",
      "epoch 5 batch id 66901 / 225000 loss 0.004021776840090752 train acc 0.8043900689077891\n",
      "epoch 5 batch id 67001 / 225000 loss 2.1933906078338623 train acc 0.8043797853763377\n",
      "epoch 5 batch id 67101 / 225000 loss 0.006287659518420696 train acc 0.8043620810420113\n",
      "epoch 5 batch id 67201 / 225000 loss 1.2423741817474365 train acc 0.8043890715911965\n",
      "epoch 5 batch id 67301 / 225000 loss 0.8215177059173584 train acc 0.8043825500364036\n",
      "epoch 5 batch id 67401 / 225000 loss 1.2586368322372437 train acc 0.8043612112579932\n",
      "epoch 5 batch id 67501 / 225000 loss 3.3777098655700684 train acc 0.8042695663767944\n",
      "epoch 5 batch id 67601 / 225000 loss 0.0003921138995792717 train acc 0.8042669487137765\n",
      "epoch 5 batch id 67701 / 225000 loss 0.887328565120697 train acc 0.8042680314914108\n",
      "epoch 5 batch id 67801 / 225000 loss 0.002283399226143956 train acc 0.8042654238138081\n",
      "epoch 5 batch id 67901 / 225000 loss 0.0015452926745638251 train acc 0.8042444146625234\n",
      "epoch 5 batch id 68001 / 225000 loss 2.7311747074127197 train acc 0.8041903795532419\n",
      "epoch 5 batch id 68101 / 225000 loss 0.002962622558698058 train acc 0.804195239423797\n",
      "epoch 5 batch id 68201 / 225000 loss 3.2579736709594727 train acc 0.8042000850427413\n",
      "epoch 5 batch id 68301 / 225000 loss 0.2611709237098694 train acc 0.804223217815259\n",
      "epoch 5 batch id 68401 / 225000 loss 0.039332155138254166 train acc 0.8041658747679128\n",
      "epoch 5 batch id 68501 / 225000 loss 0.0029450622387230396 train acc 0.8041415453788996\n",
      "epoch 5 batch id 68601 / 225000 loss 0.0012506638886407018 train acc 0.8041610180609612\n",
      "epoch 5 batch id 68701 / 225000 loss 0.006247599609196186 train acc 0.8041586003114948\n",
      "epoch 5 batch id 68801 / 225000 loss 0.006341684143990278 train acc 0.8041888926033052\n",
      "epoch 5 batch id 68901 / 225000 loss 1.5704432725906372 train acc 0.804215468570848\n",
      "epoch 5 batch id 69001 / 225000 loss 0.6210805177688599 train acc 0.8043108070897523\n",
      "epoch 5 batch id 69101 / 225000 loss 0.5131700038909912 train acc 0.8042539181777398\n",
      "epoch 5 batch id 69201 / 225000 loss 1.1891858577728271 train acc 0.8042260949986272\n",
      "epoch 5 batch id 69301 / 225000 loss 0.002896212274208665 train acc 0.8042632862440657\n",
      "epoch 5 batch id 69401 / 225000 loss 0.0003426645998843014 train acc 0.8043039725652368\n",
      "epoch 5 batch id 69501 / 225000 loss 0.7565782070159912 train acc 0.8042977798880592\n",
      "epoch 5 batch id 69601 / 225000 loss 0.0007122347014956176 train acc 0.8043347078346575\n",
      "epoch 5 batch id 69701 / 225000 loss 0.17472387850284576 train acc 0.804367943071118\n",
      "epoch 5 batch id 69801 / 225000 loss 0.9517306089401245 train acc 0.8043760118049885\n",
      "epoch 5 batch id 69901 / 225000 loss 0.9299340844154358 train acc 0.8044019398864107\n",
      "epoch 5 batch id 70001 / 225000 loss 0.0023631961084902287 train acc 0.8044027942457965\n",
      "epoch 5 batch id 70101 / 225000 loss 1.4307231903076172 train acc 0.8044286101482148\n",
      "epoch 5 batch id 70201 / 225000 loss 2.4560022354125977 train acc 0.8044614749077649\n",
      "epoch 5 batch id 70301 / 225000 loss 0.6534464359283447 train acc 0.8044729093469509\n",
      "epoch 5 batch id 70401 / 225000 loss 1.3140695095062256 train acc 0.8044488004431756\n",
      "epoch 5 batch id 70501 / 225000 loss 1.214471459388733 train acc 0.8044637664713976\n",
      "epoch 5 batch id 70601 / 225000 loss 1.8184176683425903 train acc 0.8044539029192221\n",
      "epoch 5 batch id 70701 / 225000 loss 3.254148483276367 train acc 0.8044617473585947\n",
      "epoch 5 batch id 70801 / 225000 loss 1.6404781341552734 train acc 0.8044448524738351\n",
      "epoch 5 batch id 70901 / 225000 loss 1.1071776151657104 train acc 0.8044562135936023\n",
      "epoch 5 batch id 71001 / 225000 loss 0.005926609970629215 train acc 0.8045062745595133\n",
      "epoch 5 batch id 71101 / 225000 loss 0.009413525462150574 train acc 0.8045315818342921\n",
      "epoch 5 batch id 71201 / 225000 loss 1.951828122138977 train acc 0.8045954410752658\n",
      "epoch 5 batch id 71301 / 225000 loss 0.00960424356162548 train acc 0.8045925022089452\n",
      "epoch 5 batch id 71401 / 225000 loss 1.5383495092391968 train acc 0.8045860702231061\n",
      "epoch 5 batch id 71501 / 225000 loss 0.0923416018486023 train acc 0.8046390959566999\n",
      "epoch 5 batch id 71601 / 225000 loss 0.0006355317309498787 train acc 0.8046989567184816\n",
      "epoch 5 batch id 71701 / 225000 loss 2.4008471965789795 train acc 0.80472378348977\n",
      "epoch 5 batch id 71801 / 225000 loss 1.1819547414779663 train acc 0.8047311318783861\n",
      "epoch 5 batch id 71901 / 225000 loss 1.4422550201416016 train acc 0.8047349828236047\n",
      "epoch 5 batch id 72001 / 225000 loss 1.9767465591430664 train acc 0.8047770169858752\n",
      "epoch 5 batch id 72101 / 225000 loss 1.4810562133789062 train acc 0.8047426526677854\n",
      "epoch 5 batch id 72201 / 225000 loss 0.7199273109436035 train acc 0.8047984099943214\n",
      "epoch 5 batch id 72301 / 225000 loss 0.02620840072631836 train acc 0.804819435415831\n",
      "epoch 5 batch id 72401 / 225000 loss 0.01553452666848898 train acc 0.8048300437839256\n",
      "epoch 5 batch id 72501 / 225000 loss 2.114542245864868 train acc 0.8048199335181584\n",
      "epoch 5 batch id 72601 / 225000 loss 0.001713956124149263 train acc 0.8047650858803598\n",
      "epoch 5 batch id 72701 / 225000 loss 2.0033905506134033 train acc 0.8047103891280725\n",
      "epoch 5 batch id 72801 / 225000 loss 1.0594249963760376 train acc 0.8047348250710842\n",
      "epoch 5 batch id 72901 / 225000 loss 0.8621658086776733 train acc 0.8047626232836312\n",
      "epoch 5 batch id 73001 / 225000 loss 0.7620241045951843 train acc 0.8047287023465431\n",
      "epoch 5 batch id 73101 / 225000 loss 0.24995966255664825 train acc 0.8047530129546792\n",
      "epoch 5 batch id 73201 / 225000 loss 0.214973583817482 train acc 0.8047294435868363\n",
      "epoch 5 batch id 73301 / 225000 loss 0.34368786215782166 train acc 0.8047536868528397\n",
      "epoch 5 batch id 73401 / 225000 loss 0.9022682309150696 train acc 0.8047506164766147\n",
      "epoch 5 batch id 73501 / 225000 loss 0.012287797406315804 train acc 0.8047917715405233\n",
      "epoch 5 batch id 73601 / 225000 loss 1.085174798965454 train acc 0.8047682776049239\n",
      "epoch 5 batch id 73701 / 225000 loss 1.3236223459243774 train acc 0.8047855524348381\n",
      "epoch 5 batch id 73801 / 225000 loss 0.47298669815063477 train acc 0.8047689055703853\n",
      "epoch 5 batch id 73901 / 225000 loss 0.0053091999143362045 train acc 0.8047624524701966\n",
      "epoch 5 batch id 74001 / 225000 loss 2.370870590209961 train acc 0.8047830434723855\n",
      "epoch 5 batch id 74101 / 225000 loss 0.040140241384506226 train acc 0.8047732149363707\n",
      "epoch 5 batch id 74201 / 225000 loss 4.153888702392578 train acc 0.8047465667578604\n",
      "epoch 5 batch id 74301 / 225000 loss 1.57567298412323 train acc 0.804783919462726\n",
      "epoch 5 batch id 74401 / 225000 loss 1.810092568397522 train acc 0.8047808497197618\n",
      "epoch 5 batch id 74501 / 225000 loss 0.02651694416999817 train acc 0.804737520301741\n",
      "epoch 5 batch id 74601 / 225000 loss 1.3785321712493896 train acc 0.8047278186619482\n",
      "epoch 5 batch id 74701 / 225000 loss 0.04723527282476425 train acc 0.8047482630754609\n",
      "epoch 5 batch id 74801 / 225000 loss 0.09910474717617035 train acc 0.8047419152150372\n",
      "epoch 5 batch id 74901 / 225000 loss 0.6393967866897583 train acc 0.8047322465654664\n",
      "epoch 5 batch id 75001 / 225000 loss 0.025321271270513535 train acc 0.8047392701430648\n",
      "epoch 5 batch id 75101 / 225000 loss 2.5569190979003906 train acc 0.8047828923716063\n",
      "epoch 5 batch id 75201 / 225000 loss 0.9292479157447815 train acc 0.8047865054985971\n",
      "epoch 5 batch id 75301 / 225000 loss 2.188476800918579 train acc 0.8047535889297619\n",
      "epoch 5 batch id 75401 / 225000 loss 0.0015776371583342552 train acc 0.8047804405777111\n",
      "epoch 5 batch id 75501 / 225000 loss 0.7843101024627686 train acc 0.8047906650243043\n",
      "epoch 5 batch id 75601 / 225000 loss 4.50221061706543 train acc 0.8048173965952832\n",
      "epoch 5 batch id 75701 / 225000 loss 0.8902884721755981 train acc 0.8047945205479452\n",
      "epoch 5 batch id 75801 / 225000 loss 0.692086398601532 train acc 0.8047815991873458\n",
      "epoch 5 batch id 75901 / 225000 loss 1.1335111856460571 train acc 0.8048049432813796\n",
      "epoch 5 batch id 76001 / 225000 loss 0.09362617880105972 train acc 0.8048315153747977\n",
      "epoch 5 batch id 76101 / 225000 loss 1.1351414918899536 train acc 0.8048415920947163\n",
      "epoch 5 batch id 76201 / 225000 loss 0.20015625655651093 train acc 0.8048614847574179\n",
      "epoch 5 batch id 76301 / 225000 loss 0.0027753557078540325 train acc 0.8048846017745508\n",
      "epoch 5 batch id 76401 / 225000 loss 0.14270688593387604 train acc 0.8048683917749768\n",
      "epoch 5 batch id 76501 / 225000 loss 0.002558360807597637 train acc 0.8048947072587287\n",
      "epoch 5 batch id 76601 / 225000 loss 0.0009142854833044112 train acc 0.804911163039647\n",
      "epoch 5 batch id 76701 / 225000 loss 1.0314393043518066 train acc 0.8048917224025762\n",
      "epoch 5 batch id 76801 / 225000 loss 1.4109137058258057 train acc 0.8049048840509889\n",
      "epoch 5 batch id 76901 / 225000 loss 2.587031126022339 train acc 0.8048887530721317\n",
      "epoch 5 batch id 77001 / 225000 loss 0.5342897772789001 train acc 0.8049083778132752\n",
      "epoch 5 batch id 77101 / 225000 loss 0.0068085817620158195 train acc 0.8049182241475468\n",
      "epoch 5 batch id 77201 / 225000 loss 2.557589292526245 train acc 0.8049086151733785\n",
      "epoch 5 batch id 77301 / 225000 loss 0.000629962480161339 train acc 0.8049119675036546\n",
      "epoch 5 batch id 77401 / 225000 loss 1.234690546989441 train acc 0.8049476104959884\n",
      "epoch 5 batch id 77501 / 225000 loss 0.013618501834571362 train acc 0.8049573553889627\n",
      "epoch 5 batch id 77601 / 225000 loss 2.0810296535491943 train acc 0.8049445239107743\n",
      "epoch 5 batch id 77701 / 225000 loss 0.002335841301828623 train acc 0.8049703350021236\n",
      "epoch 5 batch id 77801 / 225000 loss 0.0052619208581745625 train acc 0.8049928664155988\n",
      "epoch 5 batch id 77901 / 225000 loss 0.006030092015862465 train acc 0.8050345951913326\n",
      "epoch 5 batch id 78001 / 225000 loss 0.3762824535369873 train acc 0.8050153203164062\n",
      "epoch 5 batch id 78101 / 225000 loss 0.04105132818222046 train acc 0.8050665164338485\n",
      "epoch 5 batch id 78201 / 225000 loss 0.0013104983372613788 train acc 0.8050536438152964\n",
      "epoch 5 batch id 78301 / 225000 loss 0.0007200215477496386 train acc 0.8050599609200393\n",
      "epoch 5 batch id 78401 / 225000 loss 0.009102784097194672 train acc 0.8050535069705743\n",
      "epoch 5 batch id 78501 / 225000 loss 0.002666418207809329 train acc 0.8050407001184698\n",
      "epoch 5 batch id 78601 / 225000 loss 2.2407290935516357 train acc 0.8050088421266905\n",
      "epoch 5 batch id 78701 / 225000 loss 1.1181299686431885 train acc 0.8049993011524631\n",
      "epoch 5 batch id 78801 / 225000 loss 1.745558261871338 train acc 0.8049929569421708\n",
      "epoch 5 batch id 78901 / 225000 loss 1.3468519449234009 train acc 0.8049961343962687\n",
      "epoch 5 batch id 79001 / 225000 loss 1.2784978151321411 train acc 0.8050467715598537\n",
      "epoch 5 batch id 79101 / 225000 loss 1.0304664373397827 train acc 0.8050403913983388\n",
      "epoch 5 batch id 79201 / 225000 loss 0.0015927668428048491 train acc 0.8050434969255439\n",
      "epoch 5 batch id 79301 / 225000 loss 1.5006486177444458 train acc 0.8050497471658618\n",
      "epoch 5 batch id 79401 / 225000 loss 0.008779420517385006 train acc 0.8050685759625194\n",
      "epoch 5 batch id 79501 / 225000 loss 1.395520567893982 train acc 0.8050653450899988\n",
      "epoch 5 batch id 79601 / 225000 loss 1.4656291007995605 train acc 0.8051280762804487\n",
      "epoch 5 batch id 79701 / 225000 loss 0.004702029284089804 train acc 0.8051655562665462\n",
      "epoch 5 batch id 79801 / 225000 loss 2.9141368865966797 train acc 0.8052060751118407\n",
      "epoch 5 batch id 79901 / 225000 loss 0.003069422673434019 train acc 0.805146368631181\n",
      "epoch 5 batch id 80001 / 225000 loss 0.9122874140739441 train acc 0.805168060399245\n",
      "epoch 5 batch id 80101 / 225000 loss 0.3858627378940582 train acc 0.8051928190659292\n",
      "epoch 5 batch id 80201 / 225000 loss 0.8757427334785461 train acc 0.8051925786461516\n",
      "epoch 5 batch id 80301 / 225000 loss 1.5315542221069336 train acc 0.8052359248328165\n",
      "epoch 5 batch id 80401 / 225000 loss 1.0965080261230469 train acc 0.8052325219835574\n",
      "epoch 5 batch id 80501 / 225000 loss 0.0005365891265682876 train acc 0.8052291275884772\n",
      "epoch 5 batch id 80601 / 225000 loss 3.277721643447876 train acc 0.8052567586010099\n",
      "epoch 5 batch id 80701 / 225000 loss 3.1923909187316895 train acc 0.8052378533103679\n",
      "epoch 5 batch id 80801 / 225000 loss 1.950732946395874 train acc 0.8052530290466702\n",
      "epoch 5 batch id 80901 / 225000 loss 0.9854717254638672 train acc 0.8052928888394457\n",
      "epoch 5 batch id 81001 / 225000 loss 0.013535536825656891 train acc 0.8052647498179035\n",
      "epoch 5 batch id 81101 / 225000 loss 1.7957491874694824 train acc 0.8052582582212303\n",
      "epoch 5 batch id 81201 / 225000 loss 2.9724345207214355 train acc 0.8052302311547888\n",
      "epoch 5 batch id 81301 / 225000 loss 0.2861672639846802 train acc 0.8052545479145398\n",
      "epoch 5 batch id 81401 / 225000 loss 2.0502030849456787 train acc 0.805257306421297\n",
      "epoch 5 batch id 81501 / 225000 loss 0.9604517221450806 train acc 0.8052324511355688\n",
      "epoch 5 batch id 81601 / 225000 loss 0.24264541268348694 train acc 0.8052505484001422\n",
      "epoch 5 batch id 81701 / 225000 loss 0.858949601650238 train acc 0.8052716613015752\n",
      "epoch 5 batch id 81801 / 225000 loss 1.6171272993087769 train acc 0.8052988349775675\n",
      "epoch 5 batch id 81901 / 225000 loss 0.6270264387130737 train acc 0.805280155309459\n",
      "epoch 5 batch id 82001 / 225000 loss 1.9884272813796997 train acc 0.805264569944269\n",
      "epoch 5 batch id 82101 / 225000 loss 0.15570226311683655 train acc 0.8052733827846189\n",
      "epoch 5 batch id 82201 / 225000 loss 1.2282068729400635 train acc 0.8052608849040765\n",
      "epoch 5 batch id 82301 / 225000 loss 0.044782914221286774 train acc 0.8052666431756601\n",
      "epoch 5 batch id 82401 / 225000 loss 0.009424223564565182 train acc 0.8053178966274681\n",
      "epoch 5 batch id 82501 / 225000 loss 1.0479192733764648 train acc 0.8053175113028933\n",
      "epoch 5 batch id 82601 / 225000 loss 0.9894941449165344 train acc 0.8052929141293689\n",
      "epoch 5 batch id 82701 / 225000 loss 1.3459800481796265 train acc 0.8052925599448616\n",
      "epoch 5 batch id 82801 / 225000 loss 2.113447904586792 train acc 0.8052952259030688\n",
      "epoch 5 batch id 82901 / 225000 loss 1.6780346632003784 train acc 0.8052828072037732\n",
      "epoch 5 batch id 83001 / 225000 loss 1.0723497867584229 train acc 0.8052493343453694\n",
      "epoch 5 batch id 83101 / 225000 loss 1.9119237661361694 train acc 0.8052430175328816\n",
      "epoch 5 batch id 83201 / 225000 loss 1.1114821434020996 train acc 0.8052397206764341\n",
      "epoch 5 batch id 83301 / 225000 loss 0.4301323890686035 train acc 0.8053084596823568\n",
      "epoch 5 batch id 83401 / 225000 loss 1.1859519481658936 train acc 0.8053290727928921\n",
      "epoch 5 batch id 83501 / 225000 loss 0.001234316499903798 train acc 0.8052957449611382\n",
      "epoch 5 batch id 83601 / 225000 loss 0.7739682197570801 train acc 0.8053043623880097\n",
      "epoch 5 batch id 83701 / 225000 loss 0.13540872931480408 train acc 0.8052890646467784\n",
      "epoch 5 batch id 83801 / 225000 loss 1.6313480138778687 train acc 0.8053304853164044\n",
      "epoch 5 batch id 83901 / 225000 loss 0.0020087859593331814 train acc 0.8053271117149975\n",
      "epoch 5 batch id 84001 / 225000 loss 1.1802482604980469 train acc 0.8053386269211081\n",
      "epoch 5 batch id 84101 / 225000 loss 0.01878025382757187 train acc 0.8052817445690301\n",
      "epoch 5 batch id 84201 / 225000 loss 1.2725954055786133 train acc 0.8052695336159903\n",
      "epoch 5 batch id 84301 / 225000 loss 0.6407616138458252 train acc 0.8053136973464134\n",
      "epoch 5 batch id 84401 / 225000 loss 0.007121582515537739 train acc 0.805310363621284\n",
      "epoch 5 batch id 84501 / 225000 loss 2.863926410675049 train acc 0.8053602915941823\n",
      "epoch 5 batch id 84601 / 225000 loss 0.003816723357886076 train acc 0.8053303152445006\n",
      "epoch 5 batch id 84701 / 225000 loss 0.0029480806551873684 train acc 0.8053653439746874\n",
      "epoch 5 batch id 84801 / 225000 loss 0.006364859640598297 train acc 0.8053678612280516\n",
      "epoch 5 batch id 84901 / 225000 loss 2.3842968940734863 train acc 0.8053497603090658\n",
      "epoch 5 batch id 85001 / 225000 loss 1.0266830921173096 train acc 0.8053464076893213\n",
      "epoch 5 batch id 85101 / 225000 loss 2.3282697200775146 train acc 0.8053577513777747\n",
      "epoch 5 batch id 85201 / 225000 loss 0.0013596061617136002 train acc 0.8053808053896081\n",
      "epoch 5 batch id 85301 / 225000 loss 1.1981991529464722 train acc 0.8053891513581318\n",
      "epoch 5 batch id 85401 / 225000 loss 0.0014196785632520914 train acc 0.8053828409503402\n",
      "epoch 5 batch id 85501 / 225000 loss 1.5900599956512451 train acc 0.8053765453035637\n",
      "epoch 5 batch id 85601 / 225000 loss 0.0018571199616417289 train acc 0.8053615027861825\n",
      "epoch 5 batch id 85701 / 225000 loss 1.715491771697998 train acc 0.80536399808637\n",
      "epoch 5 batch id 85801 / 225000 loss 0.47970205545425415 train acc 0.8053431778184403\n",
      "epoch 5 batch id 85901 / 225000 loss 1.0327649116516113 train acc 0.8053747919116192\n",
      "epoch 5 batch id 86001 / 225000 loss 0.0027387710288167 train acc 0.8053249380821154\n",
      "epoch 5 batch id 86101 / 225000 loss 0.0030412492342293262 train acc 0.8053768248916969\n",
      "epoch 5 batch id 86201 / 225000 loss 4.30398416519165 train acc 0.8053966891335367\n",
      "epoch 5 batch id 86301 / 225000 loss 3.05509090423584 train acc 0.8054338883674581\n",
      "epoch 5 batch id 86401 / 225000 loss 0.0007659380789846182 train acc 0.8054478536128054\n",
      "epoch 5 batch id 86501 / 225000 loss 0.0036907633766531944 train acc 0.8054704569889365\n",
      "epoch 5 batch id 86601 / 225000 loss 1.1774358749389648 train acc 0.8054728005450283\n",
      "epoch 5 batch id 86701 / 225000 loss 0.0022628644946962595 train acc 0.8054722552219697\n",
      "epoch 5 batch id 86801 / 225000 loss 1.4849982261657715 train acc 0.8054515500973491\n",
      "epoch 5 batch id 86901 / 225000 loss 0.5430920124053955 train acc 0.8054711683409858\n",
      "epoch 5 batch id 87001 / 225000 loss 0.0024497166741639376 train acc 0.8054763738347835\n",
      "epoch 5 batch id 87101 / 225000 loss 1.204627513885498 train acc 0.8055102696869152\n",
      "epoch 5 batch id 87201 / 225000 loss 0.915216863155365 train acc 0.8055240192199631\n",
      "epoch 5 batch id 87301 / 225000 loss 0.8417460322380066 train acc 0.8054976460750736\n",
      "epoch 5 batch id 87401 / 225000 loss 0.0006730809691362083 train acc 0.8055514238967517\n",
      "epoch 5 batch id 87501 / 225000 loss 0.001928012352436781 train acc 0.805570793476646\n",
      "epoch 5 batch id 87601 / 225000 loss 1.9798672199249268 train acc 0.805558726498556\n",
      "epoch 5 batch id 87701 / 225000 loss 1.9812426567077637 train acc 0.8055523882281844\n",
      "epoch 5 batch id 87801 / 225000 loss 3.283013343811035 train acc 0.805520438263801\n",
      "epoch 5 batch id 87901 / 225000 loss 0.9812239408493042 train acc 0.8055454431690197\n",
      "epoch 5 batch id 88001 / 225000 loss 0.84958416223526 train acc 0.8055363007238554\n",
      "epoch 5 batch id 88101 / 225000 loss 0.002272944198921323 train acc 0.8055328543376352\n",
      "epoch 5 batch id 88201 / 225000 loss 0.0017420421354472637 train acc 0.8055265813312774\n",
      "epoch 5 batch id 88301 / 225000 loss 0.982848048210144 train acc 0.8055259849831825\n",
      "epoch 5 batch id 88401 / 225000 loss 0.0016148877330124378 train acc 0.8055282180065836\n",
      "epoch 5 batch id 88501 / 225000 loss 0.0026299110613763332 train acc 0.8055473949446899\n",
      "epoch 5 batch id 88601 / 225000 loss 0.0007262181024998426 train acc 0.8055439554858297\n",
      "epoch 5 batch id 88701 / 225000 loss 2.468045949935913 train acc 0.8055348868671154\n",
      "epoch 5 batch id 88801 / 225000 loss 0.9493424296379089 train acc 0.8055370998074346\n",
      "epoch 5 batch id 88901 / 225000 loss 1.435245156288147 train acc 0.8055308714187692\n",
      "epoch 5 batch id 89001 / 225000 loss 0.7557951211929321 train acc 0.8055274659835283\n",
      "epoch 5 batch id 89101 / 225000 loss 1.5241155624389648 train acc 0.8055156507783302\n",
      "epoch 5 batch id 89201 / 225000 loss 0.00030324747785925865 train acc 0.8055206780193047\n",
      "epoch 5 batch id 89301 / 225000 loss 0.0033854064531624317 train acc 0.8055368920840752\n",
      "epoch 5 batch id 89401 / 225000 loss 0.6261799335479736 train acc 0.8055782373798951\n",
      "epoch 5 batch id 89501 / 225000 loss 0.09747929871082306 train acc 0.8055552451927911\n",
      "epoch 5 batch id 89601 / 225000 loss 1.9212533235549927 train acc 0.8055462550641176\n",
      "epoch 5 batch id 89701 / 225000 loss 0.060124095529317856 train acc 0.8055094146107624\n",
      "epoch 5 batch id 89801 / 225000 loss 1.6115299463272095 train acc 0.8055450384739591\n",
      "epoch 5 batch id 89901 / 225000 loss 3.704512357711792 train acc 0.8055527747188574\n",
      "epoch 5 batch id 90001 / 225000 loss 0.4280737340450287 train acc 0.80553827179698\n",
      "epoch 5 batch id 90101 / 225000 loss 0.6172497868537903 train acc 0.8055543223715608\n",
      "epoch 5 batch id 90201 / 225000 loss 0.006651106756180525 train acc 0.8055647941818826\n",
      "epoch 5 batch id 90301 / 225000 loss 1.049856185913086 train acc 0.80561953909702\n",
      "epoch 5 batch id 90401 / 225000 loss 0.19136863946914673 train acc 0.8056243846860102\n",
      "epoch 5 batch id 90501 / 225000 loss 2.513275146484375 train acc 0.8056678931724511\n",
      "epoch 5 batch id 90601 / 225000 loss 1.1099563837051392 train acc 0.8056505998830035\n",
      "epoch 5 batch id 90701 / 225000 loss 0.08290711790323257 train acc 0.8056609078179954\n",
      "epoch 5 batch id 90801 / 225000 loss 0.6102822422981262 train acc 0.8056794528694617\n",
      "epoch 5 batch id 90901 / 225000 loss 3.1742265224456787 train acc 0.8056897063838682\n",
      "epoch 5 batch id 91001 / 225000 loss 0.6670888662338257 train acc 0.8056862012505357\n",
      "epoch 5 batch id 91101 / 225000 loss 2.538130521774292 train acc 0.8056909364331896\n",
      "epoch 5 batch id 91201 / 225000 loss 0.008736269548535347 train acc 0.8056819552417188\n",
      "epoch 5 batch id 91301 / 225000 loss 1.1669609546661377 train acc 0.8057058520717189\n",
      "epoch 5 batch id 91401 / 225000 loss 1.524692177772522 train acc 0.8056777278147942\n",
      "epoch 5 batch id 91501 / 225000 loss 1.2635610103607178 train acc 0.8056523972415602\n",
      "epoch 5 batch id 91601 / 225000 loss 1.1831533908843994 train acc 0.8056243927468041\n",
      "epoch 5 batch id 91701 / 225000 loss 0.2843623161315918 train acc 0.805610080587998\n",
      "epoch 5 batch id 91801 / 225000 loss 0.0268310084939003 train acc 0.8056638816570626\n",
      "epoch 5 batch id 91901 / 225000 loss 0.7803863883018494 train acc 0.8056767608622322\n",
      "epoch 5 batch id 92001 / 225000 loss 0.0813400149345398 train acc 0.8056733078988272\n",
      "epoch 5 batch id 92101 / 225000 loss 1.8442234992980957 train acc 0.8056725768449854\n",
      "epoch 5 batch id 92201 / 225000 loss 0.003634065855294466 train acc 0.8057152308543292\n",
      "epoch 5 batch id 92301 / 225000 loss 0.000597034755628556 train acc 0.8057009133162154\n",
      "epoch 5 batch id 92401 / 225000 loss 1.7237495183944702 train acc 0.8056893323665328\n",
      "epoch 5 batch id 92501 / 225000 loss 0.0025397478602826595 train acc 0.805731829926163\n",
      "epoch 5 batch id 92601 / 225000 loss 0.011246837675571442 train acc 0.8056986425632553\n",
      "epoch 5 batch id 92701 / 225000 loss 1.9503966569900513 train acc 0.8056924952265887\n",
      "epoch 5 batch id 92801 / 225000 loss 3.0004003047943115 train acc 0.8056863611383498\n",
      "epoch 5 batch id 92901 / 225000 loss 1.3244024515151978 train acc 0.8056748581823662\n",
      "epoch 5 batch id 93001 / 225000 loss 2.4034862518310547 train acc 0.8056553155342415\n",
      "epoch 5 batch id 93101 / 225000 loss 0.0011638810392469168 train acc 0.8056680379372939\n",
      "epoch 5 batch id 93201 / 225000 loss 0.0016278900438919663 train acc 0.8056807330393451\n",
      "epoch 5 batch id 93301 / 225000 loss 0.9839372038841248 train acc 0.8057014394272302\n",
      "epoch 5 batch id 93401 / 225000 loss 2.1915040016174316 train acc 0.8056873052751041\n",
      "epoch 5 batch id 93501 / 225000 loss 0.008895919658243656 train acc 0.8056678538197453\n",
      "epoch 5 batch id 93601 / 225000 loss 0.5063945651054382 train acc 0.8056938494246856\n",
      "epoch 5 batch id 93701 / 225000 loss 1.2697100639343262 train acc 0.8056824366869083\n",
      "epoch 5 batch id 93801 / 225000 loss 1.6366827487945557 train acc 0.8056737134998561\n",
      "epoch 5 batch id 93901 / 225000 loss 0.3596581518650055 train acc 0.8057155940831301\n",
      "epoch 5 batch id 94001 / 225000 loss 0.003895776579156518 train acc 0.8057174923671024\n",
      "epoch 5 batch id 94101 / 225000 loss 1.5231378078460693 train acc 0.8057007895771564\n",
      "epoch 5 batch id 94201 / 225000 loss 0.019364695996046066 train acc 0.8057186229445548\n",
      "epoch 5 batch id 94301 / 225000 loss 1.6267935037612915 train acc 0.8057152098068949\n",
      "epoch 5 batch id 94401 / 225000 loss 1.1764063835144043 train acc 0.8057276935625682\n",
      "epoch 5 batch id 94501 / 225000 loss 0.005411486141383648 train acc 0.8057295689992698\n",
      "epoch 5 batch id 94601 / 225000 loss 1.1348565816879272 train acc 0.8057340831492268\n",
      "epoch 5 batch id 94701 / 225000 loss 0.002480406081303954 train acc 0.8057808259680468\n",
      "epoch 5 batch id 94801 / 225000 loss 0.014999894425272942 train acc 0.8058327443803336\n",
      "epoch 5 batch id 94901 / 225000 loss 0.013814575970172882 train acc 0.8058608444589624\n",
      "epoch 5 batch id 95001 / 225000 loss 1.1746652126312256 train acc 0.8058336228039705\n",
      "epoch 5 batch id 95101 / 225000 loss 0.08777355402708054 train acc 0.8058248598858057\n",
      "epoch 5 batch id 95201 / 225000 loss 1.3489097356796265 train acc 0.8058476276509701\n",
      "epoch 5 batch id 95301 / 225000 loss 0.8185403347015381 train acc 0.8058441149620675\n",
      "epoch 5 batch id 95401 / 225000 loss 0.0020851888693869114 train acc 0.8058275070491924\n",
      "epoch 5 batch id 95501 / 225000 loss 0.0019054790027439594 train acc 0.8058502005214605\n",
      "epoch 5 batch id 95601 / 225000 loss 1.0557403564453125 train acc 0.8058623863767116\n",
      "epoch 5 batch id 95701 / 225000 loss 2.6266415119171143 train acc 0.80587977137125\n",
      "epoch 5 batch id 95801 / 225000 loss 0.8141456842422485 train acc 0.8058892913435142\n",
      "epoch 5 batch id 95901 / 225000 loss 1.8208236694335938 train acc 0.8058857571870992\n",
      "epoch 5 batch id 96001 / 225000 loss 2.3566014766693115 train acc 0.8058561889980312\n",
      "epoch 5 batch id 96101 / 225000 loss 1.0183794498443604 train acc 0.8058631023610576\n",
      "epoch 5 batch id 96201 / 225000 loss 0.5675264000892639 train acc 0.8058700013513374\n",
      "epoch 5 batch id 96301 / 225000 loss 2.1902260780334473 train acc 0.8058587138243632\n",
      "epoch 5 batch id 96401 / 225000 loss 3.1434810161590576 train acc 0.8058500430493459\n",
      "epoch 5 batch id 96501 / 225000 loss 0.25397026538848877 train acc 0.805856934125035\n",
      "epoch 5 batch id 96601 / 225000 loss 0.0004575958591885865 train acc 0.8058689868634901\n",
      "epoch 5 batch id 96701 / 225000 loss 2.936056137084961 train acc 0.8058706735194052\n",
      "epoch 5 batch id 96801 / 225000 loss 0.001247664913535118 train acc 0.8058671914546337\n",
      "epoch 5 batch id 96901 / 225000 loss 2.2149205207824707 train acc 0.8058662965294476\n",
      "epoch 5 batch id 97001 / 225000 loss 1.797096848487854 train acc 0.8058602488634138\n",
      "epoch 5 batch id 97101 / 225000 loss 0.0017159741837531328 train acc 0.8058670868477152\n",
      "epoch 5 batch id 97201 / 225000 loss 0.0006601418717764318 train acc 0.8058841987222354\n",
      "epoch 5 batch id 97301 / 225000 loss 0.41141262650489807 train acc 0.8058730126103535\n",
      "epoch 5 batch id 97401 / 225000 loss 1.1440954208374023 train acc 0.8058849498465108\n",
      "epoch 5 batch id 97501 / 225000 loss 0.008005972020328045 train acc 0.8059173752064082\n",
      "epoch 5 batch id 97601 / 225000 loss 1.1708229780197144 train acc 0.8058882593416051\n",
      "epoch 5 batch id 97701 / 225000 loss 0.00317416456528008 train acc 0.8059154972825252\n",
      "epoch 5 batch id 97801 / 225000 loss 0.177988663315773 train acc 0.8059273422562141\n",
      "epoch 5 batch id 97901 / 225000 loss 0.0027171249967068434 train acc 0.805969806232827\n",
      "epoch 5 batch id 98001 / 225000 loss 0.0006541396724060178 train acc 0.8059841226109937\n",
      "epoch 5 batch id 98101 / 225000 loss 1.3136340379714966 train acc 0.8060035065901469\n",
      "epoch 5 batch id 98201 / 225000 loss 0.2745002806186676 train acc 0.8060101220965163\n",
      "epoch 5 batch id 98301 / 225000 loss 0.0009898397838696837 train acc 0.8060116377249469\n",
      "epoch 5 batch id 98401 / 225000 loss 0.0049790930934250355 train acc 0.8060410971433217\n",
      "epoch 5 batch id 98501 / 225000 loss 0.017008084803819656 train acc 0.8060578065197308\n",
      "epoch 5 batch id 98601 / 225000 loss 0.9019029140472412 train acc 0.8060719465319824\n",
      "epoch 5 batch id 98701 / 225000 loss 0.4236467480659485 train acc 0.8060556630631909\n",
      "epoch 5 batch id 98801 / 225000 loss 1.8767153024673462 train acc 0.8060621856054089\n",
      "epoch 5 batch id 98901 / 225000 loss 0.7738156318664551 train acc 0.8060661671772783\n",
      "epoch 5 batch id 99001 / 225000 loss 3.917436361312866 train acc 0.8060524641165241\n",
      "epoch 5 batch id 99101 / 225000 loss 1.4691721200942993 train acc 0.8060488794260401\n",
      "epoch 5 batch id 99201 / 225000 loss 0.6271872520446777 train acc 0.8060175804679388\n",
      "epoch 5 batch id 99301 / 225000 loss 0.002279220847412944 train acc 0.8060039677344639\n",
      "epoch 5 batch id 99401 / 225000 loss 0.7096469402313232 train acc 0.8059903823905192\n",
      "epoch 5 batch id 99501 / 225000 loss 2.4805877208709717 train acc 0.8060019497291484\n",
      "epoch 5 batch id 99601 / 225000 loss 0.0010100610088557005 train acc 0.806056164094738\n",
      "epoch 5 batch id 99701 / 225000 loss 0.12039245665073395 train acc 0.806045074773573\n",
      "epoch 5 batch id 99801 / 225000 loss 0.0008481875993311405 train acc 0.8060615625093936\n",
      "epoch 5 batch id 99901 / 225000 loss 0.36982253193855286 train acc 0.8060579974174432\n",
      "epoch 5 batch id 100001 / 225000 loss 0.0017665091436356306 train acc 0.8061019389806102\n",
      "epoch 5 batch id 100101 / 225000 loss 0.05344954878091812 train acc 0.8060908482432743\n",
      "epoch 5 batch id 100201 / 225000 loss 0.08042144030332565 train acc 0.8060947495533977\n",
      "epoch 5 batch id 100301 / 225000 loss 0.0011977417161688209 train acc 0.8061111055722276\n",
      "epoch 5 batch id 100401 / 225000 loss 0.3958948254585266 train acc 0.8061199589645521\n",
      "epoch 5 batch id 100501 / 225000 loss 0.003666145959869027 train acc 0.8061213321260485\n",
      "epoch 5 batch id 100601 / 225000 loss 0.0037916130386292934 train acc 0.8061053071043032\n",
      "epoch 5 batch id 100701 / 225000 loss 2.635617256164551 train acc 0.8060942791034845\n",
      "epoch 5 batch id 100801 / 225000 loss 0.03649793565273285 train acc 0.8060981537881569\n",
      "epoch 5 batch id 100901 / 225000 loss 0.032324958592653275 train acc 0.8061069761449341\n",
      "epoch 5 batch id 101001 / 225000 loss 0.04000667482614517 train acc 0.8061207314779062\n",
      "epoch 5 batch id 101101 / 225000 loss 0.49505218863487244 train acc 0.8061245685008062\n",
      "epoch 5 batch id 101201 / 225000 loss 0.001969231991097331 train acc 0.8061209869467693\n",
      "epoch 5 batch id 101301 / 225000 loss 1.1968764066696167 train acc 0.8061297519274242\n",
      "epoch 5 batch id 101401 / 225000 loss 0.032875556498765945 train acc 0.8061311032435577\n",
      "epoch 5 batch id 101501 / 225000 loss 0.002932452131062746 train acc 0.8061891015852061\n",
      "epoch 5 batch id 101601 / 225000 loss 0.6193069219589233 train acc 0.8061928524325548\n",
      "epoch 5 batch id 101701 / 225000 loss 1.532698154449463 train acc 0.806203970462434\n",
      "epoch 5 batch id 101801 / 225000 loss 0.002941420301795006 train acc 0.8062445359082917\n",
      "epoch 5 batch id 101901 / 225000 loss 2.5124428272247314 train acc 0.8062678482056114\n",
      "epoch 5 batch id 102001 / 225000 loss 0.0018362561240792274 train acc 0.8062911147929922\n",
      "epoch 5 batch id 102101 / 225000 loss 0.14100989699363708 train acc 0.80629719591385\n",
      "epoch 5 batch id 102201 / 225000 loss 2.1040565967559814 train acc 0.8063057112944101\n",
      "epoch 5 batch id 102301 / 225000 loss 0.8952609300613403 train acc 0.8063435352538099\n",
      "epoch 5 batch id 102401 / 225000 loss 0.1591987907886505 train acc 0.8063544301325183\n",
      "epoch 5 batch id 102501 / 225000 loss 0.9340182542800903 train acc 0.8063653037531341\n",
      "epoch 5 batch id 102601 / 225000 loss 2.2256689071655273 train acc 0.8063688463075409\n",
      "epoch 5 batch id 102701 / 225000 loss 0.24943849444389343 train acc 0.8063529079561056\n",
      "epoch 5 batch id 102801 / 225000 loss 1.323885202407837 train acc 0.8063370006128345\n",
      "epoch 5 batch id 102901 / 225000 loss 1.0410479307174683 train acc 0.8063211241873257\n",
      "epoch 5 batch id 103001 / 225000 loss 0.002966044470667839 train acc 0.8063271230376404\n",
      "epoch 5 batch id 103101 / 225000 loss 0.004472795873880386 train acc 0.8063185614106556\n",
      "epoch 5 batch id 103201 / 225000 loss 0.918981671333313 train acc 0.8062906367186364\n",
      "epoch 5 batch id 103301 / 225000 loss 5.256970405578613 train acc 0.8063135884454168\n",
      "epoch 5 batch id 103401 / 225000 loss 0.0395386628806591 train acc 0.8063340780069825\n",
      "epoch 5 batch id 103501 / 225000 loss 0.0005569695495069027 train acc 0.8063279581839788\n",
      "epoch 5 batch id 103601 / 225000 loss 1.228632926940918 train acc 0.8063483943205182\n",
      "epoch 5 batch id 103701 / 225000 loss 1.5705807209014893 train acc 0.8063663802663427\n",
      "epoch 5 batch id 103801 / 225000 loss 3.386655569076538 train acc 0.8063722892843036\n",
      "epoch 5 batch id 103901 / 225000 loss 0.0004899946507066488 train acc 0.8063926237476059\n",
      "epoch 5 batch id 104001 / 225000 loss 2.018592119216919 train acc 0.806367246468784\n",
      "epoch 5 batch id 104101 / 225000 loss 1.922046184539795 train acc 0.8063923497372744\n",
      "epoch 5 batch id 104201 / 225000 loss 1.104364275932312 train acc 0.806412606404929\n",
      "epoch 5 batch id 104301 / 225000 loss 1.8843047618865967 train acc 0.8063896798688411\n",
      "epoch 5 batch id 104401 / 225000 loss 1.9213831424713135 train acc 0.8063715864790567\n",
      "epoch 5 batch id 104501 / 225000 loss 0.8365009427070618 train acc 0.8063774509334839\n",
      "epoch 5 batch id 104601 / 225000 loss 0.8839389085769653 train acc 0.8064095945545454\n",
      "epoch 5 batch id 104701 / 225000 loss 3.5559380054473877 train acc 0.8064154115051432\n",
      "epoch 5 batch id 104801 / 225000 loss 0.0018436943646520376 train acc 0.8064164464079541\n",
      "epoch 5 batch id 104901 / 225000 loss 3.56569766998291 train acc 0.8064508441292266\n",
      "epoch 5 batch id 105001 / 225000 loss 0.7463842034339905 train acc 0.8064613670345997\n",
      "epoch 5 batch id 105101 / 225000 loss 1.1342732906341553 train acc 0.8064457046079485\n",
      "epoch 5 batch id 105201 / 225000 loss 0.017339814454317093 train acc 0.8064657180064828\n",
      "epoch 5 batch id 105301 / 225000 loss 0.00558119174093008 train acc 0.8064667002212704\n",
      "epoch 5 batch id 105401 / 225000 loss 1.828357458114624 train acc 0.8064676805722906\n",
      "epoch 5 batch id 105501 / 225000 loss 0.005632562562823296 train acc 0.8064805072937697\n",
      "epoch 5 batch id 105601 / 225000 loss 1.1421869993209839 train acc 0.8064791053115027\n",
      "epoch 5 batch id 105701 / 225000 loss 0.02418692223727703 train acc 0.8064918969546173\n",
      "epoch 5 batch id 105801 / 225000 loss 0.005832221824675798 train acc 0.8064668575911381\n",
      "epoch 5 batch id 105901 / 225000 loss 0.9872777462005615 train acc 0.8065103256815328\n",
      "epoch 5 batch id 106001 / 225000 loss 0.03277873992919922 train acc 0.8065041839227932\n",
      "epoch 5 batch id 106101 / 225000 loss 0.06599364429712296 train acc 0.8065051224776393\n",
      "epoch 5 batch id 106201 / 225000 loss 0.7510075569152832 train acc 0.8065131213453733\n",
      "epoch 5 batch id 106301 / 225000 loss 1.108945369720459 train acc 0.8065399196620916\n",
      "epoch 5 batch id 106401 / 225000 loss 0.6186614632606506 train acc 0.806531423576846\n",
      "epoch 5 batch id 106501 / 225000 loss 0.03534773364663124 train acc 0.806537027821335\n",
      "epoch 5 batch id 106601 / 225000 loss 0.855804979801178 train acc 0.8065402763576327\n",
      "epoch 5 batch id 106701 / 225000 loss 0.004963455721735954 train acc 0.8065646057675185\n",
      "epoch 5 batch id 106801 / 225000 loss 0.0007570273010060191 train acc 0.8066052752315053\n",
      "epoch 5 batch id 106901 / 225000 loss 0.0019893422722816467 train acc 0.8066294983208763\n",
      "epoch 5 batch id 107001 / 225000 loss 1.0145227909088135 train acc 0.8066233025859572\n",
      "epoch 5 batch id 107101 / 225000 loss 3.309290647506714 train acc 0.806652132099607\n",
      "epoch 5 batch id 107201 / 225000 loss 0.005959406029433012 train acc 0.80665059094598\n",
      "epoch 5 batch id 107301 / 225000 loss 1.7786641120910645 train acc 0.8066467227705241\n",
      "epoch 5 batch id 107401 / 225000 loss 0.1511230766773224 train acc 0.8066195845476299\n",
      "epoch 5 batch id 107501 / 225000 loss 0.010255162604153156 train acc 0.8066366824494656\n",
      "epoch 5 batch id 107601 / 225000 loss 1.065507411956787 train acc 0.8066351613832585\n",
      "epoch 5 batch id 107701 / 225000 loss 0.03322681412100792 train acc 0.8066359643828748\n",
      "epoch 5 batch id 107801 / 225000 loss 0.16544601321220398 train acc 0.806643723156557\n",
      "epoch 5 batch id 107901 / 225000 loss 0.011065968312323093 train acc 0.8066792708130601\n",
      "epoch 5 batch id 108001 / 225000 loss 0.31390535831451416 train acc 0.8066985490875085\n",
      "epoch 5 batch id 108101 / 225000 loss 0.0024563814513385296 train acc 0.8067062284345196\n",
      "epoch 5 batch id 108201 / 225000 loss 1.4549872875213623 train acc 0.8067162041016257\n",
      "epoch 5 batch id 108301 / 225000 loss 0.042176585644483566 train acc 0.8067146194402637\n",
      "epoch 5 batch id 108401 / 225000 loss 0.0279025137424469 train acc 0.8067361002204777\n",
      "epoch 5 batch id 108501 / 225000 loss 0.01909511163830757 train acc 0.8067598455313776\n",
      "epoch 5 batch id 108601 / 225000 loss 1.9796957969665527 train acc 0.806749017044042\n",
      "epoch 5 batch id 108701 / 225000 loss 0.0029846406541764736 train acc 0.8067198093853782\n",
      "epoch 5 batch id 108801 / 225000 loss 0.03494527190923691 train acc 0.8067412064227351\n",
      "epoch 5 batch id 108901 / 225000 loss 0.0032391459681093693 train acc 0.8067281292182809\n",
      "epoch 5 batch id 109001 / 225000 loss 2.8394885063171387 train acc 0.8067563600333942\n",
      "epoch 5 batch id 109101 / 225000 loss 0.024851445108652115 train acc 0.8067639160044363\n",
      "epoch 5 batch id 109201 / 225000 loss 0.03022923693060875 train acc 0.8067600113552074\n",
      "epoch 5 batch id 109301 / 225000 loss 1.0687164068222046 train acc 0.8067835609921227\n",
      "epoch 5 batch id 109401 / 225000 loss 0.011770367622375488 train acc 0.8067910713796035\n",
      "epoch 5 batch id 109501 / 225000 loss 1.1790409088134766 train acc 0.8067917187970887\n",
      "epoch 5 batch id 109601 / 225000 loss 2.9661331176757812 train acc 0.8067786790266512\n",
      "epoch 5 batch id 109701 / 225000 loss 0.217800110578537 train acc 0.8067884522474726\n",
      "epoch 5 batch id 109801 / 225000 loss 0.7834129929542542 train acc 0.8067708855110609\n",
      "epoch 5 batch id 109901 / 225000 loss 0.006013814359903336 train acc 0.8068215939800366\n",
      "epoch 5 batch id 110001 / 225000 loss 0.582354724407196 train acc 0.8068153925873401\n",
      "epoch 5 batch id 110101 / 225000 loss 2.9876089096069336 train acc 0.8067887666778685\n",
      "epoch 5 batch id 110201 / 225000 loss 0.0030084981117397547 train acc 0.8067644576727979\n",
      "epoch 5 batch id 110301 / 225000 loss 1.756843090057373 train acc 0.8067560584219545\n",
      "epoch 5 batch id 110401 / 225000 loss 0.008647198788821697 train acc 0.8067522033314916\n",
      "epoch 5 batch id 110501 / 225000 loss 0.4900151789188385 train acc 0.8067574049103629\n",
      "epoch 5 batch id 110601 / 225000 loss 2.9549341201782227 train acc 0.8067535555736386\n",
      "epoch 5 batch id 110701 / 225000 loss 1.8746825456619263 train acc 0.8067542298624222\n",
      "epoch 5 batch id 110801 / 225000 loss 6.2808332443237305 train acc 0.8067752096100216\n",
      "epoch 5 batch id 110901 / 225000 loss 0.4355718195438385 train acc 0.8067645918431754\n",
      "epoch 5 batch id 111001 / 225000 loss 0.009316467680037022 train acc 0.8067697588310015\n",
      "epoch 5 batch id 111101 / 225000 loss 3.3136558532714844 train acc 0.8067591650840227\n",
      "epoch 5 batch id 111201 / 225000 loss 0.011930495500564575 train acc 0.8067688240213667\n",
      "epoch 5 batch id 111301 / 225000 loss 0.004325602203607559 train acc 0.8067582501504929\n",
      "epoch 5 batch id 111401 / 225000 loss 0.2963107228279114 train acc 0.8067611601332124\n",
      "epoch 5 batch id 111501 / 225000 loss 0.006222004070878029 train acc 0.8067864862198545\n",
      "epoch 5 batch id 111601 / 225000 loss 1.3830480575561523 train acc 0.806787125563391\n",
      "epoch 5 batch id 111701 / 225000 loss 0.03572111204266548 train acc 0.8067877637621865\n",
      "epoch 5 batch id 111801 / 225000 loss 2.231600522994995 train acc 0.8068018175150491\n",
      "epoch 5 batch id 111901 / 225000 loss 0.2218877375125885 train acc 0.8067957390908035\n",
      "epoch 5 batch id 112001 / 225000 loss 0.002943020313978195 train acc 0.8067740466602977\n",
      "epoch 5 batch id 112101 / 225000 loss 1.6951777935028076 train acc 0.8067590833266429\n",
      "epoch 5 batch id 112201 / 225000 loss 4.340622425079346 train acc 0.8067396903770911\n",
      "epoch 5 batch id 112301 / 225000 loss 0.04474056512117386 train acc 0.806742593565507\n",
      "epoch 5 batch id 112401 / 225000 loss 1.5135886669158936 train acc 0.8067276981521516\n",
      "epoch 5 batch id 112501 / 225000 loss 0.0027251422870904207 train acc 0.8067417178513969\n",
      "epoch 5 batch id 112601 / 225000 loss 0.0023474395275115967 train acc 0.8067734744806885\n",
      "epoch 5 batch id 112701 / 225000 loss 0.12043595314025879 train acc 0.8067741191293777\n",
      "epoch 5 batch id 112801 / 225000 loss 0.9665145874023438 train acc 0.8067592485882218\n",
      "epoch 5 batch id 112901 / 225000 loss 0.026628218591213226 train acc 0.8068041912826281\n",
      "epoch 5 batch id 113001 / 225000 loss 0.000997458933852613 train acc 0.8067738338598773\n",
      "epoch 5 batch id 113101 / 225000 loss 1.4541099071502686 train acc 0.8067855279794166\n",
      "epoch 5 batch id 113201 / 225000 loss 0.011974300257861614 train acc 0.8067905760549818\n",
      "epoch 5 batch id 113301 / 225000 loss 0.889699399471283 train acc 0.806786789172205\n",
      "epoch 5 batch id 113401 / 225000 loss 1.6459095478057861 train acc 0.8067940317986614\n",
      "epoch 5 batch id 113501 / 225000 loss 0.0070121572352945805 train acc 0.8068144774054854\n",
      "epoch 5 batch id 113601 / 225000 loss 0.004023321904242039 train acc 0.8068128801683084\n",
      "epoch 5 batch id 113701 / 225000 loss 0.001982894027605653 train acc 0.8068046894926166\n",
      "epoch 5 batch id 113801 / 225000 loss 0.0008301198249682784 train acc 0.8068206782014218\n",
      "epoch 5 batch id 113901 / 225000 loss 0.0019509446574375033 train acc 0.8068037155073265\n",
      "epoch 5 batch id 114001 / 225000 loss 0.0065245977602899075 train acc 0.8068262559100359\n",
      "epoch 5 batch id 114101 / 225000 loss 2.4551756381988525 train acc 0.8068224643079377\n",
      "epoch 5 batch id 114201 / 225000 loss 2.3613314628601074 train acc 0.8068033554872549\n",
      "epoch 5 batch id 114301 / 225000 loss 2.6180615425109863 train acc 0.8068127137995293\n",
      "epoch 5 batch id 114401 / 225000 loss 0.0019194934284314513 train acc 0.8068329822291763\n",
      "epoch 5 batch id 114501 / 225000 loss 0.011467920616269112 train acc 0.8068379315464493\n",
      "epoch 5 batch id 114601 / 225000 loss 1.3030816316604614 train acc 0.8068559611172678\n",
      "epoch 5 batch id 114701 / 225000 loss 0.14895394444465637 train acc 0.8068543430310111\n",
      "epoch 5 batch id 114801 / 225000 loss 0.012599287554621696 train acc 0.8068527277636954\n",
      "epoch 5 batch id 114901 / 225000 loss 1.0096309185028076 train acc 0.8068576426662953\n",
      "epoch 5 batch id 115001 / 225000 loss 1.5162750482559204 train acc 0.8068560273388927\n",
      "epoch 5 batch id 115101 / 225000 loss 0.06522843986749649 train acc 0.8068891669055873\n",
      "epoch 5 batch id 115201 / 225000 loss 0.0019012988777831197 train acc 0.8068962074981988\n",
      "epoch 5 batch id 115301 / 225000 loss 0.0010976555058732629 train acc 0.8069010676403501\n",
      "epoch 5 batch id 115401 / 225000 loss 0.005538781639188528 train acc 0.8068929212051889\n",
      "epoch 5 batch id 115501 / 225000 loss 0.0030131270177662373 train acc 0.806880459909438\n",
      "epoch 5 batch id 115601 / 225000 loss 2.882072925567627 train acc 0.8068658575617857\n",
      "epoch 5 batch id 115701 / 225000 loss 0.013908240012824535 train acc 0.8068793701005177\n",
      "epoch 5 batch id 115801 / 225000 loss 0.8058775067329407 train acc 0.8068885415497276\n",
      "epoch 5 batch id 115901 / 225000 loss 0.0017226542113348842 train acc 0.8068890691193346\n",
      "epoch 5 batch id 116001 / 225000 loss 1.5644725561141968 train acc 0.806902526702356\n",
      "epoch 5 batch id 116101 / 225000 loss 0.0034791030921041965 train acc 0.806913807805273\n",
      "epoch 5 batch id 116201 / 225000 loss 0.0017886089626699686 train acc 0.8069164637137374\n",
      "epoch 5 batch id 116301 / 225000 loss 0.014241762459278107 train acc 0.8069126662711412\n",
      "epoch 5 batch id 116401 / 225000 loss 1.2380656003952026 train acc 0.8068895456224603\n",
      "epoch 5 batch id 116501 / 225000 loss 0.00511719798669219 train acc 0.8068750482828474\n",
      "epoch 5 batch id 116601 / 225000 loss 0.005360275506973267 train acc 0.8068820164492586\n",
      "epoch 5 batch id 116701 / 225000 loss 1.2545093297958374 train acc 0.8068975415806205\n",
      "epoch 5 batch id 116801 / 225000 loss 0.7129293084144592 train acc 0.8069001977722794\n",
      "epoch 5 batch id 116901 / 225000 loss 0.9752485156059265 train acc 0.8068964337345275\n",
      "epoch 5 batch id 117001 / 225000 loss 0.04147707670927048 train acc 0.806886265929351\n",
      "epoch 5 batch id 117101 / 225000 loss 0.40646955370903015 train acc 0.8068974645818567\n",
      "epoch 5 batch id 117201 / 225000 loss 1.2604913711547852 train acc 0.8069513058762298\n",
      "epoch 5 batch id 117301 / 225000 loss 0.0011989644262939692 train acc 0.8069496423730403\n",
      "epoch 5 batch id 117401 / 225000 loss 1.5667420625686646 train acc 0.8069458522499808\n",
      "epoch 5 batch id 117501 / 225000 loss 0.0009878674754872918 train acc 0.8069612173513417\n",
      "epoch 5 batch id 117601 / 225000 loss 0.002501843264326453 train acc 0.8069765563218\n",
      "epoch 5 batch id 117701 / 225000 loss 2.1906275749206543 train acc 0.8070088614370311\n",
      "epoch 5 batch id 117801 / 225000 loss 2.942194938659668 train acc 0.8070220116976936\n",
      "epoch 5 batch id 117901 / 225000 loss 1.23952317237854 train acc 0.8070266579587959\n",
      "epoch 5 batch id 118001 / 225000 loss 0.7798019051551819 train acc 0.8070291777188329\n",
      "epoch 5 batch id 118101 / 225000 loss 0.9089911580085754 train acc 0.8070422773727572\n",
      "epoch 5 batch id 118201 / 225000 loss 0.0030698045156896114 train acc 0.8070278593243712\n",
      "epoch 5 batch id 118301 / 225000 loss 0.20511040091514587 train acc 0.8070007861302948\n",
      "epoch 5 batch id 118401 / 225000 loss 0.0006646183901466429 train acc 0.8070180995092947\n",
      "epoch 5 batch id 118501 / 225000 loss 0.22526419162750244 train acc 0.8070206158597818\n",
      "epoch 5 batch id 118601 / 225000 loss 2.828251838684082 train acc 0.8070442070471581\n",
      "epoch 5 batch id 118701 / 225000 loss 0.0008298755274154246 train acc 0.8070108929158137\n",
      "epoch 5 batch id 118801 / 225000 loss 1.436487078666687 train acc 0.8070049915404752\n",
      "epoch 5 batch id 118901 / 225000 loss 0.03012833558022976 train acc 0.8070075104498701\n",
      "epoch 5 batch id 119001 / 225000 loss 0.6821253299713135 train acc 0.8070226300619322\n",
      "epoch 5 batch id 119101 / 225000 loss 0.029850926250219345 train acc 0.8070146346378284\n",
      "epoch 5 batch id 119201 / 225000 loss 0.9380568861961365 train acc 0.8069940688417043\n",
      "epoch 5 batch id 119301 / 225000 loss 1.7095760107040405 train acc 0.8070028750806783\n",
      "epoch 5 batch id 119401 / 225000 loss 0.7676909565925598 train acc 0.8070284168474301\n",
      "epoch 5 batch id 119501 / 225000 loss 2.4149580001831055 train acc 0.8070267194416784\n",
      "epoch 5 batch id 119601 / 225000 loss 0.9899482727050781 train acc 0.8070292054414261\n",
      "epoch 5 batch id 119701 / 225000 loss 0.0027120071463286877 train acc 0.8070337758247633\n",
      "epoch 5 batch id 119801 / 225000 loss 0.0038802598137408495 train acc 0.8070362517842088\n",
      "epoch 5 batch id 119901 / 225000 loss 0.0006018082494847476 train acc 0.8070324684531405\n",
      "epoch 5 batch id 120001 / 225000 loss 0.0019738967530429363 train acc 0.8070474412713228\n",
      "epoch 5 batch id 120101 / 225000 loss 0.00571810407564044 train acc 0.8070228391104154\n",
      "epoch 5 batch id 120201 / 225000 loss 0.39777228236198425 train acc 0.8070294756283226\n",
      "epoch 5 batch id 120301 / 225000 loss 1.5790281295776367 train acc 0.8070506479580386\n",
      "epoch 5 batch id 120401 / 225000 loss 1.3143161535263062 train acc 0.8070883962757784\n",
      "epoch 5 batch id 120501 / 225000 loss 1.2162548303604126 train acc 0.8070887378527979\n",
      "epoch 5 batch id 120601 / 225000 loss 1.5407689809799194 train acc 0.8070807870581505\n",
      "epoch 5 batch id 120701 / 225000 loss 3.3051645755767822 train acc 0.8070707782039916\n",
      "epoch 5 batch id 120801 / 225000 loss 2.2245006561279297 train acc 0.8070938982293193\n",
      "epoch 5 batch id 120901 / 225000 loss 0.013074291869997978 train acc 0.8070859628952615\n",
      "epoch 5 batch id 121001 / 225000 loss 0.002334809862077236 train acc 0.8070656440855861\n",
      "epoch 5 batch id 121101 / 225000 loss 2.3130838871002197 train acc 0.8070825178982832\n",
      "epoch 5 batch id 121201 / 225000 loss 1.1765468120574951 train acc 0.8070931757988795\n",
      "epoch 5 batch id 121301 / 225000 loss 1.9098142385482788 train acc 0.8070976331604851\n",
      "epoch 5 batch id 121401 / 225000 loss 0.0013341590529307723 train acc 0.8071000238877769\n",
      "epoch 5 batch id 121501 / 225000 loss 2.420393705368042 train acc 0.8070818347174097\n",
      "epoch 5 batch id 121601 / 225000 loss 0.0065753343515098095 train acc 0.8071027376419602\n",
      "epoch 5 batch id 121701 / 225000 loss 0.232491135597229 train acc 0.8071153893558803\n",
      "epoch 5 batch id 121801 / 225000 loss 0.0008147084736265242 train acc 0.8071341778803129\n",
      "epoch 5 batch id 121901 / 225000 loss 1.4820070266723633 train acc 0.8071221729108047\n",
      "epoch 5 batch id 122001 / 225000 loss 0.12857185304164886 train acc 0.8071347775837903\n",
      "epoch 5 batch id 122101 / 225000 loss 0.7645309567451477 train acc 0.8071575990368629\n",
      "epoch 5 batch id 122201 / 225000 loss 1.7571077346801758 train acc 0.8071292378949436\n",
      "epoch 5 batch id 122301 / 225000 loss 0.9928702712059021 train acc 0.8071458941464092\n",
      "epoch 5 batch id 122401 / 225000 loss 0.5611178278923035 train acc 0.8071666081159468\n",
      "epoch 5 batch id 122501 / 225000 loss 0.0014404673129320145 train acc 0.8071872882670346\n",
      "epoch 5 batch id 122601 / 225000 loss 1.266382098197937 train acc 0.80718550419654\n",
      "epoch 5 batch id 122701 / 225000 loss 1.3581708669662476 train acc 0.8072000228196999\n",
      "epoch 5 batch id 122801 / 225000 loss 0.003187942784279585 train acc 0.8072002670988021\n",
      "epoch 5 batch id 122901 / 225000 loss 2.0373497009277344 train acc 0.8072005109803826\n",
      "epoch 5 batch id 123001 / 225000 loss 0.86058509349823 train acc 0.8071722994121999\n",
      "epoch 5 batch id 123101 / 225000 loss 0.0009472930687479675 train acc 0.8071685039114224\n",
      "epoch 5 batch id 123201 / 225000 loss 0.35834410786628723 train acc 0.8071667437764304\n",
      "epoch 5 batch id 123301 / 225000 loss 1.0341715812683105 train acc 0.8071872896407977\n",
      "epoch 5 batch id 123401 / 225000 loss 0.575505793094635 train acc 0.8071652579800812\n",
      "epoch 5 batch id 123501 / 225000 loss 0.0025857819709926844 train acc 0.8071695775742707\n",
      "epoch 5 batch id 123601 / 225000 loss 0.6324397325515747 train acc 0.8071678222668102\n",
      "epoch 5 batch id 123701 / 225000 loss 2.4072766304016113 train acc 0.8071701118018447\n",
      "epoch 5 batch id 123801 / 225000 loss 0.0016698013059794903 train acc 0.80717037826835\n",
      "epoch 5 batch id 123901 / 225000 loss 0.013158896937966347 train acc 0.8071706443047272\n",
      "epoch 5 batch id 124001 / 225000 loss 0.002825023140758276 train acc 0.8071789743631099\n",
      "epoch 5 batch id 124101 / 225000 loss 0.0006829233025200665 train acc 0.8072034069024424\n",
      "epoch 5 batch id 124201 / 225000 loss 3.24472713470459 train acc 0.8071915685058897\n",
      "epoch 5 batch id 124301 / 225000 loss 0.0026388932019472122 train acc 0.8071737154166096\n",
      "epoch 5 batch id 124401 / 225000 loss 0.0032515309285372496 train acc 0.8071920643724729\n",
      "epoch 5 batch id 124501 / 225000 loss 0.002178104128688574 train acc 0.8072164079003381\n",
      "epoch 5 batch id 124601 / 225000 loss 0.008589229546487331 train acc 0.8072366995449475\n",
      "epoch 5 batch id 124701 / 225000 loss 0.3752373158931732 train acc 0.8072529490541375\n",
      "epoch 5 batch id 124801 / 225000 loss 0.012582083232700825 train acc 0.8072711757117331\n",
      "epoch 5 batch id 124901 / 225000 loss 1.1117658615112305 train acc 0.8072813668425393\n",
      "epoch 5 batch id 125001 / 225000 loss 2.0229904651641846 train acc 0.8072615419076647\n",
      "epoch 5 batch id 125101 / 225000 loss 0.004027874208986759 train acc 0.8072857131437798\n",
      "epoch 5 batch id 125201 / 225000 loss 0.4037684202194214 train acc 0.8072998618221899\n",
      "epoch 5 batch id 125301 / 225000 loss 0.6842151284217834 train acc 0.8073139879170956\n",
      "epoch 5 batch id 125401 / 225000 loss 0.0010543580865487456 train acc 0.807322110668974\n",
      "epoch 5 batch id 125501 / 225000 loss 0.03150615841150284 train acc 0.8073262364443311\n",
      "epoch 5 batch id 125601 / 225000 loss 0.9808408617973328 train acc 0.8073582216702097\n",
      "epoch 5 batch id 125701 / 225000 loss 0.0026659993454813957 train acc 0.8073662898465406\n",
      "epoch 5 batch id 125801 / 225000 loss 0.5981001257896423 train acc 0.8073822942583923\n",
      "epoch 5 batch id 125901 / 225000 loss 1.7855433225631714 train acc 0.8074022446207735\n",
      "epoch 5 batch id 126001 / 225000 loss 0.013326526619493961 train acc 0.8074241474274013\n",
      "epoch 5 batch id 126101 / 225000 loss 0.2525685429573059 train acc 0.8074043822015686\n",
      "epoch 5 batch id 126201 / 225000 loss 2.9257562160491943 train acc 0.8073846482991418\n",
      "epoch 5 batch id 126301 / 225000 loss 0.9226530194282532 train acc 0.8074104718094077\n",
      "epoch 5 batch id 126401 / 225000 loss 5.5460968017578125 train acc 0.8074065869732043\n",
      "epoch 5 batch id 126501 / 225000 loss 1.4189609289169312 train acc 0.8073809693204006\n",
      "epoch 5 batch id 126601 / 225000 loss 2.2026357650756836 train acc 0.8073573668454436\n",
      "epoch 5 batch id 126701 / 225000 loss 1.9124844074249268 train acc 0.8073851035114167\n",
      "epoch 5 batch id 126801 / 225000 loss 0.6841719150543213 train acc 0.8074147680223343\n",
      "epoch 5 batch id 126901 / 225000 loss 0.021330511197447777 train acc 0.8074286254639443\n",
      "epoch 5 batch id 127001 / 225000 loss 0.006248696707189083 train acc 0.8074227761986126\n",
      "epoch 5 batch id 127101 / 225000 loss 1.1201215982437134 train acc 0.8074248038961142\n",
      "epoch 5 batch id 127201 / 225000 loss 2.2805140018463135 train acc 0.8074012782918373\n",
      "epoch 5 batch id 127301 / 225000 loss 2.1647210121154785 train acc 0.8074092112395033\n",
      "epoch 5 batch id 127401 / 225000 loss 0.14492915570735931 train acc 0.8074269432736007\n",
      "epoch 5 batch id 127501 / 225000 loss 2.0341317653656006 train acc 0.8074289613414797\n",
      "epoch 5 batch id 127601 / 225000 loss 0.9852765202522278 train acc 0.8074211800847956\n",
      "epoch 5 batch id 127701 / 225000 loss 0.0029987210873514414 train acc 0.8074427764856971\n",
      "epoch 5 batch id 127801 / 225000 loss 0.305678129196167 train acc 0.8074232595989077\n",
      "epoch 5 batch id 127901 / 225000 loss 0.628186047077179 train acc 0.8073959546837006\n",
      "epoch 5 batch id 128001 / 225000 loss 1.4256672859191895 train acc 0.8074214263951063\n",
      "epoch 5 batch id 128101 / 225000 loss 1.2807759046554565 train acc 0.8074117298069492\n",
      "epoch 5 batch id 128201 / 225000 loss 0.003474908648058772 train acc 0.807421548973877\n",
      "epoch 5 batch id 128301 / 225000 loss 1.27366304397583 train acc 0.8074138159484338\n",
      "epoch 5 batch id 128401 / 225000 loss 0.6051196455955505 train acc 0.80742361819612\n",
      "epoch 5 batch id 128501 / 225000 loss 1.1282340288162231 train acc 0.8074353506976599\n",
      "epoch 5 batch id 128601 / 225000 loss 2.328436851501465 train acc 0.8074451209555136\n",
      "epoch 5 batch id 128701 / 225000 loss 2.2210710048675537 train acc 0.8074568185173386\n",
      "epoch 5 batch id 128801 / 225000 loss 0.014262663200497627 train acc 0.8074549110643551\n",
      "epoch 5 batch id 128901 / 225000 loss 0.9558743238449097 train acc 0.8074704618272938\n",
      "epoch 5 batch id 129001 / 225000 loss 0.9205794930458069 train acc 0.8074666087859784\n",
      "epoch 5 batch id 129101 / 225000 loss 1.2680916786193848 train acc 0.807474380523776\n",
      "epoch 5 batch id 129201 / 225000 loss 0.007474805694073439 train acc 0.8074956850179178\n",
      "epoch 5 batch id 129301 / 225000 loss 0.4553990960121155 train acc 0.8075034222473144\n",
      "epoch 5 batch id 129401 / 225000 loss 0.11768104881048203 train acc 0.8074956916870812\n",
      "epoch 5 batch id 129501 / 225000 loss 0.3926204741001129 train acc 0.8074918340398916\n",
      "epoch 5 batch id 129601 / 225000 loss 5.144083499908447 train acc 0.8074879823458152\n",
      "epoch 5 batch id 129701 / 225000 loss 0.8718128204345703 train acc 0.8075169042644236\n",
      "epoch 5 batch id 129801 / 225000 loss 0.0016168777365237474 train acc 0.8075380775186631\n",
      "epoch 5 batch id 129901 / 225000 loss 0.0011482180561870337 train acc 0.8075284254932602\n",
      "epoch 5 batch id 130001 / 225000 loss 1.8009905815124512 train acc 0.8075534034353582\n",
      "epoch 5 batch id 130101 / 225000 loss 0.017940208315849304 train acc 0.8075725782276847\n",
      "epoch 5 batch id 130201 / 225000 loss 0.0020583299919962883 train acc 0.8075974838902927\n",
      "epoch 5 batch id 130301 / 225000 loss 1.1767841577529907 train acc 0.8075686295577164\n",
      "epoch 5 batch id 130401 / 225000 loss 0.002780110575258732 train acc 0.807568576928091\n",
      "epoch 5 batch id 130501 / 225000 loss 1.5160350799560547 train acc 0.8075838499321845\n",
      "epoch 5 batch id 130601 / 225000 loss 0.0015844848239794374 train acc 0.8075952710928707\n",
      "epoch 5 batch id 130701 / 225000 loss 0.01333853229880333 train acc 0.8076085875394986\n",
      "epoch 5 batch id 130801 / 225000 loss 1.0855265855789185 train acc 0.8076065932217643\n",
      "epoch 5 batch id 130901 / 225000 loss 1.0836244821548462 train acc 0.8076103314718757\n",
      "epoch 5 batch id 131001 / 225000 loss 0.0023795198649168015 train acc 0.8076197891619148\n",
      "epoch 5 batch id 131101 / 225000 loss 1.0728551149368286 train acc 0.8076330462772977\n",
      "epoch 5 batch id 131201 / 225000 loss 0.14690031111240387 train acc 0.8076405667639729\n",
      "epoch 5 batch id 131301 / 225000 loss 0.007687756326049566 train acc 0.8076252275306357\n",
      "epoch 5 batch id 131401 / 225000 loss 1.4162431955337524 train acc 0.8076517682513832\n",
      "epoch 5 batch id 131501 / 225000 loss 0.013597543351352215 train acc 0.8076516528391419\n",
      "epoch 5 batch id 131601 / 225000 loss 0.001886985031887889 train acc 0.807642039194231\n",
      "epoch 5 batch id 131701 / 225000 loss 0.0048955269157886505 train acc 0.8076779978891581\n",
      "epoch 5 batch id 131801 / 225000 loss 0.004566397983580828 train acc 0.8076816564365976\n",
      "epoch 5 batch id 131901 / 225000 loss 1.4563909769058228 train acc 0.8076758326320498\n",
      "epoch 5 batch id 132001 / 225000 loss 4.12389612197876 train acc 0.8076681237263355\n",
      "epoch 5 batch id 132101 / 225000 loss 0.0028951081912964582 train acc 0.8076642114745536\n",
      "epoch 5 batch id 132201 / 225000 loss 0.00241660769097507 train acc 0.8076848889191458\n",
      "epoch 5 batch id 132301 / 225000 loss 0.3749057352542877 train acc 0.807673411387669\n",
      "epoch 5 batch id 132401 / 225000 loss 0.0021271160803735256 train acc 0.8076902742426417\n",
      "epoch 5 batch id 132501 / 225000 loss 0.004681391641497612 train acc 0.8077184323137184\n",
      "epoch 5 batch id 132601 / 225000 loss 0.8529510498046875 train acc 0.8077163822293949\n",
      "epoch 5 batch id 132701 / 225000 loss 2.605940341949463 train acc 0.8076917280201354\n",
      "epoch 5 batch id 132801 / 225000 loss 1.1055974960327148 train acc 0.8076671109404296\n",
      "epoch 5 batch id 132901 / 225000 loss 1.5288065671920776 train acc 0.8076613419011144\n",
      "epoch 5 batch id 133001 / 225000 loss 0.0011826001573354006 train acc 0.8076706190179022\n",
      "epoch 5 batch id 133101 / 225000 loss 0.010294102132320404 train acc 0.8076404384640236\n",
      "epoch 5 batch id 133201 / 225000 loss 1.0797271728515625 train acc 0.8076290718538149\n",
      "epoch 5 batch id 133301 / 225000 loss 1.6880228519439697 train acc 0.8075914659304881\n",
      "epoch 5 batch id 133401 / 225000 loss 0.0032361357007175684 train acc 0.8075970195125973\n",
      "epoch 5 batch id 133501 / 225000 loss 0.9571380019187927 train acc 0.8075838383233085\n",
      "epoch 5 batch id 133601 / 225000 loss 0.002324330620467663 train acc 0.8075931317879357\n",
      "epoch 5 batch id 133701 / 225000 loss 0.6837310791015625 train acc 0.8075986716628896\n",
      "epoch 5 batch id 133801 / 225000 loss 0.6051190495491028 train acc 0.807617282382045\n",
      "epoch 5 batch id 133901 / 225000 loss 0.06263136118650436 train acc 0.80763213120141\n",
      "epoch 5 batch id 134001 / 225000 loss 0.22543421387672424 train acc 0.8076171073350199\n",
      "epoch 5 batch id 134101 / 225000 loss 0.019164228811860085 train acc 0.8076654909359363\n",
      "epoch 5 batch id 134201 / 225000 loss 2.887880802154541 train acc 0.8076709562521889\n",
      "epoch 5 batch id 134301 / 225000 loss 1.6807670593261719 train acc 0.8076745519393005\n",
      "epoch 5 batch id 134401 / 225000 loss 0.050191786140203476 train acc 0.8076855826965573\n",
      "epoch 5 batch id 134501 / 225000 loss 3.3613390922546387 train acc 0.807698455773563\n",
      "epoch 5 batch id 134601 / 225000 loss 0.9550685286521912 train acc 0.8076983083335191\n",
      "epoch 5 batch id 134701 / 225000 loss 0.0060635036788880825 train acc 0.8076833134126695\n",
      "epoch 5 batch id 134801 / 225000 loss 0.0008735040901228786 train acc 0.8076609223967182\n",
      "epoch 5 batch id 134901 / 225000 loss 1.4183176755905151 train acc 0.8076774820053224\n",
      "epoch 5 batch id 135001 / 225000 loss 1.377791404724121 train acc 0.8076829060525478\n",
      "epoch 5 batch id 135101 / 225000 loss 1.205689787864685 train acc 0.8077086772118637\n",
      "epoch 5 batch id 135201 / 225000 loss 2.22306227684021 train acc 0.8077455048409405\n",
      "epoch 5 batch id 135301 / 225000 loss 0.002139868913218379 train acc 0.8077730393714755\n",
      "epoch 5 batch id 135401 / 225000 loss 0.612804114818573 train acc 0.8077783768214415\n",
      "epoch 5 batch id 135501 / 225000 loss 0.0037118354812264442 train acc 0.8077837063933108\n",
      "epoch 5 batch id 135601 / 225000 loss 0.006015601567924023 train acc 0.807800089969838\n",
      "epoch 5 batch id 135701 / 225000 loss 0.001327902777120471 train acc 0.8077851305443585\n",
      "epoch 5 batch id 135801 / 225000 loss 0.0002888687886297703 train acc 0.8077591475762329\n",
      "epoch 5 batch id 135901 / 225000 loss 0.006957785226404667 train acc 0.8077589568877345\n",
      "epoch 5 batch id 136001 / 225000 loss 2.8271772861480713 train acc 0.8077550900361027\n",
      "epoch 5 batch id 136101 / 225000 loss 4.244869709014893 train acc 0.8077475551245031\n",
      "epoch 5 batch id 136201 / 225000 loss 1.8817815780639648 train acc 0.8077235115748049\n",
      "epoch 5 batch id 136301 / 225000 loss 0.8970255851745605 train acc 0.8077270159426563\n",
      "epoch 5 batch id 136401 / 225000 loss 0.0027669002301990986 train acc 0.8077268495099009\n",
      "epoch 5 batch id 136501 / 225000 loss 0.0019285713788121939 train acc 0.8077395037398993\n",
      "epoch 5 batch id 136601 / 225000 loss 0.8774241209030151 train acc 0.8077539695902666\n",
      "epoch 5 batch id 136701 / 225000 loss 0.006281946785748005 train acc 0.8077684142764134\n",
      "epoch 5 batch id 136801 / 225000 loss 0.00824736524373293 train acc 0.807757253236453\n",
      "epoch 5 batch id 136901 / 225000 loss 0.7007875442504883 train acc 0.8077187164447301\n",
      "epoch 5 batch id 137001 / 225000 loss 0.004386922810226679 train acc 0.807727680819848\n",
      "epoch 5 batch id 137101 / 225000 loss 0.002024746732786298 train acc 0.8077056330734276\n",
      "epoch 5 batch id 137201 / 225000 loss 1.193671703338623 train acc 0.8076890838988054\n",
      "epoch 5 batch id 137301 / 225000 loss 0.0006676525808870792 train acc 0.8076816629157836\n",
      "epoch 5 batch id 137401 / 225000 loss 0.93979811668396 train acc 0.807666974767287\n",
      "epoch 5 batch id 137501 / 225000 loss 1.4214717149734497 train acc 0.8076541261518098\n",
      "epoch 5 batch id 137601 / 225000 loss 0.016973860561847687 train acc 0.8076758163094745\n",
      "epoch 5 batch id 137701 / 225000 loss 2.8043177127838135 train acc 0.8076393780727809\n",
      "epoch 5 batch id 137801 / 225000 loss 0.14853829145431519 train acc 0.8076374627179774\n",
      "epoch 5 batch id 137901 / 225000 loss 0.7486202120780945 train acc 0.807626485667254\n",
      "epoch 5 batch id 138001 / 225000 loss 0.7328853011131287 train acc 0.8076209592684112\n",
      "epoch 5 batch id 138101 / 225000 loss 0.0011498311068862677 train acc 0.8076317332966452\n",
      "epoch 5 batch id 138201 / 225000 loss 0.8018134236335754 train acc 0.8076298290171562\n",
      "epoch 5 batch id 138301 / 225000 loss 2.105679750442505 train acc 0.8076225045372051\n",
      "epoch 5 batch id 138401 / 225000 loss 2.7265090942382812 train acc 0.8076188033323458\n",
      "epoch 5 batch id 138501 / 225000 loss 1.0973541736602783 train acc 0.8076133024310294\n",
      "epoch 5 batch id 138601 / 225000 loss 0.0028663487173616886 train acc 0.8076222393777822\n",
      "epoch 5 batch id 138701 / 225000 loss 0.9124777913093567 train acc 0.8075987195478043\n",
      "epoch 5 batch id 138801 / 225000 loss 0.0016067087417468429 train acc 0.8076130575428131\n",
      "epoch 5 batch id 138901 / 225000 loss 0.003295998787507415 train acc 0.8076129761484798\n",
      "epoch 5 batch id 139001 / 225000 loss 0.0014159532729536295 train acc 0.8076039021302005\n",
      "epoch 5 batch id 139101 / 225000 loss 0.0006502163596451283 train acc 0.8075876521376554\n",
      "epoch 5 batch id 139201 / 225000 loss 2.160309314727783 train acc 0.8076019568824937\n",
      "epoch 5 batch id 139301 / 225000 loss 1.0304585695266724 train acc 0.8075964996661905\n",
      "epoch 5 batch id 139401 / 225000 loss 3.3629069328308105 train acc 0.8076125709284725\n",
      "epoch 5 batch id 139501 / 225000 loss 4.6616010665893555 train acc 0.8075927771127088\n",
      "epoch 5 batch id 139601 / 225000 loss 0.0040421998128294945 train acc 0.8075962922901698\n",
      "epoch 5 batch id 139701 / 225000 loss 2.7391302585601807 train acc 0.8075801175367392\n",
      "epoch 5 batch id 139801 / 225000 loss 0.003992525860667229 train acc 0.8075872132531241\n",
      "epoch 5 batch id 139901 / 225000 loss 0.002924905624240637 train acc 0.807580003002123\n",
      "epoch 5 batch id 140001 / 225000 loss 2.1176116466522217 train acc 0.8075728030514068\n",
      "epoch 5 batch id 140101 / 225000 loss 2.840513229370117 train acc 0.8075905953562073\n",
      "epoch 5 batch id 140201 / 225000 loss 0.37696272134780884 train acc 0.807604795971498\n",
      "epoch 5 batch id 140301 / 225000 loss 0.033186618238687515 train acc 0.8076082850442976\n",
      "epoch 5 batch id 140401 / 225000 loss 2.7238407135009766 train acc 0.8075868405495688\n",
      "epoch 5 batch id 140501 / 225000 loss 3.06740665435791 train acc 0.8075778820079572\n",
      "epoch 5 batch id 140601 / 225000 loss 1.6351864337921143 train acc 0.8075796046969794\n",
      "epoch 5 batch id 140701 / 225000 loss 1.1285662651062012 train acc 0.807597316294838\n",
      "epoch 5 batch id 140801 / 225000 loss 0.004562855698168278 train acc 0.8075990227342136\n",
      "epoch 5 batch id 140901 / 225000 loss 0.005836636759340763 train acc 0.807600726751407\n",
      "epoch 5 batch id 141001 / 225000 loss 0.010595357045531273 train acc 0.8076095204998546\n",
      "epoch 5 batch id 141101 / 225000 loss 0.0033836241345852613 train acc 0.8076271606863169\n",
      "epoch 5 batch id 141201 / 225000 loss 0.8162378072738647 train acc 0.807621759052698\n",
      "epoch 5 batch id 141301 / 225000 loss 1.2807213068008423 train acc 0.8076057494285249\n",
      "epoch 5 batch id 141401 / 225000 loss 0.19381454586982727 train acc 0.8076003705772944\n",
      "epoch 5 batch id 141501 / 225000 loss 0.0036880874540656805 train acc 0.8076232676800871\n",
      "epoch 5 batch id 141601 / 225000 loss 1.8009635210037231 train acc 0.8076443669183128\n",
      "epoch 5 batch id 141701 / 225000 loss 2.9293763637542725 train acc 0.8076142723057707\n",
      "epoch 5 batch id 141801 / 225000 loss 1.920586109161377 train acc 0.8076141917193814\n",
      "epoch 5 batch id 141901 / 225000 loss 0.03805803507566452 train acc 0.8076229202049316\n",
      "epoch 5 batch id 142001 / 225000 loss 1.752187967300415 train acc 0.8076087492341604\n",
      "epoch 5 batch id 142101 / 225000 loss 0.6989226341247559 train acc 0.8076139506407415\n",
      "epoch 5 batch id 142201 / 225000 loss 1.0189071893692017 train acc 0.807592773609187\n",
      "epoch 5 batch id 142301 / 225000 loss 0.003034158842638135 train acc 0.8075944652532309\n",
      "epoch 5 batch id 142401 / 225000 loss 0.42598670721054077 train acc 0.8075926433100891\n",
      "epoch 5 batch id 142501 / 225000 loss 0.0037359357811510563 train acc 0.8075767889348144\n",
      "epoch 5 batch id 142601 / 225000 loss 0.188898965716362 train acc 0.8075872539463258\n",
      "epoch 5 batch id 142701 / 225000 loss 1.1450649499893188 train acc 0.8075994562056328\n",
      "epoch 5 batch id 142801 / 225000 loss 0.040957193821668625 train acc 0.8076221455031828\n",
      "epoch 5 batch id 142901 / 225000 loss 2.755703926086426 train acc 0.8076325568050609\n",
      "epoch 5 batch id 143001 / 225000 loss 0.07322002202272415 train acc 0.8076586877014846\n",
      "epoch 5 batch id 143101 / 225000 loss 1.290926218032837 train acc 0.807663817862908\n",
      "epoch 5 batch id 143201 / 225000 loss 3.727020263671875 train acc 0.8076846530401324\n",
      "epoch 5 batch id 143301 / 225000 loss 0.013221269473433495 train acc 0.8076670783874502\n",
      "epoch 5 batch id 143401 / 225000 loss 2.31207013130188 train acc 0.8076634751501035\n",
      "epoch 5 batch id 143501 / 225000 loss 3.584074020385742 train acc 0.8076546504902404\n",
      "epoch 5 batch id 143601 / 225000 loss 0.26507437229156494 train acc 0.8076580246655664\n",
      "epoch 5 batch id 143701 / 225000 loss 3.399428129196167 train acc 0.8076544352509725\n",
      "epoch 5 batch id 143801 / 225000 loss 0.0007946797413751483 train acc 0.8076508508285756\n",
      "epoch 5 batch id 143901 / 225000 loss 2.1882145404815674 train acc 0.8076073133612692\n",
      "epoch 5 batch id 144001 / 225000 loss 1.8488558530807495 train acc 0.8076211276310581\n",
      "epoch 5 batch id 144101 / 225000 loss 1.2295796871185303 train acc 0.8076314529392579\n",
      "epoch 5 batch id 144201 / 225000 loss 0.0017110456246882677 train acc 0.8076538997649115\n",
      "epoch 5 batch id 144301 / 225000 loss 0.11487744748592377 train acc 0.8076520606232805\n",
      "epoch 5 batch id 144401 / 225000 loss 1.0867575407028198 train acc 0.8076606117686166\n",
      "epoch 5 batch id 144501 / 225000 loss 2.375072717666626 train acc 0.8076726112622058\n",
      "epoch 5 batch id 144601 / 225000 loss 2.518449068069458 train acc 0.8076724918914807\n",
      "epoch 5 batch id 144701 / 225000 loss 1.0803697109222412 train acc 0.8076775557874514\n",
      "epoch 5 batch id 144801 / 225000 loss 0.07841722667217255 train acc 0.8077033307781024\n",
      "epoch 5 batch id 144901 / 225000 loss 1.5591925382614136 train acc 0.8076928385587401\n",
      "epoch 5 batch id 145001 / 225000 loss 0.9166313409805298 train acc 0.8076961538196288\n",
      "epoch 5 batch id 145101 / 225000 loss 0.0014938248787075281 train acc 0.8077115250756369\n",
      "epoch 5 batch id 145201 / 225000 loss 1.551398515701294 train acc 0.8077182664031239\n",
      "epoch 5 batch id 145301 / 225000 loss 0.22359102964401245 train acc 0.807735321849127\n",
      "epoch 5 batch id 145401 / 225000 loss 0.2127799093723297 train acc 0.8077420375375686\n",
      "epoch 5 batch id 145501 / 225000 loss 1.3785772323608398 train acc 0.8077264073786434\n",
      "epoch 5 batch id 145601 / 225000 loss 1.353061318397522 train acc 0.8077228178377895\n",
      "epoch 5 batch id 145701 / 225000 loss 2.1440963745117188 train acc 0.8077089381678918\n",
      "epoch 5 batch id 145801 / 225000 loss 0.27676063776016235 train acc 0.8077430881818369\n",
      "epoch 5 batch id 145901 / 225000 loss 3.3372435569763184 train acc 0.8077275001542141\n",
      "epoch 5 batch id 146001 / 225000 loss 0.01147322915494442 train acc 0.8077222073821412\n",
      "epoch 5 batch id 146101 / 225000 loss 0.8915171027183533 train acc 0.8077134995653692\n",
      "epoch 5 batch id 146201 / 225000 loss 1.0314100980758667 train acc 0.8077133535338336\n",
      "epoch 5 batch id 146301 / 225000 loss 0.0692702978849411 train acc 0.8077149165077477\n",
      "epoch 5 batch id 146401 / 225000 loss 0.8627381324768066 train acc 0.8077233079009023\n",
      "epoch 5 batch id 146501 / 225000 loss 0.9127647280693054 train acc 0.8077214490003481\n",
      "epoch 5 batch id 146601 / 225000 loss 0.010313322767615318 train acc 0.8076974236192114\n",
      "epoch 5 batch id 146701 / 225000 loss 0.02475428208708763 train acc 0.8076819517249371\n",
      "epoch 5 batch id 146801 / 225000 loss 0.5163034796714783 train acc 0.8076954516658605\n",
      "epoch 5 batch id 146901 / 225000 loss 3.2379648685455322 train acc 0.8076987222687388\n",
      "epoch 5 batch id 147001 / 225000 loss 0.9357871413230896 train acc 0.8076985870844416\n",
      "epoch 5 batch id 147101 / 225000 loss 0.01738891191780567 train acc 0.8077069496468413\n",
      "epoch 5 batch id 147201 / 225000 loss 2.152125358581543 train acc 0.8077169992051685\n",
      "epoch 5 batch id 147301 / 225000 loss 1.4114538431167603 train acc 0.8077270351185667\n",
      "epoch 5 batch id 147401 / 225000 loss 0.0011045499704778194 train acc 0.8077336653075624\n",
      "epoch 5 batch id 147501 / 225000 loss 2.024994134902954 train acc 0.8077267272764252\n",
      "epoch 5 batch id 147601 / 225000 loss 0.9719944000244141 train acc 0.8077418174673613\n",
      "epoch 5 batch id 147701 / 225000 loss 0.6660692095756531 train acc 0.8077450389638526\n",
      "epoch 5 batch id 147801 / 225000 loss 0.7550212144851685 train acc 0.8077397987834994\n",
      "epoch 5 batch id 147901 / 225000 loss 3.088289499282837 train acc 0.8077497785680963\n",
      "epoch 5 batch id 148001 / 225000 loss 1.5899922847747803 train acc 0.8077614340443645\n",
      "epoch 5 batch id 148101 / 225000 loss 2.6226806640625 train acc 0.8077663216318594\n",
      "epoch 5 batch id 148201 / 225000 loss 0.7144838571548462 train acc 0.8077560205396724\n",
      "epoch 5 batch id 148301 / 225000 loss 0.8479945063591003 train acc 0.8077524763824924\n",
      "epoch 5 batch id 148401 / 225000 loss 1.600066900253296 train acc 0.8077640986246724\n",
      "epoch 5 batch id 148501 / 225000 loss 1.1376591920852661 train acc 0.8077588703106376\n",
      "epoch 5 batch id 148601 / 225000 loss 0.21369601786136627 train acc 0.8077502843184097\n",
      "epoch 5 batch id 148701 / 225000 loss 3.5675761699676514 train acc 0.8077551596828535\n",
      "epoch 5 batch id 148801 / 225000 loss 4.223295211791992 train acc 0.8077365071471294\n",
      "epoch 5 batch id 148901 / 225000 loss 0.9184505343437195 train acc 0.8077296324403462\n",
      "epoch 5 batch id 149001 / 225000 loss 1.8898608684539795 train acc 0.807714377755854\n",
      "epoch 5 batch id 149101 / 225000 loss 1.3171368837356567 train acc 0.8077024969651444\n",
      "epoch 5 batch id 149201 / 225000 loss 0.0003041890449821949 train acc 0.807695658876281\n",
      "epoch 5 batch id 149301 / 225000 loss 0.02245459333062172 train acc 0.8077189704020736\n",
      "epoch 5 batch id 149401 / 225000 loss 1.5272499322891235 train acc 0.8077171504876138\n",
      "epoch 5 batch id 149501 / 225000 loss 0.007418428082019091 train acc 0.8077186774670404\n",
      "epoch 5 batch id 149601 / 225000 loss 0.868547797203064 train acc 0.8077268868523606\n",
      "epoch 5 batch id 149701 / 225000 loss 0.8778113126754761 train acc 0.8077718251715086\n",
      "epoch 5 batch id 149801 / 225000 loss 0.0053116511553525925 train acc 0.8077683059525638\n",
      "epoch 5 batch id 149901 / 225000 loss 0.0008035870268940926 train acc 0.8077564525920441\n",
      "epoch 5 batch id 150001 / 225000 loss 0.007615597452968359 train acc 0.8077662815581229\n",
      "epoch 5 batch id 150101 / 225000 loss 3.342540979385376 train acc 0.8077810940633307\n",
      "epoch 5 batch id 150201 / 225000 loss 1.1095799207687378 train acc 0.8077792424817412\n",
      "epoch 5 batch id 150301 / 225000 loss 0.0024839278776198626 train acc 0.8077773933639829\n",
      "epoch 5 batch id 150401 / 225000 loss 0.0056852600537240505 train acc 0.8077622489212173\n",
      "epoch 5 batch id 150501 / 225000 loss 0.004526042845100164 train acc 0.8077554301964771\n",
      "epoch 5 batch id 150601 / 225000 loss 0.003536467207595706 train acc 0.8077702007290788\n",
      "epoch 5 batch id 150701 / 225000 loss 1.6573933362960815 train acc 0.8077534322930836\n",
      "epoch 5 batch id 150801 / 225000 loss 0.0017231730744242668 train acc 0.8077748158168713\n",
      "epoch 5 batch id 150901 / 225000 loss 0.008497655391693115 train acc 0.8077878874228799\n",
      "epoch 5 batch id 151001 / 225000 loss 0.002209613798186183 train acc 0.807810875424666\n",
      "epoch 5 batch id 151101 / 225000 loss 0.0034117503091692924 train acc 0.8078189422968742\n",
      "epoch 5 batch id 151201 / 225000 loss 0.0046219537034630775 train acc 0.8078402259244317\n",
      "epoch 5 batch id 151301 / 225000 loss 1.5367133617401123 train acc 0.8078317393804403\n",
      "epoch 5 batch id 151401 / 225000 loss 1.2130225896835327 train acc 0.807816659070944\n",
      "epoch 5 batch id 151501 / 225000 loss 2.7826144695281982 train acc 0.8078214005188085\n",
      "epoch 5 batch id 151601 / 225000 loss 0.014507931657135487 train acc 0.8077931543987177\n",
      "epoch 5 batch id 151701 / 225000 loss 0.8733860850334167 train acc 0.8077913131752592\n",
      "epoch 5 batch id 151801 / 225000 loss 1.339905858039856 train acc 0.8077631240900917\n",
      "epoch 5 batch id 151901 / 225000 loss 2.4879367351531982 train acc 0.807743201163916\n",
      "epoch 5 batch id 152001 / 225000 loss 0.8204957246780396 train acc 0.8077413964381813\n",
      "epoch 5 batch id 152101 / 225000 loss 1.0304893255233765 train acc 0.8077198703493074\n",
      "epoch 5 batch id 152201 / 225000 loss 0.9271801114082336 train acc 0.8077147981944928\n",
      "epoch 5 batch id 152301 / 225000 loss 1.2572977542877197 train acc 0.8076916763514357\n",
      "epoch 5 batch id 152401 / 225000 loss 0.005147422663867474 train acc 0.8076948313987441\n",
      "epoch 5 batch id 152501 / 225000 loss 0.006536898203194141 train acc 0.8077110969764133\n",
      "epoch 5 batch id 152601 / 225000 loss 0.0007675732485949993 train acc 0.8076962143105222\n",
      "epoch 5 batch id 152701 / 225000 loss 0.08504500240087509 train acc 0.8077108204923347\n",
      "epoch 5 batch id 152801 / 225000 loss 0.539036750793457 train acc 0.8077286797861271\n",
      "epoch 5 batch id 152901 / 225000 loss 1.4794460535049438 train acc 0.807743245629525\n",
      "epoch 5 batch id 153001 / 225000 loss 1.21432363986969 train acc 0.8077577924327292\n",
      "epoch 5 batch id 153101 / 225000 loss 0.25629353523254395 train acc 0.8077510924161174\n",
      "epoch 5 batch id 153201 / 225000 loss 1.117365837097168 train acc 0.8077329782442674\n",
      "epoch 5 batch id 153301 / 225000 loss 1.3867976665496826 train acc 0.8077279339338947\n",
      "epoch 5 batch id 153401 / 225000 loss 0.009867745451629162 train acc 0.8077310447780653\n",
      "epoch 5 batch id 153501 / 225000 loss 0.004287062678486109 train acc 0.8077341515690452\n",
      "epoch 5 batch id 153601 / 225000 loss 0.2723188102245331 train acc 0.8077356267211802\n",
      "epoch 5 batch id 153701 / 225000 loss 0.003085726173594594 train acc 0.8077517387655253\n",
      "epoch 5 batch id 153801 / 225000 loss 0.007683995645493269 train acc 0.8077662043809858\n",
      "epoch 5 batch id 153901 / 225000 loss 0.06425611674785614 train acc 0.8077676558306963\n",
      "epoch 5 batch id 154001 / 225000 loss 0.052659545093774796 train acc 0.8077707287615016\n",
      "epoch 5 batch id 154101 / 225000 loss 0.0422455370426178 train acc 0.8077737977041032\n",
      "epoch 5 batch id 154201 / 225000 loss 2.0274224281311035 train acc 0.8077930752718854\n",
      "epoch 5 batch id 154301 / 225000 loss 0.0019092692527920008 train acc 0.807813948062553\n",
      "epoch 5 batch id 154401 / 225000 loss 0.3098991811275482 train acc 0.807797553124656\n",
      "epoch 5 batch id 154501 / 225000 loss 0.11518773436546326 train acc 0.8078038329848998\n",
      "epoch 5 batch id 154601 / 225000 loss 1.9758158922195435 train acc 0.8078165729846508\n",
      "epoch 5 batch id 154701 / 225000 loss 0.011471625417470932 train acc 0.8077888959993794\n",
      "epoch 5 batch id 154801 / 225000 loss 0.0015484291361644864 train acc 0.8077903243519099\n",
      "epoch 5 batch id 154901 / 225000 loss 0.31620851159095764 train acc 0.807780453321799\n",
      "epoch 5 batch id 155001 / 225000 loss 1.5940550565719604 train acc 0.8077867239566197\n",
      "epoch 5 batch id 155101 / 225000 loss 1.5481531620025635 train acc 0.8077881509468025\n",
      "epoch 5 batch id 155201 / 225000 loss 0.0013295897515490651 train acc 0.8078040734273619\n",
      "epoch 5 batch id 155301 / 225000 loss 1.576456904411316 train acc 0.8077974385226109\n",
      "epoch 5 batch id 155401 / 225000 loss 0.00345283723436296 train acc 0.8078004646044749\n",
      "epoch 5 batch id 155501 / 225000 loss 0.1323985606431961 train acc 0.8078002713808914\n",
      "epoch 5 batch id 155601 / 225000 loss 0.8209706544876099 train acc 0.8077968650587078\n",
      "epoch 5 batch id 155701 / 225000 loss 2.4990150928497314 train acc 0.8077950687535725\n",
      "epoch 5 batch id 155801 / 225000 loss 1.9321234226226807 train acc 0.8077948793653442\n",
      "epoch 5 batch id 155901 / 225000 loss 2.1328554153442383 train acc 0.8078075188741574\n",
      "epoch 5 batch id 156001 / 225000 loss 1.2369887828826904 train acc 0.8078089243017673\n",
      "epoch 5 batch id 156101 / 225000 loss 0.007738066837191582 train acc 0.8077879065476838\n",
      "epoch 5 batch id 156201 / 225000 loss 1.4158523082733154 train acc 0.8077877222296912\n",
      "epoch 5 batch id 156301 / 225000 loss 1.2037169933319092 train acc 0.8077987344930615\n",
      "epoch 5 batch id 156401 / 225000 loss 0.0014845519326627254 train acc 0.807795346577068\n",
      "epoch 5 batch id 156501 / 225000 loss 0.44808289408683777 train acc 0.8077823783873586\n",
      "epoch 5 batch id 156601 / 225000 loss 0.1294543296098709 train acc 0.807796565794599\n",
      "epoch 5 batch id 156701 / 225000 loss 0.0009343494893983006 train acc 0.8078091396991723\n",
      "epoch 5 batch id 156801 / 225000 loss 0.9901021718978882 train acc 0.807824886320878\n",
      "epoch 5 batch id 156901 / 225000 loss 1.5023249387741089 train acc 0.8078262726177653\n",
      "epoch 5 batch id 157001 / 225000 loss 0.7835125923156738 train acc 0.8078181030694072\n",
      "epoch 5 batch id 157101 / 225000 loss 0.0025343596935272217 train acc 0.8078274485840319\n",
      "epoch 5 batch id 157201 / 225000 loss 0.0029594851657748222 train acc 0.8078606370188485\n",
      "epoch 5 batch id 157301 / 225000 loss 0.0031139247585088015 train acc 0.8078651756822907\n",
      "epoch 5 batch id 157401 / 225000 loss 0.0024429629556834698 train acc 0.8078744734785674\n",
      "epoch 5 batch id 157501 / 225000 loss 1.462885856628418 train acc 0.8078885213427216\n",
      "epoch 5 batch id 157601 / 225000 loss 0.05566263943910599 train acc 0.8078739982614324\n",
      "epoch 5 batch id 157701 / 225000 loss 2.9875411987304688 train acc 0.8078563230417055\n",
      "epoch 5 batch id 157801 / 225000 loss 0.002657847246155143 train acc 0.8078671871534401\n",
      "epoch 5 batch id 157901 / 225000 loss 3.0689697265625 train acc 0.8078717044223912\n",
      "epoch 5 batch id 158001 / 225000 loss 1.4465382099151611 train acc 0.8078952031949165\n",
      "epoch 5 batch id 158101 / 225000 loss 0.36032575368881226 train acc 0.8078996970291143\n",
      "epoch 5 batch id 158201 / 225000 loss 1.3443082571029663 train acc 0.8078962838414422\n",
      "epoch 5 batch id 158301 / 225000 loss 0.7518454194068909 train acc 0.8079070883948932\n",
      "epoch 5 batch id 158401 / 225000 loss 0.003603826742619276 train acc 0.8079131444877242\n",
      "epoch 5 batch id 158501 / 225000 loss 1.166395664215088 train acc 0.8079255020473057\n",
      "epoch 5 batch id 158601 / 225000 loss 0.004040773957967758 train acc 0.8079126235017434\n",
      "epoch 5 batch id 158701 / 225000 loss 2.0824902057647705 train acc 0.8079170893693172\n",
      "epoch 5 batch id 158801 / 225000 loss 0.006946767680346966 train acc 0.8079309953967544\n",
      "epoch 5 batch id 158901 / 225000 loss 0.006001030560582876 train acc 0.8079354440815351\n",
      "epoch 5 batch id 159001 / 225000 loss 0.0005155866383574903 train acc 0.8079225916818134\n",
      "epoch 5 batch id 159101 / 225000 loss 0.0020575157832354307 train acc 0.807912898096178\n",
      "epoch 5 batch id 159201 / 225000 loss 2.500274181365967 train acc 0.8079236311329703\n",
      "epoch 5 batch id 159301 / 225000 loss 0.0022225198335945606 train acc 0.8079249345578496\n",
      "epoch 5 batch id 159401 / 225000 loss 0.9428908824920654 train acc 0.8079309414620988\n",
      "epoch 5 batch id 159501 / 225000 loss 0.002814594656229019 train acc 0.8079338060576423\n",
      "epoch 5 batch id 159601 / 225000 loss 1.1931804418563843 train acc 0.8079178701887832\n",
      "epoch 5 batch id 159701 / 225000 loss 1.3900107145309448 train acc 0.8079332627848291\n",
      "epoch 5 batch id 159801 / 225000 loss 1.3257009983062744 train acc 0.8079298627668162\n",
      "epoch 5 batch id 159901 / 225000 loss 0.0005694138235412538 train acc 0.8079374112732253\n",
      "epoch 5 batch id 160001 / 225000 loss 0.9482791423797607 train acc 0.807954325285467\n",
      "epoch 5 batch id 160101 / 225000 loss 1.1405354738235474 train acc 0.8079587260541783\n",
      "epoch 5 batch id 160201 / 225000 loss 0.5462942719459534 train acc 0.8079693634871193\n",
      "epoch 5 batch id 160301 / 225000 loss 0.004051344469189644 train acc 0.807958153723308\n",
      "epoch 5 batch id 160401 / 225000 loss 3.1021571159362793 train acc 0.807959426686866\n",
      "epoch 5 batch id 160501 / 225000 loss 1.3959218263626099 train acc 0.8079529099507168\n",
      "epoch 5 batch id 160601 / 225000 loss 0.17411859333515167 train acc 0.8079681944695238\n",
      "epoch 5 batch id 160701 / 225000 loss 0.0015426254831254482 train acc 0.8079881270185002\n",
      "epoch 5 batch id 160801 / 225000 loss 0.00588300172239542 train acc 0.807998706475706\n",
      "epoch 5 batch id 160901 / 225000 loss 0.007369541097432375 train acc 0.8080108265330855\n",
      "epoch 5 batch id 161001 / 225000 loss 0.020774899050593376 train acc 0.8080182731784274\n",
      "epoch 5 batch id 161101 / 225000 loss 0.2317742556333542 train acc 0.8080024332561561\n",
      "epoch 5 batch id 161201 / 225000 loss 0.12040989845991135 train acc 0.8080191810224502\n",
      "epoch 5 batch id 161301 / 225000 loss 1.1202808618545532 train acc 0.8080343581254921\n",
      "epoch 5 batch id 161401 / 225000 loss 0.9267118573188782 train acc 0.8080340270506379\n",
      "epoch 5 batch id 161501 / 225000 loss 1.52871835231781 train acc 0.8080569160562473\n",
      "epoch 5 batch id 161601 / 225000 loss 0.049297552555799484 train acc 0.8080550244119776\n",
      "epoch 5 batch id 161701 / 225000 loss 2.8223657608032227 train acc 0.8080546811708029\n",
      "epoch 5 batch id 161801 / 225000 loss 1.0145314931869507 train acc 0.8080481579223862\n",
      "epoch 5 batch id 161901 / 225000 loss 0.9407302737236023 train acc 0.8080416427322871\n",
      "epoch 5 batch id 162001 / 225000 loss 1.1035841703414917 train acc 0.8080644563922444\n",
      "epoch 5 batch id 162101 / 225000 loss 3.6602845191955566 train acc 0.808044058950901\n",
      "epoch 5 batch id 162201 / 225000 loss 0.9040076732635498 train acc 0.8080329344455336\n",
      "epoch 5 batch id 162301 / 225000 loss 0.02967068925499916 train acc 0.8080387674752466\n",
      "epoch 5 batch id 162401 / 225000 loss 0.012973551638424397 train acc 0.80803689632453\n",
      "epoch 5 batch id 162501 / 225000 loss 0.002635921584442258 train acc 0.808036565928825\n",
      "epoch 5 batch id 162601 / 225000 loss 0.0008042914560064673 train acc 0.8080531485046217\n",
      "epoch 5 batch id 162701 / 225000 loss 0.005698569118976593 train acc 0.808054345087\n",
      "epoch 5 batch id 162801 / 225000 loss 0.7799580693244934 train acc 0.8080325059428382\n",
      "epoch 5 batch id 162901 / 225000 loss 3.0174083709716797 train acc 0.8080536644956139\n",
      "epoch 5 batch id 163001 / 225000 loss 0.9995381832122803 train acc 0.8080456561616186\n",
      "epoch 5 batch id 163101 / 225000 loss 0.8262260556221008 train acc 0.8080529855733564\n",
      "epoch 5 batch id 163201 / 225000 loss 0.011339101009070873 train acc 0.8080449874694395\n",
      "epoch 5 batch id 163301 / 225000 loss 0.030814770609140396 train acc 0.808064555636524\n",
      "epoch 5 batch id 163401 / 225000 loss 0.005989575292915106 train acc 0.8080519703061793\n",
      "epoch 5 batch id 163501 / 225000 loss 0.20454184710979462 train acc 0.808056219839634\n",
      "epoch 5 batch id 163601 / 225000 loss 1.3485801219940186 train acc 0.8080528236379974\n",
      "epoch 5 batch id 163701 / 225000 loss 0.804313063621521 train acc 0.8080433228874595\n",
      "epoch 5 batch id 163801 / 225000 loss 0.12197667360305786 train acc 0.8080323074950703\n",
      "epoch 5 batch id 163901 / 225000 loss 0.3144119679927826 train acc 0.8080457105203751\n",
      "epoch 5 batch id 164001 / 225000 loss 0.005063924472779036 train acc 0.8080590972006269\n",
      "epoch 5 batch id 164101 / 225000 loss 0.0046393731608986855 train acc 0.8080602799495432\n",
      "epoch 5 batch id 164201 / 225000 loss 0.015541606582701206 train acc 0.8080675513547421\n",
      "epoch 5 batch id 164301 / 225000 loss 0.009818373247981071 train acc 0.8080809002988417\n",
      "epoch 5 batch id 164401 / 225000 loss 0.0008923758869059384 train acc 0.8080775056112798\n",
      "epoch 5 batch id 164501 / 225000 loss 0.007257858756929636 train acc 0.8080877927793751\n",
      "epoch 5 batch id 164601 / 225000 loss 1.1878033876419067 train acc 0.8080874356777905\n",
      "epoch 5 batch id 164701 / 225000 loss 0.0024770682211965322 train acc 0.8080627925756371\n",
      "epoch 5 batch id 164801 / 225000 loss 0.7730928659439087 train acc 0.8080700359827914\n",
      "epoch 5 batch id 164901 / 225000 loss 0.010152907110750675 train acc 0.8080863669716982\n",
      "epoch 5 batch id 165001 / 225000 loss 0.8749170303344727 train acc 0.8080996478809219\n",
      "epoch 5 batch id 165101 / 225000 loss 0.0045801326632499695 train acc 0.8080917135571559\n",
      "epoch 5 batch id 165201 / 225000 loss 0.7533319592475891 train acc 0.8080913553792047\n",
      "epoch 5 batch id 165301 / 225000 loss 0.9832914471626282 train acc 0.8080925100271625\n",
      "epoch 5 batch id 165401 / 225000 loss 0.7127524614334106 train acc 0.8080921518007751\n",
      "epoch 5 batch id 165501 / 225000 loss 1.7512747049331665 train acc 0.8080978362668504\n",
      "epoch 5 batch id 165601 / 225000 loss 0.8891342282295227 train acc 0.8081050235203894\n",
      "epoch 5 batch id 165701 / 225000 loss 0.004018987528979778 train acc 0.8081348332236981\n",
      "epoch 5 batch id 165801 / 225000 loss 2.6584620475769043 train acc 0.8081450051567843\n",
      "epoch 5 batch id 165901 / 225000 loss 2.3430893421173096 train acc 0.8081446163675927\n",
      "epoch 5 batch id 166001 / 225000 loss 0.03008892945945263 train acc 0.8081773603773471\n",
      "epoch 5 batch id 166101 / 225000 loss 0.8948603868484497 train acc 0.8081859832270727\n",
      "epoch 5 batch id 166201 / 225000 loss 0.7100588083267212 train acc 0.8081825620784472\n",
      "epoch 5 batch id 166301 / 225000 loss 1.3811527490615845 train acc 0.8081866615354086\n",
      "epoch 5 batch id 166401 / 225000 loss 0.007211758755147457 train acc 0.8081907560651679\n",
      "epoch 5 batch id 166501 / 225000 loss 0.3312387466430664 train acc 0.8082068576164708\n",
      "epoch 5 batch id 166601 / 225000 loss 1.3026200532913208 train acc 0.8082169374733645\n",
      "epoch 5 batch id 166701 / 225000 loss 0.003453536657616496 train acc 0.8082240058547939\n",
      "epoch 5 batch id 166801 / 225000 loss 2.7223567962646484 train acc 0.8082280681770493\n",
      "epoch 5 batch id 166901 / 225000 loss 2.2599384784698486 train acc 0.8082171466917514\n",
      "epoch 5 batch id 167001 / 225000 loss 0.08375516533851624 train acc 0.808222705253262\n",
      "epoch 5 batch id 167101 / 225000 loss 0.2961077392101288 train acc 0.80824321817344\n",
      "epoch 5 batch id 167201 / 225000 loss 0.7438879013061523 train acc 0.808256230524937\n",
      "epoch 5 batch id 167301 / 225000 loss 0.6521801948547363 train acc 0.8082393410678956\n",
      "epoch 5 batch id 167401 / 225000 loss 1.2477408647537231 train acc 0.8082284454692624\n",
      "epoch 5 batch id 167501 / 225000 loss 2.062927484512329 train acc 0.8082280105790414\n",
      "epoch 5 batch id 167601 / 225000 loss 0.009436925873160362 train acc 0.8082275762077792\n",
      "epoch 5 batch id 167701 / 225000 loss 1.8349891901016235 train acc 0.8082211793608863\n",
      "epoch 5 batch id 167801 / 225000 loss 0.5082600116729736 train acc 0.8082267090184206\n",
      "epoch 5 batch id 167901 / 225000 loss 1.7407716512680054 train acc 0.8082203203078004\n",
      "epoch 5 batch id 168001 / 225000 loss 0.0033962782472372055 train acc 0.8082243558074059\n",
      "epoch 5 batch id 168101 / 225000 loss 0.22169703245162964 train acc 0.8082283865057317\n",
      "epoch 5 batch id 168201 / 225000 loss 0.020569251850247383 train acc 0.8082338987283072\n",
      "epoch 5 batch id 168301 / 225000 loss 0.941641092300415 train acc 0.8082349480989418\n",
      "epoch 5 batch id 168401 / 225000 loss 1.4142862558364868 train acc 0.8082359962233003\n",
      "epoch 5 batch id 168501 / 225000 loss 0.01616097427904606 train acc 0.8082385267743218\n",
      "epoch 5 batch id 168601 / 225000 loss 1.2203644514083862 train acc 0.8082173296718288\n",
      "epoch 5 batch id 168701 / 225000 loss 0.6717080473899841 train acc 0.8082020853462635\n",
      "epoch 5 batch id 168801 / 225000 loss 1.8107479810714722 train acc 0.8082120366585506\n",
      "epoch 5 batch id 168901 / 225000 loss 0.10379809141159058 train acc 0.8082471388564899\n",
      "epoch 5 batch id 169001 / 225000 loss 0.7767695784568787 train acc 0.8082614895769847\n",
      "epoch 5 batch id 169101 / 225000 loss 2.8212671279907227 train acc 0.8082684312925411\n",
      "epoch 5 batch id 169201 / 225000 loss 0.5410313010215759 train acc 0.8082768423354472\n",
      "epoch 5 batch id 169301 / 225000 loss 0.0017194068059325218 train acc 0.8082926267417204\n",
      "epoch 5 batch id 169401 / 225000 loss 3.081686496734619 train acc 0.8082744493834156\n",
      "epoch 5 batch id 169501 / 225000 loss 0.061617136001586914 train acc 0.8082695677311639\n",
      "epoch 5 batch id 169601 / 225000 loss 1.1207671165466309 train acc 0.808276484218843\n",
      "epoch 5 batch id 169701 / 225000 loss 0.006832343526184559 train acc 0.8082907584516297\n",
      "epoch 5 batch id 169801 / 225000 loss 1.6840312480926514 train acc 0.808300598936402\n",
      "epoch 5 batch id 169901 / 225000 loss 1.4602129459381104 train acc 0.8083060135019806\n",
      "epoch 5 batch id 170001 / 225000 loss 5.4454450607299805 train acc 0.8083055393791801\n",
      "epoch 5 batch id 170101 / 225000 loss 3.8069307804107666 train acc 0.8083168235342532\n",
      "epoch 5 batch id 170201 / 225000 loss 2.225001811981201 train acc 0.8083163436172526\n",
      "epoch 5 batch id 170301 / 225000 loss 1.5589419603347778 train acc 0.8083261401870805\n",
      "epoch 5 batch id 170401 / 225000 loss 0.006046810187399387 train acc 0.8083344581311143\n",
      "epoch 5 batch id 170501 / 225000 loss 0.6002444624900818 train acc 0.8083398337839661\n",
      "epoch 5 batch id 170601 / 225000 loss 0.003372807987034321 train acc 0.8083349452816806\n",
      "epoch 5 batch id 170701 / 225000 loss 1.2420779466629028 train acc 0.8083447079981957\n",
      "epoch 5 batch id 170801 / 225000 loss 0.0013973905006423593 train acc 0.8083398223663796\n",
      "epoch 5 batch id 170901 / 225000 loss 0.00762896379455924 train acc 0.8083451822985237\n",
      "epoch 5 batch id 171001 / 225000 loss 0.0034095279406756163 train acc 0.8083490739820235\n",
      "epoch 5 batch id 171101 / 225000 loss 0.20812909305095673 train acc 0.8083588056177345\n",
      "epoch 5 batch id 171201 / 225000 loss 2.519090175628662 train acc 0.8083772875158439\n",
      "epoch 5 batch id 171301 / 225000 loss 1.176687479019165 train acc 0.808395747835681\n",
      "epoch 5 batch id 171401 / 225000 loss 0.8551983833312988 train acc 0.8083791809849418\n",
      "epoch 5 batch id 171501 / 225000 loss 0.00519581139087677 train acc 0.8083888723680911\n",
      "epoch 5 batch id 171601 / 225000 loss 4.071075439453125 train acc 0.8083781563044504\n",
      "epoch 5 batch id 171701 / 225000 loss 1.1847131252288818 train acc 0.8083951170930862\n",
      "epoch 5 batch id 171801 / 225000 loss 2.2084739208221436 train acc 0.8083902305574473\n",
      "epoch 5 batch id 171901 / 225000 loss 0.41554760932922363 train acc 0.8084086189143751\n",
      "epoch 5 batch id 172001 / 225000 loss 0.004835115745663643 train acc 0.8084255324096953\n",
      "epoch 5 batch id 172101 / 225000 loss 2.527395725250244 train acc 0.8084249946252491\n",
      "epoch 5 batch id 172201 / 225000 loss 0.01688060723245144 train acc 0.8084346200080139\n",
      "epoch 5 batch id 172301 / 225000 loss 0.1325743943452835 train acc 0.8084239209290718\n",
      "epoch 5 batch id 172401 / 225000 loss 0.5071007609367371 train acc 0.8084248351227661\n",
      "epoch 5 batch id 172501 / 225000 loss 0.03241496533155441 train acc 0.8084460379939826\n",
      "epoch 5 batch id 172601 / 225000 loss 2.400372266769409 train acc 0.8084541804508665\n",
      "epoch 5 batch id 172701 / 225000 loss 0.04037398099899292 train acc 0.8084666562440287\n",
      "epoch 5 batch id 172801 / 225000 loss 0.005342637188732624 train acc 0.8084458423273013\n",
      "epoch 5 batch id 172901 / 225000 loss 1.1577653884887695 train acc 0.8084496330269924\n",
      "epoch 5 batch id 173001 / 225000 loss 1.4952788352966309 train acc 0.8084577545794533\n",
      "epoch 5 batch id 173101 / 225000 loss 0.0034172700252383947 train acc 0.8084470915823709\n",
      "epoch 5 batch id 173201 / 225000 loss 0.003034187015146017 train acc 0.808450874994948\n",
      "epoch 5 batch id 173301 / 225000 loss 0.0030225885566323996 train acc 0.8084589817715997\n",
      "epoch 5 batch id 173401 / 225000 loss 0.7879874110221863 train acc 0.8084339190662106\n",
      "epoch 5 batch id 173501 / 225000 loss 1.313387393951416 train acc 0.8084261762180045\n",
      "epoch 5 batch id 173601 / 225000 loss 1.5092402696609497 train acc 0.8084270827933019\n",
      "epoch 5 batch id 173701 / 225000 loss 0.09720811992883682 train acc 0.8084179135410849\n",
      "epoch 5 batch id 173801 / 225000 loss 1.4351861476898193 train acc 0.8083943705732418\n",
      "epoch 5 batch id 173901 / 225000 loss 0.03879322484135628 train acc 0.808393856274547\n",
      "epoch 5 batch id 174001 / 225000 loss 0.15927086770534515 train acc 0.8083847219268855\n",
      "epoch 5 batch id 174101 / 225000 loss 1.3827849626541138 train acc 0.8083813418647796\n",
      "epoch 5 batch id 174201 / 225000 loss 1.8216373920440674 train acc 0.8083908817974639\n",
      "epoch 5 batch id 174301 / 225000 loss 0.19147910177707672 train acc 0.8084176223888561\n",
      "epoch 5 batch id 174401 / 225000 loss 2.3644299507141113 train acc 0.8084242636223417\n",
      "epoch 5 batch id 174501 / 225000 loss 0.13663902878761292 train acc 0.8084280319310491\n",
      "epoch 5 batch id 174601 / 225000 loss 1.2556785345077515 train acc 0.8084103183830562\n",
      "epoch 5 batch id 174701 / 225000 loss 1.1517839431762695 train acc 0.8084212454422127\n",
      "epoch 5 batch id 174801 / 225000 loss 0.6239388585090637 train acc 0.8084292996035491\n",
      "epoch 5 batch id 174901 / 225000 loss 1.7815111875534058 train acc 0.808428768274624\n",
      "epoch 5 batch id 175001 / 225000 loss 1.0045437812805176 train acc 0.8084239518631322\n",
      "epoch 5 batch id 175101 / 225000 loss 0.7175192832946777 train acc 0.808412002215864\n",
      "epoch 5 batch id 175201 / 225000 loss 0.755920946598053 train acc 0.8084014931421625\n",
      "epoch 5 batch id 175301 / 225000 loss 0.7024060487747192 train acc 0.8084066833617606\n",
      "epoch 5 batch id 175401 / 225000 loss 0.012585826218128204 train acc 0.8084018905251396\n",
      "epoch 5 batch id 175501 / 225000 loss 0.003161274828016758 train acc 0.8084013766303326\n",
      "epoch 5 batch id 175601 / 225000 loss 0.7933725714683533 train acc 0.8084108290955063\n",
      "epoch 5 batch id 175701 / 225000 loss 1.5524901151657104 train acc 0.8083975048519929\n",
      "epoch 5 batch id 175801 / 225000 loss 0.05483292043209076 train acc 0.8084126370157166\n",
      "epoch 5 batch id 175901 / 225000 loss 0.0006574159488081932 train acc 0.808434858244126\n",
      "epoch 5 batch id 176001 / 225000 loss 0.7435805201530457 train acc 0.8084357475241618\n",
      "epoch 5 batch id 176101 / 225000 loss 0.0018854279769584537 train acc 0.8084565107523524\n",
      "epoch 5 batch id 176201 / 225000 loss 1.4183979034423828 train acc 0.8084630620711574\n",
      "epoch 5 batch id 176301 / 225000 loss 0.871862530708313 train acc 0.808475278075564\n",
      "epoch 5 batch id 176401 / 225000 loss 2.0683038234710693 train acc 0.8084662218468149\n",
      "epoch 5 batch id 176501 / 225000 loss 0.3391316533088684 train acc 0.8084656744154424\n",
      "epoch 5 batch id 176601 / 225000 loss 1.6340278387069702 train acc 0.8084722057066495\n",
      "epoch 5 batch id 176701 / 225000 loss 0.11069438606500626 train acc 0.8084702406890736\n",
      "epoch 5 batch id 176801 / 225000 loss 0.004320137668401003 train acc 0.8084838321050221\n",
      "epoch 5 batch id 176901 / 225000 loss 3.571159839630127 train acc 0.8084649040989028\n",
      "epoch 5 batch id 177001 / 225000 loss 3.725269317626953 train acc 0.8084629465370252\n",
      "epoch 5 batch id 177101 / 225000 loss 2.047872543334961 train acc 0.8084482865709397\n",
      "epoch 5 batch id 177201 / 225000 loss 0.0007295231334865093 train acc 0.8084322323237454\n",
      "epoch 5 batch id 177301 / 225000 loss 0.9707993865013123 train acc 0.8084401667221279\n",
      "epoch 5 batch id 177401 / 225000 loss 0.5569832921028137 train acc 0.8084452737019521\n",
      "epoch 5 batch id 177501 / 225000 loss 0.07930003851652145 train acc 0.8084391073853106\n",
      "epoch 5 batch id 177601 / 225000 loss 0.13342584669589996 train acc 0.8084399862613386\n",
      "epoch 5 batch id 177701 / 225000 loss 0.0023538260720670223 train acc 0.8084380504330307\n",
      "epoch 5 batch id 177801 / 225000 loss 0.8184340596199036 train acc 0.8084501774455711\n",
      "epoch 5 batch id 177901 / 225000 loss 0.0004369823436718434 train acc 0.8084440222370869\n",
      "epoch 5 batch id 178001 / 225000 loss 1.5296190977096558 train acc 0.8084477053499699\n",
      "epoch 5 batch id 178101 / 225000 loss 0.004736961796879768 train acc 0.8084373473478532\n",
      "epoch 5 batch id 178201 / 225000 loss 0.08536841720342636 train acc 0.8084466417135706\n",
      "epoch 5 batch id 178301 / 225000 loss 3.9429574012756348 train acc 0.808464338394064\n",
      "epoch 5 batch id 178401 / 225000 loss 0.8918155431747437 train acc 0.8084764098855948\n",
      "epoch 5 batch id 178501 / 225000 loss 0.0022819016594439745 train acc 0.8084842661945871\n",
      "epoch 5 batch id 178601 / 225000 loss 0.003014485351741314 train acc 0.8084935134741686\n",
      "epoch 5 batch id 178701 / 225000 loss 0.0058004483580589294 train acc 0.808511144313686\n",
      "epoch 5 batch id 178801 / 225000 loss 1.4007632732391357 train acc 0.8085259590270748\n",
      "epoch 5 batch id 178901 / 225000 loss 1.6072919368743896 train acc 0.8085379623367114\n",
      "epoch 5 batch id 179001 / 225000 loss 0.0033135178964585066 train acc 0.808527605991028\n",
      "epoch 5 batch id 179101 / 225000 loss 0.8188311457633972 train acc 0.8085172612101552\n",
      "epoch 5 batch id 179201 / 225000 loss 2.2481820583343506 train acc 0.808512508300735\n",
      "epoch 5 batch id 179301 / 225000 loss 0.0003906836500391364 train acc 0.808495211962008\n",
      "epoch 5 batch id 179401 / 225000 loss 1.62306809425354 train acc 0.808479328431837\n",
      "epoch 5 batch id 179501 / 225000 loss 0.0026642675511538982 train acc 0.8084746045983031\n",
      "epoch 5 batch id 179601 / 225000 loss 0.856065034866333 train acc 0.8084712779995658\n",
      "epoch 5 batch id 179701 / 225000 loss 2.996443748474121 train acc 0.8084721287026784\n",
      "epoch 5 batch id 179801 / 225000 loss 1.6277402639389038 train acc 0.8084868827203409\n",
      "epoch 5 batch id 179901 / 225000 loss 0.009207946248352528 train acc 0.808491892763242\n",
      "epoch 5 batch id 180001 / 225000 loss 2.552734136581421 train acc 0.8084899528335954\n",
      "epoch 5 batch id 180101 / 225000 loss 0.1239171177148819 train acc 0.8085018961582667\n",
      "epoch 5 batch id 180201 / 225000 loss 0.008499367162585258 train acc 0.8085082768686078\n",
      "epoch 5 batch id 180301 / 225000 loss 0.7771240472793579 train acc 0.8085257430629891\n",
      "epoch 5 batch id 180401 / 225000 loss 2.6331381797790527 train acc 0.8085113164561172\n",
      "epoch 5 batch id 180501 / 225000 loss 0.0017891207244247198 train acc 0.808491365698805\n",
      "epoch 5 batch id 180601 / 225000 loss 0.013240602798759937 train acc 0.8085115807775151\n",
      "epoch 5 batch id 180701 / 225000 loss 0.0010235215304419398 train acc 0.8084861179517545\n",
      "epoch 5 batch id 180801 / 225000 loss 0.7936205267906189 train acc 0.8084911034784099\n",
      "epoch 5 batch id 180901 / 225000 loss 0.11087831854820251 train acc 0.8085181950348533\n",
      "epoch 5 batch id 181001 / 225000 loss 1.4302160739898682 train acc 0.8085079640443975\n",
      "epoch 5 batch id 181101 / 225000 loss 0.049830734729766846 train acc 0.8085143096945903\n",
      "epoch 5 batch id 181201 / 225000 loss 0.018286386504769325 train acc 0.8085137499241174\n",
      "epoch 5 batch id 181301 / 225000 loss 1.2617137432098389 train acc 0.8085173275381824\n",
      "epoch 5 batch id 181401 / 225000 loss 0.25017794966697693 train acc 0.8085401954785255\n",
      "epoch 5 batch id 181501 / 225000 loss 0.14792490005493164 train acc 0.8085423771769853\n",
      "epoch 5 batch id 181601 / 225000 loss 2.1005589962005615 train acc 0.8085307900286892\n",
      "epoch 5 batch id 181701 / 225000 loss 1.1332504749298096 train acc 0.8085398539358617\n",
      "epoch 5 batch id 181801 / 225000 loss 0.022606076672673225 train acc 0.8085324063123965\n",
      "epoch 5 batch id 181901 / 225000 loss 1.5556457042694092 train acc 0.8085400849912865\n",
      "epoch 5 batch id 182001 / 225000 loss 1.0905660390853882 train acc 0.8085559969450717\n",
      "epoch 5 batch id 182101 / 225000 loss 1.325735330581665 train acc 0.8085567899132898\n",
      "epoch 5 batch id 182201 / 225000 loss 1.0014156103134155 train acc 0.8085562099000554\n",
      "epoch 5 batch id 182301 / 225000 loss 0.0005959629779681563 train acc 0.8085556305231458\n",
      "epoch 5 batch id 182401 / 225000 loss 0.028321165591478348 train acc 0.8085646460271599\n",
      "epoch 5 batch id 182501 / 225000 loss 0.08916443586349487 train acc 0.8085681722291933\n",
      "epoch 5 batch id 182601 / 225000 loss 0.994015634059906 train acc 0.8085744327796671\n",
      "epoch 5 batch id 182701 / 225000 loss 3.5137712955474854 train acc 0.8085546877138056\n",
      "epoch 5 batch id 182801 / 225000 loss 3.395524024963379 train acc 0.8085623163987068\n",
      "epoch 5 batch id 182901 / 225000 loss 0.09775061160326004 train acc 0.8085562681450621\n",
      "epoch 5 batch id 183001 / 225000 loss 0.9603109955787659 train acc 0.8085488603887411\n",
      "epoch 5 batch id 183101 / 225000 loss 0.008274360559880733 train acc 0.8085578451237295\n",
      "epoch 5 batch id 183201 / 225000 loss 0.8587437868118286 train acc 0.8085709139142253\n",
      "epoch 5 batch id 183301 / 225000 loss 2.6645326614379883 train acc 0.8085676019225209\n",
      "epoch 5 batch id 183401 / 225000 loss 2.4027562141418457 train acc 0.8085642935425652\n",
      "epoch 5 batch id 183501 / 225000 loss 0.009296242147684097 train acc 0.8085746126724105\n",
      "epoch 5 batch id 183601 / 225000 loss 2.1778922080993652 train acc 0.8085808356163637\n",
      "epoch 5 batch id 183701 / 225000 loss 1.0589447021484375 train acc 0.8085884126923643\n",
      "epoch 5 batch id 183801 / 225000 loss 0.0026857079938054085 train acc 0.8086000620236016\n",
      "epoch 5 batch id 183901 / 225000 loss 0.0008659169543534517 train acc 0.8086035421232076\n",
      "epoch 5 batch id 184001 / 225000 loss 1.737119197845459 train acc 0.8086043010635812\n",
      "epoch 5 batch id 184101 / 225000 loss 0.03090169094502926 train acc 0.8086009853287054\n",
      "epoch 5 batch id 184201 / 225000 loss 0.0021448449697345495 train acc 0.8086003876200455\n",
      "epoch 5 batch id 184301 / 225000 loss 1.1689517498016357 train acc 0.8085780869338745\n",
      "epoch 5 batch id 184401 / 225000 loss 1.872183084487915 train acc 0.8085625891399721\n",
      "epoch 5 batch id 184501 / 225000 loss 1.3652459383010864 train acc 0.8085606582078146\n",
      "epoch 5 batch id 184601 / 225000 loss 0.03472872078418732 train acc 0.8085668550007855\n",
      "epoch 5 batch id 184701 / 225000 loss 0.0009161190828308463 train acc 0.808564923849898\n",
      "epoch 5 batch id 184801 / 225000 loss 0.19644425809383392 train acc 0.8085765228543136\n",
      "epoch 5 batch id 184901 / 225000 loss 0.897454023361206 train acc 0.8085786447882921\n",
      "epoch 5 batch id 185001 / 225000 loss 0.00109112320933491 train acc 0.8085875211485344\n",
      "epoch 5 batch id 185101 / 225000 loss 3.9280457496643066 train acc 0.8085923360759801\n",
      "epoch 5 batch id 185201 / 225000 loss 0.1488913893699646 train acc 0.8086038952273475\n",
      "epoch 5 batch id 185301 / 225000 loss 1.9136602878570557 train acc 0.8086167910588717\n",
      "epoch 5 batch id 185401 / 225000 loss 0.8324863910675049 train acc 0.8086134918366136\n",
      "epoch 5 batch id 185501 / 225000 loss 0.606760561466217 train acc 0.8085953714535231\n",
      "epoch 5 batch id 185601 / 225000 loss 0.3430114984512329 train acc 0.8086109449841327\n",
      "epoch 5 batch id 185701 / 225000 loss 0.0022018151357769966 train acc 0.8086036154894157\n",
      "epoch 5 batch id 185801 / 225000 loss 3.825193166732788 train acc 0.8086016759866739\n",
      "epoch 5 batch id 185901 / 225000 loss 1.2684844732284546 train acc 0.8085957041651202\n",
      "epoch 5 batch id 186001 / 225000 loss 1.061470866203308 train acc 0.808612588104365\n",
      "epoch 5 batch id 186101 / 225000 loss 1.4933582544326782 train acc 0.8086240804724316\n",
      "epoch 5 batch id 186201 / 225000 loss 0.002693490358069539 train acc 0.8086395884017809\n",
      "epoch 5 batch id 186301 / 225000 loss 0.706909716129303 train acc 0.8086376347953044\n",
      "epoch 5 batch id 186401 / 225000 loss 1.4265482425689697 train acc 0.8086437304520898\n",
      "epoch 5 batch id 186501 / 225000 loss 0.015805751085281372 train acc 0.808656521948944\n",
      "epoch 5 batch id 186601 / 225000 loss 0.8013904094696045 train acc 0.8086612611936699\n",
      "epoch 5 batch id 186701 / 225000 loss 1.2459486722946167 train acc 0.8086713515192742\n",
      "epoch 5 batch id 186801 / 225000 loss 0.004675591364502907 train acc 0.8086640328477899\n",
      "epoch 5 batch id 186901 / 225000 loss 0.006789914332330227 train acc 0.8086527091882868\n",
      "epoch 5 batch id 187001 / 225000 loss 1.2705326080322266 train acc 0.8086654616820231\n",
      "epoch 5 batch id 187101 / 225000 loss 0.029094181954860687 train acc 0.8086648387769173\n",
      "epoch 5 batch id 187201 / 225000 loss 0.024135038256645203 train acc 0.8086615456114017\n",
      "epoch 5 batch id 187301 / 225000 loss 0.6127718687057495 train acc 0.8086569212123801\n",
      "epoch 5 batch id 187401 / 225000 loss 2.7609610557556152 train acc 0.8086563038617723\n",
      "epoch 5 batch id 187501 / 225000 loss 2.0611119270324707 train acc 0.8086570204958907\n",
      "epoch 5 batch id 187601 / 225000 loss 0.4227393865585327 train acc 0.8086537385195175\n",
      "epoch 5 batch id 187701 / 225000 loss 0.00037161551881581545 train acc 0.8086571195678233\n",
      "epoch 5 batch id 187801 / 225000 loss 3.5582690238952637 train acc 0.8086618282117773\n",
      "epoch 5 batch id 187901 / 225000 loss 0.003001589560881257 train acc 0.8086625403803066\n",
      "epoch 5 batch id 188001 / 225000 loss 0.051440924406051636 train acc 0.8086592624507316\n",
      "epoch 5 batch id 188101 / 225000 loss 2.6725988388061523 train acc 0.80866927873855\n",
      "epoch 5 batch id 188201 / 225000 loss 0.001882179407402873 train acc 0.8086593588769454\n",
      "epoch 5 batch id 188301 / 225000 loss 3.2673768997192383 train acc 0.808669364474963\n",
      "epoch 5 batch id 188401 / 225000 loss 0.10340142250061035 train acc 0.8086740516239298\n",
      "epoch 5 batch id 188501 / 225000 loss 1.0724354982376099 train acc 0.8086787337998207\n",
      "epoch 5 batch id 188601 / 225000 loss 0.22008642554283142 train acc 0.8086966665076007\n",
      "epoch 5 batch id 188701 / 225000 loss 1.2308305501937866 train acc 0.8087119305144117\n",
      "epoch 5 batch id 188801 / 225000 loss 1.1188760995864868 train acc 0.8087139368965207\n",
      "epoch 5 batch id 188901 / 225000 loss 0.01582927256822586 train acc 0.8086987363751383\n",
      "epoch 5 batch id 189001 / 225000 loss 0.04413768649101257 train acc 0.8086914884048233\n",
      "epoch 5 batch id 189101 / 225000 loss 2.6081743240356445 train acc 0.8087199433107175\n",
      "epoch 5 batch id 189201 / 225000 loss 0.6858755350112915 train acc 0.8087219412159555\n",
      "epoch 5 batch id 189301 / 225000 loss 0.006170905195176601 train acc 0.8087318608987802\n",
      "epoch 5 batch id 189401 / 225000 loss 3.351736068725586 train acc 0.8087232907957191\n",
      "epoch 5 batch id 189501 / 225000 loss 0.5035077333450317 train acc 0.8087397955683611\n",
      "epoch 5 batch id 189601 / 225000 loss 1.8632203340530396 train acc 0.8087430973465329\n",
      "epoch 5 batch id 189701 / 225000 loss 1.387040138244629 train acc 0.8087477135070453\n",
      "epoch 5 batch id 189801 / 225000 loss 1.4870176315307617 train acc 0.8087299329297527\n",
      "epoch 5 batch id 189901 / 225000 loss 2.6318912506103516 train acc 0.8087240193574546\n",
      "epoch 5 batch id 190001 / 225000 loss 1.9042497873306274 train acc 0.8087404803132615\n",
      "epoch 5 batch id 190101 / 225000 loss 0.0003908654907718301 train acc 0.8087371975949627\n",
      "epoch 5 batch id 190201 / 225000 loss 0.7773542404174805 train acc 0.808735232727483\n",
      "epoch 5 batch id 190301 / 225000 loss 1.382047414779663 train acc 0.8087398384664295\n",
      "epoch 5 batch id 190401 / 225000 loss 0.42285826802253723 train acc 0.8087457523857543\n",
      "epoch 5 batch id 190501 / 225000 loss 0.015372277237474918 train acc 0.8087555970834799\n",
      "epoch 5 batch id 190601 / 225000 loss 1.824712872505188 train acc 0.8087431335617337\n",
      "epoch 5 batch id 190701 / 225000 loss 0.5474931001663208 train acc 0.8087634569299584\n",
      "epoch 5 batch id 190801 / 225000 loss 0.005903911776840687 train acc 0.8087680358069402\n",
      "epoch 5 batch id 190901 / 225000 loss 0.05448157340288162 train acc 0.8087595140936925\n",
      "epoch 5 batch id 191001 / 225000 loss 0.008028668351471424 train acc 0.8087693258150481\n",
      "epoch 5 batch id 191101 / 225000 loss 0.005168675445020199 train acc 0.8087856683115211\n",
      "epoch 5 batch id 191201 / 225000 loss 0.4674343168735504 train acc 0.8087863034189152\n",
      "epoch 5 batch id 191301 / 225000 loss 0.29694247245788574 train acc 0.8087921652265279\n",
      "epoch 5 batch id 191401 / 225000 loss 1.081760287284851 train acc 0.8087967147507066\n",
      "epoch 5 batch id 191501 / 225000 loss 0.16874220967292786 train acc 0.8087921211899677\n",
      "epoch 5 batch id 191601 / 225000 loss 0.28639280796051025 train acc 0.8088031899624741\n",
      "epoch 5 batch id 191701 / 225000 loss 1.174269676208496 train acc 0.8088038142732693\n",
      "epoch 5 batch id 191801 / 225000 loss 1.657231092453003 train acc 0.808812258538798\n",
      "epoch 5 batch id 191901 / 225000 loss 0.004384729545563459 train acc 0.8088115747182141\n",
      "epoch 5 batch id 192001 / 225000 loss 0.42705172300338745 train acc 0.8088147978395945\n",
      "epoch 5 batch id 192101 / 225000 loss 1.0925973653793335 train acc 0.808810209212862\n",
      "epoch 5 batch id 192201 / 225000 loss 0.01100432313978672 train acc 0.8088108282475117\n",
      "epoch 5 batch id 192301 / 225000 loss 0.004362136125564575 train acc 0.8088192469097925\n",
      "epoch 5 batch id 192401 / 225000 loss 0.00284010311588645 train acc 0.8088406505163694\n",
      "epoch 5 batch id 192501 / 225000 loss 1.1617801189422607 train acc 0.8088334606053994\n",
      "epoch 5 batch id 192601 / 225000 loss 1.6268235445022583 train acc 0.8088418544036635\n",
      "epoch 5 batch id 192701 / 225000 loss 0.00418299762532115 train acc 0.8088528341835278\n",
      "epoch 5 batch id 192801 / 225000 loss 6.432816505432129 train acc 0.8088573192047759\n",
      "epoch 5 batch id 192901 / 225000 loss 1.0195720195770264 train acc 0.808869575585404\n",
      "epoch 5 batch id 193001 / 225000 loss 0.2139267772436142 train acc 0.808866275304273\n",
      "epoch 5 batch id 193101 / 225000 loss 1.6908214092254639 train acc 0.8088720410562348\n",
      "epoch 5 batch id 193201 / 225000 loss 0.6863663196563721 train acc 0.8088790948287017\n",
      "epoch 5 batch id 193301 / 225000 loss 0.0004630544572137296 train acc 0.8088835546634523\n",
      "epoch 5 batch id 193401 / 225000 loss 1.3610820770263672 train acc 0.8088802539800725\n",
      "epoch 5 batch id 193501 / 225000 loss 0.015689700841903687 train acc 0.8088666208443367\n",
      "epoch 5 batch id 193601 / 225000 loss 0.23686155676841736 train acc 0.8088684975800745\n",
      "epoch 5 batch id 193701 / 225000 loss 0.006974241696298122 train acc 0.8088742443250164\n",
      "epoch 5 batch id 193801 / 225000 loss 1.2607585191726685 train acc 0.8088799851393955\n",
      "epoch 5 batch id 193901 / 225000 loss 1.8152841329574585 train acc 0.8088805627614092\n",
      "epoch 5 batch id 194001 / 225000 loss 0.2713506519794464 train acc 0.8088669646032752\n",
      "epoch 5 batch id 194101 / 225000 loss 0.007415831089019775 train acc 0.8088636843705082\n",
      "epoch 5 batch id 194201 / 225000 loss 0.6561630368232727 train acc 0.8088784300801747\n",
      "epoch 5 batch id 194301 / 225000 loss 3.934357166290283 train acc 0.8088687140055892\n",
      "epoch 5 batch id 194401 / 225000 loss 1.9245566129684448 train acc 0.80886543793499\n",
      "epoch 5 batch id 194501 / 225000 loss 4.86437463760376 train acc 0.8088557385309073\n",
      "epoch 5 batch id 194601 / 225000 loss 0.6331325769424438 train acc 0.8088666039742859\n",
      "epoch 5 batch id 194701 / 225000 loss 1.7829612493515015 train acc 0.8088594819749256\n",
      "epoch 5 batch id 194801 / 225000 loss 0.00039380922680720687 train acc 0.8088587840924841\n",
      "epoch 5 batch id 194901 / 225000 loss 0.5759751796722412 train acc 0.8088696312486853\n",
      "epoch 5 batch id 195001 / 225000 loss 0.0006155654555186629 train acc 0.8088509802513834\n",
      "epoch 5 batch id 195101 / 225000 loss 0.004192717373371124 train acc 0.8088438808617076\n",
      "epoch 5 batch id 195201 / 225000 loss 0.005407117307186127 train acc 0.8088547189819725\n",
      "epoch 5 batch id 195301 / 225000 loss 0.04618346691131592 train acc 0.8088604257018653\n",
      "epoch 5 batch id 195401 / 225000 loss 0.40896061062812805 train acc 0.8088674060009928\n",
      "epoch 5 batch id 195501 / 225000 loss 0.2744778096675873 train acc 0.8088910031150736\n",
      "epoch 5 batch id 195601 / 225000 loss 1.7383908033370972 train acc 0.8088877357477723\n",
      "epoch 5 batch id 195701 / 225000 loss 2.3543286323547363 train acc 0.8088946913914594\n",
      "epoch 5 batch id 195801 / 225000 loss 0.42399537563323975 train acc 0.8088850414451407\n",
      "epoch 5 batch id 195901 / 225000 loss 0.5006821155548096 train acc 0.8089009244465317\n",
      "epoch 5 batch id 196001 / 225000 loss 0.8656014800071716 train acc 0.8089002096928077\n",
      "epoch 5 batch id 196101 / 225000 loss 3.060079574584961 train acc 0.8088982208147842\n",
      "epoch 5 batch id 196201 / 225000 loss 0.26907607913017273 train acc 0.8089038791851214\n",
      "epoch 5 batch id 196301 / 225000 loss 0.002156246919184923 train acc 0.8089133524536298\n",
      "epoch 5 batch id 196401 / 225000 loss 0.001629261183552444 train acc 0.8089189973574472\n",
      "epoch 5 batch id 196501 / 225000 loss 1.9642339944839478 train acc 0.8089246365158447\n",
      "epoch 5 batch id 196601 / 225000 loss 0.43096596002578735 train acc 0.8089213686603832\n",
      "epoch 5 batch id 196701 / 225000 loss 0.0034943430218845606 train acc 0.8089142912339032\n",
      "epoch 5 batch id 196801 / 225000 loss 0.182686910033226 train acc 0.8089199241873771\n",
      "epoch 5 batch id 196901 / 225000 loss 0.6675384640693665 train acc 0.8089344391343873\n",
      "epoch 5 batch id 197001 / 225000 loss 0.4236884117126465 train acc 0.8089159445891138\n",
      "epoch 5 batch id 197101 / 225000 loss 0.04191253334283829 train acc 0.8089114210480921\n",
      "epoch 5 batch id 197201 / 225000 loss 0.7132840752601624 train acc 0.8089170440312169\n",
      "epoch 5 batch id 197301 / 225000 loss 2.37971830368042 train acc 0.8089112574188676\n",
      "epoch 5 batch id 197401 / 225000 loss 0.6932482719421387 train acc 0.8089320722792691\n",
      "epoch 5 batch id 197501 / 225000 loss 1.4260905981063843 train acc 0.8089326129994279\n",
      "epoch 5 batch id 197601 / 225000 loss 0.0008988152258098125 train acc 0.8089356835238688\n",
      "epoch 5 batch id 197701 / 225000 loss 0.006508907303214073 train acc 0.808922311976166\n",
      "epoch 5 batch id 197801 / 225000 loss 2.601426124572754 train acc 0.8089241207071753\n",
      "epoch 5 batch id 197901 / 225000 loss 0.0029724212363362312 train acc 0.8089208745787035\n",
      "epoch 5 batch id 198001 / 225000 loss 0.0010719421552494168 train acc 0.8088999550507321\n",
      "epoch 5 batch id 198101 / 225000 loss 1.6185437440872192 train acc 0.8089093442234012\n",
      "epoch 5 batch id 198201 / 225000 loss 2.5575904846191406 train acc 0.8088985423887871\n",
      "epoch 5 batch id 198301 / 225000 loss 1.3109195232391357 train acc 0.8088890121582847\n",
      "epoch 5 batch id 198401 / 225000 loss 0.0061952173709869385 train acc 0.8088983926492306\n",
      "epoch 5 batch id 198501 / 225000 loss 2.000312089920044 train acc 0.8089065042493488\n",
      "epoch 5 batch id 198601 / 225000 loss 0.1585100293159485 train acc 0.8089070548486664\n",
      "epoch 5 batch id 198701 / 225000 loss 0.002238290151581168 train acc 0.8089101212374371\n",
      "epoch 5 batch id 198801 / 225000 loss 0.985266387462616 train acc 0.8089207297750012\n",
      "epoch 5 batch id 198901 / 225000 loss 0.8544754385948181 train acc 0.8089300707387093\n",
      "epoch 5 batch id 199001 / 225000 loss 1.4057989120483398 train acc 0.8089117642624911\n",
      "epoch 5 batch id 199101 / 225000 loss 1.2554454803466797 train acc 0.80889975439601\n",
      "epoch 5 batch id 199201 / 225000 loss 2.038572311401367 train acc 0.8088940316564676\n",
      "epoch 5 batch id 199301 / 225000 loss 0.12745748460292816 train acc 0.8088908234278804\n",
      "epoch 5 batch id 199401 / 225000 loss 1.9395266771316528 train acc 0.8089001559671215\n",
      "epoch 5 batch id 199501 / 225000 loss 2.082664966583252 train acc 0.8088944416318715\n",
      "epoch 5 batch id 199601 / 225000 loss 1.1483187675476074 train acc 0.8088874805236447\n",
      "epoch 5 batch id 199701 / 225000 loss 1.2453261613845825 train acc 0.8088680076714688\n",
      "epoch 5 batch id 199801 / 225000 loss 0.002848199103027582 train acc 0.808864820496394\n",
      "epoch 5 batch id 199901 / 225000 loss 1.7952098846435547 train acc 0.8088741427006368\n",
      "epoch 5 batch id 200001 / 225000 loss 0.2865716516971588 train acc 0.8088872055639722\n",
      "epoch 5 batch id 200101 / 225000 loss 1.3670810461044312 train acc 0.8088815148350084\n",
      "epoch 5 batch id 200201 / 225000 loss 0.0030698473565280437 train acc 0.8088920634762065\n",
      "epoch 5 batch id 200301 / 225000 loss 1.118241786956787 train acc 0.8088976090983071\n",
      "epoch 5 batch id 200401 / 225000 loss 1.0982816219329834 train acc 0.8089143766747671\n",
      "epoch 5 batch id 200501 / 225000 loss 0.179438054561615 train acc 0.8089261400192518\n",
      "epoch 5 batch id 200601 / 225000 loss 2.149688482284546 train acc 0.8089291678506089\n",
      "epoch 5 batch id 200701 / 225000 loss 0.004921677056699991 train acc 0.808943403371184\n",
      "epoch 5 batch id 200801 / 225000 loss 1.2554341554641724 train acc 0.8089638497816246\n",
      "epoch 5 batch id 200901 / 225000 loss 0.9526576995849609 train acc 0.8089618767452625\n",
      "epoch 5 batch id 201001 / 225000 loss 1.0564038753509521 train acc 0.8089748309709902\n",
      "epoch 5 batch id 201101 / 225000 loss 2.3269224166870117 train acc 0.8089703681234802\n",
      "epoch 5 batch id 201201 / 225000 loss 0.0022458641324192286 train acc 0.8089733649435142\n",
      "epoch 5 batch id 201301 / 225000 loss 1.515058159828186 train acc 0.8089825683926061\n",
      "epoch 5 batch id 201401 / 225000 loss 0.009907186031341553 train acc 0.8089768670463404\n",
      "epoch 5 batch id 201501 / 225000 loss 0.004316653590649366 train acc 0.8089736527362147\n",
      "epoch 5 batch id 201601 / 225000 loss 0.9509029984474182 train acc 0.8089816022737982\n",
      "epoch 5 batch id 201701 / 225000 loss 2.071390390396118 train acc 0.8089895439288848\n",
      "epoch 5 batch id 201801 / 225000 loss 2.894772529602051 train acc 0.8089900446479452\n",
      "epoch 5 batch id 201901 / 225000 loss 0.006928793154656887 train acc 0.8089967360240911\n",
      "epoch 5 batch id 202001 / 225000 loss 0.016618937253952026 train acc 0.8089786684224336\n",
      "epoch 5 batch id 202101 / 225000 loss 0.005217398516833782 train acc 0.8089927808373041\n",
      "epoch 5 batch id 202201 / 225000 loss 0.017395883798599243 train acc 0.808990806178011\n",
      "epoch 5 batch id 202301 / 225000 loss 1.8805330991744995 train acc 0.808985126123944\n",
      "epoch 5 batch id 202401 / 225000 loss 0.004193459637463093 train acc 0.8090041551178107\n",
      "epoch 5 batch id 202501 / 225000 loss 0.007241474464535713 train acc 0.8090120542614604\n",
      "epoch 5 batch id 202601 / 225000 loss 2.0132339000701904 train acc 0.8090162437500309\n",
      "epoch 5 batch id 202701 / 225000 loss 2.276047945022583 train acc 0.8089994622621497\n",
      "epoch 5 batch id 202801 / 225000 loss 0.17788797616958618 train acc 0.809003653828137\n",
      "epoch 5 batch id 202901 / 225000 loss 0.11672572046518326 train acc 0.8090090733904712\n",
      "epoch 5 batch id 203001 / 225000 loss 1.9370417594909668 train acc 0.8090083300082266\n",
      "epoch 5 batch id 203101 / 225000 loss 0.025678511708974838 train acc 0.8090162037606905\n",
      "epoch 5 batch id 203201 / 225000 loss 3.389512300491333 train acc 0.8090191485278123\n",
      "epoch 5 batch id 203301 / 225000 loss 0.001014237990602851 train acc 0.8090171715830222\n",
      "epoch 5 batch id 203401 / 225000 loss 0.1075795367360115 train acc 0.8090238002763015\n",
      "epoch 5 batch id 203501 / 225000 loss 0.001893928973004222 train acc 0.8090390219212682\n",
      "epoch 5 batch id 203601 / 225000 loss 0.0018629208207130432 train acc 0.8090505449383844\n",
      "epoch 5 batch id 203701 / 225000 loss 1.7574858665466309 train acc 0.8090326017054408\n",
      "epoch 5 batch id 203801 / 225000 loss 0.01657194085419178 train acc 0.8090551567460414\n",
      "epoch 5 batch id 203901 / 225000 loss 1.2688206434249878 train acc 0.8090531679589604\n",
      "epoch 5 batch id 204001 / 225000 loss 0.0014105425216257572 train acc 0.8090609849951715\n",
      "epoch 5 batch id 204101 / 225000 loss 1.358157992362976 train acc 0.8090528708825533\n",
      "epoch 5 batch id 204201 / 225000 loss 0.15443216264247894 train acc 0.8090655775436947\n",
      "epoch 5 batch id 204301 / 225000 loss 0.6285600066184998 train acc 0.8090611401804201\n",
      "epoch 5 batch id 204401 / 225000 loss 0.002964673563838005 train acc 0.8090664918469088\n",
      "epoch 5 batch id 204501 / 225000 loss 1.1852598190307617 train acc 0.809079173206977\n",
      "epoch 5 batch id 204601 / 225000 loss 1.891449213027954 train acc 0.8090759575955152\n",
      "epoch 5 batch id 204701 / 225000 loss 1.345818042755127 train acc 0.8090812941802922\n",
      "epoch 5 batch id 204801 / 225000 loss 0.0009272490278817713 train acc 0.8090670943989531\n",
      "epoch 5 batch id 204901 / 225000 loss 0.569054365158081 train acc 0.8090699898975603\n",
      "epoch 5 batch id 205001 / 225000 loss 0.008644860237836838 train acc 0.809082638621275\n",
      "epoch 5 batch id 205101 / 225000 loss 0.08946920186281204 train acc 0.8090940560991902\n",
      "epoch 5 batch id 205201 / 225000 loss 1.6430399417877197 train acc 0.809081096096023\n",
      "epoch 5 batch id 205301 / 225000 loss 1.2211294174194336 train acc 0.8090620600971257\n",
      "epoch 5 batch id 205401 / 225000 loss 0.001838252297602594 train acc 0.8090722537864957\n",
      "epoch 5 batch id 205501 / 225000 loss 0.01666092500090599 train acc 0.8090593233122954\n",
      "epoch 5 batch id 205601 / 225000 loss 0.1833288073539734 train acc 0.8090512692058891\n",
      "epoch 5 batch id 205701 / 225000 loss 0.0017560662236064672 train acc 0.809050515067987\n",
      "epoch 5 batch id 205801 / 225000 loss 1.1622161865234375 train acc 0.8090315401771614\n",
      "epoch 5 batch id 205901 / 225000 loss 0.010464094579219818 train acc 0.8090210829476302\n",
      "epoch 5 batch id 206001 / 225000 loss 0.0009683617390692234 train acc 0.8090324804248523\n",
      "epoch 5 batch id 206101 / 225000 loss 0.0233099814504385 train acc 0.8090341628618978\n",
      "epoch 5 batch id 206201 / 225000 loss 0.7315528988838196 train acc 0.8090334188485991\n",
      "epoch 5 batch id 206301 / 225000 loss 0.5137723088264465 train acc 0.8090229809840961\n",
      "epoch 5 batch id 206401 / 225000 loss 0.21672280132770538 train acc 0.8090173981715205\n",
      "epoch 5 batch id 206501 / 225000 loss 1.3835229873657227 train acc 0.8090251378927947\n",
      "epoch 5 batch id 206601 / 225000 loss 0.0035941565874964 train acc 0.8090449707407031\n",
      "epoch 5 batch id 206701 / 225000 loss 1.4202320575714111 train acc 0.8090309190569954\n",
      "epoch 5 batch id 206801 / 225000 loss 0.002843499183654785 train acc 0.8090265520959763\n",
      "epoch 5 batch id 206901 / 225000 loss 0.011998150497674942 train acc 0.8090342724298094\n",
      "epoch 5 batch id 207001 / 225000 loss 0.0008148323395289481 train acc 0.809029908068077\n",
      "epoch 5 batch id 207101 / 225000 loss 0.003519828896969557 train acc 0.8090352050448815\n",
      "epoch 5 batch id 207201 / 225000 loss 0.17523886263370514 train acc 0.8090320510036149\n",
      "epoch 5 batch id 207301 / 225000 loss 0.004713099449872971 train acc 0.8090445776913763\n",
      "epoch 5 batch id 207401 / 225000 loss 0.04081953689455986 train acc 0.8090378059893636\n",
      "epoch 5 batch id 207501 / 225000 loss 0.0030373011250048876 train acc 0.8090467033893812\n",
      "epoch 5 batch id 207601 / 225000 loss 0.572664737701416 train acc 0.8090411414203207\n",
      "epoch 5 batch id 207701 / 225000 loss 0.0016014771535992622 train acc 0.8090428067269777\n",
      "epoch 5 batch id 207801 / 225000 loss 1.1894538402557373 train acc 0.8090432673567499\n",
      "epoch 5 batch id 207901 / 225000 loss 0.0036444817669689655 train acc 0.8090401200571425\n",
      "epoch 5 batch id 208001 / 225000 loss 0.3454633057117462 train acc 0.8090441872875611\n",
      "epoch 5 batch id 208101 / 225000 loss 0.30978941917419434 train acc 0.8090290291733341\n",
      "epoch 5 batch id 208201 / 225000 loss 2.1527652740478516 train acc 0.8090162871455949\n",
      "epoch 5 batch id 208301 / 225000 loss 0.07277536392211914 train acc 0.8090107584697145\n",
      "epoch 5 batch id 208401 / 225000 loss 0.011349879205226898 train acc 0.8090112331514724\n",
      "epoch 5 batch id 208501 / 225000 loss 2.116391181945801 train acc 0.8090189015880019\n",
      "epoch 5 batch id 208601 / 225000 loss 3.0420939922332764 train acc 0.8090145780700956\n",
      "epoch 5 batch id 208701 / 225000 loss 0.8775479793548584 train acc 0.8090078629235126\n",
      "epoch 5 batch id 208801 / 225000 loss 0.0033172108232975006 train acc 0.8090203112054061\n",
      "epoch 5 batch id 208901 / 225000 loss 0.03480956330895424 train acc 0.8090088127869182\n",
      "epoch 5 batch id 209001 / 225000 loss 1.0067787170410156 train acc 0.8090176602025828\n",
      "epoch 5 batch id 209101 / 225000 loss 2.975620985031128 train acc 0.8090241079669633\n",
      "epoch 5 batch id 209201 / 225000 loss 0.5157747268676758 train acc 0.8090233794293527\n",
      "epoch 5 batch id 209301 / 225000 loss 0.4072091281414032 train acc 0.8090083181637928\n",
      "epoch 5 batch id 209401 / 225000 loss 3.4511401653289795 train acc 0.8090052100992832\n",
      "epoch 5 batch id 209501 / 225000 loss 0.006700693629682064 train acc 0.8090223913012349\n",
      "epoch 5 batch id 209601 / 225000 loss 1.2165498733520508 train acc 0.8090133157761652\n",
      "epoch 5 batch id 209701 / 225000 loss 3.637709140777588 train acc 0.8090078254276327\n",
      "epoch 5 batch id 209801 / 225000 loss 1.7615822553634644 train acc 0.8090190227882612\n",
      "epoch 5 batch id 209901 / 225000 loss 0.8087339401245117 train acc 0.809023063253629\n",
      "epoch 5 batch id 210001 / 225000 loss 0.0031764546874910593 train acc 0.8090342426940824\n",
      "epoch 5 batch id 210101 / 225000 loss 0.004025386180728674 train acc 0.8090620701472149\n",
      "epoch 5 batch id 210201 / 225000 loss 2.4651806354522705 train acc 0.8090672737046922\n",
      "epoch 5 batch id 210301 / 225000 loss 2.0767178535461426 train acc 0.8090772274026277\n",
      "epoch 5 batch id 210401 / 225000 loss 0.026383746415376663 train acc 0.8090681603224319\n",
      "epoch 5 batch id 210501 / 225000 loss 1.9927294254302979 train acc 0.8090792917848372\n",
      "epoch 5 batch id 210601 / 225000 loss 0.44355928897857666 train acc 0.8090785418872655\n",
      "epoch 5 batch id 210701 / 225000 loss 0.14729037880897522 train acc 0.8090742331550396\n",
      "epoch 5 batch id 210801 / 225000 loss 0.11130411922931671 train acc 0.8090699285107755\n",
      "epoch 5 batch id 210901 / 225000 loss 0.01980898529291153 train acc 0.8090798526322777\n",
      "epoch 5 batch id 211001 / 225000 loss 0.004206443205475807 train acc 0.809077919061995\n",
      "epoch 5 batch id 211101 / 225000 loss 0.0048103975132107735 train acc 0.8090830929270822\n",
      "epoch 5 batch id 211201 / 225000 loss 0.00432105315849185 train acc 0.8090716900014678\n",
      "epoch 5 batch id 211301 / 225000 loss 0.0660906508564949 train acc 0.8090602978689169\n",
      "epoch 5 batch id 211401 / 225000 loss 0.5869280695915222 train acc 0.809067837900483\n",
      "epoch 5 batch id 211501 / 225000 loss 0.0035355505533516407 train acc 0.8090600044444234\n",
      "epoch 5 batch id 211601 / 225000 loss 2.9347686767578125 train acc 0.8090663560191115\n",
      "epoch 5 batch id 211701 / 225000 loss 0.5046197772026062 train acc 0.8090656161284075\n",
      "epoch 5 batch id 211801 / 225000 loss 0.0007219440303742886 train acc 0.809041269871247\n",
      "epoch 5 batch id 211901 / 225000 loss 0.00040223903488367796 train acc 0.809029924351466\n",
      "epoch 5 batch id 212001 / 225000 loss 0.0009292272734455764 train acc 0.809045712048528\n",
      "epoch 5 batch id 212101 / 225000 loss 0.0018294882029294968 train acc 0.8090414472350437\n",
      "epoch 5 batch id 212201 / 225000 loss 0.8068554401397705 train acc 0.8090407208260093\n",
      "epoch 5 batch id 212301 / 225000 loss 1.442861557006836 train acc 0.8090553035548584\n",
      "epoch 5 batch id 212401 / 225000 loss 2.1197938919067383 train acc 0.8090522172682802\n",
      "epoch 5 batch id 212501 / 225000 loss 1.6401005983352661 train acc 0.8090514868165326\n",
      "epoch 5 batch id 212601 / 225000 loss 0.004037529695779085 train acc 0.8090437015818364\n",
      "epoch 5 batch id 212701 / 225000 loss 0.8366111516952515 train acc 0.8090476772558662\n",
      "epoch 5 batch id 212801 / 225000 loss 0.0014820704236626625 train acc 0.809058698032434\n",
      "epoch 5 batch id 212901 / 225000 loss 0.46358364820480347 train acc 0.8090485718714332\n",
      "epoch 5 batch id 213001 / 225000 loss 0.5129678249359131 train acc 0.8090408026253398\n",
      "epoch 5 batch id 213101 / 225000 loss 1.0634840726852417 train acc 0.8090271749076728\n",
      "epoch 5 batch id 213201 / 225000 loss 0.08600886166095734 train acc 0.8090241133953405\n",
      "epoch 5 batch id 213301 / 225000 loss 0.4484376013278961 train acc 0.8090327752800034\n",
      "epoch 5 batch id 213401 / 225000 loss 1.309935450553894 train acc 0.8090461150603793\n",
      "epoch 5 batch id 213501 / 225000 loss 3.023465633392334 train acc 0.8090325103863683\n",
      "epoch 5 batch id 213601 / 225000 loss 0.004604747984558344 train acc 0.809022429670273\n",
      "epoch 5 batch id 213701 / 225000 loss 3.140056610107422 train acc 0.8090275665532684\n",
      "epoch 5 batch id 213801 / 225000 loss 1.456079125404358 train acc 0.8090210055144738\n",
      "epoch 5 batch id 213901 / 225000 loss 0.8767948150634766 train acc 0.8090167881403079\n",
      "epoch 5 batch id 214001 / 225000 loss 0.026215746998786926 train acc 0.809014911145275\n",
      "epoch 5 batch id 214101 / 225000 loss 0.7349549531936646 train acc 0.809032886348032\n",
      "epoch 5 batch id 214201 / 225000 loss 0.3505373001098633 train acc 0.8090251679497295\n",
      "epoch 5 batch id 214301 / 225000 loss 0.9329136610031128 train acc 0.8090349555065072\n",
      "epoch 5 batch id 214401 / 225000 loss 1.0054399967193604 train acc 0.8090400697757939\n",
      "epoch 5 batch id 214501 / 225000 loss 0.15550245344638824 train acc 0.8090451792765535\n",
      "epoch 5 batch id 214601 / 225000 loss 0.8488292694091797 train acc 0.8090374695364887\n",
      "epoch 5 batch id 214701 / 225000 loss 0.036351557821035385 train acc 0.8090309313883028\n",
      "epoch 5 batch id 214801 / 225000 loss 0.022743497043848038 train acc 0.8090337102713675\n",
      "epoch 5 batch id 214901 / 225000 loss 0.017673974856734276 train acc 0.8090423032000782\n",
      "epoch 5 batch id 215001 / 225000 loss 0.5479540824890137 train acc 0.8090450742089572\n",
      "epoch 5 batch id 215101 / 225000 loss 0.0003478139406070113 train acc 0.8090420314177991\n",
      "epoch 5 batch id 215201 / 225000 loss 0.019278597086668015 train acc 0.8090506085008898\n",
      "epoch 5 batch id 215301 / 225000 loss 1.9154165983200073 train acc 0.8090556941212536\n",
      "epoch 5 batch id 215401 / 225000 loss 0.004123985767364502 train acc 0.8090642568976003\n",
      "epoch 5 batch id 215501 / 225000 loss 1.5080986022949219 train acc 0.8090565705031532\n",
      "epoch 5 batch id 215601 / 225000 loss 1.2453378438949585 train acc 0.8090546889856726\n",
      "epoch 5 batch id 215701 / 225000 loss 0.0032475513871759176 train acc 0.8090667173541152\n",
      "epoch 5 batch id 215801 / 225000 loss 3.670353651046753 train acc 0.8090683083025565\n",
      "epoch 5 batch id 215901 / 225000 loss 0.7452850937843323 train acc 0.8090548445815443\n",
      "epoch 5 batch id 216001 / 225000 loss 1.1749125719070435 train acc 0.8090471803371281\n",
      "epoch 5 batch id 216101 / 225000 loss 0.0028021885082125664 train acc 0.8090406800523829\n",
      "epoch 5 batch id 216201 / 225000 loss 0.9156467914581299 train acc 0.8090284041239402\n",
      "epoch 5 batch id 216301 / 225000 loss 1.1660264730453491 train acc 0.8090380996851609\n",
      "epoch 5 batch id 216401 / 225000 loss 1.0210410356521606 train acc 0.8090385441841766\n",
      "epoch 5 batch id 216501 / 225000 loss 0.4707629382610321 train acc 0.8090539997505786\n",
      "epoch 5 batch id 216601 / 225000 loss 2.7387983798980713 train acc 0.8090613616742305\n",
      "epoch 5 batch id 216701 / 225000 loss 0.002692640293389559 train acc 0.8090652558133096\n",
      "epoch 5 batch id 216801 / 225000 loss 1.876516342163086 train acc 0.8090587681791136\n",
      "epoch 5 batch id 216901 / 225000 loss 1.0735626220703125 train acc 0.8090753385184946\n",
      "epoch 5 batch id 217001 / 225000 loss 0.47729966044425964 train acc 0.8090746125593892\n",
      "epoch 5 batch id 217101 / 225000 loss 1.8090113401412964 train acc 0.809069281118005\n",
      "epoch 5 batch id 217201 / 225000 loss 2.187230110168457 train acc 0.8090570485402921\n",
      "epoch 5 batch id 217301 / 225000 loss 0.1708528846502304 train acc 0.8090413757875021\n",
      "epoch 5 batch id 217401 / 225000 loss 0.8254048824310303 train acc 0.8090567660682334\n",
      "epoch 5 batch id 217501 / 225000 loss 1.0429017543792725 train acc 0.809049153796994\n",
      "epoch 5 batch id 217601 / 225000 loss 0.04261230677366257 train acc 0.8090495907647484\n",
      "epoch 5 batch id 217701 / 225000 loss 0.0010476774768903852 train acc 0.8090500273310641\n",
      "epoch 5 batch id 217801 / 225000 loss 1.9159564971923828 train acc 0.809036689455053\n",
      "epoch 5 batch id 217901 / 225000 loss 1.6197164058685303 train acc 0.8090313949913034\n",
      "epoch 5 batch id 218001 / 225000 loss 1.9734165668487549 train acc 0.809023811817377\n",
      "epoch 5 batch id 218101 / 225000 loss 0.00885691586881876 train acc 0.8090334294661647\n",
      "epoch 5 batch id 218201 / 225000 loss 0.08820059895515442 train acc 0.8090350181713191\n",
      "epoch 5 batch id 218301 / 225000 loss 0.9328558444976807 train acc 0.8090411862520098\n",
      "epoch 5 batch id 218401 / 225000 loss 0.06172453984618187 train acc 0.8090336124834593\n",
      "epoch 5 batch id 218501 / 225000 loss 2.2282235622406006 train acc 0.809024901487865\n",
      "epoch 5 batch id 218601 / 225000 loss 0.18783026933670044 train acc 0.8090264911871401\n",
      "epoch 5 batch id 218701 / 225000 loss 1.013308048248291 train acc 0.8090475123570537\n",
      "epoch 5 batch id 218801 / 225000 loss 0.7781505584716797 train acc 0.8090433773154602\n",
      "epoch 5 batch id 218901 / 225000 loss 1.7178353071212769 train acc 0.80906208742765\n",
      "epoch 5 batch id 219001 / 225000 loss 0.0003197311598341912 train acc 0.8090705065273675\n",
      "epoch 5 batch id 219101 / 225000 loss 0.0008600358851253986 train acc 0.8090846230733771\n",
      "epoch 5 batch id 219201 / 225000 loss 1.308416485786438 train acc 0.8090998672451312\n",
      "epoch 5 batch id 219301 / 225000 loss 0.0004209681646898389 train acc 0.809075198015513\n",
      "epoch 5 batch id 219401 / 225000 loss 1.5848274230957031 train acc 0.8090744800616223\n",
      "epoch 5 batch id 219501 / 225000 loss 4.275079250335693 train acc 0.809062373292149\n",
      "epoch 5 batch id 219601 / 225000 loss 0.0029003056697547436 train acc 0.809061661832141\n",
      "epoch 5 batch id 219701 / 225000 loss 3.3854424953460693 train acc 0.8090472960978785\n",
      "epoch 5 batch id 219801 / 225000 loss 0.8307733535766602 train acc 0.809055691284389\n",
      "epoch 5 batch id 219901 / 225000 loss 0.9350875616073608 train acc 0.8090595313345551\n",
      "epoch 5 batch id 220001 / 225000 loss 3.2415688037872314 train acc 0.8090645042522534\n",
      "epoch 5 batch id 220101 / 225000 loss 0.03771907463669777 train acc 0.8090626575981027\n",
      "epoch 5 batch id 220201 / 225000 loss 1.0231125354766846 train acc 0.8090698952320834\n",
      "epoch 5 batch id 220301 / 225000 loss 0.3779951333999634 train acc 0.8090703174293353\n",
      "epoch 5 batch id 220401 / 225000 loss 0.0010930768912658095 train acc 0.8090866193892042\n",
      "epoch 5 batch id 220501 / 225000 loss 1.8607299327850342 train acc 0.8090961038725448\n",
      "epoch 5 batch id 220601 / 225000 loss 1.9536218643188477 train acc 0.8090851809375298\n",
      "epoch 5 batch id 220701 / 225000 loss 0.8960105180740356 train acc 0.8090686041295689\n",
      "epoch 5 batch id 220801 / 225000 loss 1.273773193359375 train acc 0.809073554920494\n",
      "epoch 5 batch id 220901 / 225000 loss 2.162574529647827 train acc 0.8090683156708208\n",
      "epoch 5 batch id 221001 / 225000 loss 0.9436504244804382 train acc 0.8090743933285369\n",
      "epoch 5 batch id 221101 / 225000 loss 1.4473016262054443 train acc 0.8090895111283983\n",
      "epoch 5 batch id 221201 / 225000 loss 0.7510565519332886 train acc 0.8090865321585345\n",
      "epoch 5 batch id 221301 / 225000 loss 0.9933497309684753 train acc 0.8090914636626133\n",
      "epoch 5 batch id 221401 / 225000 loss 0.00045898716780357063 train acc 0.8090918740204426\n",
      "epoch 5 batch id 221501 / 225000 loss 3.0465378761291504 train acc 0.8091013133123552\n",
      "epoch 5 batch id 221601 / 225000 loss 0.005310560576617718 train acc 0.8090938217787826\n",
      "epoch 5 batch id 221701 / 225000 loss 1.2089309692382812 train acc 0.809103251676808\n",
      "epoch 5 batch id 221801 / 225000 loss 0.003081116359680891 train acc 0.809099147433961\n",
      "epoch 5 batch id 221901 / 225000 loss 3.672795534133911 train acc 0.8090995534044462\n",
      "epoch 5 batch id 222001 / 225000 loss 0.004518931731581688 train acc 0.8091033373723542\n",
      "epoch 5 batch id 222101 / 225000 loss 1.9290809631347656 train acc 0.8091003642486977\n",
      "epoch 5 batch id 222201 / 225000 loss 2.419011116027832 train acc 0.8091131453053767\n",
      "epoch 5 batch id 222301 / 225000 loss 0.11149240285158157 train acc 0.8091270394645098\n",
      "epoch 5 batch id 222401 / 225000 loss 0.0016402408946305513 train acc 0.809118439215651\n",
      "epoch 5 batch id 222501 / 225000 loss 1.1036020517349243 train acc 0.809115464649597\n",
      "epoch 5 batch id 222601 / 225000 loss 1.8580836057662964 train acc 0.8091181081845994\n",
      "epoch 5 batch id 222701 / 225000 loss 0.11368061602115631 train acc 0.8091229945083318\n",
      "epoch 5 batch id 222801 / 225000 loss 0.0020170847419649363 train acc 0.8091312426784439\n",
      "epoch 5 batch id 222901 / 225000 loss 0.6217212677001953 train acc 0.8091282677062911\n",
      "epoch 5 batch id 223001 / 225000 loss 2.8212382793426514 train acc 0.8091129636189972\n",
      "epoch 5 batch id 223101 / 225000 loss 4.006680488586426 train acc 0.8091099995069497\n",
      "epoch 5 batch id 223201 / 225000 loss 0.0007589443121105433 train acc 0.8090991975842402\n",
      "epoch 5 batch id 223301 / 225000 loss 0.41947421431541443 train acc 0.8091029596822227\n",
      "epoch 5 batch id 223401 / 225000 loss 0.0062619419768452644 train acc 0.8091111946678842\n",
      "epoch 5 batch id 223501 / 225000 loss 1.4095195531845093 train acc 0.8091115923418687\n",
      "epoch 5 batch id 223601 / 225000 loss 0.634190559387207 train acc 0.8091153438490883\n",
      "epoch 5 batch id 223701 / 225000 loss 0.0007441749330610037 train acc 0.8091123866232158\n",
      "epoch 5 batch id 223801 / 225000 loss 0.0006486015045084059 train acc 0.8091194856144521\n",
      "epoch 5 batch id 223901 / 225000 loss 0.016169467940926552 train acc 0.8091142960504866\n",
      "epoch 5 batch id 224001 / 225000 loss 1.3033033609390259 train acc 0.8091057629207012\n",
      "epoch 5 batch id 224101 / 225000 loss 1.8332804441452026 train acc 0.8091128553643223\n",
      "epoch 5 batch id 224201 / 225000 loss 0.8633410334587097 train acc 0.8091154811976753\n",
      "epoch 5 batch id 224301 / 225000 loss 2.939549207687378 train acc 0.8091203338371207\n",
      "epoch 5 batch id 224401 / 225000 loss 0.203014075756073 train acc 0.8091118132272138\n",
      "epoch 5 batch id 224501 / 225000 loss 0.051721084862947464 train acc 0.8091200039198043\n",
      "epoch 5 batch id 224601 / 225000 loss 0.5126978158950806 train acc 0.8091226218939364\n",
      "epoch 5 batch id 224701 / 225000 loss 0.5689427852630615 train acc 0.8091363634340746\n",
      "epoch 5 batch id 224801 / 225000 loss 1.00592839717865 train acc 0.809127850854756\n",
      "epoch 5 batch id 224901 / 225000 loss 1.8339630365371704 train acc 0.8091115646439989\n",
      "epoch 5 train acc 0.8091122222222222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67e09522a2c433f8c6c983bb207e4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.79898\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mxnet\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#=========================================================#\n",
    "\n",
    "##나중에 argpaser로 변경\n",
    "max_grad_norm = 1\n",
    "log_interval = 1000\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "batch_size = 4\n",
    "max_len = 512\n",
    "learning_rate = 5e-5 \n",
    "\n",
    "#########################\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:1\")\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "\n",
    "data = pd.read_pickle(\"../result/sample5_tokenized.pkl\")\n",
    "##############\n",
    "\n",
    "print(data.info())\n",
    "\n",
    "label_to_int = {}\n",
    "for i, item in enumerate(data['접수기관'].unique()):\n",
    "    label_to_int[item] = i\n",
    "\n",
    "data['접수기관'] = data['접수기관'].apply(lambda x : label_to_int[x])\n",
    "data = data[['token', '접수기관']]\n",
    "\n",
    "\n",
    "\n",
    "dataset_train, dataest_test = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "print(f\"train len : {len(dataset_train)}, test len : {len(dataest_test)}\")\n",
    "\n",
    "\n",
    "\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset,bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([\" \".join(dataset.iloc[i]['token'])]) for i in range(len(dataset))]\n",
    "        self.labels = [np.int32(dataset.iloc[i]['접수기관']) for i in range(len(dataset))]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n",
    "\n",
    "\n",
    "\n",
    "print('get bertmodel and vocab')\n",
    "bertmodel, vocab = get_pytorch_kobert_model()\n",
    "\n",
    "\n",
    "print(\"data setting\")\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "train_data = BERTDataset(dataset_train, tok, max_len, True, False)\n",
    "test_data = BERTDataset(dataest_test, tok, max_len, True, False)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size = batch_size, num_workers = 8)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size = batch_size, num_workers = 8)\n",
    "\n",
    "\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes = len(dataset_train['접수기관'].unique()),   ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)\n",
    "\n",
    "\n",
    "    #BERT 모델 불러오기\n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
    "\n",
    "#optimizer와 schedule 설정\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "\n",
    "#정확도 측정을 위한 함수 정의\n",
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc\n",
    "    \n",
    "train_dataloader\n",
    "\n",
    "\n",
    "print(\"Train Start\")\n",
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} / {} loss {} train acc {}\".format(e+1, batch_id+1 , len(train_dataloader), loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../result/kobert/' # google 드라이브 연동 해야함. 관련코드는 뺐음\n",
    "torch.save(model, PATH + 'KoBERT_0623_e5.pt')  # 전체 모델 저장\n",
    "torch.save(model.state_dict(), PATH + 'Kobert_0623_e5_state_dict.pt')  # 모델 객체의 state_dict 저장\n",
    "torch.save({\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict()\n",
    "}, PATH + 'all.tar') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/mglee/VSCODE/git_folder/complain_department_classification/code/.cache/kobert_v1.zip\n",
      "using cached model. /home/mglee/VSCODE/git_folder/complain_department_classification/code/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Komodel = torch.load(PATH + 'KoBERT_0623_e5.pt')  # 전체 모델을 통째로 불러옴, 클래스 선언 필수\n",
    "Komodel.load_state_dict(torch.load(PATH + 'Kobert_0623_e5_state_dict.pt'))  # state_dict를 불러 온 후, 모델에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/mglee/VSCODE/git_folder/complain_department_classification/code/.cache/kobert_v1.zip\n",
      "using cached model. /home/mglee/VSCODE/git_folder/complain_department_classification/code/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "data setting\n",
      "using cached model. /home/mglee/VSCODE/git_folder/complain_department_classification/code/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "_, dataset_Q = train_test_split(data, test_size=0.01, random_state=42)\n",
    "\n",
    "#bertmodel, vocab = get_pytorch_kobert_model()\n",
    "\n",
    "print(\"data setting\")\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "Q_data = BERTDataset(dataset_Q, tok, max_len, True, False)\n",
    "\n",
    "Q_dataloader = torch.utils.data.DataLoader(\n",
    "    Q_data, batch_size = 4, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>접수기관</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260189</th>\n",
       "      <td>[민원, 유입, 경로, 모바일, 사고, 발생, 지역, 광주, 광역시, 광산구, 쌍,...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969141</th>\n",
       "      <td>[불법, 주차, 울산, 광역시, 남구, 신정동, 부근, 신고, 위치, 안내, 지방행...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573889</th>\n",
       "      <td>[평소, 업무, 협조, 감사, 당사, 지자체, 로부터, 생활, 폐기물, 발생, 음식...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32931</th>\n",
       "      <td>[불법, 정차, 불법, 정차, 구역, 정차, 통행, 방해, 함, 상세, 위치, 설명...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739352</th>\n",
       "      <td>[민원, 유입, 경로, 모바일, 사고, 발생, 지역, 경기도, 용인시, 처인구, 역...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88065</th>\n",
       "      <td>[통행, 사진, 차, 주말, 양옆, 가운데, 주차, 사람, 통행, 불편, 끼, 기,...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359477</th>\n",
       "      <td>[장애인, 전용, 구역, 불법, 주차, 홈플러스, 장애인, 구역, 불법, 정차, 경...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887074</th>\n",
       "      <td>[민원, 유입, 경로, 모바일, 사고, 발생, 지역, 충청남도, 서천군, 장항읍, ...</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164007</th>\n",
       "      <td>[번호판, 양쪽, 검은색, 스티커, 부착, 차량]</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307658</th>\n",
       "      <td>[업무, 수고, 기본, 신도시, 기반시설, 인구, 교통, 점점, 것, 일반, 남위,...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    token  접수기관\n",
       "260189  [민원, 유입, 경로, 모바일, 사고, 발생, 지역, 광주, 광역시, 광산구, 쌍,...    37\n",
       "969141  [불법, 주차, 울산, 광역시, 남구, 신정동, 부근, 신고, 위치, 안내, 지방행...    21\n",
       "573889  [평소, 업무, 협조, 감사, 당사, 지자체, 로부터, 생활, 폐기물, 발생, 음식...    63\n",
       "32931   [불법, 정차, 불법, 정차, 구역, 정차, 통행, 방해, 함, 상세, 위치, 설명...    40\n",
       "739352  [민원, 유입, 경로, 모바일, 사고, 발생, 지역, 경기도, 용인시, 처인구, 역...    19\n",
       "...                                                   ...   ...\n",
       "88065   [통행, 사진, 차, 주말, 양옆, 가운데, 주차, 사람, 통행, 불편, 끼, 기,...    60\n",
       "359477  [장애인, 전용, 구역, 불법, 주차, 홈플러스, 장애인, 구역, 불법, 정차, 경...    40\n",
       "887074  [민원, 유입, 경로, 모바일, 사고, 발생, 지역, 충청남도, 서천군, 장항읍, ...   311\n",
       "164007                        [번호판, 양쪽, 검은색, 스티커, 부착, 차량]    85\n",
       "307658  [업무, 수고, 기본, 신도시, 기반시설, 인구, 교통, 점점, 것, 일반, 남위,...    13\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330\n"
     ]
    }
   ],
   "source": [
    "for item in Q_dataloader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2493e3d191c3448abf3be5c9075cadc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.776\n"
     ]
    }
   ],
   "source": [
    "Komodel.eval()\n",
    "test_acc = 0\n",
    "for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(Q_dataloader)):\n",
    "    token_ids = token_ids.long().to(device)\n",
    "    segment_ids = segment_ids.long().to(device)\n",
    "    valid_length= valid_length\n",
    "    label = label.long().to(device)\n",
    "    out = Komodel(token_ids, valid_length, segment_ids)\n",
    "    test_acc += calc_accuracy(out, label)\n",
    "print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('svmglee')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6f34507fa43ba317958b721fa8398d2051b96ef3f3b32ff98429c26ce06f8cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
